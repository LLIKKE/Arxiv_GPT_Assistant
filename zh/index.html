<!DOCTYPE html><html data-color-mode="light" data-light-theme="light" data-dark-theme="dark" lang="en-US"><head><title>LLIKKE/Arxiv_GPT_Assistant</title><meta charset="utf-8"><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="description" content="Deepseek based personalized ArXiv paper assistant bot"><link rel="canonical" href="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta property="og:type" content="website"><meta property="og:url" content="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:description" content="Deepseek based personalized ArXiv paper assistant bot"><meta property="og:locale" content="en_US"><meta property="og:site_name" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:description" content="Deepseek based personalized ArXiv paper assistant bot"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon.png" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon.svg" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon-dark.png" media="(prefers-color-scheme: dark)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon-dark.svg" media="(prefers-color-scheme: dark)"><link rel="mask-icon" href="https://github.githubassets.com/pinned-octocat.svg" color="#000000"><link href="index.css" rel="stylesheet"></head><body><div class="container-lg px-3 my-5 markdown-body"><div class="position-relative"><span class="profile-color-modes-toggle js-promo-color-modes-toggle" tabindex="0" aria-label="Toggle dark mode" aria-checked="true" role="checkbox"><div class="profile-color-modes-toggle-track" div></div><div class="profile-color-modes-toggle-thumb"><svg style="fill: var(--color-scale-yellow-0); margin: 7px 0 0 7px;" aria-hidden="true" width="14" height="13" viewBox="0 0 14 13" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.52208 7.71754C7.5782 7.71754 10.0557 5.24006 10.0557 2.18394C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961C9.95801 1.07727 10.3495 0.771159 10.6474 0.99992C12.1153 2.12716 13.0615 3.89999 13.0615 5.89383C13.0615 9.29958 10.3006 12.0605 6.89485 12.0605C3.95334 12.0605 1.49286 10.001 0.876728 7.24527C0.794841 6.87902 1.23668 6.65289 1.55321 6.85451C2.41106 7.40095 3.4296 7.71754 4.52208 7.71754Z"></path></svg></div></span></div><script type="text/javascript">(function() {
  var MODE_KEY = 'markdown_to_pages_dark_mode';
  function toggleMode() {
    var mode = document.documentElement.getAttribute('data-color-mode') === 'light' ? 'dark' : 'light';
    document.documentElement.setAttribute('data-color-mode', mode);
    localStorage.setItem(MODE_KEY, mode);
  }
  var mode = localStorage.getItem(MODE_KEY);
  if (mode == null) {
    var query = window.matchMedia('(prefers-color-scheme: dark)');
    mode = query.matches ? 'dark' : 'light';
  }
  document.documentElement.setAttribute('data-color-mode', mode);
  document.querySelector('.profile-color-modes-toggle').onclick = toggleMode;
})();</script><div><div class="markdown-heading"><h2 class="heading-element">PRISM：面向边缘场景的基础模型分布式推理框架</h2><a id="user-content-prism面向边缘场景的基础模型分布式推理框架" class="anchor" aria-label="Permalink: PRISM：面向边缘场景的基础模型分布式推理框架" href="#prism面向边缘场景的基础模型分布式推理框架"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2507.12145v1 公告类型：新研究<br>
摘要：基础模型（FMs）在从图像分类到自然语言处理等广泛领域取得了显著成功，但其在边缘设备上的部署仍面临重大挑战。这引发了人们对于开发实用高效策略、将基础模型引入边缘环境日益增长的兴趣。本研究提出PRISM——一种面向边缘设备分布式Transformer推理的通信高效且计算感知策略。该方法利用分段均值表示（Segment Means）来近似中间输出特征，大幅降低设备间通信开销。同时，我们重构自注意力机制以消除位置划分中因逐设备计算键/值（Key/Value）导致的冗余运算，并针对自回归模型设计了分区感知的因果掩码方案。我们在ViT、BERT和GPT-2模型上，通过CIFAR-10、CIFAR-100、ImageNet-1k、GLUE和CBT等多样化数据集进行评估。实验结果表明：在通信开销方面最高可减少99.2%（BERT模型在压缩率CR=128时），单设备计算量降低51.24%（相同配置下），而准确率仅轻微下降。该方法为资源受限的分布式环境中部署基础模型提供了可扩展的实用解决方案。</p>
<div class="markdown-heading"><h2 class="heading-element">ONNX模型选择性量化调优</h2><a id="user-content-onnx模型选择性量化调优" class="anchor" aria-label="Permalink: ONNX模型选择性量化调优" href="#onnx模型选择性量化调优"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2507.12196v1 公告类型：新研究<br>
摘要：量化是一种通过降低深度神经网络模型精度来缩减模型体积和计算需求的技术，但往往以牺牲准确率为代价。然而，完全量化模型可能导致性能低于可接受阈值，且因实际限制在低端硬件加速器上面临部署挑战。为解决这些问题，可选择仅对部分网络层进行量化，但如何筛选排除层却非易事。为此，我们提出TuneQn——一套支持选择性量化、跨CPU/GPU设备部署与执行ONNX模型的工具集，结合性能分析与多目标优化技术。TuneQn能生成选择性量化的ONNX模型，将其部署于不同硬件，测量准确率、模型大小等指标，通过帕累托前沿最小化确定最佳候选模型并可视化结果。为验证TuneQn的效能，我们在四种ONNX模型上采用两种量化配置，跨CPU/GPU设备进行评估。实验表明，该工具能有效执行选择性量化与调优：相比完全量化模型，所选候选模型的准确率损失最高降低54.14%；相较原始模型，模型体积最大缩减72.9%。</p>
</div></div><div class="footer container-xl width-full p-responsive"><div class="position-relative flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between pt-4 pb-4 mt-6 f6 color-text-secondary border-top color-border-secondary text-center"><div class="footer-octicon d-lg-block mx-lg-4"><a title="LLIKKE/Arxiv_GPT_Assistant" href="https://github.com/LLIKKE/Arxiv_GPT_Assistant" target="_blank" rel="noreferrer noopener"><svg class="octicon octicon-mark-github gh-logo" width="36" height="36" viewBox="0 0 98 98" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"></path></svg></a></div><span class="mt-2 d-block footprint"><span>powered by </span><a href="https://github.com/wranders/markdown-to-pages-action" target="_blank" rel="noreferrer noopener">markdown-to-pages-action</a></span></div></div></body></html>