<!DOCTYPE html><html data-color-mode="light" data-light-theme="light" data-dark-theme="dark" lang="en-US"><head><title>LLIKKE/Arxiv_GPT_Assistant</title><meta charset="utf-8"><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="description" content="Deepseek based personalized ArXiv paper assistant bot"><link rel="canonical" href="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta property="og:type" content="website"><meta property="og:url" content="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:description" content="Deepseek based personalized ArXiv paper assistant bot"><meta property="og:locale" content="en_US"><meta property="og:site_name" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:description" content="Deepseek based personalized ArXiv paper assistant bot"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon.png" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon.svg" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon-dark.png" media="(prefers-color-scheme: dark)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon-dark.svg" media="(prefers-color-scheme: dark)"><link rel="mask-icon" href="https://github.githubassets.com/pinned-octocat.svg" color="#000000"><link href="index.css" rel="stylesheet"></head><body><div class="container-lg px-3 my-5 markdown-body"><div class="position-relative"><span class="profile-color-modes-toggle js-promo-color-modes-toggle" tabindex="0" aria-label="Toggle dark mode" aria-checked="true" role="checkbox"><div class="profile-color-modes-toggle-track" div></div><div class="profile-color-modes-toggle-thumb"><svg style="fill: var(--color-scale-yellow-0); margin: 7px 0 0 7px;" aria-hidden="true" width="14" height="13" viewBox="0 0 14 13" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.52208 7.71754C7.5782 7.71754 10.0557 5.24006 10.0557 2.18394C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961C9.95801 1.07727 10.3495 0.771159 10.6474 0.99992C12.1153 2.12716 13.0615 3.89999 13.0615 5.89383C13.0615 9.29958 10.3006 12.0605 6.89485 12.0605C3.95334 12.0605 1.49286 10.001 0.876728 7.24527C0.794841 6.87902 1.23668 6.65289 1.55321 6.85451C2.41106 7.40095 3.4296 7.71754 4.52208 7.71754Z"></path></svg></div></span></div><script type="text/javascript">(function() {
  var MODE_KEY = 'markdown_to_pages_dark_mode';
  function toggleMode() {
    var mode = document.documentElement.getAttribute('data-color-mode') === 'light' ? 'dark' : 'light';
    document.documentElement.setAttribute('data-color-mode', mode);
    localStorage.setItem(MODE_KEY, mode);
  }
  var mode = localStorage.getItem(MODE_KEY);
  if (mode == null) {
    var query = window.matchMedia('(prefers-color-scheme: dark)');
    mode = query.matches ? 'dark' : 'light';
  }
  document.documentElement.setAttribute('data-color-mode', mode);
  document.querySelector('.profile-color-modes-toggle').onclick = toggleMode;
})();</script><div><div class="markdown-heading"><h2 class="heading-element">MERIT：面向语言模型大批次训练的最大归一化逐元素比率</h2><a id="user-content-merit面向语言模型大批次训练的最大归一化逐元素比率" class="anchor" aria-label="Permalink: MERIT：面向语言模型大批次训练的最大归一化逐元素比率" href="#merit面向语言模型大批次训练的最大归一化逐元素比率"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.20577v1 公告类型：新成果<br>
摘要：大批次训练已成为加速深度神经网络训练的重要方法，但其在优化和泛化方面仍存在挑战。现有优化器（如AdamW）在语言模型的大批次训练中出现性能下降，这是由于注意力层中最大注意力对数概率的急剧增加导致的信息瓶颈。虽然LAMB优化器部分解决了这一问题，但某些注意力层仍面临此挑战。其根源在于LAMB基于$l_2$范数的信任比率难以直接影响查询/键权重的最大值。此外，LAMB中逐权重的信任比率因忽略行列内部权重值的关联性而易产生误差。基于这些发现，我们提出新型优化器MERIT，其利用最大范数计算信任比率，从而更有效地约束最大注意力对数概率。进一步地，我们构建了逐元素信任比率，通过关注局部权重结构提供更稳健的更新缩放策略。在多种规模GPT-2模型上进行的大批次训练实验表明，MERIT具有卓越性能。值得注意的是，在GPT-2 Medium的训练中，MERIT实现了6k批次大小的训练，与标准批次大小（480）在48B训练令牌量下相比性能零衰减。本研究凸显了在大批次训练中考虑最大注意力对数概率和细粒度信任比率的重要性，成功提升了训练稳定性，为更大批次规模的应用铺平道路，从而加速大语言模型的开发与迭代。代码已开源：<a href="https://github.com/NUS-HPC-AI-Lab/MERIT%E3%80%82">https://github.com/NUS-HPC-AI-Lab/MERIT。</a></p>
<div class="markdown-heading"><h2 class="heading-element">自适应训练与展开方法实现深度与精度可扩展的自组合神经算子</h2><a id="user-content-自适应训练与展开方法实现深度与精度可扩展的自组合神经算子" class="anchor" aria-label="Permalink: 自适应训练与展开方法实现深度与精度可扩展的自组合神经算子" href="#自适应训练与展开方法实现深度与精度可扩展的自组合神经算子"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>该翻译保持了原文的技术术语准确性，同时符合中文表达习惯：</p>
<ol>
<li>"Self-Composing"译为"自组合"准确体现自我组合的数学概念</li>
<li>"Neural Operators"采用学界通用译法"神经算子"</li>
<li>"Depth and Accuracy Scaling"译为"深度与精度可扩展"准确传达原文的维度扩展含义</li>
<li>"Adaptive Train-and-Unroll Approach"译为"自适应训练与展开方法"既保留技术特征又符合中文动宾结构</li>
<li>通过"实现...可扩展的..."的句式连接，使整个标题在中文语境下保持技术文档的严谨性</li>
</ol>
<p>arXiv:2508.20650v1 公告类型：新成果<br>
摘要：本研究提出了一种通过自组合增强神经算子效率与精度的创新框架，兼具理论保证与实践优势。受数值偏微分方程（PDE）迭代求解方法的启发，我们通过重复应用单一神经算子块构建特定神经算子，在不显式增加新模块的情况下逐步深化模型，从而提升模型容量。为高效训练这些模型，我们引入自适应训练与展开策略——在训练过程中逐渐增加神经算子的深度。该方法揭示了模型精度随深度变化的缩放规律，并通过自适应训练策略实现显著的计算节约。我们的架构在标准基准测试中达到了最先进（SOTA）性能，并在具有挑战性的高频超声计算机断层成像（USCT）问题上验证了其有效性：采用多网格启发式主干网络的结构在解析复杂波动现象方面展现出卓越性能。该框架为大规模数据驱动的科学机器学习应用提供了计算可行、精确且可扩展的解决方案。</p>
<div class="markdown-heading"><h2 class="heading-element">将表格基础模型转化为图基础模型</h2><a id="user-content-将表格基础模型转化为图基础模型" class="anchor" aria-label="Permalink: 将表格基础模型转化为图基础模型" href="#将表格基础模型转化为图基础模型"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.20906v1 公告类型：新成果<br>
摘要：尽管基础模型已彻底变革自然语言处理与计算机视觉等领域，但其在图机器学习中的应用潜力仍待深入探索。设计图基础模型（GFM）的核心挑战之一在于如何处理不同图数据集中可能存在的多样化节点特征。虽然现有GFM研究多集中于文本属性图，但如何处理其他类型的任意特征这一问题尚未得到完全解决。这一挑战并非图领域独有，在表格数据的机器学习领域同样存在。受TabPFNv2等表格基础模型近期成功的启发，本研究提出G2T-FM——一种以TabPFNv2为骨干网络的简洁图基础模型。具体而言，G2T-FM通过邻域特征聚合增强原始节点特征，添加结构嵌入，再将构建的节点表征输入TabPFNv2进行处理。即使在完全上下文学习设定下，本模型仍取得强劲性能：显著优于现有公开GFM，并与经过充分调优的从头训练GNN模型表现相当。经微调后，G2T-FM进一步超越精调GNN基线，彰显了所提方法的潜力。更广泛而言，本文揭示了利用表格基础模型处理图机器学习任务这一既往被忽视的研究方向。</p>
<div class="markdown-heading"><h2 class="heading-element">教师校准在知识蒸馏中的作用</h2><a id="user-content-教师校准在知识蒸馏中的作用" class="anchor" aria-label="Permalink: 教师校准在知识蒸馏中的作用" href="#教师校准在知识蒸馏中的作用"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.20224v1 公告类型：新研究<br>
摘要：知识蒸馏（KD）已成为深度学习领域有效的模型压缩技术，能够将大型教师模型的知识迁移至紧凑型学生模型。尽管KD已取得显著成功，但学界尚未完全理解哪些因素有助于提升学生模型的性能。本文揭示了教师模型的校准误差与学生模型精度之间存在强相关性，由此提出教师模型的校准是影响KD效果的关键因素。进一步地，我们证明通过简单采用降低教师模型校准误差的校准方法，即可有效提升KD性能。该算法具有通用性，在从分类到检测的多种任务中均展现显著效果，且能轻松集成到现有先进方法中，持续获得更优的性能表现。</p>
<div class="markdown-heading"><h2 class="heading-element">DFAMS：基于动态流引导的联邦对齐多原型搜索</h2><a id="user-content-dfams基于动态流引导的联邦对齐多原型搜索" class="anchor" aria-label="Permalink: DFAMS：基于动态流引导的联邦对齐多原型搜索" href="#dfams基于动态流引导的联邦对齐多原型搜索"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.20353v1 公告类型：新研究<br>
摘要：联邦检索（FR）通过跨多个外部知识源路由查询，在必要的外部知识分散时缓解大语言模型（LLM）的幻觉问题。然而，现有方法难以针对模糊查询检索高质量相关文档，尤其在跨域场景下，这显著限制了其支持下游生成任务的效果。受动态信息流（DIF）启发，我们提出DFAMS框架——该创新方案利用DIF识别潜在查询意图，并构建语义对齐的知识分区以实现跨异构源的精准检索。具体而言，DFAMS通过少量标注查询的梯度信号探测LLM中的DIF，采用基于沙普利值的归因方法追踪与意图识别及子域边界检测相关的神经元激活路径。随后，DFAMS借助DIF通过多原型对比学习训练对齐模块，实现知识库内细粒度建模与跨库语义对齐。在五个基准测试上的实验表明，DFAMS在知识分类准确率上最高超越先进FR方法14.37%，检索召回率提升5.38%，下游问答准确率提高6.45%，证明了其在复杂联邦检索场景中的有效性。</p>
<div class="markdown-heading"><h2 class="heading-element">通过回归视角对调查数据可信度进行维度无关测试</h2><a id="user-content-通过回归视角对调查数据可信度进行维度无关测试" class="anchor" aria-label="Permalink: 通过回归视角对调查数据可信度进行维度无关测试" href="#通过回归视角对调查数据可信度进行维度无关测试"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.20616v1 公告类型：新研究<br>
摘要：评估抽样调查是否真实反映总体特征，是确保下游研究有效性的关键问题。该问题通常可归结为估计两个高维分布之间的距离，而这一过程往往需要样本量随维度呈指数级增长。然而，根据数据分析所采用的模型，从数据中得出的结论在不同底层分布间可能保持一致。基于此，我们提出一种基于任务的抽样调查可信度评估方法，特别引入了一种模型特异性距离度量来量化这种可信度概念。我们还设计了一种算法，用于在回归模型背景下验证调查数据的可信度。值得注意的是，该算法的样本复杂度与数据维度无关——这种高效性源于算法专注于验证调查数据可信度而非重建底层回归模型的特点。进一步研究表明，若试图通过重建回归模型来验证可信度，其样本复杂度将随数据维度线性增长。我们通过理论证明验证了算法的正确性，并通过数值实验展示了算法的实际性能。</p>
<div class="markdown-heading"><h2 class="heading-element">ATM-GAD：面向金融交易网络的自适应时序模式图异常检测系统</h2><a id="user-content-atm-gad面向金融交易网络的自适应时序模式图异常检测系统" class="anchor" aria-label="Permalink: ATM-GAD：面向金融交易网络的自适应时序模式图异常检测系统" href="#atm-gad面向金融交易网络的自适应时序模式图异常检测系统"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>（注：翻译采用技术文献常用命名规范，其中：</p>
<ul>
<li>"Adaptive"译为"自适应"体现算法动态调整特性</li>
<li>"Temporal Motif"译为"时序模式"准确表达时间序列中的特定模式概念</li>
<li>"Graph Anomaly Detection"采用"图异常检测"这一领域标准译法</li>
<li>补充"系统"二字使技术名称更符合中文语境下的完整表述）</li>
</ul>
<p>arXiv:2508.20829v1 公告类型：新成果<br>
摘要：金融欺诈检测对保障数十亿美元资金安全至关重要，但现代金融系统中错综复杂的实体关系和快速变化的交易行为常常使传统机器学习模型失效。近期基于图谱的检测器通过将交易表示为网络取得进展，但仍忽略了两个根植于时间维度的欺诈特征：(1) 时间 motif（时序模式）——在资金流动过程中揭示可疑模式的重复性特征子图；(2) 账户特异性异常活动区间——欺诈行为仅以每个实体特有的短时爆发形式显现。为同时利用这两种信号，我们提出ATM-GAD自适应图神经网络，利用时序模式进行金融异常检测。时序模式提取器将每个账户的交易历史压缩为信息最丰富的模式单元，同时保留拓扑结构和时间特征。这些模式单元通过双注意力模块进行分析：IntraA（内部注意力）解析单个模式单元内的交互，而InterA（跨模式注意力）聚合跨模式证据以揭示多步欺诈方案。并行运作的可微分自适应时间窗学习器为每个节点定制观察窗口，使模型能精准聚焦于最具揭示性的时间片段。在四个真实数据集上的实验表明，ATM-GAD持续优于七个强基准异常检测方法，能发现以往方法遗漏的欺诈模式。</p>
<div class="markdown-heading"><h2 class="heading-element">GPT-FT：基于GPT的高效自动化特征转换技术——实现序列重构与性能提升</h2><a id="user-content-gpt-ft基于gpt的高效自动化特征转换技术实现序列重构与性能提升" class="anchor" aria-label="Permalink: GPT-FT：基于GPT的高效自动化特征转换技术——实现序列重构与性能提升" href="#gpt-ft基于gpt的高效自动化特征转换技术实现序列重构与性能提升"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.20824v1 公告类型：新研究<br>
摘要：特征变换通过优化数据表示对提升机器学习模型性能具有关键作用。当前最先进的方法将此项任务视为连续嵌入优化问题，将离散搜索转化为可学习过程。尽管有效，这些方法通常依赖顺序编码器-解码器结构，导致高计算成本和参数需求，限制了可扩展性与效率。为解决这些局限性，我们提出一个新颖框架，通过四个步骤实现自动化特征变换：变换记录收集、基于改进型生成式预训练变换器（GPT）构建嵌入空间、梯度上升搜索以及自回归重构。在我们的方法中，改进型GPT模型承担两个主要功能：(a) 特征变换序列重构；(b) 通过构建嵌入空间进行下游任务的模型性能评估与增强。这种多目标优化框架减少了参数量并加速变换过程。在基准数据集上的实验结果表明，所提框架达到或超越基线性能，并显著提升计算效率。此项工作凸显了基于变换器的架构在可扩展、高性能自动化特征变换方面的潜力。</p>
<div class="markdown-heading"><h2 class="heading-element">Re4：具备重写、解析、评审与修订功能的科学计算代理</h2><a id="user-content-re4具备重写解析评审与修订功能的科学计算代理" class="anchor" aria-label="Permalink: Re4：具备重写、解析、评审与修订功能的科学计算代理" href="#re4具备重写解析评审与修订功能的科学计算代理"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.20729v1 公告类型：新成果<br>
摘要：大语言模型（LLMs）作为生成式人工智能中活跃且前景广阔的领域，已在数学与科学推理等多个领域展现出执行复杂任务的能力。本研究构建了一种新颖的智能体框架，用于解决科学计算中的典型问题。该框架通过三个推理型LLM（分别担任顾问、评审员和程序员角色）以"重写-解析-评审-修正"的逻辑链进行协同交互：顾问模块赋予智能体知识迁移能力，将问题与专业领域洞察相连接，通过文本增强重写问题描述；程序员模块负责生成并执行结构良好的代码以实现问题求解；评审模块通过与代码运行时输出的交互反馈，使智能体具备自我调试与优化能力。借助端到端评审机制，程序员提供的可执行代码得以迭代完善。我们对该框架在求解偏微分方程、病态线性系统和数据驱动的物理分析问题中的表现进行了全面评估。与单模型相比，该协同框架显著提高了无缺陷代码生成率，减少了非物理解的产生，从而建立了基于自然语言描述的高度可靠的自主代码生成框架。评审机制将最新推理模型的平均执行成功率（无缺陷代码且无非NaN解）提升了17.6%。该框架为自动代码生成与评审确立了极具前景的科学计算新范式。</p>
<div class="markdown-heading"><h2 class="heading-element">学习原始具身世界模型：迈向可扩展的机器人学习</h2><a id="user-content-学习原始具身世界模型迈向可扩展的机器人学习" class="anchor" aria-label="Permalink: 学习原始具身世界模型：迈向可扩展的机器人学习" href="#学习原始具身世界模型迈向可扩展的机器人学习"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.20840v1 公告类型：新研究<br>
摘要：尽管基于视频生成的具身世界模型日益受到关注，但其对大规模具身交互数据的依赖仍是关键瓶颈。具身数据的稀缺性、采集难度及高维特性从根本上限制了语言与动作之间的对齐粒度，并加剧了长时序视频生成的挑战——阻碍生成式模型在具身领域实现"GPT时刻"。我们提出一个朴素观察：具身数据的多样性远超相对有限的原始动作空间。基于此，我们提出一种新颖的世界建模范式——原始具身世界模型（PEWM）。通过将视频生成限制在固定短时序内，我们的方法能够：1）实现语言概念与机器人动作视觉表征的细粒度对齐；2）降低学习复杂度；3）提高具身数据收集效率；4）减少推理延迟。通过配备模块化视觉语言模型（VLM）规划器和起止热图引导机制（SGG），PEWM进一步实现灵活闭环控制，并支持原始级策略在长周期复杂任务中的组合泛化。该框架利用视频模型的时空视觉先验和VLM的语义感知能力，弥合细粒度物理交互与高层推理之间的鸿沟，为构建可扩展、可解释、通用型的具身智能铺平道路。</p>
<div class="markdown-heading"><h2 class="heading-element">潜在变量建模在稳健因果效应估计中的应用</h2><a id="user-content-潜在变量建模在稳健因果效应估计中的应用" class="anchor" aria-label="Permalink: 潜在变量建模在稳健因果效应估计中的应用" href="#潜在变量建模在稳健因果效应估计中的应用"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.20259v1 公告类型：新研究<br>
摘要：潜变量模型为观测数据中不可观测因素的纳入与推断提供了强大框架。在因果推断中，该模型有助于解释影响处理变量或结果变量的隐藏因素，从而应对缺失或未测量协变量带来的挑战。本文提出一个新框架，将潜变量建模与双重机器学习（DML）范式相结合，旨在存在此类隐藏因素的情况下实现稳健的因果效应估计。我们考虑两种场景：一是潜变量仅影响结果变量，二是潜变量可能同时影响处理变量和结果变量。为保持计算可行性，我们仅在DML的第二阶段引入潜变量，将表示学习与潜变量推断分离。通过大量合成数据集和真实数据集的实验，我们验证了所提方法的鲁棒性与有效性。</p>
<div class="markdown-heading"><h2 class="heading-element">重新思考Transformer连接性：TLinFormer，通往精确、全上下文感知线性注意力的路径</h2><a id="user-content-重新思考transformer连接性tlinformer通往精确全上下文感知线性注意力的路径" class="anchor" aria-label="Permalink: 重新思考Transformer连接性：TLinFormer，通往精确、全上下文感知线性注意力的路径" href="#重新思考transformer连接性tlinformer通往精确全上下文感知线性注意力的路径"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.20407v1 公告类型：新论文<br>
摘要：Transformer架构已成为现代人工智能的基石，但其核心自注意力机制存在随序列长度呈二次方增长的计算复杂度瓶颈，严重限制了其在长序列任务中的应用。为应对这一挑战，现有线性注意力方法通常依赖与数据无关的核近似或受限的上下文选择，导致模型性能下降。本文回归连接主义的第一性原理，从信息流的拓扑结构出发，提出了一种新型线性注意力架构——\textbf{TLinFormer}。通过重构神经元连接模式，TLinFormer在保持精确注意力分数计算、确保信息流完整感知历史上下文的同时，实现了严格的线性复杂度。该设计旨在弥合现有高效注意力方法与标准注意力之间的性能差距。通过系列实验，我们系统评估了TLinFormer在长序列推理任务中相对标准Transformer基线的性能表现。结果表明，TLinFormer在\textbf{推理延迟}、\textbf{KV缓存效率}、\textbf{内存占用}和\textbf{整体加速比}等关键指标上展现出压倒性优势。</p>
<div class="markdown-heading"><h2 class="heading-element">高效神经符号约束与目标学习</h2><a id="user-content-高效神经符号约束与目标学习" class="anchor" aria-label="Permalink: 高效神经符号约束与目标学习" href="#高效神经符号约束与目标学习"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.20978v1 公告类型：新成果<br>
摘要：在持续探索将离散推理与神经网络融合的过程中，研究者日益关注能够从自然输入中学习解决离散推理或优化问题的神经架构——这一任务正是大型语言模型所面临的挑战。<br>
研究目标：我们提出一种可微分的神经符号架构及专用损失函数，用于学习解决NP难推理问题。<br>
方法：新型概率损失函数可同步学习约束条件与目标函数，从而构建出可被详细检验并能通过附加约束完善的完整模型。通过将组合求解器移出训练循环，该架构在实现可扩展训练的同时，通过精确推理达到最高精度。<br>
结果：实证研究表明，该架构能高效学习从自然输入解决NP难推理问题。在数独基准测试的三个变体（符号型、视觉型和多解型）中，本方法仅需其他混合方法训练时间的零头即可完成。在视觉最小割/最大割任务中，其优化效果优于专注遗憾最小化的决策聚焦学习损失函数。最终，该方法成功学习了蛋白质设计这一大型现实世界问题的能量优化公式。</p>
<div class="markdown-heading"><h2 class="heading-element">令牌打包器：保护大语言模型免受有害强化学习微调的影响</h2><a id="user-content-令牌打包器保护大语言模型免受有害强化学习微调的影响" class="anchor" aria-label="Permalink: 令牌打包器：保护大语言模型免受有害强化学习微调的影响" href="#令牌打包器保护大语言模型免受有害强化学习微调的影响"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.20697v1 公告类型：新研究<br>
摘要：随着大语言模型（LLM）能力持续增强，通过微调进行恶意滥用的风险也日益加剧。虽然现有研究多假设攻击者依赖监督微调（SFT）实施滥用，但我们系统性地证明：在同等计算预算下，强化学习（RL）能使攻击者更有效地突破安全对齐机制，为高级恶意任务提供助力。为应对这一新兴威胁，我们提出首个专门针对基于RL的恶意微调的有效防御方案——TokenBuncher。该方案通过抑制模型响应不确定性（RL依赖的核心基础）实现防御：通过约束不确定性，基于RL的微调无法再利用差异化奖励信号驱动模型实施恶意行为。我们通过熵奖励RL算法与Token噪声注入机制实现这一防御，后者可防止专业领域恶意能力的升级。在多模型和多RL算法的广泛实验中，TokenBuncher能稳健抵御恶意RL微调，同时保持良性任务效用与可微调性。研究结果表明：基于RL的恶意微调比SFT具有更大的系统性风险，而TokenBuncher提供了有效且通用的防御方案。</p>
<div class="markdown-heading"><h2 class="heading-element">单智能体鲁棒深度强化学习在公交车辆调度控制中的应用</h2><a id="user-content-单智能体鲁棒深度强化学习在公交车辆调度控制中的应用" class="anchor" aria-label="Permalink: 单智能体鲁棒深度强化学习在公交车辆调度控制中的应用" href="#单智能体鲁棒深度强化学习在公交车辆调度控制中的应用"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.20784v1 公告类型：新研究<br>
摘要：由于随机交通流量和乘客需求的波动，公交串车问题始终是城市公共交通面临的挑战。传统解决方案多依赖于环线场景下的多智能体强化学习（MARL），但这种方法忽略了现实运营中存在的异构线路、时刻表、需求波动及可变车队规模等特征。我们提出了一种新颖的单智能体强化学习（RL）框架用于公交驻站控制，该框架在近现实仿真环境下避免了MARL存在的数据不平衡和收敛性问题。通过构建具有动态乘客需求的双向时刻表网络，核心创新在于将多智能体问题重构为单智能体问题——在数值特征（车头时距、载客量、速度）基础上，通过增加分类标识符（车辆ID、站点ID、时段）扩展状态空间。这种高维编码使单智能体策略能够捕捉智能体间的相互依赖关系，类似于将不可分离的输入投射到更高维空间。我们进一步设计了符合运营目标的结构化奖励函数：采用脊形奖励函数平衡均匀车头时距与时刻表遵循度，取代了对车头时距偏差的指数惩罚。实验表明，改进的软演员-评论家（SAC）算法相比基准方法（如在随机条件下-43万对比-53万的奖励值）实现了更稳定优异的性能。这些结果证明，通过分类结构化和时刻表感知奖励增强的单智能体深度RL，能够有效管理非环线现实场景中的公交驻站控制。该范式为MARL框架提供了更鲁棒、可扩展的替代方案，尤其在智能体特定经验不平衡的场景中具有显著优势。</p>
<div class="markdown-heading"><h2 class="heading-element">基于轨迹的核心集：通过损失差异相关性选择数据</h2><a id="user-content-基于轨迹的核心集通过损失差异相关性选择数据" class="anchor" aria-label="Permalink: 基于轨迹的核心集：通过损失差异相关性选择数据" href="#基于轨迹的核心集通过损失差异相关性选择数据"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.20230v1 公告类型：新成果<br>
摘要：深度学习模型虽在各领域实现顶尖性能，但在实时或资源受限场景下面临可扩展性挑战。为此，我们提出损失差异相关性（CLD）——一种简单可扩展的核心集选择指标，通过衡量训练样本与预留验证集损失轨迹的匹配度，识别最具影响力的训练样本。CLD具有极高效率，仅需利用训练检查点计算的单样本损失值，避免了现有多数子集选择方法中耗时的梯度与曲率计算。我们建立了通用理论框架，为基于CLD的核心集提供收敛性保证，证明其收敛误差上界取决于所选样本的匹配度与验证集的代表性。在CIFAR-100和ImageNet-1k数据集上，基于CLD的核心集在不同子集规模下通常优于或接近最先进方法，即使未领先时也与计算成本更高的基线保持1%以内的差距。CLD能有效跨架构迁移（ResNet、VGG、DenseNet），实现代理到目标的选择且性能衰减小于1%。此外，CLD仅使用早期检查点时仍保持稳定，准确率损失可忽略不计。最后，CLD通过每类验证对齐实现内在偏差削减，无需额外分层抽样。这些特性使CLD成为可扩展数据集优化的原理清晰、高效稳定、可迁移的工具。</p>
<div class="markdown-heading"><h2 class="heading-element">VarDiU：一步扩散蒸馏的变分扩散上界</h2><a id="user-content-vardiu一步扩散蒸馏的变分扩散上界" class="anchor" aria-label="Permalink: VarDiU：一步扩散蒸馏的变分扩散上界" href="#vardiu一步扩散蒸馏的变分扩散上界"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.20646v1 公告类型：新成果<br>
摘要：近期，扩散蒸馏方法成功将千步级别的教师扩散模型压缩为单步生成的学生模型，同时保持了样本质量。现有方法大多通过扩散散度训练学生模型，其梯度需借助学生模型的评分函数进行近似（该函数通过去噪评分匹配学习获得）。由于去噪评分匹配训练存在固有缺陷，所得梯度估计不可避免地存在偏差，导致性能未达最优。本文提出VarDiU（发音为/va:rdju:/），即变分扩散上界法，该方法采用无偏梯度估计器，可直接应用于扩散蒸馏。通过该目标函数，我们将本方法与Diff-Instruct进行对比实验，证明其不仅能获得更优的生成质量，还能为单步扩散蒸馏提供更高效稳定的训练流程。</p>
<div class="markdown-heading"><h2 class="heading-element">基于强化学习引导的扩散模型在推理阶段的对齐控制</h2><a id="user-content-基于强化学习引导的扩散模型在推理阶段的对齐控制" class="anchor" aria-label="Permalink: 基于强化学习引导的扩散模型在推理阶段的对齐控制" href="#基于强化学习引导的扩散模型在推理阶段的对齐控制"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.21016v1 公告类型：新成果<br>
摘要：基于去噪的生成模型，特别是扩散模型与流匹配算法，已取得显著成功。然而，使其输出分布与复杂下游目标（如人类偏好、组合准确性或数据可压缩性）保持一致仍具挑战性。尽管受大型语言模型人类反馈强化学习（RLHF）进展启发，强化学习（RL）微调方法已被适配到这些生成框架中，但现有RL方法对扩散模型并非最优解，且在微调后对对齐强度的控制灵活性有限。本研究通过随机微分方程和隐式奖励条件的新视角，重新阐释扩散模型的RL微调。我们提出强化学习引导（RLG）——一种推理时方法，通过几何平均结合基础模型与RL微调模型的输出，适配无分类器引导（CFG）机制。理论分析表明，RLG的引导尺度在数学上等效于调节标准RL目标中的KL正则化系数，无需额外训练即可动态控制对齐-质量权衡。大量实验证明，RLG在不同架构、RL算法和下游任务（包括人类偏好、组合控制、可压缩性和文本渲染）中持续提升RL微调模型的性能。此外，RLG支持内插和外推操作，从而为生成式对齐控制提供前所未有的灵活性。我们的方法为推理时增强和控制扩散模型对齐提供了实用且理论可靠的解决方案。RLG源代码已公开于Github：<a href="https://github.com/jinluo12345/Reinforcement-learning-guidance%E3%80%82">https://github.com/jinluo12345/Reinforcement-learning-guidance。</a></p>
<div class="markdown-heading"><h2 class="heading-element">从变压器中的信号与系统我们能学到什么？概率建模与推理架构的启示</h2><a id="user-content-从变压器中的信号与系统我们能学到什么概率建模与推理架构的启示" class="anchor" aria-label="Permalink: 从变压器中的信号与系统我们能学到什么？概率建模与推理架构的启示" href="#从变压器中的信号与系统我们能学到什么概率建模与推理架构的启示"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.20211v1 公告类型：新成果<br>
摘要：二十世纪四十年代，维纳提出了一种线性预测器，其通过线性组合历史数据来计算未来预测值。而Transformer则对这一理念进行了推广：它是一种非线性预测器，通过非线性组合历史标记（tokens）来计算下一个标记的预测。本文提出一个概率模型，将Transformer信号解释为条件测度的代理变量，并将层级操作视为不动点更新。针对概率模型为隐马尔可夫模型（HMM）的特殊情况，我们描述了不动点更新的显式形式。本文部分旨在尝试搭建经典非线性滤波理论与现代推理架构之间的桥梁。</p>
<div class="markdown-heading"><h2 class="heading-element">FORGE：基于图嵌入的基础优化表示</h2><a id="user-content-forge基于图嵌入的基础优化表示" class="anchor" aria-label="Permalink: FORGE：基于图嵌入的基础优化表示" href="#forge基于图嵌入的基础优化表示"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.20330v1 公告类型：新成果<br>
摘要：组合优化问题在科学与工程领域无处不在，但基于学习的加速求解方法通常需要解决大量难解优化实例以收集训练数据，导致显著的计算开销。现有方法需为每个下游任务针对不同问题分布训练专用模型，严重限制了其可扩展性与泛化能力。本研究提出Forge方法，通过无监督方式在大量多样化混合整数规划（MIP）实例集合上预训练向量量化图自编码器，且不依赖于问题解。向量量化过程生成的离散代码分配可作为表示优化实例的词汇表。我们在监督与无监督两种设置下评估该方法：在无监督场景中，Forge嵌入能有效区分和聚类未见过的实例；在监督场景中，通过微调Forge嵌入，单一模型即可预测变量（用于热启动）和整性间隙（用于割生成），且跨多种问题类型分布均适用。两类预测均有助于提升顶尖商业优化求解器的性能。最后，我们在<a href="https://github.com/skadio/forge/%E5%BC%80%E6%BA%90%E4%BB%A3%E7%A0%81%E4%B8%8E%E9%A2%84%E8%AE%AD%E7%BB%83%E6%9D%83%E9%87%8D%EF%BC%8C%E4%BB%A5%E4%BF%83%E8%BF%9B%E5%AE%9E%E4%BE%8B%E7%BA%A7MIP%E5%B5%8C%E5%85%A5%E7%9A%84%E8%BF%9B%E4%B8%80%E6%AD%A5%E7%A0%94%E7%A9%B6%E4%B8%8E%E5%AE%9E%E8%B7%B5%E5%BA%94%E7%94%A8%E3%80%82">https://github.com/skadio/forge/开源代码与预训练权重，以促进实例级MIP嵌入的进一步研究与实践应用。</a></p>
<div class="markdown-heading"><h2 class="heading-element">信标：集成网格选择的训练后量化技术</h2><a id="user-content-信标集成网格选择的训练后量化技术" class="anchor" aria-label="Permalink: 信标：集成网格选择的训练后量化技术" href="#信标集成网格选择的训练后量化技术"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>（注：此处"Beacon"作为专有技术名称保留音译"信标"，同时通过冒号明确其技术属性，后半部分采用技术文档常见的四字格结构"集成网格选择"保持专业感，"训练后量化技术"准确传达"Post-Training Quantization"的核心概念并符合中文技术术语习惯。）</p>
<p>arXiv:2508.20293v1 公告类型：新成果<br>
摘要：量化作为一种广泛应用的压缩技术，能有效降低大型预训练模型的内存与计算成本。在逐通道训练后量化（PTQ）中，核心挑战在于如何选择合适的缩放因子，将权重值替换为缩放量化网格中的对应值。现有方法通常通过启发式调优或网格搜索预先固定缩放比例。本文提出Beacon算法——一种简单有效的解决方案，无需人工调优即可实现量化。该算法直接使用固定的非缩放字母表执行逐通道PTQ，并通过利用对称标量量化的几何特性自动确定最优缩放因子。仅需最小改动即可同时支持对称与非对称量化，且不依赖反向传播或大型校准集。尽管方法简单且无需调参，Beacon仍能达到与最先进方法相媲美的性能，为高效模型部署提供了实用解决方案。</p>
<div class="markdown-heading"><h2 class="heading-element">BiListing：房源信息的多模态对齐</h2><a id="user-content-bilisting房源信息的多模态对齐" class="anchor" aria-label="Permalink: BiListing：房源信息的多模态对齐" href="#bilisting房源信息的多模态对齐"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.20396v1 公告类型：新研究<br>
摘要：爱彼迎（Airbnb）作为旅行住宿领域的领导者，由于从文本和图像中提取有效信息存在能力限制及相应复杂性，历来依赖结构化数据来理解、排序和向用户推荐房源。随着表示学习技术的兴起，利用文本和照片中的丰富信息变得更为便捷。主流方法是通过生成文本文档和图像的嵌入向量，实现房源相似度计算或将嵌入向量作为机器学习模型特征等应用场景。</p>
<p>然而，爱彼迎房源包含多样化的非结构化数据：多张图片、标题、描述和评论等多种非结构化文本文档，这使得单一嵌入方法面临挑战。特别是如何整合不同信息的多个嵌入向量以形成统一表征，成为一项重要课题。</p>
<p>本文提出双模态房源表征模型BiListing（Bimodal Listing），通过利用大语言模型和预训练语言-图像模型，实现对房源文本与照片的跨模态对齐。该方法具有多重优势：将非结构化数据压缩为每个房源的单模态嵌入向量；支持用户友好语义下的零样本库存高效搜索；克服冷启动问题；支持基于单一模态或双模态的房源间相似搜索。</p>
<p>我们通过离线与在线测试，将BiListing嵌入向量应用于爱彼迎搜索排序模型，并成功实现生产环境部署，取得NDCG指标0.425%的提升，创造数千万美元的增量收入。</p>
<div class="markdown-heading"><h2 class="heading-element">AI-SearchPlanner：通过帕累托最优多目标强化学习实现模块化智能搜索</h2><a id="user-content-ai-searchplanner通过帕累托最优多目标强化学习实现模块化智能搜索" class="anchor" aria-label="Permalink: AI-SearchPlanner：通过帕累托最优多目标强化学习实现模块化智能搜索" href="#ai-searchplanner通过帕累托最优多目标强化学习实现模块化智能搜索"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.20368v1 公告类型：新研究<br>
摘要：近期研究探索将大语言模型（LLMs）与搜索引擎结合，以同时利用LLMs内部预训练知识与外部信息。特别值得注意的是，强化学习（RL）已成为通过多轮搜索引擎交互增强LLM推理能力的重要范式。然而，现有基于RL的搜索代理依赖单一LLM以端到端方式同时处理搜索规划与问答（QA）任务，这限制了二者能力的同步优化。实际应用中，成熟的AI搜索系统通常采用大型冻结LLM（如GPT-4、DeepSeek-R1）来保证高质量QA。因此，更高效的方法是使用专用于搜索规划的小型可训练LLM。本文提出<strong>AI-SearchPlanner</strong>——一种新颖的强化学习框架，通过聚焦搜索规划来提升冻结QA模型的性能。具体而言，我们引入三大创新：1）搜索规划器与生成器的架构解耦，2）面向搜索规划的双重奖励对齐机制，3）规划效用与成本的帕累托优化，以实现目标。在真实数据集上的大量实验表明，AI-SearchPlanner在效能与效率上均优于现有基于RL的搜索代理，并在不同冻结QA模型和数据领域展现出强大的泛化能力。</p>
</div></div><div class="footer container-xl width-full p-responsive"><div class="position-relative flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between pt-4 pb-4 mt-6 f6 color-text-secondary border-top color-border-secondary text-center"><div class="footer-octicon d-lg-block mx-lg-4"><a title="LLIKKE/Arxiv_GPT_Assistant" href="https://github.com/LLIKKE/Arxiv_GPT_Assistant" target="_blank" rel="noreferrer noopener"><svg class="octicon octicon-mark-github gh-logo" width="36" height="36" viewBox="0 0 98 98" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"></path></svg></a></div><span class="mt-2 d-block footprint"><span>powered by </span><a href="https://github.com/wranders/markdown-to-pages-action" target="_blank" rel="noreferrer noopener">markdown-to-pages-action</a></span></div></div></body></html>