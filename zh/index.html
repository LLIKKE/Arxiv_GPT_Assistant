<!DOCTYPE html><html data-color-mode="light" data-light-theme="light" data-dark-theme="dark" lang="en-US"><head><title>LLIKKE/Arxiv_GPT_Assistant</title><meta charset="utf-8"><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="description" content="Deepseek based personalized ArXiv paper assistant bot"><link rel="canonical" href="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta property="og:type" content="website"><meta property="og:url" content="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:description" content="Deepseek based personalized ArXiv paper assistant bot"><meta property="og:locale" content="en_US"><meta property="og:site_name" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:description" content="Deepseek based personalized ArXiv paper assistant bot"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon.png" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon.svg" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon-dark.png" media="(prefers-color-scheme: dark)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon-dark.svg" media="(prefers-color-scheme: dark)"><link rel="mask-icon" href="https://github.githubassets.com/pinned-octocat.svg" color="#000000"><link href="index.css" rel="stylesheet"></head><body><div class="container-lg px-3 my-5 markdown-body"><div class="position-relative"><span class="profile-color-modes-toggle js-promo-color-modes-toggle" tabindex="0" aria-label="Toggle dark mode" aria-checked="true" role="checkbox"><div class="profile-color-modes-toggle-track" div></div><div class="profile-color-modes-toggle-thumb"><svg style="fill: var(--color-scale-yellow-0); margin: 7px 0 0 7px;" aria-hidden="true" width="14" height="13" viewBox="0 0 14 13" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.52208 7.71754C7.5782 7.71754 10.0557 5.24006 10.0557 2.18394C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961C9.95801 1.07727 10.3495 0.771159 10.6474 0.99992C12.1153 2.12716 13.0615 3.89999 13.0615 5.89383C13.0615 9.29958 10.3006 12.0605 6.89485 12.0605C3.95334 12.0605 1.49286 10.001 0.876728 7.24527C0.794841 6.87902 1.23668 6.65289 1.55321 6.85451C2.41106 7.40095 3.4296 7.71754 4.52208 7.71754Z"></path></svg></div></span></div><script type="text/javascript">(function() {
  var MODE_KEY = 'markdown_to_pages_dark_mode';
  function toggleMode() {
    var mode = document.documentElement.getAttribute('data-color-mode') === 'light' ? 'dark' : 'light';
    document.documentElement.setAttribute('data-color-mode', mode);
    localStorage.setItem(MODE_KEY, mode);
  }
  var mode = localStorage.getItem(MODE_KEY);
  if (mode == null) {
    var query = window.matchMedia('(prefers-color-scheme: dark)');
    mode = query.matches ? 'dark' : 'light';
  }
  document.documentElement.setAttribute('data-color-mode', mode);
  document.querySelector('.profile-color-modes-toggle').onclick = toggleMode;
})();</script><div><div class="markdown-heading"><h2 class="heading-element">MergeQuant：通过通道校准实现大型语言模型的精确4位静态量化</h2><a id="user-content-mergequant通过通道校准实现大型语言模型的精确4位静态量化" class="anchor" aria-label="Permalink: MergeQuant：通过通道校准实现大型语言模型的精确4位静态量化" href="#mergequant通过通道校准实现大型语言模型的精确4位静态量化"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2503.07654v1 公告类型：新研究  摘要：量化技术已被广泛用于压缩和加速大型语言模型（LLMs）的推理过程。现有方法主要探索基于每个令牌的动态校准，以确保在4位量化下既能实现推理加速又能保持模型精度。然而，在长序列的自回归生成推理中，重复的动态量化和反量化步骤的开销变得相当高昂。本研究中，我们提出了MergeQuant，一种精确且高效的每通道静态量化框架。MergeQuant通过量化步骤迁移（QSM）方法，将每通道的量化步骤与相应的缩放和线性映射整合，从而消除了矩阵乘法前后的量化开销。此外，鉴于不同通道范围间的显著差异，我们提出了维度重构和自适应裁剪，以解决量化比例因子的非均匀性问题，并将通道变化重新分配到后续模块，以在QSM下平衡参数分布。在W4A4的静态量化设置下，MergeQuant将Llama-2-70B模型在零样本任务上的精度差距缩小至与FP16基线相比仅1.3个点。在Llama-2-7B模型上，MergeQuant在解码阶段实现了高达1.77倍的加速，端到端相比FP16基线加速高达2.06倍。</p>
<div class="markdown-heading"><h2 class="heading-element">SplitQuantV2：无需GPU增强LLM的低比特量化</h2><a id="user-content-splitquantv2无需gpu增强llm的低比特量化" class="anchor" aria-label="Permalink: SplitQuantV2：无需GPU增强LLM的低比特量化" href="#splitquantv2无需gpu增强llm的低比特量化"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2503.07657v1 公告类型：新研究  摘要：大型语言模型（LLMs）的量化对于在计算资源有限的设备上部署至关重要。虽然先进的量化算法相比基本的线性量化提供了更好的性能，但它们通常需要高端图形处理单元（GPU），且往往局限于特定的深度神经网络（DNN）框架，并需要校准数据集。这一限制给在各种神经处理单元（NPU）和边缘AI设备上使用此类算法带来了挑战，因为这些设备具有多样化的模型格式和框架。在本文中，我们展示了SplitQuantV2，这是一种旨在增强LLMs低比特线性量化的创新算法，能够达到与先进算法相当的结果。SplitQuantV2通过将线性和卷积层拆分为功能等效、对量化友好的结构来预处理模型。该算法的平台无关性、简洁性和高效性使得无需GPU即可实现。我们在使用AI2推理挑战（ARC）数据集的Llama 3.2 1B Instruct模型上的评估表明，SplitQuantV2将INT4量化模型的准确率提高了11.76个百分点，与原始浮点模型的性能相匹配。值得注意的是，SplitQuantV2仅使用苹果M4 CPU就完成了1B模型的预处理和线性INT4量化，耗时仅2分6秒。SplitQuantV2为LLMs的低比特量化提供了一个实用的解决方案，特别是在硬件限制或框架不兼容导致无法使用复杂、计算密集型算法的情况下。</p>
<div class="markdown-heading"><h2 class="heading-element">通过动态块级回退实现精确的INT8训练</h2><a id="user-content-通过动态块级回退实现精确的int8训练" class="anchor" aria-label="Permalink: 通过动态块级回退实现精确的INT8训练" href="#通过动态块级回退实现精确的int8训练"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2503.08040v1 公告类型：新摘要 摘要：Transformer模型在各类AI应用中取得了显著成功，但面临高昂的训练成本。低比特训练，如INT8训练，能够利用具有更高吞吐量的计算单元，并已在采用块级量化的GPT2模型上证明了其有效性。然而，它在融合了GLU单元的现代Transformer变体上表现不佳，因为这些变体展现出复杂的激活异常值分布。为应对这一挑战，我们提出了回退量化法，通过实现混合精度的GEMM（通用矩阵乘法），动态地将包含异常值的激活块从8位回退至16位处理。实验表明，我们的方法在微调和预训练场景下均表现出稳健的能力。此外，在RTX4090 GPU上，我们的方法实现了1.57倍的端到端训练加速。</p>
</div></div><div class="footer container-xl width-full p-responsive"><div class="position-relative flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between pt-4 pb-4 mt-6 f6 color-text-secondary border-top color-border-secondary text-center"><div class="footer-octicon d-lg-block mx-lg-4"><a title="LLIKKE/Arxiv_GPT_Assistant" href="https://github.com/LLIKKE/Arxiv_GPT_Assistant" target="_blank" rel="noreferrer noopener"><svg class="octicon octicon-mark-github gh-logo" width="36" height="36" viewBox="0 0 98 98" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"></path></svg></a></div><span class="mt-2 d-block footprint"><span>powered by </span><a href="https://github.com/wranders/markdown-to-pages-action" target="_blank" rel="noreferrer noopener">markdown-to-pages-action</a></span></div></div></body></html>