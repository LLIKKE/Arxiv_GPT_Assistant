<!DOCTYPE html><html data-color-mode="light" data-light-theme="light" data-dark-theme="dark" lang="en-US"><head><title>LLIKKE/Arxiv_GPT_Assistant</title><meta charset="utf-8"><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="description" content="Deepseek based personalized ArXiv paper assistant bot"><link rel="canonical" href="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta property="og:type" content="website"><meta property="og:url" content="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:description" content="Deepseek based personalized ArXiv paper assistant bot"><meta property="og:locale" content="en_US"><meta property="og:site_name" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:description" content="Deepseek based personalized ArXiv paper assistant bot"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon.png" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon.svg" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon-dark.png" media="(prefers-color-scheme: dark)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon-dark.svg" media="(prefers-color-scheme: dark)"><link rel="mask-icon" href="https://github.githubassets.com/pinned-octocat.svg" color="#000000"><link href="index.css" rel="stylesheet"></head><body><div class="container-lg px-3 my-5 markdown-body"><div class="position-relative"><span class="profile-color-modes-toggle js-promo-color-modes-toggle" tabindex="0" aria-label="Toggle dark mode" aria-checked="true" role="checkbox"><div class="profile-color-modes-toggle-track" div></div><div class="profile-color-modes-toggle-thumb"><svg style="fill: var(--color-scale-yellow-0); margin: 7px 0 0 7px;" aria-hidden="true" width="14" height="13" viewBox="0 0 14 13" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.52208 7.71754C7.5782 7.71754 10.0557 5.24006 10.0557 2.18394C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961C9.95801 1.07727 10.3495 0.771159 10.6474 0.99992C12.1153 2.12716 13.0615 3.89999 13.0615 5.89383C13.0615 9.29958 10.3006 12.0605 6.89485 12.0605C3.95334 12.0605 1.49286 10.001 0.876728 7.24527C0.794841 6.87902 1.23668 6.65289 1.55321 6.85451C2.41106 7.40095 3.4296 7.71754 4.52208 7.71754Z"></path></svg></div></span></div><script type="text/javascript">(function() {
  var MODE_KEY = 'markdown_to_pages_dark_mode';
  function toggleMode() {
    var mode = document.documentElement.getAttribute('data-color-mode') === 'light' ? 'dark' : 'light';
    document.documentElement.setAttribute('data-color-mode', mode);
    localStorage.setItem(MODE_KEY, mode);
  }
  var mode = localStorage.getItem(MODE_KEY);
  if (mode == null) {
    var query = window.matchMedia('(prefers-color-scheme: dark)');
    mode = query.matches ? 'dark' : 'light';
  }
  document.documentElement.setAttribute('data-color-mode', mode);
  document.querySelector('.profile-color-modes-toggle').onclick = toggleMode;
})();</script><div><div class="markdown-heading"><h2 class="heading-element">《通过分布匹配增强向量量化的理论与实证研究》</h2><a id="user-content-通过分布匹配增强向量量化的理论与实证研究" class="anchor" aria-label="Permalink: 《通过分布匹配增强向量量化的理论与实证研究》" href="#通过分布匹配增强向量量化的理论与实证研究"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>自回归模型（autoregressive models）的成功很大程度上依赖于向量量化（vector quantization）的有效性。该技术通过将连续特征映射至可学习码本（codebook）中的最近邻码向量（code vectors），实现特征的离散化。现有向量量化方法存在两个关键问题：训练不稳定性与码本坍塌（codebook collapse）。训练不稳定性源于直通估计器（straight-through estimator）引入的梯度差异，在量化误差较大时尤为显著；而码本坍塌则表现为训练过程中仅有少量码向量被激活。深入分析表明，这些问题主要由特征与码向量的分布失配驱动，导致码向量缺乏代表性，并在压缩过程中造成显著的数据信息损失。为此，我们采用Wasserstein距离（Wasserstein distance）对齐这两个分布，实现了接近100%的码本利用率，并显著降低了量化误差。实证分析与理论验证均证实了该方法的有效性。</p>
<p>（注：翻译过程中对专业术语采用"中文（英文原词）"的格式处理，便于读者对照理解；通过拆分长句、调整语序保持中文表达习惯；关键概念如Wasserstein distance保留英文名以符合学术文献惯例；动词"address"译为"为此"体现逻辑衔接；量化指标"100%"保留数字符号符合中文技术文本规范）</p>
<div class="markdown-heading"><h2 class="heading-element">内在与外在的有组织注意力：Softmax不变性与网络稀疏性</h2><a id="user-content-内在与外在的有组织注意力softmax不变性与网络稀疏性" class="anchor" aria-label="Permalink: 内在与外在的有组织注意力：Softmax不变性与网络稀疏性" href="#内在与外在的有组织注意力softmax不变性与网络稀疏性"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>我们研究了Transformer中自注意力机制的内在（注意力头内部）与外在（注意力头之间）结构。通过运用仿微分计算理论（并辅以计算实例验证），我们获得了自注意力机制对softmax激活具有不变性的理论证据，这一特性依赖于注意力头的内在组织方式。进一步地，我们采用现有的张量层次化组织方法，通过沿网络三维张量的查询轴、键轴和头轴构建层次划分树来解析网络结构。这种组织结构具有重要价值，因为它使得我们能在呈现规律性的网络三维张量几何空间上高效执行常规信号处理任务。我们通过以下方式对此进行例证：定性方面，可视化由注意力头构成的层次树结构与扩散映射嵌入；定量方面，通过双哈尔基（针对查询与键空间）和三哈尔基（额外包含头空间）研究单个注意力头及整体网络的扩展系数，进而分析网络稀疏性。为展示理论与方法学发现的应用价值，我们提供了视觉与语言Transformer的计算实例。这些发现具有双重意义：（1）从理论上为可解释性分析的后续步骤提供了依据，并可在下游可解释性任务中实现经验性应用；（2）利用网络三维张量的组织结构可实现模型剪枝（基于网络稀疏性）和网络架构对比等实际网络应用。</p>
<div class="markdown-heading"><h2 class="heading-element">基于Kronecker适应的大型语言模型奇异值分解方法</h2><a id="user-content-基于kronecker适应的大型语言模型奇异值分解方法" class="anchor" aria-label="Permalink: 基于Kronecker适应的大型语言模型奇异值分解方法" href="#基于kronecker适应的大型语言模型奇异值分解方法"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>大规模预训练的Transformer模型在各类语言与推理任务中取得了最先进的性能表现，但完整微调会带来巨大的存储、内存和计算开销。参数高效微调（PEFT）方法通过学习少量任务特定参数来降低这些成本，然而现有方案要么会引入推理延迟（适配器模块），要么存在收敛欠佳问题（随机初始化的低秩更新），或依赖可能不匹配任务复杂度的固定秩选择（基于克罗内克积的分解方法）。我们提出SoKA（基于SVD的克罗内克积自适应），这是一种新颖的PEFT策略，将克罗内克积张量分解与SVD驱动的初始化、频谱感知的动态秩选择相结合。我们的克罗内克积SVD（KPSVD）流程将完整权重更新的主成分提取为紧凑的克罗内克因子，同时采用基于能量阈值和肘点准则的自适应秩选择算法来修剪可忽略成分。在LLaMA2-7B模型上进行的算术推理（GSM8K）、形式数学（MATH）和代码生成（MBPP）实验表明，SoKA仅需99万个可训练参数，比LoRA/PiSSA减少25%，同时达到或超越基线性能。此外，SoKA展现出更快的收敛速度和更稳定的梯度，凸显了其在大规模模型适配中的鲁棒性与高效性。</p>
</div></div><div class="footer container-xl width-full p-responsive"><div class="position-relative flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between pt-4 pb-4 mt-6 f6 color-text-secondary border-top color-border-secondary text-center"><div class="footer-octicon d-lg-block mx-lg-4"><a title="LLIKKE/Arxiv_GPT_Assistant" href="https://github.com/LLIKKE/Arxiv_GPT_Assistant" target="_blank" rel="noreferrer noopener"><svg class="octicon octicon-mark-github gh-logo" width="36" height="36" viewBox="0 0 98 98" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"></path></svg></a></div><span class="mt-2 d-block footprint"><span>powered by </span><a href="https://github.com/wranders/markdown-to-pages-action" target="_blank" rel="noreferrer noopener">markdown-to-pages-action</a></span></div></div></body></html>