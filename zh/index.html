<!DOCTYPE html><html data-color-mode="light" data-light-theme="light" data-dark-theme="dark" lang="en-US"><head><title>LLIKKE/Arxiv_GPT_Assistant</title><meta charset="utf-8"><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="description" content="Deepseek based personalized ArXiv paper assistant bot"><link rel="canonical" href="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta property="og:type" content="website"><meta property="og:url" content="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:description" content="Deepseek based personalized ArXiv paper assistant bot"><meta property="og:locale" content="en_US"><meta property="og:site_name" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:description" content="Deepseek based personalized ArXiv paper assistant bot"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon.png" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon.svg" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon-dark.png" media="(prefers-color-scheme: dark)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon-dark.svg" media="(prefers-color-scheme: dark)"><link rel="mask-icon" href="https://github.githubassets.com/pinned-octocat.svg" color="#000000"><link href="index.css" rel="stylesheet"></head><body><div class="container-lg px-3 my-5 markdown-body"><div class="position-relative"><span class="profile-color-modes-toggle js-promo-color-modes-toggle" tabindex="0" aria-label="Toggle dark mode" aria-checked="true" role="checkbox"><div class="profile-color-modes-toggle-track" div></div><div class="profile-color-modes-toggle-thumb"><svg style="fill: var(--color-scale-yellow-0); margin: 7px 0 0 7px;" aria-hidden="true" width="14" height="13" viewBox="0 0 14 13" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.52208 7.71754C7.5782 7.71754 10.0557 5.24006 10.0557 2.18394C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961C9.95801 1.07727 10.3495 0.771159 10.6474 0.99992C12.1153 2.12716 13.0615 3.89999 13.0615 5.89383C13.0615 9.29958 10.3006 12.0605 6.89485 12.0605C3.95334 12.0605 1.49286 10.001 0.876728 7.24527C0.794841 6.87902 1.23668 6.65289 1.55321 6.85451C2.41106 7.40095 3.4296 7.71754 4.52208 7.71754Z"></path></svg></div></span></div><script type="text/javascript">(function() {
  var MODE_KEY = 'markdown_to_pages_dark_mode';
  function toggleMode() {
    var mode = document.documentElement.getAttribute('data-color-mode') === 'light' ? 'dark' : 'light';
    document.documentElement.setAttribute('data-color-mode', mode);
    localStorage.setItem(MODE_KEY, mode);
  }
  var mode = localStorage.getItem(MODE_KEY);
  if (mode == null) {
    var query = window.matchMedia('(prefers-color-scheme: dark)');
    mode = query.matches ? 'dark' : 'light';
  }
  document.documentElement.setAttribute('data-color-mode', mode);
  document.querySelector('.profile-color-modes-toggle').onclick = toggleMode;
})();</script><div><div class="markdown-heading"><h2 class="heading-element">大型语言模型量化技术的综合评估</h2><a id="user-content-大型语言模型量化技术的综合评估" class="anchor" aria-label="Permalink: 大型语言模型量化技术的综合评估" href="#大型语言模型量化技术的综合评估"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2507.17417v1 公告类型：新研究<br>
摘要：对于大语言模型（LLM）而言，训练后量化（PTQ）能显著降低内存占用和计算开销。模型量化是一个快速发展的研究领域。尽管许多论文报道了突破性性能，但由于每种量化方法通常包含多个组件，这些实验可能未在相同基准下进行。此外，深入理解现有方法之间的理论关联至关重要。为弥合这些空白，我们对前沿方法进行了系统性梳理，并在统一实验框架下进行全面评估以确保公平比较。据我们所知，这种公平且全面的调研仍具有关键意义却尚未充分探索。</p>
<p>为解析理论关联，我们将已发表的量化方法解耦为两个步骤：预量化变换与量化误差补偿。前者定义为量化前应用的预处理步骤，旨在通过减少异常值影响使数据分布更平坦，从而适配量化操作；后者则指通过技术手段抵消量化过程中引入的误差以提升模型性能。我们评估并量化了各方法组件的实际影响，同时针对新型MXFP4数据格式及其性能进行了分析验证。</p>
<p>实验结果表明：在预量化变换中，优化旋转与缩放策略能实现最佳性能；而在误差补偿方面，低秩修正与GPTQ的组合使用偶尔能超越单独使用GPTQ的效果。此外，我们对MXFP4量化的潜力进行探索，发现INT4最优预量化策略并不能直接迁移至MXFP4，这一发现为后续研究提供了新方向。</p>
<div class="markdown-heading"><h2 class="heading-element">HydraOpt：驾驭适配器合并的效率与性能权衡之道</h2><a id="user-content-hydraopt驾驭适配器合并的效率与性能权衡之道" class="anchor" aria-label="Permalink: HydraOpt：驾驭适配器合并的效率与性能权衡之道" href="#hydraopt驾驭适配器合并的效率与性能权衡之道"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2507.17706v1 公告类型：新论文<br>
摘要：大语言模型（LLMs）常采用适配器（如基于低秩分解的适配器）来在下游任务中实现强劲性能。然而，为每个任务单独存储适配器会显著增加内存需求，这对移动设备等资源受限的环境构成挑战。虽然模型融合技术可以降低存储成本，但通常会导致性能大幅下降。本研究提出HydraOpt——一种新型模型融合技术，该技术通过挖掘低秩适配器矩阵间的固有相似性实现优化。与现有方法只能在存储空间和性能之间形成固定权衡不同，HydraOpt使我们能够自主调节效率与性能的平衡曲线。实验表明，相较于存储全部适配器的基准方案，HydraOpt在保持竞争力性能（仅下降0.2-1.8%）的同时，显著减少了存储占用（降幅达48%）。此外，在相同或略逊的存储效率条件下，其性能表现优于现有融合技术。</p>
<p>（翻译说明：</p>
<ol>
<li>专业术语处理："low-rank-based adapters"译为"基于低秩分解的适配器"，既保留数学概念又符合中文表达；</li>
<li>技术概念转化："navigate this spectrum"意译为"自主调节平衡曲线"，将抽象概念具象化；</li>
<li>数据呈现优化：括号内百分比统一采用中文表述习惯；</li>
<li>被动语态转换："are produced"转为主动式"形成"；</li>
<li>长句拆分：将原文复合句拆分为符合中文短句习惯的表达；</li>
<li>技术名词一致性："HydraOpt"保留原名不翻译，符合机器学习领域惯例）</li>
</ol>
<div class="markdown-heading"><h2 class="heading-element">SiLQ：简易大型语言模型量化感知训练</h2><a id="user-content-silq简易大型语言模型量化感知训练" class="anchor" aria-label="Permalink: SiLQ：简易大型语言模型量化感知训练" href="#silq简易大型语言模型量化感知训练"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2507.16933v1 公告类型：新研究<br>
摘要：大型语言模型可通过量化降低推理延迟、缩小模型体积并减少能耗，从而以更低成本提供更佳用户体验。当前挑战在于如何以合理时间实现精度损失最小的量化模型，尤其需避免使用与专用推理加速器不兼容的机制。本文展示了一种简单的端到端量化感知训练方法：在总训练预算增加不足0.1%的情况下，该方法在多个现代基准测试中（包括基础模型和指令变体）以显著优势超越现有主流量化方案。该方法能轻松适配不同模型架构，可同时应用于激活值、缓存和权重，且除量化操作外无需引入任何额外计算。</p>
</div></div><div class="footer container-xl width-full p-responsive"><div class="position-relative flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between pt-4 pb-4 mt-6 f6 color-text-secondary border-top color-border-secondary text-center"><div class="footer-octicon d-lg-block mx-lg-4"><a title="LLIKKE/Arxiv_GPT_Assistant" href="https://github.com/LLIKKE/Arxiv_GPT_Assistant" target="_blank" rel="noreferrer noopener"><svg class="octicon octicon-mark-github gh-logo" width="36" height="36" viewBox="0 0 98 98" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"></path></svg></a></div><span class="mt-2 d-block footprint"><span>powered by </span><a href="https://github.com/wranders/markdown-to-pages-action" target="_blank" rel="noreferrer noopener">markdown-to-pages-action</a></span></div></div></body></html>