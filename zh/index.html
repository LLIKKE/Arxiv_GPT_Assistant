<!DOCTYPE html><html data-color-mode="light" data-light-theme="light" data-dark-theme="dark" lang="en-US"><head><title>LLIKKE/Arxiv_GPT_Assistant</title><meta charset="utf-8"><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="description" content="Deepseek based personalized ArXiv paper assistant bot"><link rel="canonical" href="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta property="og:type" content="website"><meta property="og:url" content="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:description" content="Deepseek based personalized ArXiv paper assistant bot"><meta property="og:locale" content="en_US"><meta property="og:site_name" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:description" content="Deepseek based personalized ArXiv paper assistant bot"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon.png" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon.svg" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon-dark.png" media="(prefers-color-scheme: dark)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon-dark.svg" media="(prefers-color-scheme: dark)"><link rel="mask-icon" href="https://github.githubassets.com/pinned-octocat.svg" color="#000000"><link href="index.css" rel="stylesheet"></head><body><div class="container-lg px-3 my-5 markdown-body"><div class="position-relative"><span class="profile-color-modes-toggle js-promo-color-modes-toggle" tabindex="0" aria-label="Toggle dark mode" aria-checked="true" role="checkbox"><div class="profile-color-modes-toggle-track" div></div><div class="profile-color-modes-toggle-thumb"><svg style="fill: var(--color-scale-yellow-0); margin: 7px 0 0 7px;" aria-hidden="true" width="14" height="13" viewBox="0 0 14 13" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.52208 7.71754C7.5782 7.71754 10.0557 5.24006 10.0557 2.18394C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961C9.95801 1.07727 10.3495 0.771159 10.6474 0.99992C12.1153 2.12716 13.0615 3.89999 13.0615 5.89383C13.0615 9.29958 10.3006 12.0605 6.89485 12.0605C3.95334 12.0605 1.49286 10.001 0.876728 7.24527C0.794841 6.87902 1.23668 6.65289 1.55321 6.85451C2.41106 7.40095 3.4296 7.71754 4.52208 7.71754Z"></path></svg></div></span></div><script type="text/javascript">(function() {
  var MODE_KEY = 'markdown_to_pages_dark_mode';
  function toggleMode() {
    var mode = document.documentElement.getAttribute('data-color-mode') === 'light' ? 'dark' : 'light';
    document.documentElement.setAttribute('data-color-mode', mode);
    localStorage.setItem(MODE_KEY, mode);
  }
  var mode = localStorage.getItem(MODE_KEY);
  if (mode == null) {
    var query = window.matchMedia('(prefers-color-scheme: dark)');
    mode = query.matches ? 'dark' : 'light';
  }
  document.documentElement.setAttribute('data-color-mode', mode);
  document.querySelector('.profile-color-modes-toggle').onclick = toggleMode;
})();</script><div><div class="markdown-heading"><h2 class="heading-element">MiLo：采用低秩补偿器混合策略的高效量化混合专家推理系统</h2><a id="user-content-milo采用低秩补偿器混合策略的高效量化混合专家推理系统" class="anchor" aria-label="Permalink: MiLo：采用低秩补偿器混合策略的高效量化混合专家推理系统" href="#milo采用低秩补偿器混合策略的高效量化混合专家推理系统"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>高效部署具有海量参数的混合专家模型（MoE）的关键技术路径是量化。然而，当前最先进的MoE模型在极端量化（如低于4比特）时会出现不可忽视的准确率下降。为此，我们提出MiLo创新方法——通过引入低秩补偿器混合组件来增强高量化度MoE模型。这些补偿器仅消耗少量额外内存，却能显著恢复极端量化导致的精度损失。MiLo还发现：由于混合专家模型独特的稠密-稀疏混合架构，其不同权重表现出显著异质性特征，因此采用自适应秩选择策略配合迭代优化来弥合准确率差距。该方法无需依赖校准数据，可泛化至不同MoE模型和数据集，避免对校准集的过拟合。针对3比特等极端量化导致的硬件效率瓶颈，MiLo开发了与Tensor Core兼容的3比特计算内核，实测实现了3比特量化MoE模型的延迟加速。评估表明，MiLo在各类任务中均优于现有方法，在多款最先进MoE模型上展现出卓越性能。</p>
<p>（注：根据技术文献翻译规范，在保证专业性的同时：</p>
<ol>
<li>保留"MoE/Tensor Core"等专业术语原名</li>
<li>"SoTA"译为"最先进"符合中文语境</li>
<li>"kernel"译为"内核"而非直译"核"避免歧义</li>
<li>采用"补偿器混合组件"等符合中文科技论文表述习惯的译法</li>
<li>通过"显著异质性特征"等表述准确传达技术细节）</li>
</ol>
<div class="markdown-heading"><h2 class="heading-element">GPTQv2：面向非对称校准的高效免微调量化技术</h2><a id="user-content-gptqv2面向非对称校准的高效免微调量化技术" class="anchor" aria-label="Permalink: GPTQv2：面向非对称校准的高效免微调量化技术" href="#gptqv2面向非对称校准的高效免微调量化技术"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>（注：根据技术文档翻译惯例，GPTQv2作为专有名词保留不译；"Efficient Finetuning-Free Quantization"采用"高效免微调量化技术"的译法，既保持技术准确性又符合中文表达习惯；"Asymmetric Calibration"译为"非对称校准"，这是机器学习量化领域的标准术语翻译。整体采用技术文档常见的"功能+特性"命名结构，使中文标题既专业又简洁。）</p>
<p>我们推出GPTQv2，一种无需微调的新型量化方法，专为压缩大规模Transformer架构设计。与先前独立校准各层的GPTQ方法不同，我们始终将量化层的输出与全精度模型中的精确输出对齐，形成名为"非对称校准"的创新方案。该方案能有效减少先前层级积累的量化误差。我们通过最优脑压缩理论分析该问题，推导出闭式解。新解法显式地同步最小化量化误差与非对称累积误差，并创新性地采用通道并行化、神经元分解、矩阵融合的Cholesky重构等技术实现并行计算。GPTQv2实现极为简洁，仅比GPTQ多20行代码即可显著提升低比特量化性能。值得注意的是，在单块GPU上，我们成功量化了4050亿参数的语言Transformer，以及以90%ImageNet预训练精度登顶的视觉Transformer模型EVA-02。代码已开源在github.com/Intelligent-Computing-Lab-Yale/GPTQv2。</p>
<p>（翻译说明：</p>
<ol>
<li>专业术语处理："finetuning-free"译为"无需微调"、"asymmetric calibration"译为"非对称校准"、"optimal brain compression"译为"最优脑压缩"等，既保持专业性又符合中文表达习惯</li>
<li>长句拆分：将原文复合长句拆分为符合中文短句习惯的表达，如将并行计算技术部分处理为排比句式</li>
<li>数字规范：405B译为"4050亿"符合中文数量级表达</li>
<li>技术品牌名保留：GPTQv2、EVA-02等专有名称不做翻译</li>
<li>被动语态转换："is easy to implement"转化为主动式"实现极为简洁"</li>
<li>文化适配："rank first"译为"登顶"更符合中文技术竞争语境</li>
<li>补充说明：在ImageNet精度处添加"预训练"明确上下文</li>
<li>代码仓库链接保留原貌确保可访问性）</li>
</ol>
<div class="markdown-heading"><h2 class="heading-element">大型语言模型中的认知记忆</h2><a id="user-content-大型语言模型中的认知记忆" class="anchor" aria-label="Permalink: 大型语言模型中的认知记忆" href="#大型语言模型中的认知记忆"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>本文深入探讨了大型语言模型（LLM）中的记忆机制，重点分析了其对生成上下文丰富响应、减少幻觉现象及提升效率的关键作用。研究将记忆系统划分为感官记忆、短期记忆与长期记忆三类：感官记忆对应输入提示，短期记忆处理即时上下文，长期记忆则通过外部数据库或特定结构实现。在基于文本的记忆模块中，系统阐述了记忆获取（筛选与摘要生成）、记忆管理（更新、调取、存储与冲突解决）及记忆利用（全文检索、SQL查询、语义搜索）的全流程。基于键值缓存的记忆模块则详述了筛选方法（基于规则摘要、评分机制、特殊标记嵌入）与压缩技术（低秩压缩、键值合并、多模态压缩），以及卸载共享注意力机制等管理策略。参数化记忆方法（LoRA、TTT、MoE）通过将记忆转化为模型参数来提升效率，而基于隐藏状态的记忆方案（分块机制、循环Transformer、Mamba模型）则通过融合RNN隐藏状态与当代技术来优化长文本处理。本文全面解析了LLM记忆机制的架构，强调了其重要性并指明了未来研究方向。</p>
</div></div><div class="footer container-xl width-full p-responsive"><div class="position-relative flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between pt-4 pb-4 mt-6 f6 color-text-secondary border-top color-border-secondary text-center"><div class="footer-octicon d-lg-block mx-lg-4"><a title="LLIKKE/Arxiv_GPT_Assistant" href="https://github.com/LLIKKE/Arxiv_GPT_Assistant" target="_blank" rel="noreferrer noopener"><svg class="octicon octicon-mark-github gh-logo" width="36" height="36" viewBox="0 0 98 98" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"></path></svg></a></div><span class="mt-2 d-block footprint"><span>powered by </span><a href="https://github.com/wranders/markdown-to-pages-action" target="_blank" rel="noreferrer noopener">markdown-to-pages-action</a></span></div></div></body></html>