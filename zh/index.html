<!DOCTYPE html><html data-color-mode="light" data-light-theme="light" data-dark-theme="dark" lang="en-US"><head><title>LLIKKE/Arxiv_GPT_Assistant</title><meta charset="utf-8"><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="description" content="Deepseek based personalized ArXiv paper assistant bot"><link rel="canonical" href="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta property="og:type" content="website"><meta property="og:url" content="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:description" content="Deepseek based personalized ArXiv paper assistant bot"><meta property="og:locale" content="en_US"><meta property="og:site_name" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:description" content="Deepseek based personalized ArXiv paper assistant bot"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon.png" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon.svg" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon-dark.png" media="(prefers-color-scheme: dark)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon-dark.svg" media="(prefers-color-scheme: dark)"><link rel="mask-icon" href="https://github.githubassets.com/pinned-octocat.svg" color="#000000"><link href="index.css" rel="stylesheet"></head><body><div class="container-lg px-3 my-5 markdown-body"><div class="position-relative"><span class="profile-color-modes-toggle js-promo-color-modes-toggle" tabindex="0" aria-label="Toggle dark mode" aria-checked="true" role="checkbox"><div class="profile-color-modes-toggle-track" div></div><div class="profile-color-modes-toggle-thumb"><svg style="fill: var(--color-scale-yellow-0); margin: 7px 0 0 7px;" aria-hidden="true" width="14" height="13" viewBox="0 0 14 13" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.52208 7.71754C7.5782 7.71754 10.0557 5.24006 10.0557 2.18394C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961C9.95801 1.07727 10.3495 0.771159 10.6474 0.99992C12.1153 2.12716 13.0615 3.89999 13.0615 5.89383C13.0615 9.29958 10.3006 12.0605 6.89485 12.0605C3.95334 12.0605 1.49286 10.001 0.876728 7.24527C0.794841 6.87902 1.23668 6.65289 1.55321 6.85451C2.41106 7.40095 3.4296 7.71754 4.52208 7.71754Z"></path></svg></div></span></div><script type="text/javascript">(function() {
  var MODE_KEY = 'markdown_to_pages_dark_mode';
  function toggleMode() {
    var mode = document.documentElement.getAttribute('data-color-mode') === 'light' ? 'dark' : 'light';
    document.documentElement.setAttribute('data-color-mode', mode);
    localStorage.setItem(MODE_KEY, mode);
  }
  var mode = localStorage.getItem(MODE_KEY);
  if (mode == null) {
    var query = window.matchMedia('(prefers-color-scheme: dark)');
    mode = query.matches ? 'dark' : 'light';
  }
  document.documentElement.setAttribute('data-color-mode', mode);
  document.querySelector('.profile-color-modes-toggle').onclick = toggleMode;
})();</script><div><div class="markdown-heading"><h2 class="heading-element">修剪无惊喜之处：通过首词惊异值实现高效代码推理</h2><a id="user-content-修剪无惊喜之处通过首词惊异值实现高效代码推理" class="anchor" aria-label="Permalink: 修剪无惊喜之处：通过首词惊异值实现高效代码推理" href="#修剪无惊喜之处通过首词惊异值实现高效代码推理"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.05988v1 公告类型：新研究<br>
摘要：近期，大型推理模型（LRMs）通过扩展思维链（CoT）的长度，在代码推理任务中展现出卓越能力。然而，过长的推理轨迹会带来训练成本、推理延迟和部署可行性方面的重大挑战。虽然目前已有多种CoT压缩方法应对这一挑战，但它们存在固有缺陷：基于词元级别的压缩往往会破坏语法和逻辑连贯性，而基于困惑度的步骤级方法又难以可靠捕捉逻辑关键推理步骤。本文提出ASAP（锚点引导的基于惊异值的剪枝框架），一种新颖的"由粗到细"CoT压缩框架。ASAP首先执行锚点引导剪枝以保留核心推理结构，有效缩小后续处理搜索空间；随后通过基于首创的"首词惊异值"指标选择逻辑关键步骤，实现逻辑感知的剪枝；最终指导模型在推理时自主生成并利用这些精简CoT，实现高效的代码任务推理。实验表明，ASAP在多个代码生成基准测试中达到最先进准确率，同时显著降低训练和推理成本。在极具挑战性的LiveCodeBench v4_v5基准测试中，相较最强基线方法，我们的方案减少了23.5%的词元生成和43.5%的推理延迟，同时保持36.19%的Pass@1竞争性准确率。这一成果为构建强大且高效的大型推理模型指明了前景广阔的发展方向。</p>
<p>（注：专业术语说明：</p>
<ol>
<li>"surprisal"译为"惊异值"，是信息论中衡量事件意外程度的指标</li>
<li>"Pass@1"保留英文术语，指模型首次生成即通过测试的准确率</li>
<li>"Chain-of-Thought"统一译为"思维链"，简称CoT保持英文缩写</li>
<li>"LiveCodeBench"作为专有名称保留不译）</li>
</ol>
<div class="markdown-heading"><h2 class="heading-element">DP-LLM：运行时模型自适应与动态分层精度分配</h2><a id="user-content-dp-llm运行时模型自适应与动态分层精度分配" class="anchor" aria-label="Permalink: DP-LLM：运行时模型自适应与动态分层精度分配" href="#dp-llm运行时模型自适应与动态分层精度分配"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.06041v1 公告类型：新研究<br>
摘要：如何有效处理对设备端大型语言模型（LLM）的多样化运行时约束查询（如延迟与精度需求）？多尺度量化通过叠加不同比特宽度量化的模型变体，实现了内存高效的LLM运行时自适应。然而，一个关键问题仍未解决：如何合理配置模型以匹配目标精度或延迟？混合精度虽提供了可行方案，但我们进一步利用核心发现——各层敏感性在解码迭代过程中会动态变化。基于此，我们提出DP-LLM创新机制，该机制根据输入值动态分配每层计算精度。DP-LLM为LLM中的每个线性层增设精度选择器，通过轻量级误差估计器和微调学习的阈值，在运行时动态确定比特宽度。多模型多基准测试表明，DP-LLM实现了更优的性能-延迟权衡，显著超越现有方法。</p>
<p>（注：翻译严格遵循技术文献规范，处理要点包括：</p>
<ol>
<li>专业术语统一（如"quantization"译为"量化"、"fine-tuning"译为"微调"）</li>
<li>长句拆分重组（如将原文复合从句转化为中文短句链）</li>
<li>被动语态转化（如"models be properly configured"译为主动式"合理配置模型"）</li>
<li>概念显化（如"runtime"译为"运行时"而非字面直译"运行时间"）</li>
<li>技术表述准确性（如"mixed-precision"译为专业术语"混合精度"而非字面直译））</li>
</ol>
<div class="markdown-heading"><h2 class="heading-element">《第四态：带符号零的三进制系统——稳定大语言模型量化的新途径（及其他应用）》</h2><a id="user-content-第四态带符号零的三进制系统稳定大语言模型量化的新途径及其他应用" class="anchor" aria-label="Permalink: 《第四态：带符号零的三进制系统——稳定大语言模型量化的新途径（及其他应用）》" href="#第四态带符号零的三进制系统稳定大语言模型量化的新途径及其他应用"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>（翻译说明：</p>
<ol>
<li>"The Fourth State" 译为"第四态"，呼应物理学中物质第四态（等离子体）的命名逻辑，突出技术突破性</li>
<li>"Signed-Zero Ternary" 采用技术领域惯用译法"带符号零的三进制"，精确传达-0/+0的数学特性</li>
<li>副标题处理为破折号连接主副标题，符合中文技术论文标题规范</li>
<li>"Stable LLM Quantization" 译为"稳定大语言模型量化"，其中：
<ul>
<li>"Stable" 取计算机领域常用译法"稳定"而非"稳固"</li>
<li>"LLM" 使用中文领域通用全称"大语言模型"</li>
</ul>
</li>
<li>括号中的"(and More)" 译为"及其他应用"，既保留原文的开放性暗示，又符合中文标题简洁性要求）</li>
</ol>
<p>arXiv:2508.05905v1 公告类型：新研究<br>
摘要：量化通常被视为一种以性能质量换取计算需求降低的手段，即作为一种次优近似方案。然而，若从固定总资源预算的角度审视，则会得出截然不同的结论。我们提出有符号零三元量化（SZT）——这种2比特量化方法能确定性提供梯度信息，且不造成前向路径的性能损失。分析表明，与非量化方案相比，该量化方式可能提升信息密度。</p>
<p>（注：根据学术论文摘要的翻译规范，进行了以下处理：</p>
<ol>
<li>保留arXiv编号格式和公告类型标记</li>
<li>"Signed-Zero Ternary"采用技术术语译法"有符号零三元量化"并附加括号标注原缩写"SZT"</li>
<li>"deterministically"译为"确定性"以保持数学严谨性</li>
<li>"information density"译为"信息密度"符合信息论术语惯例</li>
<li>通过破折号和分号重构长句结构，符合中文表达习惯）</li>
</ol>
</div></div><div class="footer container-xl width-full p-responsive"><div class="position-relative flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between pt-4 pb-4 mt-6 f6 color-text-secondary border-top color-border-secondary text-center"><div class="footer-octicon d-lg-block mx-lg-4"><a title="LLIKKE/Arxiv_GPT_Assistant" href="https://github.com/LLIKKE/Arxiv_GPT_Assistant" target="_blank" rel="noreferrer noopener"><svg class="octicon octicon-mark-github gh-logo" width="36" height="36" viewBox="0 0 98 98" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"></path></svg></a></div><span class="mt-2 d-block footprint"><span>powered by </span><a href="https://github.com/wranders/markdown-to-pages-action" target="_blank" rel="noreferrer noopener">markdown-to-pages-action</a></span></div></div></body></html>