<!DOCTYPE html><html data-color-mode="light" data-light-theme="light" data-dark-theme="dark" lang="en-US"><head><title>LLIKKE/Arxiv_GPT_Assistant</title><meta charset="utf-8"><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="description" content="Deepseek based personalized ArXiv paper assistant bot"><link rel="canonical" href="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta property="og:type" content="website"><meta property="og:url" content="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:description" content="Deepseek based personalized ArXiv paper assistant bot"><meta property="og:locale" content="en_US"><meta property="og:site_name" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:description" content="Deepseek based personalized ArXiv paper assistant bot"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon.png" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon.svg" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon-dark.png" media="(prefers-color-scheme: dark)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon-dark.svg" media="(prefers-color-scheme: dark)"><link rel="mask-icon" href="https://github.githubassets.com/pinned-octocat.svg" color="#000000"><link href="index.css" rel="stylesheet"></head><body><div class="container-lg px-3 my-5 markdown-body"><div class="position-relative"><span class="profile-color-modes-toggle js-promo-color-modes-toggle" tabindex="0" aria-label="Toggle dark mode" aria-checked="true" role="checkbox"><div class="profile-color-modes-toggle-track" div></div><div class="profile-color-modes-toggle-thumb"><svg style="fill: var(--color-scale-yellow-0); margin: 7px 0 0 7px;" aria-hidden="true" width="14" height="13" viewBox="0 0 14 13" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.52208 7.71754C7.5782 7.71754 10.0557 5.24006 10.0557 2.18394C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961C9.95801 1.07727 10.3495 0.771159 10.6474 0.99992C12.1153 2.12716 13.0615 3.89999 13.0615 5.89383C13.0615 9.29958 10.3006 12.0605 6.89485 12.0605C3.95334 12.0605 1.49286 10.001 0.876728 7.24527C0.794841 6.87902 1.23668 6.65289 1.55321 6.85451C2.41106 7.40095 3.4296 7.71754 4.52208 7.71754Z"></path></svg></div></span></div><script type="text/javascript">(function() {
  var MODE_KEY = 'markdown_to_pages_dark_mode';
  function toggleMode() {
    var mode = document.documentElement.getAttribute('data-color-mode') === 'light' ? 'dark' : 'light';
    document.documentElement.setAttribute('data-color-mode', mode);
    localStorage.setItem(MODE_KEY, mode);
  }
  var mode = localStorage.getItem(MODE_KEY);
  if (mode == null) {
    var query = window.matchMedia('(prefers-color-scheme: dark)');
    mode = query.matches ? 'dark' : 'light';
  }
  document.documentElement.setAttribute('data-color-mode', mode);
  document.querySelector('.profile-color-modes-toggle').onclick = toggleMode;
})();</script><div><div class="markdown-heading"><h2 class="heading-element">《计算编码：面向可重构硬件的神经网络高效压缩》</h2><a id="user-content-计算编码面向可重构硬件的神经网络高效压缩" class="anchor" aria-label="Permalink: 《计算编码：面向可重构硬件的神经网络高效压缩》" href="#计算编码面向可重构硬件的神经网络高效压缩"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2504.17403v1 公告类型：新研究<br>
摘要：随着最先进神经网络（NNs）规模的持续扩大，其资源高效实现变得愈发重要。本文提出一种压缩方案，可减少在FPGA等可重构硬件上进行神经网络推理所需的计算量。该方案通过正则化训练剪枝、权重共享和线性计算编码（LCC）三项技术的协同实现。与常见以缩减神经网络权重存储空间为目标的压缩技术不同，我们的方法以硬件友好方式优化减少推理所需的加法运算次数。对于简单多层感知器以及ResNet-34等大规模深度神经网络，所提方案均展现出具有竞争力的性能表现。</p>
<p>（注：根据学术论文摘要的翻译规范，进行了以下处理：</p>
<ol>
<li>保留专业术语缩写（NNs/FPGA/LCC/ResNet）及编号格式</li>
<li>"state of the art"译为"最先进的"符合中文文献习惯</li>
<li>"hardware-friendly manner"意译为"硬件友好方式"既准确又符合中文表达</li>
<li>将英语长句拆分为符合中文阅读习惯的短句结构</li>
<li>"multilayer perceptrons"采用业界通用译名"多层感知器"</li>
<li>保持被动语态到主动语态的合理转换（如"are optimized"译为"以...优化"））</li>
</ol>
<div class="markdown-heading"><h2 class="heading-element">反斜杠：大型语言模型的速率约束优化训练</h2><a id="user-content-反斜杠大型语言模型的速率约束优化训练" class="anchor" aria-label="Permalink: 反斜杠：大型语言模型的速率约束优化训练" href="#反斜杠大型语言模型的速率约束优化训练"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2504.16968v1 公告类型：新研究<br>
摘要：大型语言模型（LLM）的快速发展推动了训练完成后参数压缩技术的广泛研究，然而训练阶段的压缩领域仍鲜有探索。本研究提出速率约束训练法（Backslash），这是一种基于率失真优化（RDO）的新型训练时压缩方法。Backslash实现了模型精度与复杂度之间的灵活权衡，在保持性能的同时显著减少参数冗余。在多种架构和任务中的实验表明，Backslash可在不损失精度的情况下降低60%-90%的内存占用，且相比训练后压缩获得显著的增益。此外，Backslash展现出极强的通用性：通过小拉格朗日乘数增强模型泛化能力，提升模型对剪枝的鲁棒性（在80%剪枝率下仍保持精度），并能简化网络结构以加速边缘设备推理。</p>
<p>（注：Backslash作为方法名保留不译，RDO采用"率失真优化"的标准译法，技术术语如"Lagrange multipliers"译为"拉格朗日乘数"保持学术惯例，长难句按中文表达习惯拆分重组，确保专业性与可读性平衡）</p>
</div></div><div class="footer container-xl width-full p-responsive"><div class="position-relative flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between pt-4 pb-4 mt-6 f6 color-text-secondary border-top color-border-secondary text-center"><div class="footer-octicon d-lg-block mx-lg-4"><a title="LLIKKE/Arxiv_GPT_Assistant" href="https://github.com/LLIKKE/Arxiv_GPT_Assistant" target="_blank" rel="noreferrer noopener"><svg class="octicon octicon-mark-github gh-logo" width="36" height="36" viewBox="0 0 98 98" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"></path></svg></a></div><span class="mt-2 d-block footprint"><span>powered by </span><a href="https://github.com/wranders/markdown-to-pages-action" target="_blank" rel="noreferrer noopener">markdown-to-pages-action</a></span></div></div></body></html>