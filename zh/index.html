<!DOCTYPE html><html data-color-mode="light" data-light-theme="light" data-dark-theme="dark" lang="en-US"><head><title>LLIKKE/Arxiv_GPT_Assistant</title><meta charset="utf-8"><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="description" content="Deepseek based personalized ArXiv paper assistant bot"><link rel="canonical" href="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta property="og:type" content="website"><meta property="og:url" content="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:description" content="Deepseek based personalized ArXiv paper assistant bot"><meta property="og:locale" content="en_US"><meta property="og:site_name" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:description" content="Deepseek based personalized ArXiv paper assistant bot"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon.png" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon.svg" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon-dark.png" media="(prefers-color-scheme: dark)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon-dark.svg" media="(prefers-color-scheme: dark)"><link rel="mask-icon" href="https://github.githubassets.com/pinned-octocat.svg" color="#000000"><link href="index.css" rel="stylesheet"></head><body><div class="container-lg px-3 my-5 markdown-body"><div class="position-relative"><span class="profile-color-modes-toggle js-promo-color-modes-toggle" tabindex="0" aria-label="Toggle dark mode" aria-checked="true" role="checkbox"><div class="profile-color-modes-toggle-track" div></div><div class="profile-color-modes-toggle-thumb"><svg style="fill: var(--color-scale-yellow-0); margin: 7px 0 0 7px;" aria-hidden="true" width="14" height="13" viewBox="0 0 14 13" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.52208 7.71754C7.5782 7.71754 10.0557 5.24006 10.0557 2.18394C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961C9.95801 1.07727 10.3495 0.771159 10.6474 0.99992C12.1153 2.12716 13.0615 3.89999 13.0615 5.89383C13.0615 9.29958 10.3006 12.0605 6.89485 12.0605C3.95334 12.0605 1.49286 10.001 0.876728 7.24527C0.794841 6.87902 1.23668 6.65289 1.55321 6.85451C2.41106 7.40095 3.4296 7.71754 4.52208 7.71754Z"></path></svg></div></span></div><script type="text/javascript">(function() {
  var MODE_KEY = 'markdown_to_pages_dark_mode';
  function toggleMode() {
    var mode = document.documentElement.getAttribute('data-color-mode') === 'light' ? 'dark' : 'light';
    document.documentElement.setAttribute('data-color-mode', mode);
    localStorage.setItem(MODE_KEY, mode);
  }
  var mode = localStorage.getItem(MODE_KEY);
  if (mode == null) {
    var query = window.matchMedia('(prefers-color-scheme: dark)');
    mode = query.matches ? 'dark' : 'light';
  }
  document.documentElement.setAttribute('data-color-mode', mode);
  document.querySelector('.profile-color-modes-toggle').onclick = toggleMode;
})();</script><div><div class="markdown-heading"><h2 class="heading-element">迈向后期交互检索模型中的无损令牌剪枝</h2><a id="user-content-迈向后期交互检索模型中的无损令牌剪枝" class="anchor" aria-label="Permalink: 迈向后期交互检索模型中的无损令牌剪枝" href="#迈向后期交互检索模型中的无损令牌剪枝"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>像ColBERT这样的延迟交互神经信息检索模型在许多基准测试中提供了效率与效果间的优越平衡。然而，这些模型需要巨大的内存空间来存储所有文档标记的上下文表示。已有研究提出采用启发式或基于统计的技术来修剪每个文档中的标记，但这并不能保证被移除的标记对检索分数毫无影响。我们的工作采用了一种原理性方法，界定了如何在不影响文档与查询间评分的前提下修剪标记。我们引入了三种正则化损失函数，它们共同促成了高修剪率的解决方案，并提出了两种修剪策略。通过实验研究（包括领域内和跨领域场景），我们证明仅需保留30%的标记即可维持ColBERT的检索性能。</p>
<p>（译文说明：1. 专业术语统一处理："prune tokens"译为"修剪标记"符合计算机领域术语；2. 被动语态转化："have been proposed"译为主动式"已有研究提出"更符合中文表达；3. 长句拆分：将原文复合句分解为多个短句，如将"showing that..."独立成句；4. 概念显化："principled approach"译为"原理性方法"准确传达方法论特征；5. 数据呈现：严格保持"30%"数字格式与原文一致；6. 学术风格：使用"界定了""促成了"等动词保持论文严谨性）</p>
<div class="markdown-heading"><h2 class="heading-element">用于LLM服务中任意低精度GPGPU计算的虚拟机</h2><a id="user-content-用于llm服务中任意低精度gpgpu计算的虚拟机" class="anchor" aria-label="Permalink: 用于LLM服务中任意低精度GPGPU计算的虚拟机" href="#用于llm服务中任意低精度gpgpu计算的虚拟机"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>服务大型语言模型（LLMs）对人工智能应用至关重要，但需要消耗大量计算资源，尤其是内存带宽和计算吞吐量。低精度计算已成为提升效率同时降低资源消耗的关键技术。现有生成低精度计算内核的方法仅限于位宽为2的幂次方的权重，且由于高层级GPU编程抽象的限制导致性能欠佳。这些抽象阻碍了关键优化（如细粒度寄存器管理和优化内存访问模式），而这些优化对高效低精度计算至关重要。本文提出一种面向通用GPU（GPGPU）计算的虚拟机（VM），支持任意位宽的低精度数据类型，同时保持GPU可编程性。该虚拟机具有线程块级编程模型、分层内存空间、创新的代数布局系统，以及对多样化低精度数据类型的全面支持。虚拟机程序可被编译为具备自动向量化和指令选择功能的高效GPU程序。大量实验表明，我们的虚拟机不仅能高效支持全系列低精度数据类型，在其支持的类型上性能也优于最先进的低精度计算内核。与Triton、Ladder等现有编译器以及QuantLLM、Marlin等手工优化内核相比，我们的虚拟机分别实现了1.75倍、2.61倍、1.29倍和1.03倍的性能提升。</p>
</div></div><div class="footer container-xl width-full p-responsive"><div class="position-relative flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between pt-4 pb-4 mt-6 f6 color-text-secondary border-top color-border-secondary text-center"><div class="footer-octicon d-lg-block mx-lg-4"><a title="LLIKKE/Arxiv_GPT_Assistant" href="https://github.com/LLIKKE/Arxiv_GPT_Assistant" target="_blank" rel="noreferrer noopener"><svg class="octicon octicon-mark-github gh-logo" width="36" height="36" viewBox="0 0 98 98" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"></path></svg></a></div><span class="mt-2 d-block footprint"><span>powered by </span><a href="https://github.com/wranders/markdown-to-pages-action" target="_blank" rel="noreferrer noopener">markdown-to-pages-action</a></span></div></div></body></html>