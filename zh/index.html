<!DOCTYPE html><html data-color-mode="light" data-light-theme="light" data-dark-theme="dark" lang="en-US"><head><title>LLIKKE/Arxiv_GPT_Assistant</title><meta charset="utf-8"><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="description" content="Deepseek based personalized ArXiv paper assistant bot"><link rel="canonical" href="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta property="og:type" content="website"><meta property="og:url" content="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:description" content="Deepseek based personalized ArXiv paper assistant bot"><meta property="og:locale" content="en_US"><meta property="og:site_name" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:description" content="Deepseek based personalized ArXiv paper assistant bot"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon.png" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon.svg" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon-dark.png" media="(prefers-color-scheme: dark)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon-dark.svg" media="(prefers-color-scheme: dark)"><link rel="mask-icon" href="https://github.githubassets.com/pinned-octocat.svg" color="#000000"><link href="index.css" rel="stylesheet"></head><body><div class="container-lg px-3 my-5 markdown-body"><div class="position-relative"><span class="profile-color-modes-toggle js-promo-color-modes-toggle" tabindex="0" aria-label="Toggle dark mode" aria-checked="true" role="checkbox"><div class="profile-color-modes-toggle-track" div></div><div class="profile-color-modes-toggle-thumb"><svg style="fill: var(--color-scale-yellow-0); margin: 7px 0 0 7px;" aria-hidden="true" width="14" height="13" viewBox="0 0 14 13" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.52208 7.71754C7.5782 7.71754 10.0557 5.24006 10.0557 2.18394C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961C9.95801 1.07727 10.3495 0.771159 10.6474 0.99992C12.1153 2.12716 13.0615 3.89999 13.0615 5.89383C13.0615 9.29958 10.3006 12.0605 6.89485 12.0605C3.95334 12.0605 1.49286 10.001 0.876728 7.24527C0.794841 6.87902 1.23668 6.65289 1.55321 6.85451C2.41106 7.40095 3.4296 7.71754 4.52208 7.71754Z"></path></svg></div></span></div><script type="text/javascript">(function() {
  var MODE_KEY = 'markdown_to_pages_dark_mode';
  function toggleMode() {
    var mode = document.documentElement.getAttribute('data-color-mode') === 'light' ? 'dark' : 'light';
    document.documentElement.setAttribute('data-color-mode', mode);
    localStorage.setItem(MODE_KEY, mode);
  }
  var mode = localStorage.getItem(MODE_KEY);
  if (mode == null) {
    var query = window.matchMedia('(prefers-color-scheme: dark)');
    mode = query.matches ? 'dark' : 'light';
  }
  document.documentElement.setAttribute('data-color-mode', mode);
  document.querySelector('.profile-color-modes-toggle').onclick = toggleMode;
})();</script><div><div class="markdown-heading"><h2 class="heading-element">乳液：平滑量化训练的优化环境</h2><a id="user-content-乳液平滑量化训练的优化环境" class="anchor" aria-label="Permalink: 乳液：平滑量化训练的优化环境" href="#乳液平滑量化训练的优化环境"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv：2510.08757v1宣布类型：新摘要：为量化目标优化神经网络从根本上来说具有挑战性，因为量化器是逐段不变的，除了衍生物未定义的量化阈值之外，在任何地方都产生零梯度。大多数现有方法通过使用直通估计器（STE）等技术放松梯度计算来处理这个问题，并且不提供任何收敛保证。在这项工作中，从Nesterov平滑的灵感，我们近似的量化损失表面与连续的损失表面。特别是，我们引入了LOTION，通过s\textbf{T}随机-非\textbf{I}se sm\textbf {O}othi\textbf{N}g进行低精度优化，这是一个原则性的平滑框架，可以在无偏随机舍入噪声下用其期望值替换原始量化损失。在这个框架中，标准优化器保证收敛到损失曲面的局部最小值。此外，当使用来自随机舍入的噪声时，我们表明，原始量化损失的全局最小值被保留。我们的经验表明，这种方法优于标准的QAT合成测试平台和150 M和300 M参数的语言模型。</p>
<div class="markdown-heading"><h2 class="heading-element">用于减轻变压器中的极端令牌现象的值状态门控注意</h2><a id="user-content-用于减轻变压器中的极端令牌现象的值状态门控注意" class="anchor" aria-label="Permalink: 用于减轻变压器中的极端令牌现象的值状态门控注意" href="#用于减轻变压器中的极端令牌现象的值状态门控注意"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv：2510.09017v1宣布类型：新摘要：基于Transformer架构的大型模型容易受到极端令牌现象的影响，例如注意力下沉和值状态流失。这些会降低模型性能、量化保真度和可解释性的问题源于有问题的相互强化机制，其中模型通过将注意力集中在具有接近零值状态的代币上来学习低效的“无操作”行为。在本文中，我们提出了价值状态门控注意力（VGA），这是一种简单、专用且稳定的架构机制，通过直接打破这个循环来有效地执行“无操作”注意力。VGA引入了一个可学习的、数据相关的门，直接根据值载体（V）计算，来调制输出。通过对基础梯度的理论分析，我们表明，用自身的函数来门控价值状态在脱钩价值和注意力分数更新方面比之前门控输入嵌入的方法更有效。这创建了一个直接的监管途径，允许模型根据代币的新兴价值表示抑制代币的贡献。我们的实验表明，VGA显着减轻了注意力下沉的形成并稳定了价值状态规范，从而提高了性能、稳健的量化保真度和增强的模型解释性。</p>
<div class="markdown-heading"><h2 class="heading-element">本地法学硕士--动态局部控制的数学框架</h2><a id="user-content-本地法学硕士--动态局部控制的数学框架" class="anchor" aria-label="Permalink: 本地法学硕士--动态局部控制的数学框架" href="#本地法学硕士--动态局部控制的数学框架"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv：2510.09338v1宣布类型：新摘要：我们提出了一种新颖的框架，用于训练具有连续可调整的内部表示的大型语言模型，该表示涵盖从本地化（可解释、基于规则）到分布式（可概括、高效）编码的全方位。关键创新是局部旋钮，这是一种可调参数，可以动态控制训练和推理期间的局部化程度，而无需模型重新训练。这是通过对注意力机制、信息论锚点设计和动态规则注入的群体稀疏性惩罚来实现的。我们提供了严格的数学证明，建立了显式阈值条件，在此条件下，注意力可证明集中在语义相关块上，注意力熵和指针保真度具有指数界限。具体来说，我们证明，当组稀疏性惩罚超过某些阈值时，模型的注意力机制集中在语义相关的块上，以可忽略的误差实现低信息量和高保真度。该框架使从业者能够在可解释模式和高性能模式之间持续插入，支持需要透明度和能力的监管领域中的应用程序。</p>
<div class="markdown-heading"><h2 class="heading-element">FATHOMS-RAG：使用检索增强生成的多模式系统中思维和观察评估框架</h2><a id="user-content-fathoms-rag使用检索增强生成的多模式系统中思维和观察评估框架" class="anchor" aria-label="Permalink: FATHOMS-RAG：使用检索增强生成的多模式系统中思维和观察评估框架" href="#fathoms-rag使用检索增强生成的多模式系统中思维和观察评估框架"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv：2510.08945v1宣布类型：新摘要：检索增强生成（RAG）已成为提高大型语言模型（LLM）中事实准确性的一种有前途的范式。我们引入了一个旨在评估RAG管道整体的基准，评估管道吸收、检索和推理多种信息模式的能力，将其与专注于检索等特定方面的现有基准区分开来。我们提出了（1）一个由93个问题组成的小型人类创建的数据集，旨在评估管道吸收一个或多个文档中跨这些模式分布的文本数据、表格、图像和数据的能力;（2）短语级召回指标的正确性;（3）最近邻嵌入分类器，用于识别潜在的管道幻觉;（4）对使用开源检索机制构建的2个管道和4个开源基础模型的比较评估;以及（5）对我们的正确性和幻觉指标一致性的第三方人类评估。我们发现，封闭源管道在正确性和幻觉指标方面都明显优于开放源管道，在依赖多模式和跨文档信息的问题上存在更大的性能差距。对我们指标的人类评估显示，在1-5 Likert量表上，正确性的平均一致性为4.62，幻觉检测的平均一致性为4.53（5表示“强烈同意”）。</p>
<div class="markdown-heading"><h2 class="heading-element">交叉注意力在推荐模型中秘密执行垂直对齐</h2><a id="user-content-交叉注意力在推荐模型中秘密执行垂直对齐" class="anchor" aria-label="Permalink: 交叉注意力在推荐模型中秘密执行垂直对齐" href="#交叉注意力在推荐模型中秘密执行垂直对齐"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv：2510.09435v1宣布类型：新摘要：跨域顺序推荐（CDSR）旨在对齐从不同域收集的异类用户行为序列。虽然交叉注意被广泛用于增强一致性和提高推荐性能，但其底层机制尚未被完全理解。大多数研究者将交叉注意解释为剩余对齐，其中输出是通过引用另一个域数据（输入键和值）从查询输入中去除冗余信息并保留非冗余信息而生成的。除了流行的观点，我们引入正交对齐，交叉注意发现新的信息，是不存在于查询输入的现象，并进一步认为，这两个对比对齐机制可以共存于推荐模型。我们发现，当查询输入和输出的交叉注意是正交的，模型性能提高了300多个实验。值得注意的是，正交对齐自然出现，没有任何显式的正交约束。我们的关键见解是，正交对齐自然出现，因为它改进了缩放定律。我们表明，额外包含交叉注意模块的基线优于参数匹配的基线，从而实现了卓越的每个模型参数准确性。我们希望这些发现为多模式研究中的参数高效缩放提供新的方向。</p>
<div class="markdown-heading"><h2 class="heading-element">资源高效神经网络训练的自动进化优化</h2><a id="user-content-资源高效神经网络训练的自动进化优化" class="anchor" aria-label="Permalink: 资源高效神经网络训练的自动进化优化" href="#资源高效神经网络训练的自动进化优化"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv：2510.09566v1宣布类型：新摘要：优化神经网络模型存在许多关键挑战，包括分布式计算、压缩技术和高效训练，无论它们是否应用于特定任务。解决此类问题至关重要，因为对可扩展和资源高效模型的需求正在增加。为了应对这些挑战，我们开发了一个新的自动化机器学习（AutoML）框架，即具有鲁棒自动化的参数高效训练（PETRA）。它将进化优化应用于模型架构和训练策略。PETRA包括修剪、量化和损失正规化。对具有金融事件序列以及图像和时间序列（基准）的现实世界数据的实验研究证明了PETRA改进神经模型性能和可扩展性的能力--即模型大小（高达75%）和延迟（高达33%）显着减少，吞吐量（13%）增加（13%）而目标指标没有明显下降。</p>
<div class="markdown-heading"><h2 class="heading-element">Tiny-R1 V：通过模型合并的轻量级多模式统一推理模型</h2><a id="user-content-tiny-r1-v通过模型合并的轻量级多模式统一推理模型" class="anchor" aria-label="Permalink: Tiny-R1 V：通过模型合并的轻量级多模式统一推理模型" href="#tiny-r1-v通过模型合并的轻量级多模式统一推理模型"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv：2510.08987v1宣布类型：新摘要：尽管多模式大型语言模型（MLLM）在不同任务中表现出了非凡的能力，但它们在推理效率方面遇到了许多挑战，例如模型大小大、思考过度以及轻量级场景中的准确性受到影响。然而，对轻量级MLLM推理能力的研究相当缺乏。为此，我们提出Tiny-R1 V，这是一种新型的轻量级3B模型，通过两阶段优化实现更快的推理和更高的准确性，同时统一跨多个任务的多模式推理并使用更少的令牌。在第一阶段，Tiny-R1 V引入了一种新型强化学习方法--长度信息相对政策优化（LIPO）来训练每个推理模型。LIPO旨在动态调整群体内响应的优势，即通过优先考虑简洁但高质量的响应，以鼓励生成更短、更准确的响应。在第二阶段，我们提出自适应模型合并（AMM），这是一种免训练的模型合并方法，可以将多个专业模型合并到统一的架构中。具体来说，AMM自适应地调整任务载体的权重，并通过新颖的梯度投影正规化损失函数对合并后的载体进行鲁棒优化，从而减轻它们之间的冗余冲突。对涵盖数学、结构化数据（图表、表格、文档）、OCR和通用功能的十个广泛使用的推理基准进行了广泛评估，展示了Tiny-R1 V的卓越性能，使轻量级模型能够在各种多模式推理任务中表现出色。</p>
<div class="markdown-heading"><h2 class="heading-element">AdaPM：LLM培训的部分动量算法</h2><a id="user-content-adapmllm培训的部分动量算法" class="anchor" aria-label="Permalink: AdaPM：LLM培训的部分动量算法" href="#adapmllm培训的部分动量算法"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv：2510.09103v1宣布类型：新摘要：在大型语言模型的训练中，动量被广泛使用，并且经常被证明可以实现显着的加速。然而，储存动量通常会带来记忆方面的挑战。在本文中，我们提出了AdaPM，这是一种自适应训练策略，利用部分动量来实现内存高效优化器。为此，AdaPM采用非均匀动量设计：对于大多数块来说，完全动量并不需要保持优化的性能。在AdaPM的动量设计中，为了减轻部分动量造成的偏差和性能损失，我们通过偏差修正技术增强部分动量。从经验上看，我们验证了我们的方法在动量上减少了超过90%美元的内存，同时保持预训练60 M至1.5B的各种语言模型以及监督式微调和RL HF的效率和性能。通过结合二阶统计数据的内存高效技术，AdaPM可以在优化器状态中进一步减少高达95美元的内存，从而为预训练GPT-2 1.5B节省超过30美元的GPU小时。</p>
<div class="markdown-heading"><h2 class="heading-element">多模式提示优化：为什么不利用多模式实现MLLM</h2><a id="user-content-多模式提示优化为什么不利用多模式实现mllm" class="anchor" aria-label="Permalink: 多模式提示优化：为什么不利用多模式实现MLLM" href="#多模式提示优化为什么不利用多模式实现mllm"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv：2510.09201v1宣布类型：新摘要：大型语言模型（LLM）取得了显着的成功，其多模式扩展（MLLM）进一步释放了跨越图像、视频和文本以外的其他形式的功能。然而，尽管发生了这一转变，旨在减少手动提示制作负担同时最大化性能的提示优化方法仍然局限于文本，最终限制了MLLM的全部潜力。受此差距的启发，我们引入了多模式提示优化的新问题，该问题将提示优化的先前定义扩展到由文本和非文本提示对定义的多模式空间。为了解决这个问题，我们随后提出了多模式提示优化器（MPO），这是一个统一的框架，不仅通过保留印象的更新来执行多模式提示的联合优化，而且还通过利用早期评估作为先验来指导候选提示的选择过程基于Bayesian的选择策略。通过跨越文本（例如图像、视频甚至分子）的各种形式的广泛实验，我们证明MPO优于领先的纯文本优化方法，将多模式提示优化确立为实现MLLM潜力的关键一步。</p>
<div class="markdown-heading"><h2 class="heading-element">Logits Replay + Molip：稳定、低成本的训练后，忘记最少</h2><a id="user-content-logits-replay--molip稳定低成本的训练后忘记最少" class="anchor" aria-label="Permalink: Logits Replay + Molip：稳定、低成本的训练后，忘记最少" href="#logits-replay--molip稳定低成本的训练后忘记最少"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv：2510.09152v1宣布类型：新摘要：大型语言模型（LLM）在训练后常常面临权衡：专业领域的改进常常以牺牲通用能力为代价。现有的解决方案试图通过正规化、选择性参数更新或以数据为中心的重播来缓解这种紧张关系，但每种解决方案都在计算、数据访问或适应性方面带来了巨大的成本。最近的工作表明，训练信号可以被压缩到logit的子集，而不会出现严重的准确性损失，这为高效适应提供了一条途径。然而，天真截断会破坏优化的稳定并加剧遗忘。   我们引入了Logits Replay + MoTrap，这是一个两阶段框架，可以压缩logit空间中的监督并稳定更新级别的优化。在第0阶段，我们记录覆盖概率阈值的动态Top-K代币子集，始终包括黄金标签。在第1阶段，我们重播这些紧凑子集来计算精确的重正化损失，避免完全softmax计算和隐式正规化。为了确保稳定性，我们设计了MoTrap，这是一个优化器，可以限制梯度动量旋转并应用基于arctan 2的更新重新缩放。从经验上看，我们的方法提高了通信技术（CT）和NL 2SQL任务的领域性能，同时减少了一般基准测试（MMLU、BBH、GPQA、MATH）的遗忘，并将训练成本降低了40%以上。这些贡献共同为LLM的领域适应提供了一条可扩展的、架构不可知的路径，而不会牺牲通用性。</p>
<div class="markdown-heading"><h2 class="heading-element">iMoWM：驯服机器人操纵的交互式多模式世界模型</h2><a id="user-content-imowm驯服机器人操纵的交互式多模式世界模型" class="anchor" aria-label="Permalink: iMoWM：驯服机器人操纵的交互式多模式世界模型" href="#imowm驯服机器人操纵的交互式多模式世界模型"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv：2510.09036v1宣布类型：新摘要：经验丰富的世界模型在机器人操纵方面具有巨大的潜力，因为它们可以作为现实世界互动的模拟器。虽然基于2D视频的世界模型取得了广泛进展，但这些方法通常缺乏几何和空间推理，而几何和空间推理对于捕捉3D世界的物理结构至关重要。为了解决这一局限性，我们引入了iMoWM，这是一种新颖的交互式世界模型，旨在以基于动作的自回归方式生成彩色图像、深度图和机器人手臂面罩。为了克服与三维信息相关的高计算成本，我们提出了MMTokenizer，它将多模式输入统一为紧凑的令牌表示。该设计使iMoWM能够利用大规模预训练的VideoGPT模型，同时保持高效率并融入更丰富的物理信息。凭借其多模式表示，iMoWM不仅提高了未来预测的视觉质量，而且还充当基于模型的强化学习（MBRL）的有效模拟器，并促进了现实世界的模仿学习。大量实验证明了iMoWM在这些任务中的优越性，展示了机器人操纵的多模式世界建模的优势。主页：<a href="https://xingyoujun.github.io/imowm/" rel="nofollow">https://xingyoujun.github.io/imowm/</a></p>
<div class="markdown-heading"><h2 class="heading-element">FLToP CTC：通过相对阈值进行帧级令牌修剪，以在不同平台上进行高效且节省内存的解码</h2><a id="user-content-fltop-ctc通过相对阈值进行帧级令牌修剪以在不同平台上进行高效且节省内存的解码" class="anchor" aria-label="Permalink: FLToP CTC：通过相对阈值进行帧级令牌修剪，以在不同平台上进行高效且节省内存的解码" href="#fltop-ctc通过相对阈值进行帧级令牌修剪以在不同平台上进行高效且节省内存的解码"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv：2510.09085v1宣布类型：新摘要：基于ATC的ASB系统在资源有限的环境中面临计算和内存瓶颈。传统的CTC解码器，需要系统中高达90%的处理时间（例如，wav 2 vec 2-L4图形处理器上的大型），由于详尽的代币级操作而面临效率低下的问题。本文介绍了连接主义时态分类的帧级令牌修剪（FLToP CTC），这是一种新型解码算法，采用相对阈值概率指导的帧级令牌修剪。通过动态消除每帧的低概率令牌，FLToP CTC减少了计算和内存需求，同时保持可忽略的WER降级。在LibriSpeech上，FLToP CTC与标准CTC解码器相比实现了10.5倍的运行时加速和2.78倍的内存减少。其简单性使得跨平台（中央处理器、图形处理器等）无缝集成到CTC解码器中。FLToP CTC解决了CTC瓶颈，为资源有限的环境和实时应用程序提供可扩展性，增强语音识别的可访问性和效率。</p>
<div class="markdown-heading"><h2 class="heading-element">LM Fight Arena：通过游戏竞赛对大型多模式进行基准测试</h2><a id="user-content-lm-fight-arena通过游戏竞赛对大型多模式进行基准测试" class="anchor" aria-label="Permalink: LM Fight Arena：通过游戏竞赛对大型多模式进行基准测试" href="#lm-fight-arena通过游戏竞赛对大型多模式进行基准测试"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv：2510.08928v1宣布类型：新摘要：大型多模式模型（LSYS）的现有基准常常无法捕捉其在实时对抗环境中的性能。我们介绍了LM Fight Arena（大型模型Fight Arena），这是一个新颖的框架，通过在经典格斗游戏《真人快打II》中将Letts相互对抗来评估Letts，这项任务需要快速的视觉理解和战术、顺序决策。在受控锦标赛中，我们测试了六种领先的开源和开源模型，其中每个代理控制同一角色，以确保公平的比较。系统会提示模型解释游戏框架和状态数据以选择下一步动作。与静态评估不同，LM Fight Arena在动态环境中提供了对LMM战略推理能力的完全自动化、可重复且客观的评估。这项工作引入了一个具有挑战性且引人入胜的基准，弥合了人工智能评估和互动娱乐之间的差距。</p>
<div class="markdown-heading"><h2 class="heading-element">ADE：强化学习的概念驱动探索</h2><a id="user-content-ade强化学习的概念驱动探索" class="anchor" aria-label="Permalink: ADE：强化学习的概念驱动探索" href="#ade强化学习的概念驱动探索"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv：2510.08851v1宣布类型：新摘要：智能探索仍然是强化学习（RL）的一个关键挑战，尤其是在视觉控制任务中。与低维基于状态的RL不同，视觉RL必须从原始像素中提取与任务相关的结构，这使得探索效率低下。我们提出了概念驱动探索（ADE），它利用预先训练的视觉语言模型（VLM）从文本任务描述中生成以对象为中心的视觉概念，作为弱的、潜在有噪音的监督信号。ADE不是直接影响这些有噪音的信号，而是训练一项通过辅助目标重建概念的策略，使用重建准确性作为内在奖励来指导探索任务相关对象。由于该策略内化了这些概念，因此仅在培训期间需要VLM查询，从而减少了部署期间对外部模型的依赖。在五个具有挑战性的模拟视觉操纵任务中，ADE实现了高效、有针对性的探索，并对有噪音的VLM预测保持稳健。最后，我们通过在Franka Research 3手臂上部署ADE来演示现实世界的转移，在现实世界的操纵任务中获得了80%的成功率。</p>
<div class="markdown-heading"><h2 class="heading-element">SQS：通过稀疏量化子分布的Bayesian DNN压缩</h2><a id="user-content-sqs通过稀疏量化子分布的bayesian-dnn压缩" class="anchor" aria-label="Permalink: SQS：通过稀疏量化子分布的Bayesian DNN压缩" href="#sqs通过稀疏量化子分布的bayesian-dnn压缩"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv：2510.08999v1宣布类型：新摘要：压缩大规模神经网络对于在资源受限的设备上部署模型至关重要。大多数现有方法单独采用权重修剪或低位量化，通常会导致次优压缩率以保持可接受的性能下降。我们引入了一个通过Bayesian变分学习（SQS）同时修剪和低位量化的统一框架，该框架可以实现比之前基线更高的压缩率，同时保持相当的性能。关键想法是在诱导稀疏性之前采用尖峰和板，并使用高斯混合模型（GSYS）对量化权重进行建模，以实现低位精度。理论上，我们为稀疏和量化的深度神经网络提供了我们提出的变分方法的一致结果。压缩ResNet、BERT-base、Llama 3和Qwen 2.5模型的大量实验表明，我们的方法比一系列现有方法实现了更高的压缩率，但性能下降相当。</p>
</div></div><div class="footer container-xl width-full p-responsive"><div class="position-relative flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between pt-4 pb-4 mt-6 f6 color-text-secondary border-top color-border-secondary text-center"><div class="footer-octicon d-lg-block mx-lg-4"><a title="LLIKKE/Arxiv_GPT_Assistant" href="https://github.com/LLIKKE/Arxiv_GPT_Assistant" target="_blank" rel="noreferrer noopener"><svg class="octicon octicon-mark-github gh-logo" width="36" height="36" viewBox="0 0 98 98" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"></path></svg></a></div><span class="mt-2 d-block footprint"><span>powered by </span><a href="https://github.com/wranders/markdown-to-pages-action" target="_blank" rel="noreferrer noopener">markdown-to-pages-action</a></span></div></div></body></html>