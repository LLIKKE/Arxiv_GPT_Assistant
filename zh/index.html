<!DOCTYPE html><html data-color-mode="light" data-light-theme="light" data-dark-theme="dark" lang="en-US"><head><title>LLIKKE/gpt_paper_assistant_ori</title><meta charset="utf-8"><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="description" content="Deepseek based personalized ArXiv paper assistant bot"><link rel="canonical" href="https://llikke.github.io/gpt_paper_assistant_ori/"><meta property="og:title" content="LLIKKE/gpt_paper_assistant_ori"><meta property="og:type" content="website"><meta property="og:url" content="https://llikke.github.io/gpt_paper_assistant_ori/"><meta property="og:description" content="Deepseek based personalized ArXiv paper assistant bot"><meta property="og:locale" content="en_US"><meta property="og:site_name" content="LLIKKE/gpt_paper_assistant_ori"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="LLIKKE/gpt_paper_assistant_ori"><meta name="twitter:description" content="Deepseek based personalized ArXiv paper assistant bot"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon.png" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon.svg" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon-dark.png" media="(prefers-color-scheme: dark)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon-dark.svg" media="(prefers-color-scheme: dark)"><link rel="mask-icon" href="https://github.githubassets.com/pinned-octocat.svg" color="#000000"><link href="index.css" rel="stylesheet"></head><body><div class="container-lg px-3 my-5 markdown-body"><div class="position-relative"><span class="profile-color-modes-toggle js-promo-color-modes-toggle" tabindex="0" aria-label="Toggle dark mode" aria-checked="true" role="checkbox"><div class="profile-color-modes-toggle-track" div></div><div class="profile-color-modes-toggle-thumb"><svg style="fill: var(--color-scale-yellow-0); margin: 7px 0 0 7px;" aria-hidden="true" width="14" height="13" viewBox="0 0 14 13" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.52208 7.71754C7.5782 7.71754 10.0557 5.24006 10.0557 2.18394C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961C9.95801 1.07727 10.3495 0.771159 10.6474 0.99992C12.1153 2.12716 13.0615 3.89999 13.0615 5.89383C13.0615 9.29958 10.3006 12.0605 6.89485 12.0605C3.95334 12.0605 1.49286 10.001 0.876728 7.24527C0.794841 6.87902 1.23668 6.65289 1.55321 6.85451C2.41106 7.40095 3.4296 7.71754 4.52208 7.71754Z"></path></svg></div></span></div><script type="text/javascript">(function() {
  var MODE_KEY = 'markdown_to_pages_dark_mode';
  function toggleMode() {
    var mode = document.documentElement.getAttribute('data-color-mode') === 'light' ? 'dark' : 'light';
    document.documentElement.setAttribute('data-color-mode', mode);
    localStorage.setItem(MODE_KEY, mode);
  }
  var mode = localStorage.getItem(MODE_KEY);
  if (mode == null) {
    var query = window.matchMedia('(prefers-color-scheme: dark)');
    mode = query.matches ? 'dark' : 'light';
  }
  document.documentElement.setAttribute('data-color-mode', mode);
  document.querySelector('.profile-color-modes-toggle').onclick = toggleMode;
})();</script><div><div class="markdown-heading"><h2 class="heading-element">等级也很重要：LLM微调中适配器专家混合的层级配置</h2><a id="user-content-等级也很重要llm微调中适配器专家混合的层级配置" class="anchor" aria-label="Permalink: 等级也很重要：LLM微调中适配器专家混合的层级配置" href="#等级也很重要llm微调中适配器专家混合的层级配置"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2502.03884v1 公告类型：新发布 摘要：大型语言模型（LLMs）在各种任务中表现出显著的成功，伴随着其参数规模的持续增加。参数高效微调（PEFT）方法，如低秩适应（LoRA），通过显著减少可训练参数的数量来解决微调LLMs的挑战。最近的研究将LoRA与专家混合（MoE）架构相结合，利用多个适配器专家和门控机制来进一步提高微调性能。然而，现有方法主要关注调整每层的适配器专家分配以优化引入的可训练参数大小，而忽略了适配器秩的关键因素。为此，我们提出了一种专家分配和秩配置的分层方案HILO，该方案动态调整各层适配器专家的数量和秩，以匹配适配器粒度下模型层的不同表征复杂性。在多个基准任务上的大量实验表明，HILO在精度方面优于现有方法，同时引入更少的可训练参数，为LLMs的微调提供了一种高效实用的解决方案。</p>
<div class="markdown-heading"><h2 class="heading-element">从配置空间清理到特征空间边缘：基于学习的碰撞检测中的样本复杂性</h2><a id="user-content-从配置空间清理到特征空间边缘基于学习的碰撞检测中的样本复杂性" class="anchor" aria-label="Permalink: 从配置空间清理到特征空间边缘：基于学习的碰撞检测中的样本复杂性" href="#从配置空间清理到特征空间边缘基于学习的碰撞检测中的样本复杂性"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2502.04170v1 通告类型：新论文  摘要：运动规划是机器人领域的一个核心挑战，近年来基于学习的方法受到了广泛关注。我们的工作关注这些方法的一个特定方面：利用机器学习技术，尤其是支持向量机（SVM），来评估机器人配置是否存在碰撞，这一操作被称为“碰撞检测”。尽管这些方法越来越受欢迎，但支持其效率和预测精度的理论却不足。这与机器学习方法，尤其是SVM的一般理论成果和丰富理论结果形成鲜明对比。我们的工作通过分析用于运动规划中基于学习的碰撞检测的支持向量机分类器的样本复杂度来弥合这一差距。我们限制了在给定置信水平下达到指定精度所需的样本数量。这一结果用与机器人运动规划相关的术语来表述，例如系统的安全距离。基于这些理论结果，我们提出了一种碰撞检测算法，该算法还可以就算法在将机器人配置分类为无碰撞或碰撞时的错误提供统计保证。</p>
<div class="markdown-heading"><h2 class="heading-element">正交表示学习用于估计因果量</h2><a id="user-content-正交表示学习用于估计因果量" class="anchor" aria-label="Permalink: 正交表示学习用于估计因果量" href="#正交表示学习用于估计因果量"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2502.04274v1 公告类型：新论文 摘要：表示学习被广泛用于从观察数据中估计因果关系量（例如，条件平均处理效应）。虽然现有的表示学习方法具有端到端学习的优势，但它们没有Neyman-正交学习者的有利理论特性，如双重稳健性和准最优效率。此外，这类表示学习方法通常采用额外的约束，如平衡，甚至可能导致估计不一致。在本文中，我们提出了一类新的Neyman-正交学习者，用于在表示层面上定义的因果关系量，我们称之为OR-学习者。我们的OR-学习者具有几个实际优势：它们允许基于任何学习到的表示来一致估计因果关系量，同时提供包括双重稳健性和准最优效率在内的有利理论特性。在多次实验中，我们表明，在一定的正则性条件下，我们的OR-学习者改进了现有的表示学习方法，并实现了最先进的性能。据我们所知，我们的OR-学习者是第一个为因果关系量估计提供表示学习方法与Neyman-正交学习者统一框架的工作。</p>
<div class="markdown-heading"><h2 class="heading-element">生成对抗网络：架起艺术与机器智能的桥梁</h2><a id="user-content-生成对抗网络架起艺术与机器智能的桥梁" class="anchor" aria-label="Permalink: 生成对抗网络：架起艺术与机器智能的桥梁" href="#生成对抗网络架起艺术与机器智能的桥梁"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2502.04116v1 公告类型：新书 Abstract：本书从对生成对抗网络（GANs）的基本原理和历史发展的详细介绍开始，通过与传统的生成模型进行对比，并通过Python示例阐明其核心对抗机制。文本系统地处理了数学和理论基础，包括概率论、统计学和博弈论，为理解GAN训练固有的目标、损失函数和优化挑战提供了一个坚实的框架。随后的章节回顾了经典变体，如条件GANs、DCGANs、InfoGAN和LAPGAN，然后进入高级训练方法，如Wasserstein GANs、带梯度惩罚的GANs、最小二乘GANs和谱归一化技术。本书进一步探讨了生成器和判别器的架构改进和特定任务适应性，展示了在高分辨率图像生成、艺术风格迁移、视频合成、文本到图像生成和其他多媒体应用中的实际实现。结论部分提供了对新兴研究趋势的见解，包括自注意力机制、基于Transformer的生成模型，以及与扩散模型的比较分析，从而为学术和应用环境中未来发展的有希望的方向进行了规划。</p>
</div></div><div class="footer container-xl width-full p-responsive"><div class="position-relative flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between pt-4 pb-4 mt-6 f6 color-text-secondary border-top color-border-secondary text-center"><div class="footer-octicon d-lg-block mx-lg-4"><a title="LLIKKE/gpt_paper_assistant_ori" href="https://github.com/LLIKKE/gpt_paper_assistant_ori" target="_blank" rel="noreferrer noopener"><svg class="octicon octicon-mark-github gh-logo" width="36" height="36" viewBox="0 0 98 98" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"></path></svg></a></div><span class="mt-2 d-block footprint"><span>powered by </span><a href="https://github.com/wranders/markdown-to-pages-action" target="_blank" rel="noreferrer noopener">markdown-to-pages-action</a></span></div></div></body></html>