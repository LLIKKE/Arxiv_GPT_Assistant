<!DOCTYPE html><html data-color-mode="light" data-light-theme="light" data-dark-theme="dark" lang="en-US"><head><title>LLIKKE/Arxiv_GPT_Assistant</title><meta charset="utf-8"><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="description" content="Deepseek based personalized ArXiv paper assistant bot"><link rel="canonical" href="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta property="og:type" content="website"><meta property="og:url" content="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:description" content="Deepseek based personalized ArXiv paper assistant bot"><meta property="og:locale" content="en_US"><meta property="og:site_name" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:description" content="Deepseek based personalized ArXiv paper assistant bot"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon.png" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon.svg" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon-dark.png" media="(prefers-color-scheme: dark)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon-dark.svg" media="(prefers-color-scheme: dark)"><link rel="mask-icon" href="https://github.githubassets.com/pinned-octocat.svg" color="#000000"><link href="index.css" rel="stylesheet"></head><body><div class="container-lg px-3 my-5 markdown-body"><div class="position-relative"><span class="profile-color-modes-toggle js-promo-color-modes-toggle" tabindex="0" aria-label="Toggle dark mode" aria-checked="true" role="checkbox"><div class="profile-color-modes-toggle-track" div></div><div class="profile-color-modes-toggle-thumb"><svg style="fill: var(--color-scale-yellow-0); margin: 7px 0 0 7px;" aria-hidden="true" width="14" height="13" viewBox="0 0 14 13" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.52208 7.71754C7.5782 7.71754 10.0557 5.24006 10.0557 2.18394C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961C9.95801 1.07727 10.3495 0.771159 10.6474 0.99992C12.1153 2.12716 13.0615 3.89999 13.0615 5.89383C13.0615 9.29958 10.3006 12.0605 6.89485 12.0605C3.95334 12.0605 1.49286 10.001 0.876728 7.24527C0.794841 6.87902 1.23668 6.65289 1.55321 6.85451C2.41106 7.40095 3.4296 7.71754 4.52208 7.71754Z"></path></svg></div></span></div><script type="text/javascript">(function() {
  var MODE_KEY = 'markdown_to_pages_dark_mode';
  function toggleMode() {
    var mode = document.documentElement.getAttribute('data-color-mode') === 'light' ? 'dark' : 'light';
    document.documentElement.setAttribute('data-color-mode', mode);
    localStorage.setItem(MODE_KEY, mode);
  }
  var mode = localStorage.getItem(MODE_KEY);
  if (mode == null) {
    var query = window.matchMedia('(prefers-color-scheme: dark)');
    mode = query.matches ? 'dark' : 'light';
  }
  document.documentElement.setAttribute('data-color-mode', mode);
  document.querySelector('.profile-color-modes-toggle').onclick = toggleMode;
})();</script><div><div class="markdown-heading"><h1 class="heading-element">Personalized Daily Arxiv Papers 08/19/2025</h1><a id="user-content-personalized-daily-arxiv-papers-08192025" class="anchor" aria-label="Permalink: Personalized Daily Arxiv Papers 08/19/2025" href="#personalized-daily-arxiv-papers-08192025"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>Total relevant papers: 56</p>
<p>Paper selection prompt and criteria at the bottom</p>
<p>Table of contents with paper titles:</p>
<ol start="0">
<li>
<p><a href="#link0">PC-Sampler: Position-Aware Calibration of Decoding Bias in Masked Diffusion Models</a>
<strong>Authors:</strong> Pengcheng Huang, Shuhao Liu, Zhenghao Liu, Yukun Yan, Shuo Wang, Zulong Chen, Tong Xiao</p>
</li>
<li>
<p><a href="#link1">Temporal and Rotational Calibration for Event-Centric Multi-Sensor Systems</a>
<strong>Authors:</strong> Jiayao Mai, Xiuyuan Lu, Kuan Dai, Shaojie Shen, Yi Zhou</p>
</li>
<li>
<p><a href="#link2">AI Models for Depressive Disorder Detection and Diagnosis: A Review</a>
<strong>Authors:</strong> Dorsa Macky Aleagha, Payam Zohari, Mostafa Haghir Chehreghani</p>
</li>
<li>
<p><a href="#link3">RadarQA: Multi-modal Quality Analysis of Weather Radar Forecasts</a>
<strong>Authors:</strong> Xuming He, Zhiyuan You, Junchao Gong, Couhua Liu, Xiaoyu Yue, Peiqin Zhuang, Wenlong Zhang, Lei Bai</p>
</li>
<li>
<p><a href="#link4">Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware</a>
<strong>Authors:</strong> Yuannuo Feng, Wenyong Zhou, Yuexi Lyu, Yixiang Zhang, Zhengwu Liu, Ngai Wong, Wang Kang</p>
</li>
<li>
<p><a href="#link5">L-SR1: Learned Symmetric-Rank-One Preconditioning</a>
<strong>Authors:</strong> Gal Lifshitz, Shahar Zuler, Ori Fouks, Dan Raviv</p>
</li>
<li>
<p><a href="#link6">Trust Region Constrained Measure Transport in Path Space for Stochastic Optimal Control and Inference</a>
<strong>Authors:</strong> Denis Blessing, Julius Berner, Lorenz Richter, Carles Domingo-Enrich, Yuanqi Du, Arash Vahdat, Gerhard Neumann</p>
</li>
<li>
<p><a href="#link7">Mantis: A Simulation-Grounded Foundation Model for Disease Forecasting</a>
<strong>Authors:</strong> Carson Dudley, Reiden Magdaleno, Christopher Harding, Ananya Sharma, Emily Martin, Marisa Eisenberg</p>
</li>
<li>
<p><a href="#link8">Score-informed Neural Operator for Enhancing Ordering-based Causal Discovery</a>
<strong>Authors:</strong> Jiyeon Kang, Songseong Kim, Chanhui Lee, Doyeong Hwang, Joanie Hayoun Chung, Yunkyung Ko, Sumin Lee, Sungwoong Kim, Sungbin Lim</p>
</li>
<li>
<p><a href="#link9">Sparse Attention across Multiple-context KV Cache</a>
<strong>Authors:</strong> Ziyi Cao, Qingyi Si, Jingbin Zhang, Bingquan Liu</p>
</li>
<li>
<p><a href="#link10">Fed-Meta-Align: A Similarity-Aware Aggregation and Personalization Pipeline for Federated TinyML on Heterogeneous Data</a>
<strong>Authors:</strong> Hemanth Macharla, Mayukha Pal</p>
</li>
<li>
<p><a href="#link11">Energy-Efficient Wireless LLM Inference via Uncertainty and Importance-Aware Speculative Decoding</a>
<strong>Authors:</strong> Jihoon Park, Seungeun Oh, Seong-Lyun Kim</p>
</li>
<li>
<p><a href="#link12">FedSODA: Federated Fine-tuning of LLMs via Similarity Group Pruning and Orchestrated Distillation Alignment</a>
<strong>Authors:</strong> Manning Zhu, Songtao Guo, Pengzhan Zhou, Yansong Ning, Chang Han, Dewen Qiao</p>
</li>
<li>
<p><a href="#link13">ENA: Efficient N-dimensional Attention</a>
<strong>Authors:</strong> Yibo Zhong</p>
</li>
<li>
<p><a href="#link14">Self-Guided Action Diffusion</a>
<strong>Authors:</strong> Rhea Malhotra, Yuejiang Liu, Chelsea Finn</p>
</li>
<li>
<p><a href="#link15">Simultaneous Contact Sequence and Patch Planning for Dynamic Locomotion</a>
<strong>Authors:</strong> Victor Dh'edin, Haizhou Zhao, Majid Khadiv</p>
</li>
<li>
<p><a href="#link16">FlowMol3: Flow Matching for 3D De Novo Small-Molecule Generation</a>
<strong>Authors:</strong> Ian Dunn, David R. Koes</p>
</li>
<li>
<p><a href="#link17">FLARE: Fast Low-rank Attention Routing Engine</a>
<strong>Authors:</strong> Vedant Puri, Aditya Joglekar, Kevin Ferguson, Yu-hsuan Chen, Yongjie Jessica Zhang, Levent Burak Kara</p>
</li>
<li>
<p><a href="#link18">Towards Open-Ended Emotional Support Conversations in LLMs via Reinforcement Learning with Future-Oriented Rewards</a>
<strong>Authors:</strong> Ting Yang, Li Chen, Huimin Wang</p>
</li>
<li>
<p><a href="#link19">e-boost: Boosted E-Graph Extraction with Adaptive Heuristics and Exact Solving</a>
<strong>Authors:</strong> Jiaqi Yin, Zhan Song, Chen Chen, Yaohui Cai, Zhiru Zhang, Cunxi Yu</p>
</li>
<li>
<p><a href="#link20">OmniD: Generalizable Robot Manipulation Policy via Image-Based BEV Representation</a>
<strong>Authors:</strong> Jilei Mao, Jiarui Guan, Yingjuan Tang, Qirui Hu, Zhihang Li, Junjie Yu, Yongjie Mao, Yunzhe Sun, Shuang Liu, Xiaozhu Ju</p>
</li>
<li>
<p><a href="#link21">Generative Medical Event Models Improve with Scale</a>
<strong>Authors:</strong> Shane Waxler, Paul Blazek, Davis White, Daniel Sneider, Kevin Chung, Mani Nagarathnam, Patrick Williams, Hank Voeller, Karen Wong, Matthew Swanhorst, Sheng Zhang, Naoto Usuyama, Cliff Wong, Tristan Naumann, Hoifung Poon, Andrew Loza, Daniella Meeker, Seth Hain, Rahul Shah</p>
</li>
<li>
<p><a href="#link22">Fairness-Aware Multi-view Evidential Learning with Adaptive Prior</a>
<strong>Authors:</strong> Haishun Chen, Cai Xu, Jinlong Yu, Yilin Zhang, Ziyu Guan, Wei Zhao</p>
</li>
<li>
<p><a href="#link23">MAPF-World: Action World Model for Multi-Agent Path Finding</a>
<strong>Authors:</strong> Zhanjiang Yang, Meng Li, Yang Shen, Yueming Li, Lijun Sun</p>
</li>
<li>
<p><a href="#link24">GraphCogent: Overcoming LLMs' Working Memory Constraints via Multi-Agent Collaboration in Complex Graph Understanding</a>
<strong>Authors:</strong> Rongzheng Wang, Qizhi Chen, Yihong Huang, Yizhuo Ma, Muquan Li, Jiakai Li, Ke Qin, Guangchun Luo, Shuang Liang</p>
</li>
<li>
<p><a href="#link25">Maximum Score Routing For Mixture-of-Experts</a>
<strong>Authors:</strong> Bowen Dong, Yilong Fan, Yutao Sun, Zhenyu Li, Tengyu Pan, Xun Zhou, Jianyong Wang</p>
</li>
<li>
<p><a href="#link26">MDPO: Overcoming the Training-Inference Divide of Masked Diffusion Language Models</a>
<strong>Authors:</strong> Haoyu He, Katrin Renz, Yong Cao, Andreas Geiger</p>
</li>
<li>
<p><a href="#link27">Communication-Efficient Distributed Asynchronous ADMM</a>
<strong>Authors:</strong> Sagar Shrestha</p>
</li>
<li>
<p><a href="#link28">CRoC: Context Refactoring Contrast for Graph Anomaly Detection with Limited Supervision</a>
<strong>Authors:</strong> Siyue Xie, Da Sun Handason Tam, Wing Cheong Lau</p>
</li>
<li>
<p><a href="#link29">FedUNet: A Lightweight Additive U-Net Module for Federated Learning with Heterogeneous Models</a>
<strong>Authors:</strong> Beomseok Seo, Kichang Lee, JaeYeon Park</p>
</li>
<li>
<p><a href="#link30">Time-Scale Coupling Between States and Parameters in Recurrent Neural Networks</a>
<strong>Authors:</strong> Lorenzo Livi</p>
</li>
<li>
<p><a href="#link31">Geodesic Tracing-Based Kinematic Integration of Rolling and Sliding Contact on Manifold Meshes for Dexterous In-Hand Manipulation</a>
<strong>Authors:</strong> Sunyu Wang, Arjun S. Lakshmipathy, Jean Oh, Nancy S. Pollard</p>
</li>
<li>
<p><a href="#link32">Reinforcement Learning with Rubric Anchors</a>
<strong>Authors:</strong> Zenan Huang, Yihong Zhuang, Guoshan Lu, Zeyu Qin, Haokai Xu, Tianyu Zhao, Ru Peng, Jiaqi Hu, Zhanming Shen, Xiaomeng Hu, Xijun Gu, Peiyi Tu, Jiaxin Liu, Wenyu Chen, Yuzhuo Fu, Zhiting Fan, Yanmei Gu, Yuanyuan Wang, Zhengkai Yang, Jianguo Li, Junbo Zhao</p>
</li>
<li>
<p><a href="#link33">Talk Less, Fly Lighter: Autonomous Semantic Compression for UAV Swarm Communication via LLMs</a>
<strong>Authors:</strong> Fei Lin, Tengchao Zhang, Qinghua Ni, Jun Huang, Siji Ma, Yonglin Tian, Yisheng Lv, Naiqi Wu</p>
</li>
<li>
<p><a href="#link34">SparseMap: A Sparse Tensor Accelerator Framework Based on Evolution Strategy</a>
<strong>Authors:</strong> Boran Zhao, Haiming Zhai, Zihang Yuan, Hetian Liu, Tian Xia, Wenzhe Zhao, Pengju Ren</p>
</li>
<li>
<p><a href="#link35">Contrastive Regularization over LoRA for Multimodal Biomedical Image Incremental Learning</a>
<strong>Authors:</strong> Haojie Zhang, Yixiong Liang, Hulin Kuang, Lihui Cen, Zhe Qu, Yigang Cen, Min Zeng, Shichao Kan</p>
</li>
<li>
<p><a href="#link36">Illuminating LLM Coding Agents: Visual Analytics for Deeper Understanding and Enhancement</a>
<strong>Authors:</strong> Junpeng Wang, Yuzhong Chen, Menghai Pan, Chin-Chia Michael Yeh, Mahashweta Das</p>
</li>
<li>
<p><a href="#link37">FedUHD: Unsupervised Federated Learning using Hyperdimensional Computing</a>
<strong>Authors:</strong> You Hak Lee, Xiaofan Yu, Quanling Zhao, Flavio Ponzina, Tajana Rosing</p>
</li>
<li>
<p><a href="#link38">BUILDA: A Thermal Building Data Generation Framework for Transfer Learning</a>
<strong>Authors:</strong> Thomas Krug, Fabian Raisch, Dominik Aimer, Markus Wirnsberger, Ferdinand Sigg, Benjamin Sch"afer, Benjamin Tischler</p>
</li>
<li>
<p><a href="#link39">EvoCut: Strengthening Integer Programs via Evolution-Guided Language Models</a>
<strong>Authors:</strong> Milad Yazdani, Mahdi Mostajabdaveh, Samin Aref, Zirui Zhou</p>
</li>
<li>
<p><a href="#link40">GALA: Can Graph-Augmented Large Language Model Agentic Workflows Elevate Root Cause Analysis?</a>
<strong>Authors:</strong> Yifang Tian, Yaming Liu, Zichun Chong, Zihang Huang, Hans-Arno Jacobsen</p>
</li>
<li>
<p><a href="#link41">Wavy Transformer</a>
<strong>Authors:</strong> Satoshi Noguchi, Yoshinobu Kawahara</p>
</li>
<li>
<p><a href="#link42">STM3: Mixture of Multiscale Mamba for Long-Term Spatio-Temporal Time-Series Prediction</a>
<strong>Authors:</strong> Haolong Chen, Liang Zhang, Zhengyuan Xin, Guangxu Zhu</p>
</li>
<li>
<p><a href="#link43">Fully Spiking Actor-Critic Neural Network for Robotic Manipulation</a>
<strong>Authors:</strong> Liwen Zhang, Heng Deng, Guanghui Sun</p>
</li>
<li>
<p><a href="#link44">QuarkMed Medical Foundation Model Technical Report</a>
<strong>Authors:</strong> Ao Li, Bin Yan, Bingfeng Cai, Chenxi Li, Cunzhong Zhao, Fugen Yao, Gaoqiang Liu, Guanjun Jiang, Jian Xu, Liang Dong, Liansheng Sun, Rongshen Zhang, Xiaolei Gui, Xin Liu, Xin Shang, Yao Wu, Yu Cao, Zhenxin Ma, Zhuang Jia</p>
</li>
<li>
<p><a href="#link45">An LLM + ASP Workflow for Joint Entity-Relation Extraction</a>
<strong>Authors:</strong> Trang Tran, Trung Hoang Le, Huiping Cao, Tran Cao Son</p>
</li>
<li>
<p><a href="#link46">Deploying Models to Non-participating Clients in Federated Learning without Fine-tuning: A Hypernetwork-based Approach</a>
<strong>Authors:</strong> Yuhao Zhou, Jindi Lv, Yuxin Tian, Dan Si, Qing Ye, Jiancheng Lv</p>
</li>
<li>
<p><a href="#link47">UniCast: A Unified Multimodal Prompting Framework for Time Series Forecasting</a>
<strong>Authors:</strong> Sehyuk Park, Soyeon Caren Han, Eduard Hovy</p>
</li>
<li>
<p><a href="#link48">RLNVR: Reinforcement Learning from Non-Verified Real-World Rewards</a>
<strong>Authors:</strong> Rohit Krishnan, Jon Evans</p>
</li>
<li>
<p><a href="#link49">Distribution Matching via Generalized Consistency Models</a>
<strong>Authors:</strong> Sagar Shrestha, Rajesh Shrestha, Tri Nguyen, Subash Timilsina</p>
</li>
<li>
<p><a href="#link50">ProtTeX-CC: Activating In-Context Learning in Protein LLM via Two-Stage Instruction Compression</a>
<strong>Authors:</strong> Chuanliu Fan, Zicheng Ma, Jun Gao, Nan Yu, Jun Zhang, Ziqiang Cao, Yi Qin Gao, Guohong Fu</p>
</li>
<li>
<p><a href="#link51">Help or Hurdle? Rethinking Model Context Protocol-Augmented Large Language Models</a>
<strong>Authors:</strong> Wei Song, Haonan Zhong, Ziqi Ding, Jingling Xue, Yuekang Li</p>
</li>
<li>
<p><a href="#link52">SL-ACC: A Communication-Efficient Split Learning Framework with Adaptive Channel-wise Compression</a>
<strong>Authors:</strong> Zehang Lin, Zheng Lin, Miao Yang, Jianhao Huang, Yuxin Zhang, Zihan Fang, Xia Du, Zhe Chen, Shunzhi Zhu, Wei Ni</p>
</li>
<li>
<p><a href="#link53">DynamixSFT: Dynamic Mixture Optimization of Instruction Tuning Collections</a>
<strong>Authors:</strong> Haebin Shin, Lei Ji, Xiao Liu, Zhiwei Yu, Qi Chen, Yeyun Gong</p>
</li>
<li>
<p><a href="#link54">Learning to Steer: Input-dependent Steering for Multimodal LLMs</a>
<strong>Authors:</strong> Jayneel Parekh, Pegah Khayatan, Mustafa Shukor, Arnaud Dapogny, Alasdair Newson, Matthieu Cord</p>
</li>
<li>
<p><a href="#link55">Seeing the Many: Exploring Parameter Distributions Conditioned on Features in Surrogates</a>
<strong>Authors:</strong> Xiaohan Wang, Zhimin Li, Joshua A. Levine, Matthew Berger</p>
</li>
</ol>
<hr>
<div class="markdown-heading"><h2 class="heading-element">0. <a href="https://arxiv.org/abs/2508.13021" rel="nofollow">PC-Sampler: Position-Aware Calibration of Decoding Bias in Masked Diffusion Models</a> <a id="user-content-link0"></a>
</h2><a id="user-content-0-pc-sampler-position-aware-calibration-of-decoding-bias-in-masked-diffusion-models-" class="anchor" aria-label="Permalink: 0. PC-Sampler: Position-Aware Calibration of Decoding Bias in Masked Diffusion Models" href="#0-pc-sampler-position-aware-calibration-of-decoding-bias-in-masked-diffusion-models-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.13021
<strong>Authors:</strong> Pengcheng Huang, Shuhao Liu, Zhenghao Liu, Yukun Yan, Shuo Wang, Zulong Chen, Tong Xiao</p>
<p><strong>Abstract:</strong> arXiv:2508.13021v1 Announce Type: new  Abstract: Recent advances in masked diffusion models (MDMs) have established them as powerful non-autoregressive alternatives for sequence generation. Nevertheless, our preliminary experiments reveal that the generation quality of MDMs is still highly sensitive to the choice of decoding strategy. In particular, widely adopted uncertainty-based samplers suffer from two key limitations: a lack of global trajectory control and a pronounced bias toward trivial tokens in the early stages of decoding. These shortcomings restrict the full potential of MDMs. In this work, we introduce Position-Aware Confidence-Calibrated Sampling (PC-Sampler), a novel decoding strategy that unifies global trajectory planning with content-aware informativeness maximization. PC-Sampler incorporates a position-aware weighting mechanism to regulate the decoding path and a calibrated confidence score to suppress the premature selection of trivial tokens. Extensive experiments on three advanced MDMs across seven challenging benchmarks-including logical reasoning and planning tasks-demonstrate that PC-Sampler consistently outperforms existing MDM decoding strategies by more than 10% on average, significantly narrowing the performance gap with state-of-the-art autoregressive models. All codes are available at <a href="https://github.com/NEUIR/PC-Sampler">https://github.com/NEUIR/PC-Sampler</a>.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">1. <a href="https://arxiv.org/abs/2508.12564" rel="nofollow">Temporal and Rotational Calibration for Event-Centric Multi-Sensor Systems</a> <a id="user-content-link1"></a>
</h2><a id="user-content-1-temporal-and-rotational-calibration-for-event-centric-multi-sensor-systems-" class="anchor" aria-label="Permalink: 1. Temporal and Rotational Calibration for Event-Centric Multi-Sensor Systems" href="#1-temporal-and-rotational-calibration-for-event-centric-multi-sensor-systems-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12564
<strong>Authors:</strong> Jiayao Mai, Xiuyuan Lu, Kuan Dai, Shaojie Shen, Yi Zhou</p>
<p><strong>Abstract:</strong> arXiv:2508.12564v1 Announce Type: new  Abstract: Event cameras generate asynchronous signals in response to pixel-level brightness changes, offering a sensing paradigm with theoretically microsecond-scale latency that can significantly enhance the performance of multi-sensor systems. Extrinsic calibration is a critical prerequisite for effective sensor fusion; however, the configuration that involves event cameras remains an understudied topic. In this paper, we propose a motion-based temporal and rotational calibration framework tailored for event-centric multi-sensor systems, eliminating the need for dedicated calibration targets. Our method uses as input the rotational motion estimates obtained from event cameras and other heterogeneous sensors, respectively. Different from conventional approaches that rely on event-to-frame conversion, our method efficiently estimates angular velocity from normal flow observations, which are derived from the spatio-temporal profile of event data. The overall calibration pipeline adopts a two-step approach: it first initializes the temporal offset and rotational extrinsics by exploiting kinematic correlations in the spirit of Canonical Correlation Analysis (CCA), and then refines both temporal and rotational parameters through a joint non-linear optimization using a continuous-time parametrization in SO(3). Extensive evaluations on both publicly available and self-collected datasets validate that the proposed method achieves calibration accuracy comparable to target-based methods, while exhibiting superior stability over purely CCA-based methods, and highlighting its precision, robustness and flexibility. To facilitate future research, our implementation will be made open-source. Code: <a href="https://github.com/NAIL-HNU/EvMultiCalib">https://github.com/NAIL-HNU/EvMultiCalib</a>.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">2. <a href="https://arxiv.org/abs/2508.12022" rel="nofollow">AI Models for Depressive Disorder Detection and Diagnosis: A Review</a> <a id="user-content-link2"></a>
</h2><a id="user-content-2-ai-models-for-depressive-disorder-detection-and-diagnosis-a-review-" class="anchor" aria-label="Permalink: 2. AI Models for Depressive Disorder Detection and Diagnosis: A Review" href="#2-ai-models-for-depressive-disorder-detection-and-diagnosis-a-review-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12022
<strong>Authors:</strong> Dorsa Macky Aleagha, Payam Zohari, Mostafa Haghir Chehreghani</p>
<p><strong>Abstract:</strong> arXiv:2508.12022v1 Announce Type: new  Abstract: Major Depressive Disorder is one of the leading causes of disability worldwide, yet its diagnosis still depends largely on subjective clinical assessments. Integrating Artificial Intelligence (AI) holds promise for developing objective, scalable, and timely diagnostic tools. In this paper, we present a comprehensive survey of state-of-the-art AI methods for depression detection and diagnosis, based on a systematic review of 55 key studies. We introduce a novel hierarchical taxonomy that structures the field by primary clinical task (diagnosis vs. prediction), data modality (text, speech, neuroimaging, multimodal), and computational model class (e.g., graph neural networks, large language models, hybrid approaches). Our in-depth analysis reveals three major trends: the predominance of graph neural networks for modeling brain connectivity, the rise of large language models for linguistic and conversational data, and an emerging focus on multimodal fusion, explainability, and algorithmic fairness. Alongside methodological insights, we provide an overview of prominent public datasets and standard evaluation metrics as a practical guide for researchers. By synthesizing current advances and highlighting open challenges, this survey offers a comprehensive roadmap for future innovation in computational psychiatry.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">3. <a href="https://arxiv.org/abs/2508.12291" rel="nofollow">RadarQA: Multi-modal Quality Analysis of Weather Radar Forecasts</a> <a id="user-content-link3"></a>
</h2><a id="user-content-3-radarqa-multi-modal-quality-analysis-of-weather-radar-forecasts-" class="anchor" aria-label="Permalink: 3. RadarQA: Multi-modal Quality Analysis of Weather Radar Forecasts" href="#3-radarqa-multi-modal-quality-analysis-of-weather-radar-forecasts-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12291
<strong>Authors:</strong> Xuming He, Zhiyuan You, Junchao Gong, Couhua Liu, Xiaoyu Yue, Peiqin Zhuang, Wenlong Zhang, Lei Bai</p>
<p><strong>Abstract:</strong> arXiv:2508.12291v1 Announce Type: new  Abstract: Quality analysis of weather forecasts is an essential topic in meteorology. Although traditional score-based evaluation metrics can quantify certain forecast errors, they are still far from meteorological experts in terms of descriptive capability, interpretability, and understanding of dynamic evolution. With the rapid development of Multi-modal Large Language Models (MLLMs), these models become potential tools to overcome the above challenges. In this work, we introduce an MLLM-based weather forecast analysis method, RadarQA, integrating key physical attributes with detailed assessment reports. We introduce a novel and comprehensive task paradigm for multi-modal quality analysis, encompassing both single frame and sequence, under both rating and assessment scenarios. To support training and benchmarking, we design a hybrid annotation pipeline that combines human expert labeling with automated heuristics. With such an annotation method, we construct RQA-70K, a large-scale dataset with varying difficulty levels for radar forecast quality evaluation. We further design a multi-stage training strategy that iteratively improves model performance at each stage. Extensive experiments show that RadarQA outperforms existing general MLLMs across all evaluation settings, highlighting its potential for advancing quality analysis in weather prediction.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">4. <a href="https://arxiv.org/abs/2508.11940" rel="nofollow">Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware</a> <a id="user-content-link4"></a>
</h2><a id="user-content-4-extending-straight-through-estimation-for-robust-neural-networks-on-analog-cim-hardware-" class="anchor" aria-label="Permalink: 4. Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware" href="#4-extending-straight-through-estimation-for-robust-neural-networks-on-analog-cim-hardware-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.11940
<strong>Authors:</strong> Yuannuo Feng, Wenyong Zhou, Yuexi Lyu, Yixiang Zhang, Zhengwu Liu, Ngai Wong, Wang Kang</p>
<p><strong>Abstract:</strong> arXiv:2508.11940v1 Announce Type: new  Abstract: Analog Compute-In-Memory (CIM) architectures promise significant energy efficiency gains for neural network inference, but suffer from complex hardware-induced noise that poses major challenges for deployment. While noise-aware training methods have been proposed to address this issue, they typically rely on idealized and differentiable noise models that fail to capture the full complexity of analog CIM hardware variations. Motivated by the Straight-Through Estimator (STE) framework in quantization, we decouple forward noise simulation from backward gradient computation, enabling noise-aware training with more accurate but computationally intractable noise modeling in analog CIM systems. We provide theoretical analysis demonstrating that our approach preserves essential gradient directional information while maintaining computational tractability and optimization stability. Extensive experiments show that our extended STE framework achieves up to 5.3% accuracy improvement on image classification, 0.72 perplexity reduction on text generation, 2.2$\times$ speedup in training time, and 37.9% lower peak memory usage compared to standard noise-aware training methods.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">5. <a href="https://arxiv.org/abs/2508.12270" rel="nofollow">L-SR1: Learned Symmetric-Rank-One Preconditioning</a> <a id="user-content-link5"></a>
</h2><a id="user-content-5-l-sr1-learned-symmetric-rank-one-preconditioning-" class="anchor" aria-label="Permalink: 5. L-SR1: Learned Symmetric-Rank-One Preconditioning" href="#5-l-sr1-learned-symmetric-rank-one-preconditioning-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12270
<strong>Authors:</strong> Gal Lifshitz, Shahar Zuler, Ori Fouks, Dan Raviv</p>
<p><strong>Abstract:</strong> arXiv:2508.12270v1 Announce Type: new  Abstract: End-to-end deep learning has achieved impressive results but remains limited by its reliance on large labeled datasets, poor generalization to unseen scenarios, and growing computational demands. In contrast, classical optimization methods are data-efficient and lightweight but often suffer from slow convergence. While learned optimizers offer a promising fusion of both worlds, most focus on first-order methods, leaving learned second-order approaches largely unexplored.   We propose a novel learned second-order optimizer that introduces a trainable preconditioning unit to enhance the classical Symmetric-Rank-One (SR1) algorithm. This unit generates data-driven vectors used to construct positive semi-definite rank-one matrices, aligned with the secant constraint via a learned projection. Our method is evaluated through analytic experiments and on the real-world task of Monocular Human Mesh Recovery (HMR), where it outperforms existing learned optimization-based approaches. Featuring a lightweight model and requiring no annotated data or fine-tuning, our approach offers strong generalization and is well-suited for integration into broader optimization-based frameworks.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">6. <a href="https://arxiv.org/abs/2508.12511" rel="nofollow">Trust Region Constrained Measure Transport in Path Space for Stochastic Optimal Control and Inference</a> <a id="user-content-link6"></a>
</h2><a id="user-content-6-trust-region-constrained-measure-transport-in-path-space-for-stochastic-optimal-control-and-inference-" class="anchor" aria-label="Permalink: 6. Trust Region Constrained Measure Transport in Path Space for Stochastic Optimal Control and Inference" href="#6-trust-region-constrained-measure-transport-in-path-space-for-stochastic-optimal-control-and-inference-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12511
<strong>Authors:</strong> Denis Blessing, Julius Berner, Lorenz Richter, Carles Domingo-Enrich, Yuanqi Du, Arash Vahdat, Gerhard Neumann</p>
<p><strong>Abstract:</strong> arXiv:2508.12511v1 Announce Type: new  Abstract: Solving stochastic optimal control problems with quadratic control costs can be viewed as approximating a target path space measure, e.g. via gradient-based optimization. In practice, however, this optimization is challenging in particular if the target measure differs substantially from the prior. In this work, we therefore approach the problem by iteratively solving constrained problems incorporating trust regions that aim for approaching the target measure gradually in a systematic way. It turns out that this trust region based strategy can be understood as a geometric annealing from the prior to the target measure, where, however, the incorporated trust regions lead to a principled and educated way of choosing the time steps in the annealing path. We demonstrate in multiple optimal control applications that our novel method can improve performance significantly, including tasks in diffusion-based sampling, transition path sampling, and fine-tuning of diffusion models.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">7. <a href="https://arxiv.org/abs/2508.12260" rel="nofollow">Mantis: A Simulation-Grounded Foundation Model for Disease Forecasting</a> <a id="user-content-link7"></a>
</h2><a id="user-content-7-mantis-a-simulation-grounded-foundation-model-for-disease-forecasting-" class="anchor" aria-label="Permalink: 7. Mantis: A Simulation-Grounded Foundation Model for Disease Forecasting" href="#7-mantis-a-simulation-grounded-foundation-model-for-disease-forecasting-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12260
<strong>Authors:</strong> Carson Dudley, Reiden Magdaleno, Christopher Harding, Ananya Sharma, Emily Martin, Marisa Eisenberg</p>
<p><strong>Abstract:</strong> arXiv:2508.12260v1 Announce Type: new  Abstract: Infectious disease forecasting in novel outbreaks or low resource settings has been limited by the need for disease-specific data, bespoke training, and expert tuning. We introduce Mantis, a foundation model trained entirely on mechanistic simulations, which enables out-of-the-box forecasting across diseases, regions, and outcomes, even in settings with limited historical data. Mantis is built on over 400 million simulated days of outbreak dynamics spanning diverse pathogens, transmission modes, interventions, and surveillance artifacts. Despite requiring no real-world data during training, Mantis outperformed 39 expert-tuned models we tested across six diseases, including all models in the CDC's COVID-19 Forecast Hub. Mantis generalized to novel epidemiological regimes, including diseases with held-out transmission mechanisms, demonstrating that it captures fundamental contagion dynamics. Critically, Mantis is mechanistically interpretable, enabling public health decision-makers to identify the latent drivers behind its predictions. Finally, Mantis delivers accurate forecasts at 8-week horizons, more than doubling the actionable range of most models, enabling proactive public health planning. Together, these capabilities position Mantis as a foundation for next-generation disease forecasting systems: general, interpretable, and deployable where traditional models fail.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">8. <a href="https://arxiv.org/abs/2508.12650" rel="nofollow">Score-informed Neural Operator for Enhancing Ordering-based Causal Discovery</a> <a id="user-content-link8"></a>
</h2><a id="user-content-8-score-informed-neural-operator-for-enhancing-ordering-based-causal-discovery-" class="anchor" aria-label="Permalink: 8. Score-informed Neural Operator for Enhancing Ordering-based Causal Discovery" href="#8-score-informed-neural-operator-for-enhancing-ordering-based-causal-discovery-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12650
<strong>Authors:</strong> Jiyeon Kang, Songseong Kim, Chanhui Lee, Doyeong Hwang, Joanie Hayoun Chung, Yunkyung Ko, Sumin Lee, Sungwoong Kim, Sungbin Lim</p>
<p><strong>Abstract:</strong> arXiv:2508.12650v1 Announce Type: new  Abstract: Ordering-based approaches to causal discovery identify topological orders of causal graphs, providing scalable alternatives to combinatorial search methods. Under the Additive Noise Model (ANM) assumption, recent causal ordering methods based on score matching require an accurate estimation of the Hessian diagonal of the log-densities. However, previous approaches mainly use Stein gradient estimators, which are computationally expensive and memory-intensive. Although DiffAN addresses these limitations by substituting kernel-based estimates with diffusion models, it remains numerically unstable due to the second-order derivatives of score models. To alleviate these problems, we propose Score-informed Neural Operator (SciNO), a probabilistic generative model in smooth function spaces designed to stably approximate the Hessian diagonal and to preserve structural information during the score modeling. Empirical results show that SciNO reduces order divergence by 42.7% on synthetic graphs and by 31.5% on real-world datasets on average compared to DiffAN, while maintaining memory efficiency and scalability. Furthermore, we propose a probabilistic control algorithm for causal reasoning with autoregressive models that integrates SciNO's probability estimates with autoregressive model priors, enabling reliable data-driven causal ordering informed by semantic information. Consequently, the proposed method enhances causal reasoning abilities of LLMs without additional fine-tuning or prompt engineering.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">9. <a href="https://arxiv.org/abs/2508.11661" rel="nofollow">Sparse Attention across Multiple-context KV Cache</a> <a id="user-content-link9"></a>
</h2><a id="user-content-9-sparse-attention-across-multiple-context-kv-cache-" class="anchor" aria-label="Permalink: 9. Sparse Attention across Multiple-context KV Cache" href="#9-sparse-attention-across-multiple-context-kv-cache-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.11661
<strong>Authors:</strong> Ziyi Cao, Qingyi Si, Jingbin Zhang, Bingquan Liu</p>
<p><strong>Abstract:</strong> arXiv:2508.11661v1 Announce Type: new  Abstract: Large language models face significant cost challenges in long-sequence inference. To address this, reusing historical Key-Value (KV) Cache for improved inference efficiency has become a mainstream approach. Recent advances further enhance throughput by sparse attention mechanisms to select the most relevant KV Cache, thereby reducing sequence length. However, such techniques are limited to single-context scenarios, where historical KV Cache is computed sequentially with causal-attention dependencies. In retrieval-augmented generation (RAG) scenarios, where retrieved documents as context are unknown beforehand, each document's KV Cache is computed and stored independently (termed multiple-context KV Cache), lacking cross-attention between contexts. This renders existing methods ineffective. Although prior work partially recomputes multiple-context KV Cache to mitigate accuracy loss from missing cross-attention, it requires retaining all KV Cache throughout, failing to reduce memory overhead. This paper presents SamKV, the first exploration of attention sparsification for multiple-context KV Cache. Specifically, SamKV takes into account the complementary information of other contexts when sparsifying one context, and then locally recomputes the sparsified information. Experiments demonstrate that our method compresses sequence length to 15% without accuracy degradation compared with full-recompuation baselines, significantly boosting throughput in multi-context RAG scenarios.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">10. <a href="https://arxiv.org/abs/2508.11794" rel="nofollow">Fed-Meta-Align: A Similarity-Aware Aggregation and Personalization Pipeline for Federated TinyML on Heterogeneous Data</a> <a id="user-content-link10"></a>
</h2><a id="user-content-10-fed-meta-align-a-similarity-aware-aggregation-and-personalization-pipeline-for-federated-tinyml-on-heterogeneous-data-" class="anchor" aria-label="Permalink: 10. Fed-Meta-Align: A Similarity-Aware Aggregation and Personalization Pipeline for Federated TinyML on Heterogeneous Data" href="#10-fed-meta-align-a-similarity-aware-aggregation-and-personalization-pipeline-for-federated-tinyml-on-heterogeneous-data-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.11794
<strong>Authors:</strong> Hemanth Macharla, Mayukha Pal</p>
<p><strong>Abstract:</strong> arXiv:2508.11794v1 Announce Type: new  Abstract: Real-time fault classification in resource-constrained Internet of Things (IoT) devices is critical for industrial safety, yet training robust models in such heterogeneous environments remains a significant challenge. Standard Federated Learning (FL) often fails in the presence of non-IID data, leading to model divergence. This paper introduces Fed-Meta-Align, a novel four-phase framework designed to overcome these limitations through a sophisticated initialization and training pipeline. Our process begins by training a foundational model on a general public dataset to establish a competent starting point. This model then undergoes a serial meta-initialization phase, where it sequentially trains on a subset of IOT Device data to learn a heterogeneity-aware initialization that is already situated in a favorable region of the loss landscape. This informed model is subsequently refined in a parallel FL phase, which utilizes a dual-criterion aggregation mechanism that weights for IOT devices updates based on both local performance and cosine similarity alignment. Finally, an on-device personalization phase adapts the converged global model into a specialized expert for each IOT Device. Comprehensive experiments demonstrate that Fed-Meta-Align achieves an average test accuracy of 91.27% across heterogeneous IOT devices, outperforming personalized FedAvg and FedProx by up to 3.87% and 3.37% on electrical and mechanical fault datasets, respectively. This multi-stage approach of sequenced initialization and adaptive aggregation provides a robust pathway for deploying high-performance intelligence on diverse TinyML networks.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">11. <a href="https://arxiv.org/abs/2508.12590" rel="nofollow">Energy-Efficient Wireless LLM Inference via Uncertainty and Importance-Aware Speculative Decoding</a> <a id="user-content-link11"></a>
</h2><a id="user-content-11-energy-efficient-wireless-llm-inference-via-uncertainty-and-importance-aware-speculative-decoding-" class="anchor" aria-label="Permalink: 11. Energy-Efficient Wireless LLM Inference via Uncertainty and Importance-Aware Speculative Decoding" href="#11-energy-efficient-wireless-llm-inference-via-uncertainty-and-importance-aware-speculative-decoding-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12590
<strong>Authors:</strong> Jihoon Park, Seungeun Oh, Seong-Lyun Kim</p>
<p><strong>Abstract:</strong> arXiv:2508.12590v1 Announce Type: new  Abstract: To address the growing demand for on-device LLM inference in resource-constrained environments, hybrid language models (HLM) have emerged, combining lightweight local models with powerful cloud-based LLMs. Recent studies on HLM have primarily focused on improving accuracy and latency, while often overlooking communication and energy efficiency. We propose a token-level filtering mechanism for an energy-efficient importance- and uncertainty-aware HLM inference that leverages both epistemic uncertainty and attention-based importance. Our method opportunistically uploads only informative tokens, reducing LLM usage and communication costs. Experiments with TinyLlama-1.1B and LLaMA-2-7B demonstrate that our method achieves up to 87.5% BERT Score and token throughput of 0.37 tokens/sec while saving the energy consumption by 40.7% compared to standard HLM. Furthermore, compared to our previous U-HLM baseline, our method improves BERTScore from 85.8% to 87.0%, energy savings from 31.6% to 43.6%, and throughput from 0.36 to 0.40. This approach enables an energy-efficient and accurate deployment of LLMs in bandwidth-constrained edge environments.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">12. <a href="https://arxiv.org/abs/2508.12727" rel="nofollow">FedSODA: Federated Fine-tuning of LLMs via Similarity Group Pruning and Orchestrated Distillation Alignment</a> <a id="user-content-link12"></a>
</h2><a id="user-content-12-fedsoda-federated-fine-tuning-of-llms-via-similarity-group-pruning-and-orchestrated-distillation-alignment-" class="anchor" aria-label="Permalink: 12. FedSODA: Federated Fine-tuning of LLMs via Similarity Group Pruning and Orchestrated Distillation Alignment" href="#12-fedsoda-federated-fine-tuning-of-llms-via-similarity-group-pruning-and-orchestrated-distillation-alignment-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12727
<strong>Authors:</strong> Manning Zhu, Songtao Guo, Pengzhan Zhou, Yansong Ning, Chang Han, Dewen Qiao</p>
<p><strong>Abstract:</strong> arXiv:2508.12727v1 Announce Type: new  Abstract: Federated fine-tuning (FFT) of large language models (LLMs) has recently emerged as a promising solution to enable domain-specific adaptation while preserving data privacy. Despite its benefits, FFT on resource-constrained clients relies on the high computational and memory demands of full-model fine-tuning, which limits the potential advancement. This paper presents FedSODA, a resource-efficient FFT framework that enables clients to adapt LLMs without accessing or storing the full model. Specifically, we first propose a similarity group pruning (SGP) module, which prunes redundant layers from the full LLM while retaining the most critical layers to preserve the model performance. Moreover, we introduce an orchestrated distillation alignment (ODA) module to reduce gradient divergence between the sub-LLM and the full LLM during FFT. Through the use of the QLoRA, clients only need to deploy quantized sub-LLMs and fine-tune lightweight adapters, significantly reducing local resource requirements. We conduct extensive experiments on three open-source LLMs across a variety of downstream tasks. The experimental results demonstrate that FedSODA reduces communication overhead by an average of 70.6%, decreases storage usage by 75.6%, and improves task accuracy by 3.1%, making it highly suitable for practical FFT applications under resource constraints.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">13. <a href="https://arxiv.org/abs/2508.11921" rel="nofollow">ENA: Efficient N-dimensional Attention</a> <a id="user-content-link13"></a>
</h2><a id="user-content-13-ena-efficient-n-dimensional-attention-" class="anchor" aria-label="Permalink: 13. ENA: Efficient N-dimensional Attention" href="#13-ena-efficient-n-dimensional-attention-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.11921
<strong>Authors:</strong> Yibo Zhong</p>
<p><strong>Abstract:</strong> arXiv:2508.11921v1 Announce Type: new  Abstract: Efficient modeling of long sequences of high-order data requires a more efficient architecture than Transformer. In this paper, we investigate two key aspects of extending linear recurrent models, especially those originally designed for language modeling, to high-order data (1D to ND): scanning strategies and attention-hybrid architectures. Empirical results suggest that scanning provides limited benefits, while attention-hybrid models yield promising results. Focusing on the latter, we further evaluate types of attention and find that tiled high-order sliding window attention (SWA) is efficient in both theory and practice. We term the resulting hybrid architecture of linear recurrence and high-order SWA as Efficient N-dimensional Attention (ENA). We then conduct several experiments to demonstrate its effectiveness. The intuition behind ENA is that linear recurrence compresses global information into a state, while SWA complements it by enforcing strict local modeling. Together, they form a simple framework that offers a promising and practical solution for ultra-long high-order data modeling.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">14. <a href="https://arxiv.org/abs/2508.12189" rel="nofollow">Self-Guided Action Diffusion</a> <a id="user-content-link14"></a>
</h2><a id="user-content-14-self-guided-action-diffusion-" class="anchor" aria-label="Permalink: 14. Self-Guided Action Diffusion" href="#14-self-guided-action-diffusion-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12189
<strong>Authors:</strong> Rhea Malhotra, Yuejiang Liu, Chelsea Finn</p>
<p><strong>Abstract:</strong> arXiv:2508.12189v1 Announce Type: new  Abstract: Recent works have shown the promise of inference-time search over action samples for improving generative robot policies. In particular, optimizing cross-chunk coherence via bidirectional decoding has proven effective in boosting the consistency and reactivity of diffusion policies. However, this approach remains computationally expensive as the diversity of sampled actions grows. In this paper, we introduce self-guided action diffusion, a more efficient variant of bidirectional decoding tailored for diffusion-based policies. At the core of our method is to guide the proposal distribution at each diffusion step based on the prior decision. Experiments in simulation tasks show that the proposed self-guidance enables near-optimal performance at negligible inference cost. Notably, under a tight sampling budget, our method achieves up to 70% higher success rates than existing counterparts on challenging dynamic tasks. See project website at <a href="https://rhea-mal.github.io/selfgad.github.io" rel="nofollow">https://rhea-mal.github.io/selfgad.github.io</a>.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">15. <a href="https://arxiv.org/abs/2508.12928" rel="nofollow">Simultaneous Contact Sequence and Patch Planning for Dynamic Locomotion</a> <a id="user-content-link15"></a>
</h2><a id="user-content-15-simultaneous-contact-sequence-and-patch-planning-for-dynamic-locomotion-" class="anchor" aria-label="Permalink: 15. Simultaneous Contact Sequence and Patch Planning for Dynamic Locomotion" href="#15-simultaneous-contact-sequence-and-patch-planning-for-dynamic-locomotion-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12928
<strong>Authors:</strong> Victor Dh'edin, Haizhou Zhao, Majid Khadiv</p>
<p><strong>Abstract:</strong> arXiv:2508.12928v1 Announce Type: new  Abstract: Legged robots have the potential to traverse highly constrained environments with agile maneuvers. However, planning such motions requires solving a highly challenging optimization problem with a mixture of continuous and discrete decision variables. In this paper, we present a full pipeline based on Monte-Carlo tree search (MCTS) and whole-body trajectory optimization (TO) to perform simultaneous contact sequence and patch selection on highly challenging environments. Through extensive simulation experiments, we show that our framework can quickly find a diverse set of dynamically consistent plans. We experimentally show that these plans are transferable to a real quadruped robot. We further show that the same framework can find highly complex acyclic humanoid maneuvers. To the best of our knowledge, this is the first demonstration of simultaneous contact sequence and patch selection for acyclic multi-contact locomotion using the whole-body dynamics of a quadruped.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">16. <a href="https://arxiv.org/abs/2508.12629" rel="nofollow">FlowMol3: Flow Matching for 3D De Novo Small-Molecule Generation</a> <a id="user-content-link16"></a>
</h2><a id="user-content-16-flowmol3-flow-matching-for-3d-de-novo-small-molecule-generation-" class="anchor" aria-label="Permalink: 16. FlowMol3: Flow Matching for 3D De Novo Small-Molecule Generation" href="#16-flowmol3-flow-matching-for-3d-de-novo-small-molecule-generation-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12629
<strong>Authors:</strong> Ian Dunn, David R. Koes</p>
<p><strong>Abstract:</strong> arXiv:2508.12629v1 Announce Type: new  Abstract: A generative model capable of sampling realistic molecules with desired properties could accelerate chemical discovery across a wide range of applications. Toward this goal, significant effort has focused on developing models that jointly sample molecular topology and 3D structure. We present FlowMol3, an open-source, multi-modal flow matching model that advances the state of the art for all-atom, small-molecule generation. Its substantial performance gains over previous FlowMol versions are achieved without changes to the graph neural network architecture or the underlying flow matching formulation. Instead, FlowMol3's improvements arise from three architecture-agnostic techniques that incur negligible computational cost: self-conditioning, fake atoms, and train-time geometry distortion. FlowMol3 achieves nearly 100% molecular validity for drug-like molecules with explicit hydrogens, more accurately reproduces the functional group composition and geometry of its training data, and does so with an order of magnitude fewer learnable parameters than comparable methods. We hypothesize that these techniques mitigate a general pathology affecting transport-based generative models, enabling detection and correction of distribution drift during inference. Our results highlight simple, transferable strategies for improving the stability and quality of diffusion- and flow-based molecular generative models.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">17. <a href="https://arxiv.org/abs/2508.12594" rel="nofollow">FLARE: Fast Low-rank Attention Routing Engine</a> <a id="user-content-link17"></a>
</h2><a id="user-content-17-flare-fast-low-rank-attention-routing-engine-" class="anchor" aria-label="Permalink: 17. FLARE: Fast Low-rank Attention Routing Engine" href="#17-flare-fast-low-rank-attention-routing-engine-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12594
<strong>Authors:</strong> Vedant Puri, Aditya Joglekar, Kevin Ferguson, Yu-hsuan Chen, Yongjie Jessica Zhang, Levent Burak Kara</p>
<p><strong>Abstract:</strong> arXiv:2508.12594v1 Announce Type: new  Abstract: The quadratic complexity of self-attention limits its applicability and scalability on large unstructured meshes. We introduce Fast Low-rank Attention Routing Engine (FLARE), a linear complexity self-attention mechanism that routes attention through fixed-length latent sequences. Each attention head performs global communication among $N$ tokens by projecting the input sequence onto a fixed length latent sequence of $M \ll N$ tokens using learnable query tokens. By routing attention through a bottleneck sequence, FLARE learns a low-rank form of attention that can be applied at $O(NM)$ cost. FLARE not only scales to unprecedented problem sizes, but also delivers superior accuracy compared to state-of-the-art neural PDE surrogates across diverse benchmarks. We also release a new additive manufacturing dataset to spur further research. Our code is available at <a href="https://github.com/vpuri3/FLARE.py">https://github.com/vpuri3/FLARE.py</a>.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">18. <a href="https://arxiv.org/abs/2508.12935" rel="nofollow">Towards Open-Ended Emotional Support Conversations in LLMs via Reinforcement Learning with Future-Oriented Rewards</a> <a id="user-content-link18"></a>
</h2><a id="user-content-18-towards-open-ended-emotional-support-conversations-in-llms-via-reinforcement-learning-with-future-oriented-rewards-" class="anchor" aria-label="Permalink: 18. Towards Open-Ended Emotional Support Conversations in LLMs via Reinforcement Learning with Future-Oriented Rewards" href="#18-towards-open-ended-emotional-support-conversations-in-llms-via-reinforcement-learning-with-future-oriented-rewards-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12935
<strong>Authors:</strong> Ting Yang, Li Chen, Huimin Wang</p>
<p><strong>Abstract:</strong> arXiv:2508.12935v1 Announce Type: new  Abstract: Emotional Support Conversation (ESC) systems aim to alleviate users' emotional difficulties and provide long-term, systematic support for emotional well-being. However, most large language model (LLM)-based ESC systems rely on predefined strategies, which limits their effectiveness in complex, real-life scenarios. To enable flexible responses to diverse emotional problem scenarios, this paper introduces a novel end-to-end framework (RLFF-ESC) that directly learns enduring emotionally supportive response skills using reinforcement learning. For sustained emotional support, we first employ an LLM-based multi-agent mechanism to simulate future dialogue trajectories and collect future-oriented rewards. We then train a future-oriented reward model, which is subsequently used to train the emotional support policy model. Additionally, we incorporate an explicit reasoning process during response generation to further enhance the quality, relevance, and contextual appropriateness of the system's responses. We evaluate the backbone policy model on Qwen2.5-7B-Instruct-1M and LLaMA3.1-8B-Instruct models, testing the proposed RLFF-ESC framework across two public ESC datasets. Experimental results demonstrate that RLFF-ESC consistently outperforms existing baselines in terms of goal completion and response quality.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">19. <a href="https://arxiv.org/abs/2508.13020" rel="nofollow">e-boost: Boosted E-Graph Extraction with Adaptive Heuristics and Exact Solving</a> <a id="user-content-link19"></a>
</h2><a id="user-content-19-e-boost-boosted-e-graph-extraction-with-adaptive-heuristics-and-exact-solving-" class="anchor" aria-label="Permalink: 19. e-boost: Boosted E-Graph Extraction with Adaptive Heuristics and Exact Solving" href="#19-e-boost-boosted-e-graph-extraction-with-adaptive-heuristics-and-exact-solving-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.13020
<strong>Authors:</strong> Jiaqi Yin, Zhan Song, Chen Chen, Yaohui Cai, Zhiru Zhang, Cunxi Yu</p>
<p><strong>Abstract:</strong> arXiv:2508.13020v1 Announce Type: new  Abstract: E-graphs have attracted growing interest in many fields, particularly in logic synthesis and formal verification. E-graph extraction is a challenging NP-hard combinatorial optimization problem. It requires identifying optimal terms from exponentially many equivalent expressions, serving as the primary performance bottleneck in e-graph based optimization tasks. However, traditional extraction methods face a critical trade-off: heuristic approaches offer speed but sacrifice optimality, while exact methods provide optimal solutions but face prohibitive computational costs on practical problems. We present e-boost, a novel framework that bridges this gap through three key innovations: (1) parallelized heuristic extraction that leverages weak data dependence to compute DAG costs concurrently, enabling efficient multi-threaded performance without sacrificing extraction quality; (2) adaptive search space pruning that employs a parameterized threshold mechanism to retain only promising candidates, dramatically reducing the solution space while preserving near-optimal solutions; and (3) initialized exact solving that formulates the reduced problem as an Integer Linear Program with warm-start capabilities, guiding solvers toward high-quality solutions faster.   Across the diverse benchmarks in formal verification and logic synthesis fields, e-boost demonstrates 558x runtime speedup over traditional exact approaches (ILP) and 19.04% performance improvement over the state-of-the-art extraction framework (SmoothE). In realistic logic synthesis tasks, e-boost produces 7.6% and 8.1% area improvements compared to conventional synthesis tools with two different technology mapping libraries. e-boost is available at <a href="https://github.com/Yu-Maryland/e-boost">https://github.com/Yu-Maryland/e-boost</a>.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">20. <a href="https://arxiv.org/abs/2508.11898" rel="nofollow">OmniD: Generalizable Robot Manipulation Policy via Image-Based BEV Representation</a> <a id="user-content-link20"></a>
</h2><a id="user-content-20-omnid-generalizable-robot-manipulation-policy-via-image-based-bev-representation-" class="anchor" aria-label="Permalink: 20. OmniD: Generalizable Robot Manipulation Policy via Image-Based BEV Representation" href="#20-omnid-generalizable-robot-manipulation-policy-via-image-based-bev-representation-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.11898
<strong>Authors:</strong> Jilei Mao, Jiarui Guan, Yingjuan Tang, Qirui Hu, Zhihang Li, Junjie Yu, Yongjie Mao, Yunzhe Sun, Shuang Liu, Xiaozhu Ju</p>
<p><strong>Abstract:</strong> arXiv:2508.11898v1 Announce Type: new  Abstract: The visuomotor policy can easily overfit to its training datasets, such as fixed camera positions and backgrounds. This overfitting makes the policy perform well in the in-distribution scenarios but underperform in the out-of-distribution generalization. Additionally, the existing methods also have difficulty fusing multi-view information to generate an effective 3D representation. To tackle these issues, we propose Omni-Vision Diffusion Policy (OmniD), a multi-view fusion framework that synthesizes image observations into a unified bird's-eye view (BEV) representation. We introduce a deformable attention-based Omni-Feature Generator (OFG) to selectively abstract task-relevant features while suppressing view-specific noise and background distractions. OmniD achieves 11%, 17%, and 84% average improvement over the best baseline model for in-distribution, out-of-distribution, and few-shot experiments, respectively. Training code and simulation benchmark are available: <a href="https://github.com/1mather/omnid.git">https://github.com/1mather/omnid.git</a></p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">21. <a href="https://arxiv.org/abs/2508.12104" rel="nofollow">Generative Medical Event Models Improve with Scale</a> <a id="user-content-link21"></a>
</h2><a id="user-content-21-generative-medical-event-models-improve-with-scale-" class="anchor" aria-label="Permalink: 21. Generative Medical Event Models Improve with Scale" href="#21-generative-medical-event-models-improve-with-scale-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12104
<strong>Authors:</strong> Shane Waxler, Paul Blazek, Davis White, Daniel Sneider, Kevin Chung, Mani Nagarathnam, Patrick Williams, Hank Voeller, Karen Wong, Matthew Swanhorst, Sheng Zhang, Naoto Usuyama, Cliff Wong, Tristan Naumann, Hoifung Poon, Andrew Loza, Daniella Meeker, Seth Hain, Rahul Shah</p>
<p><strong>Abstract:</strong> arXiv:2508.12104v1 Announce Type: new  Abstract: Realizing personalized medicine at scale calls for methods that distill insights from longitudinal patient journeys, which can be viewed as a sequence of medical events. Foundation models pretrained on large-scale medical event data represent a promising direction for scaling real-world evidence generation and generalizing to diverse downstream tasks. Using Epic Cosmos, a dataset with medical events from de-identified longitudinal health records for 16.3 billion encounters over 300 million unique patient records from 310 health systems, we introduce the Cosmos Medical Event Transformer ( CoMET) models, a family of decoder-only transformer models pretrained on 118 million patients representing 115 billion discrete medical events (151 billion tokens). We present the largest scaling-law study for medical event data, establishing a methodology for pretraining and revealing power-law scaling relationships for compute, tokens, and model size. Based on this, we pretrained a series of compute-optimal models with up to 1 billion parameters. Conditioned on a patient's real-world history, CoMET autoregressively generates the next medical event, simulating patient health timelines. We studied 78 real-world tasks, including diagnosis prediction, disease prognosis, and healthcare operations. Remarkably for a foundation model with generic pretraining and simulation-based inference, CoMET generally outperformed or matched task-specific supervised models on these tasks, without requiring task-specific fine-tuning or few-shot examples. CoMET's predictive power consistently improves as the model and pretraining scale. Our results show that CoMET, a generative medical event foundation model, can effectively capture complex clinical dynamics, providing an extensible and generalizable framework to support clinical decision-making, streamline healthcare operations, and improve patient outcomes.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">22. <a href="https://arxiv.org/abs/2508.12997" rel="nofollow">Fairness-Aware Multi-view Evidential Learning with Adaptive Prior</a> <a id="user-content-link22"></a>
</h2><a id="user-content-22-fairness-aware-multi-view-evidential-learning-with-adaptive-prior-" class="anchor" aria-label="Permalink: 22. Fairness-Aware Multi-view Evidential Learning with Adaptive Prior" href="#22-fairness-aware-multi-view-evidential-learning-with-adaptive-prior-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12997
<strong>Authors:</strong> Haishun Chen, Cai Xu, Jinlong Yu, Yilin Zhang, Ziyu Guan, Wei Zhao</p>
<p><strong>Abstract:</strong> arXiv:2508.12997v1 Announce Type: new  Abstract: Multi-view evidential learning aims to integrate information from multiple views to improve prediction performance and provide trustworthy uncertainty esitimation. Most previous methods assume that view-specific evidence learning is naturally reliable. However, in practice, the evidence learning process tends to be biased. Through empirical analysis on real-world data, we reveal that samples tend to be assigned more evidence to support data-rich classes, thereby leading to unreliable uncertainty estimation in predictions. This motivates us to delve into a new Biased Evidential Multi-view Learning (BEML) problem. To this end, we propose Fairness-Aware Multi-view Evidential Learning (FAML). FAML first introduces an adaptive prior based on training trajectory, which acts as a regularization strategy to flexibly calibrate the biased evidence learning process. Furthermore, we explicitly incorporate a fairness constraint based on class-wise evidence variance to promote balanced evidence allocation. In the multi-view fusion stage, we propose an opinion alignment mechanism to mitigate view-specific bias across views, thereby encouraging the integration of consistent and mutually supportive evidence. Extensive experiments on five real-world multi-view datasets demonstrate that FAML achieves more balanced evidence allocation and improves both prediction performance and the reliability of uncertainty estimation compared to state-of-the-art methods.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">23. <a href="https://arxiv.org/abs/2508.12087" rel="nofollow">MAPF-World: Action World Model for Multi-Agent Path Finding</a> <a id="user-content-link23"></a>
</h2><a id="user-content-23-mapf-world-action-world-model-for-multi-agent-path-finding-" class="anchor" aria-label="Permalink: 23. MAPF-World: Action World Model for Multi-Agent Path Finding" href="#23-mapf-world-action-world-model-for-multi-agent-path-finding-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12087
<strong>Authors:</strong> Zhanjiang Yang, Meng Li, Yang Shen, Yueming Li, Lijun Sun</p>
<p><strong>Abstract:</strong> arXiv:2508.12087v1 Announce Type: new  Abstract: Multi-agent path finding (MAPF) is the problem of planning conflict-free paths from the designated start locations to goal positions for multiple agents. It underlies a variety of real-world tasks, including multi-robot coordination, robot-assisted logistics, and social navigation. Recent decentralized learnable solvers have shown great promise for large-scale MAPF, especially when leveraging foundation models and large datasets. However, these agents are reactive policy models and exhibit limited modeling of environmental temporal dynamics and inter-agent dependencies, resulting in performance degradation in complex, long-term planning scenarios. To address these limitations, we propose MAPF-World, an autoregressive action world model for MAPF that unifies situation understanding and action generation, guiding decisions beyond immediate local observations. It improves situational awareness by explicitly modeling environmental dynamics, including spatial features and temporal dependencies, through future state and actions prediction. By incorporating these predicted futures, MAPF-World enables more informed, coordinated, and far-sighted decision-making, especially in complex multi-agent settings. Furthermore, we augment MAPF benchmarks by introducing an automatic map generator grounded in real-world scenarios, capturing practical map layouts for training and evaluating MAPF solvers. Extensive experiments demonstrate that MAPF-World outperforms state-of-the-art learnable solvers, showcasing superior zero-shot generalization to out-of-distribution cases. Notably, MAPF-World is trained with a 96.5% smaller model size and 92% reduced data.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">24. <a href="https://arxiv.org/abs/2508.12379" rel="nofollow">GraphCogent: Overcoming LLMs' Working Memory Constraints via Multi-Agent Collaboration in Complex Graph Understanding</a> <a id="user-content-link24"></a>
</h2><a id="user-content-24-graphcogent-overcoming-llms-working-memory-constraints-via-multi-agent-collaboration-in-complex-graph-understanding-" class="anchor" aria-label="Permalink: 24. GraphCogent: Overcoming LLMs' Working Memory Constraints via Multi-Agent Collaboration in Complex Graph Understanding" href="#24-graphcogent-overcoming-llms-working-memory-constraints-via-multi-agent-collaboration-in-complex-graph-understanding-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12379
<strong>Authors:</strong> Rongzheng Wang, Qizhi Chen, Yihong Huang, Yizhuo Ma, Muquan Li, Jiakai Li, Ke Qin, Guangchun Luo, Shuang Liang</p>
<p><strong>Abstract:</strong> arXiv:2508.12379v1 Announce Type: new  Abstract: Large language models (LLMs) show promising performance on small-scale graph reasoning tasks but fail when handling real-world graphs with complex queries. This phenomenon stems from LLMs' inability to effectively process complex graph topology and perform multi-step reasoning simultaneously. To address these limitations, we propose GraphCogent, a collaborative agent framework inspired by human Working Memory Model that decomposes graph reasoning into specialized cognitive processes: sense, buffer, and execute. The framework consists of three modules: Sensory Module standardizes diverse graph text representations via subgraph sampling, Buffer Module integrates and indexes graph data across multiple formats, and Execution Module combines tool calling and model generation for efficient reasoning. We also introduce Graph4real, a comprehensive benchmark contains with four domains of real-world graphs (Web, Social, Transportation, and Citation) to evaluate LLMs' graph reasoning capabilities. Our Graph4real covers 21 different graph reasoning tasks, categorized into three types (Structural Querying, Algorithmic Reasoning, and Predictive Modeling tasks), with graph scales that are 10 times larger than existing benchmarks. Experiments show that Llama3.1-8B based GraphCogent achieves a 50% improvement over massive-scale LLMs like DeepSeek-R1 (671B). Compared to state-of-the-art agent-based baseline, our framework outperforms by 20% in accuracy while reducing token usage by 80% for in-toolset tasks and 30% for out-toolset tasks. Code will be available after review.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">25. <a href="https://arxiv.org/abs/2508.12801" rel="nofollow">Maximum Score Routing For Mixture-of-Experts</a> <a id="user-content-link25"></a>
</h2><a id="user-content-25-maximum-score-routing-for-mixture-of-experts-" class="anchor" aria-label="Permalink: 25. Maximum Score Routing For Mixture-of-Experts" href="#25-maximum-score-routing-for-mixture-of-experts-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12801
<strong>Authors:</strong> Bowen Dong, Yilong Fan, Yutao Sun, Zhenyu Li, Tengyu Pan, Xun Zhou, Jianyong Wang</p>
<p><strong>Abstract:</strong> arXiv:2508.12801v1 Announce Type: new  Abstract: Routing networks in sparsely activated mixture-of-experts (MoE) dynamically allocate input tokens to top-k experts through differentiable sparse transformations, enabling scalable model capacity while preserving computational efficiency. Traditional MoE networks impose an expert capacity constraint to ensure GPU-friendly computation. However, this leads to token dropping when capacity is saturated and results in low hardware efficiency due to padding in underutilized experts. Removing the capacity constraint, in turn, compromises load balancing and computational efficiency. To address these issues, we propose Maximum Score Routing ($\mathbf{MaxScore}$), a novel MoE routing paradigm that models routing as a minimum-cost maximum-flow problem and integrates a SoftTopk operator. MaxScore resolves the fundamental limitations of iterative rerouting and optimal transport formulations, achieving lower training losses and higher evaluation scores at equivalent FLOPs compared to both constrained and unconstrained baselines. Implementation details and experimental configurations can be obtained from $\href{<a href="https://github.com/dongbw18/MaxScore.git%7D%7BMaxScore%7D$">https://github.com/dongbw18/MaxScore.git}{MaxScore}$</a>.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">26. <a href="https://arxiv.org/abs/2508.13148" rel="nofollow">MDPO: Overcoming the Training-Inference Divide of Masked Diffusion Language Models</a> <a id="user-content-link26"></a>
</h2><a id="user-content-26-mdpo-overcoming-the-training-inference-divide-of-masked-diffusion-language-models-" class="anchor" aria-label="Permalink: 26. MDPO: Overcoming the Training-Inference Divide of Masked Diffusion Language Models" href="#26-mdpo-overcoming-the-training-inference-divide-of-masked-diffusion-language-models-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.13148
<strong>Authors:</strong> Haoyu He, Katrin Renz, Yong Cao, Andreas Geiger</p>
<p><strong>Abstract:</strong> arXiv:2508.13148v1 Announce Type: new  Abstract: Diffusion language models, as a promising alternative to traditional autoregressive (AR) models, enable faster generation and richer conditioning on bidirectional context. However, they suffer from a key discrepancy between training and inference: during inference, MDLMs progressively reveal the structure of the generated sequence by producing fewer and fewer masked tokens, whereas this structure is ignored in training as tokens are masked at random. Although this discrepancy between training and inference can lead to suboptimal performance, it has been largely overlooked by previous works, leaving closing this gap between the two stages an open problem. To address this, we frame the problem of learning effective denoising trajectories as a sequential decision-making problem and use the resulting framework to apply reinforcement learning. We propose a novel Masked Diffusion Policy Optimization (MDPO) to exploit the Markov property diffusion possesses and explicitly train the model under the same progressive refining schedule used at inference. MDPO matches the performance of the previous state-of-the-art (SOTA) method with 60x fewer gradient updates, while achieving average improvements of 9.6% on MATH500 and 54.2% on Countdown over SOTA when trained within the same number of weight updates. Additionally, we improve the remasking strategy of MDLMs as a plug-in inference replacement to overcome the limitation that the model cannot refine tokens flexibly. This simple yet effective training-free strategy, what we refer to as RCR, consistently improves performance and yields additional gains when combined with MDPO. Our findings establish great potential for investigating the discrepancy between pre-training and inference of MDLMs. Code: <a href="https://github.com/autonomousvision/mdpo">https://github.com/autonomousvision/mdpo</a>. Project Page: <a href="https://cli212.github.io/MDPO/" rel="nofollow">https://cli212.github.io/MDPO/</a>.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">27. <a href="https://arxiv.org/abs/2508.12233" rel="nofollow">Communication-Efficient Distributed Asynchronous ADMM</a> <a id="user-content-link27"></a>
</h2><a id="user-content-27-communication-efficient-distributed-asynchronous-admm-" class="anchor" aria-label="Permalink: 27. Communication-Efficient Distributed Asynchronous ADMM" href="#27-communication-efficient-distributed-asynchronous-admm-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12233
<strong>Authors:</strong> Sagar Shrestha</p>
<p><strong>Abstract:</strong> arXiv:2508.12233v1 Announce Type: new  Abstract: In distributed optimization and federated learning, asynchronous alternating direction method of multipliers (ADMM) serves as an attractive option for large-scale optimization, data privacy, straggler nodes and variety of objective functions. However, communication costs can become a major bottleneck when the nodes have limited communication budgets or when the data to be communicated is prohibitively large. In this work, we propose introducing coarse quantization to the data to be exchanged in aynchronous ADMM so as to reduce communication overhead for large-scale federated learning and distributed optimization applications. We experimentally verify the convergence of the proposed method for several distributed learning tasks, including neural networks.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">28. <a href="https://arxiv.org/abs/2508.12278" rel="nofollow">CRoC: Context Refactoring Contrast for Graph Anomaly Detection with Limited Supervision</a> <a id="user-content-link28"></a>
</h2><a id="user-content-28-croc-context-refactoring-contrast-for-graph-anomaly-detection-with-limited-supervision-" class="anchor" aria-label="Permalink: 28. CRoC: Context Refactoring Contrast for Graph Anomaly Detection with Limited Supervision" href="#28-croc-context-refactoring-contrast-for-graph-anomaly-detection-with-limited-supervision-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12278
<strong>Authors:</strong> Siyue Xie, Da Sun Handason Tam, Wing Cheong Lau</p>
<p><strong>Abstract:</strong> arXiv:2508.12278v1 Announce Type: new  Abstract: Graph Neural Networks (GNNs) are widely used as the engine for various graph-related tasks, with their effectiveness in analyzing graph-structured data. However, training robust GNNs often demands abundant labeled data, which is a critical bottleneck in real-world applications. This limitation severely impedes progress in Graph Anomaly Detection (GAD), where anomalies are inherently rare, costly to label, and may actively camouflage their patterns to evade detection. To address these problems, we propose Context Refactoring Contrast (CRoC), a simple yet effective framework that trains GNNs for GAD by jointly leveraging limited labeled and abundant unlabeled data. Different from previous works, CRoC exploits the class imbalance inherent in GAD to refactor the context of each node, which builds augmented graphs by recomposing the attributes of nodes while preserving their interaction patterns. Furthermore, CRoC encodes heterogeneous relations separately and integrates them into the message-passing process, enhancing the model's capacity to capture complex interaction semantics. These operations preserve node semantics while encouraging robustness to adversarial camouflage, enabling GNNs to uncover intricate anomalous cases. In the training stage, CRoC is further integrated with the contrastive learning paradigm. This allows GNNs to effectively harness unlabeled data during joint training, producing richer, more discriminative node embeddings. CRoC is evaluated on seven real-world GAD datasets with varying scales. Extensive experiments demonstrate that CRoC achieves up to 14% AUC improvement over baseline GNNs and outperforms state-of-the-art GAD methods under limited-label settings.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">29. <a href="https://arxiv.org/abs/2508.12740" rel="nofollow">FedUNet: A Lightweight Additive U-Net Module for Federated Learning with Heterogeneous Models</a> <a id="user-content-link29"></a>
</h2><a id="user-content-29-fedunet-a-lightweight-additive-u-net-module-for-federated-learning-with-heterogeneous-models-" class="anchor" aria-label="Permalink: 29. FedUNet: A Lightweight Additive U-Net Module for Federated Learning with Heterogeneous Models" href="#29-fedunet-a-lightweight-additive-u-net-module-for-federated-learning-with-heterogeneous-models-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12740
<strong>Authors:</strong> Beomseok Seo, Kichang Lee, JaeYeon Park</p>
<p><strong>Abstract:</strong> arXiv:2508.12740v1 Announce Type: new  Abstract: Federated learning (FL) enables decentralized model training without sharing local data. However, most existing methods assume identical model architectures across clients, limiting their applicability in heterogeneous real-world environments. To address this, we propose FedUNet, a lightweight and architecture-agnostic FL framework that attaches a U-Net-inspired additive module to each client's backbone. By sharing only the compact bottleneck of the U-Net, FedUNet enables efficient knowledge transfer without structural alignment. The encoder-decoder design and skip connections in the U-Net help capture both low-level and high-level features, facilitating the extraction of clientinvariant representations. This enables cooperative learning between the backbone and the additive module with minimal communication cost. Experiment with VGG variants shows that FedUNet achieves 93.11% accuracy and 92.68% in compact form (i.e., a lightweight version of FedUNet) with only 0.89 MB low communication overhead.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">30. <a href="https://arxiv.org/abs/2508.12121" rel="nofollow">Time-Scale Coupling Between States and Parameters in Recurrent Neural Networks</a> <a id="user-content-link30"></a>
</h2><a id="user-content-30-time-scale-coupling-between-states-and-parameters-in-recurrent-neural-networks-" class="anchor" aria-label="Permalink: 30. Time-Scale Coupling Between States and Parameters in Recurrent Neural Networks" href="#30-time-scale-coupling-between-states-and-parameters-in-recurrent-neural-networks-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12121
<strong>Authors:</strong> Lorenzo Livi</p>
<p><strong>Abstract:</strong> arXiv:2508.12121v1 Announce Type: new  Abstract: We study how gating mechanisms in recurrent neural networks (RNNs) implicitly induce adaptive learning-rate behavior, even when training is carried out with a fixed, global learning rate. This effect arises from the coupling between state-space time scales--parametrized by the gates--and parameter-space dynamics during gradient descent. By deriving exact Jacobians for leaky-integrator and gated RNNs, we obtain a first-order expansion that makes explicit how constant, scalar, and multi-dimensional gates reshape gradient propagation, modulate effective step sizes, and introduce anisotropy in parameter updates. These findings reveal that gates not only control memory retention in the hidden states, but also act as data-driven preconditioners that adapt optimization trajectories in parameter space. We further draw formal analogies with learning-rate schedules, momentum, and adaptive methods such as Adam, showing that these optimization behaviors emerge naturally from gating. Numerical experiments confirm the validity of our perturbative analysis, supporting the view that gate-induced corrections remain small while exerting systematic effects on training dynamics. Overall, this work provides a unified dynamical-systems perspective on how gating couples state evolution with parameter updates, explaining why gated architectures achieve robust trainability and stability in practice.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">31. <a href="https://arxiv.org/abs/2508.12439" rel="nofollow">Geodesic Tracing-Based Kinematic Integration of Rolling and Sliding Contact on Manifold Meshes for Dexterous In-Hand Manipulation</a> <a id="user-content-link31"></a>
</h2><a id="user-content-31-geodesic-tracing-based-kinematic-integration-of-rolling-and-sliding-contact-on-manifold-meshes-for-dexterous-in-hand-manipulation-" class="anchor" aria-label="Permalink: 31. Geodesic Tracing-Based Kinematic Integration of Rolling and Sliding Contact on Manifold Meshes for Dexterous In-Hand Manipulation" href="#31-geodesic-tracing-based-kinematic-integration-of-rolling-and-sliding-contact-on-manifold-meshes-for-dexterous-in-hand-manipulation-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12439
<strong>Authors:</strong> Sunyu Wang, Arjun S. Lakshmipathy, Jean Oh, Nancy S. Pollard</p>
<p><strong>Abstract:</strong> arXiv:2508.12439v1 Announce Type: new  Abstract: Reasoning about rolling and sliding contact, or roll-slide contact for short, is critical for dexterous manipulation tasks that involve intricate geometries. But existing works on roll-slide contact mostly focus on continuous shapes with differentiable parametrizations. This work extends roll-slide contact modeling to manifold meshes. Specifically, we present an integration scheme based on geodesic tracing to first-order time-integrate roll-slide contact directly on meshes, enabling dexterous manipulation to reason over high-fidelity discrete representations of an object's true geometry. Using our method, we planned dexterous motions of a multi-finger robotic hand manipulating five objects in-hand in simulation. The planning was achieved with a least-squares optimizer that strives to maintain the most stable instantaneous grasp by minimizing contact sliding and spinning. Then, we evaluated our method against a baseline using collision detection and a baseline using primitive shapes. The results show that our method performed the best in accuracy and precision, even for coarse meshes. We conclude with a future work discussion on incorporating multiple contacts and contact forces to achieve accurate and robust mesh-based surface contact modeling.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">32. <a href="https://arxiv.org/abs/2508.12790" rel="nofollow">Reinforcement Learning with Rubric Anchors</a> <a id="user-content-link32"></a>
</h2><a id="user-content-32-reinforcement-learning-with-rubric-anchors-" class="anchor" aria-label="Permalink: 32. Reinforcement Learning with Rubric Anchors" href="#32-reinforcement-learning-with-rubric-anchors-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12790
<strong>Authors:</strong> Zenan Huang, Yihong Zhuang, Guoshan Lu, Zeyu Qin, Haokai Xu, Tianyu Zhao, Ru Peng, Jiaqi Hu, Zhanming Shen, Xiaomeng Hu, Xijun Gu, Peiyi Tu, Jiaxin Liu, Wenyu Chen, Yuzhuo Fu, Zhiting Fan, Yanmei Gu, Yuanyuan Wang, Zhengkai Yang, Jianguo Li, Junbo Zhao</p>
<p><strong>Abstract:</strong> arXiv:2508.12790v1 Announce Type: new  Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a powerful paradigm for enhancing Large Language Models (LLMs), exemplified by the success of OpenAI's o-series. In RLVR, rewards are derived from verifiable signals-such as passing unit tests in code generation or matching correct answers in mathematical reasoning. While effective, this requirement largely confines RLVR to domains with automatically checkable outcomes. To overcome this, we extend the RLVR paradigm to open-ended tasks by integrating rubric-based rewards, where carefully designed rubrics serve as structured, model-interpretable criteria for automatic scoring of subjective outputs. We construct, to our knowledge, the largest rubric reward system to date, with over 10,000 rubrics from humans, LLMs, or a hybrid human-LLM collaboration. Implementing rubric-based RL is challenging; we tackle these issues with a clear framework and present an open-sourced Qwen-30B-A3B model with notable gains: 1) With only 5K+ samples, our system improves by +5.2% on open-ended benchmarks (especially humanities), outperforming a 671B DeepSeek-V3 model by +2.4%, while preserving general and reasoning abilities. 2) Our method provides fine-grained stylistic control, using rubrics as anchors to mitigate the "AI-like" tone and produce more human-like, expressive responses. We share key lessons in rubric construction, data selection, and training, and discuss limitations and future releases.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">33. <a href="https://arxiv.org/abs/2508.12043" rel="nofollow">Talk Less, Fly Lighter: Autonomous Semantic Compression for UAV Swarm Communication via LLMs</a> <a id="user-content-link33"></a>
</h2><a id="user-content-33-talk-less-fly-lighter-autonomous-semantic-compression-for-uav-swarm-communication-via-llms-" class="anchor" aria-label="Permalink: 33. Talk Less, Fly Lighter: Autonomous Semantic Compression for UAV Swarm Communication via LLMs" href="#33-talk-less-fly-lighter-autonomous-semantic-compression-for-uav-swarm-communication-via-llms-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12043
<strong>Authors:</strong> Fei Lin, Tengchao Zhang, Qinghua Ni, Jun Huang, Siji Ma, Yonglin Tian, Yisheng Lv, Naiqi Wu</p>
<p><strong>Abstract:</strong> arXiv:2508.12043v1 Announce Type: new  Abstract: The rapid adoption of Large Language Models (LLMs) in unmanned systems has significantly enhanced the semantic understanding and autonomous task execution capabilities of Unmanned Aerial Vehicle (UAV) swarms. However, limited communication bandwidth and the need for high-frequency interactions pose severe challenges to semantic information transmission within the swarm. This paper explores the feasibility of LLM-driven UAV swarms for autonomous semantic compression communication, aiming to reduce communication load while preserving critical task semantics. To this end, we construct four types of 2D simulation scenarios with different levels of environmental complexity and design a communication-execution pipeline that integrates system prompts with task instruction prompts. On this basis, we systematically evaluate the semantic compression performance of nine mainstream LLMs in different scenarios and analyze their adaptability and stability through ablation studies on environmental complexity and swarm size. Experimental results demonstrate that LLM-based UAV swarms have the potential to achieve efficient collaborative communication under bandwidth-constrained and multi-hop link conditions.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">34. <a href="https://arxiv.org/abs/2508.12906" rel="nofollow">SparseMap: A Sparse Tensor Accelerator Framework Based on Evolution Strategy</a> <a id="user-content-link34"></a>
</h2><a id="user-content-34-sparsemap-a-sparse-tensor-accelerator-framework-based-on-evolution-strategy-" class="anchor" aria-label="Permalink: 34. SparseMap: A Sparse Tensor Accelerator Framework Based on Evolution Strategy" href="#34-sparsemap-a-sparse-tensor-accelerator-framework-based-on-evolution-strategy-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12906
<strong>Authors:</strong> Boran Zhao, Haiming Zhai, Zihang Yuan, Hetian Liu, Tian Xia, Wenzhe Zhao, Pengju Ren</p>
<p><strong>Abstract:</strong> arXiv:2508.12906v1 Announce Type: new  Abstract: The growing demand for sparse tensor algebra (SpTA) in machine learning and big data has driven the development of various sparse tensor accelerators. However, most existing manually designed accelerators are limited to specific scenarios, and it's time-consuming and challenging to adjust a large number of design factors when scenarios change. Therefore, automating the design of SpTA accelerators is crucial. Nevertheless, previous works focus solely on either mapping (i.e., tiling communication and computation in space and time) or sparse strategy (i.e., bypassing zero elements for efficiency), leading to suboptimal designs due to the lack of comprehensive consideration of both. A unified framework that jointly optimizes both is urgently needed. However, integrating mapping and sparse strategies leads to a combinatorial explosion in the design space(e.g., as large as $O(10^{41})$ for the workload $P_{32 \times 64} \times Q_{64 \times 48} = Z_{32 \times 48}$). This vast search space renders most conventional optimization methods (e.g., particle swarm optimization, reinforcement learning and Monte Carlo tree search) inefficient. To address this challenge, we propose an evolution strategy-based sparse tensor accelerator optimization framework, called SparseMap. SparseMap constructing a more comprehensive design space with the consideration of both mapping and sparse strategy. We introduce a series of enhancements to genetic encoding and evolutionary operators, enabling SparseMap to efficiently explore the vast and diverse design space. We quantitatively compare SparseMap with prior works and classical optimization methods, demonstrating that SparseMap consistently finds superior solutions.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">35. <a href="https://arxiv.org/abs/2508.11673" rel="nofollow">Contrastive Regularization over LoRA for Multimodal Biomedical Image Incremental Learning</a> <a id="user-content-link35"></a>
</h2><a id="user-content-35-contrastive-regularization-over-lora-for-multimodal-biomedical-image-incremental-learning-" class="anchor" aria-label="Permalink: 35. Contrastive Regularization over LoRA for Multimodal Biomedical Image Incremental Learning" href="#35-contrastive-regularization-over-lora-for-multimodal-biomedical-image-incremental-learning-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.11673
<strong>Authors:</strong> Haojie Zhang, Yixiong Liang, Hulin Kuang, Lihui Cen, Zhe Qu, Yigang Cen, Min Zeng, Shichao Kan</p>
<p><strong>Abstract:</strong> arXiv:2508.11673v1 Announce Type: new  Abstract: Multimodal Biomedical Image Incremental Learning (MBIIL) is essential for handling diverse tasks and modalities in the biomedical domain, as training separate models for each modality or task significantly increases inference costs. Existing incremental learning methods focus on task expansion within a single modality, whereas MBIIL seeks to train a unified model incrementally across modalities. The MBIIL faces two challenges: I) How to preserve previously learned knowledge during incremental updates? II) How to effectively leverage knowledge acquired from existing modalities to support new modalities? To address these challenges, we propose MSLoRA-CR, a method that fine-tunes Modality-Specific LoRA modules while incorporating Contrastive Regularization to enhance intra-modality knowledge sharing and promote inter-modality knowledge differentiation. Our approach builds upon a large vision-language model (LVLM), keeping the pretrained model frozen while incrementally adapting new LoRA modules for each modality or task. Experiments on the incremental learning of biomedical images demonstrate that MSLoRA-CR outperforms both the state-of-the-art (SOTA) approach of training separate models for each modality and the general incremental learning method (incrementally fine-tuning LoRA). Specifically, MSLoRA-CR achieves a 1.88% improvement in overall performance compared to unconstrained incremental learning methods while maintaining computational efficiency. Our code is publicly available at <a href="https://github.com/VentusAislant/MSLoRA_CR">https://github.com/VentusAislant/MSLoRA_CR</a>.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">36. <a href="https://arxiv.org/abs/2508.12555" rel="nofollow">Illuminating LLM Coding Agents: Visual Analytics for Deeper Understanding and Enhancement</a> <a id="user-content-link36"></a>
</h2><a id="user-content-36-illuminating-llm-coding-agents-visual-analytics-for-deeper-understanding-and-enhancement-" class="anchor" aria-label="Permalink: 36. Illuminating LLM Coding Agents: Visual Analytics for Deeper Understanding and Enhancement" href="#36-illuminating-llm-coding-agents-visual-analytics-for-deeper-understanding-and-enhancement-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12555
<strong>Authors:</strong> Junpeng Wang, Yuzhong Chen, Menghai Pan, Chin-Chia Michael Yeh, Mahashweta Das</p>
<p><strong>Abstract:</strong> arXiv:2508.12555v1 Announce Type: new  Abstract: Coding agents powered by large language models (LLMs) have gained traction for automating code generation through iterative problem-solving with minimal human involvement. Despite the emergence of various frameworks, e.g., LangChain, AutoML, and AIDE, ML scientists still struggle to effectively review and adjust the agents' coding process. The current approach of manually inspecting individual outputs is inefficient, making it difficult to track code evolution, compare coding iterations, and identify improvement opportunities. To address this challenge, we introduce a visual analytics system designed to enhance the examination of coding agent behaviors. Focusing on the AIDE framework, our system supports comparative analysis across three levels: (1) Code-Level Analysis, which reveals how the agent debugs and refines its code over iterations; (2) Process-Level Analysis, which contrasts different solution-seeking processes explored by the agent; and (3) LLM-Level Analysis, which highlights variations in coding behavior across different LLMs. By integrating these perspectives, our system enables ML scientists to gain a structured understanding of agent behaviors, facilitating more effective debugging and prompt engineering. Through case studies using coding agents to tackle popular Kaggle competitions, we demonstrate how our system provides valuable insights into the iterative coding process.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">37. <a href="https://arxiv.org/abs/2508.12021" rel="nofollow">FedUHD: Unsupervised Federated Learning using Hyperdimensional Computing</a> <a id="user-content-link37"></a>
</h2><a id="user-content-37-feduhd-unsupervised-federated-learning-using-hyperdimensional-computing-" class="anchor" aria-label="Permalink: 37. FedUHD: Unsupervised Federated Learning using Hyperdimensional Computing" href="#37-feduhd-unsupervised-federated-learning-using-hyperdimensional-computing-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12021
<strong>Authors:</strong> You Hak Lee, Xiaofan Yu, Quanling Zhao, Flavio Ponzina, Tajana Rosing</p>
<p><strong>Abstract:</strong> arXiv:2508.12021v1 Announce Type: new  Abstract: Unsupervised federated learning (UFL) has gained attention as a privacy-preserving, decentralized machine learning approach that eliminates the need for labor-intensive data labeling. However, UFL faces several challenges in practical applications: (1) non-independent and identically distributed (non-iid) data distribution across devices, (2) expensive computational and communication costs at the edge, and (3) vulnerability to communication noise. Previous UFL approaches have relied on deep neural networks (NN), which introduce substantial overhead in both computation and communication. In this paper, we propose FedUHD, the first UFL framework based on Hyperdimensional Computing (HDC). HDC is a brain-inspired computing scheme with lightweight training and inference operations, much smaller model size, and robustness to communication noise. FedUHD introduces two novel HDC-based designs to improve UFL performance. On the client side, a kNN-based cluster hypervector removal method addresses non-iid data samples by eliminating detrimental outliers. On the server side, a weighted HDC aggregation technique balances the non-iid data distribution across clients. Our experiments demonstrate that FedUHD achieves up to 173.6x and 612.7x better speedup and energy efficiency, respectively, in training, up to 271x lower communication cost, and 15.50% higher accuracy on average across diverse settings, along with superior robustness to various types of noise compared to state-of-the-art NN-based UFL approaches.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">38. <a href="https://arxiv.org/abs/2508.12703" rel="nofollow">BUILDA: A Thermal Building Data Generation Framework for Transfer Learning</a> <a id="user-content-link38"></a>
</h2><a id="user-content-38-builda-a-thermal-building-data-generation-framework-for-transfer-learning-" class="anchor" aria-label="Permalink: 38. BUILDA: A Thermal Building Data Generation Framework for Transfer Learning" href="#38-builda-a-thermal-building-data-generation-framework-for-transfer-learning-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12703
<strong>Authors:</strong> Thomas Krug, Fabian Raisch, Dominik Aimer, Markus Wirnsberger, Ferdinand Sigg, Benjamin Sch"afer, Benjamin Tischler</p>
<p><strong>Abstract:</strong> arXiv:2508.12703v1 Announce Type: new  Abstract: Transfer learning (TL) can improve data-driven modeling of building thermal dynamics. Therefore, many new TL research areas emerge in the field, such as selecting the right source model for TL. However, these research directions require massive amounts of thermal building data which is lacking presently. Neither public datasets nor existing data generators meet the needs of TL research in terms of data quality and quantity. Moreover, existing data generation approaches typically require expert knowledge in building simulation. We present BuilDa, a thermal building data generation framework for producing synthetic data of adequate quality and quantity for TL research. The framework does not require profound building simulation knowledge to generate large volumes of data. BuilDa uses a single-zone Modelica model that is exported as a Functional Mock-up Unit (FMU) and simulated in Python. We demonstrate BuilDa by generating data and utilizing it for pretraining and fine-tuning TL models.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">39. <a href="https://arxiv.org/abs/2508.11850" rel="nofollow">EvoCut: Strengthening Integer Programs via Evolution-Guided Language Models</a> <a id="user-content-link39"></a>
</h2><a id="user-content-39-evocut-strengthening-integer-programs-via-evolution-guided-language-models-" class="anchor" aria-label="Permalink: 39. EvoCut: Strengthening Integer Programs via Evolution-Guided Language Models" href="#39-evocut-strengthening-integer-programs-via-evolution-guided-language-models-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.11850
<strong>Authors:</strong> Milad Yazdani, Mahdi Mostajabdaveh, Samin Aref, Zirui Zhou</p>
<p><strong>Abstract:</strong> arXiv:2508.11850v1 Announce Type: new  Abstract: Integer programming lies at the heart of crucial combinatorial optimization tasks but remains challenging due to its NP-hard nature. An effective approach for practically solving integer programs is the manual design of acceleration cuts, i.e. inequalities that improve solver performance. However, this creative process demands deep expertise and is yet to be automated. Our proposed framework, EvoCut, automates the generation of acceleration cuts by combining large language models (LLMs) with an evolutionary search. EvoCut (i) initializes a diverse population of candidate cuts via an LLM-based initializer agent; (ii) for each cut empirically evaluates both preservation of the optimal solution and its ability to cut off fractional solutions across a verification set; and (iii) iteratively refines the population through evolutionary crossover and mutation agents. We quantify each cut's utility by its relative reduction in the solver's optimality gap. Our comparisons against standard integer programming practice show that EvoCut reduces optimality gap by 17-57% within a fixed time. It obtains the same solutions up to 4 times as fast, and obtains higher-quality solutions within the same time limit. Requiring no human expert input, EvoCut reliably generates, improves, and empirically verifies cuts that generalize to unseen instances. The code is available at <a href="https://github.com/milad1378yz/EvoCut">https://github.com/milad1378yz/EvoCut</a>.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">40. <a href="https://arxiv.org/abs/2508.12472" rel="nofollow">GALA: Can Graph-Augmented Large Language Model Agentic Workflows Elevate Root Cause Analysis?</a> <a id="user-content-link40"></a>
</h2><a id="user-content-40-gala-can-graph-augmented-large-language-model-agentic-workflows-elevate-root-cause-analysis-" class="anchor" aria-label="Permalink: 40. GALA: Can Graph-Augmented Large Language Model Agentic Workflows Elevate Root Cause Analysis?" href="#40-gala-can-graph-augmented-large-language-model-agentic-workflows-elevate-root-cause-analysis-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12472
<strong>Authors:</strong> Yifang Tian, Yaming Liu, Zichun Chong, Zihang Huang, Hans-Arno Jacobsen</p>
<p><strong>Abstract:</strong> arXiv:2508.12472v1 Announce Type: new  Abstract: Root cause analysis (RCA) in microservice systems is challenging, requiring on-call engineers to rapidly diagnose failures across heterogeneous telemetry such as metrics, logs, and traces. Traditional RCA methods often focus on single modalities or merely rank suspect services, falling short of providing actionable diagnostic insights with remediation guidance. This paper introduces GALA, a novel multi-modal framework that combines statistical causal inference with LLM-driven iterative reasoning for enhanced RCA. Evaluated on an open-source benchmark, GALA achieves substantial improvements over state-of-the-art methods of up to 42.22% accuracy. Our novel human-guided LLM evaluation score shows GALA generates significantly more causally sound and actionable diagnostic outputs than existing methods. Through comprehensive experiments and a case study, we show that GALA bridges the gap between automated failure diagnosis and practical incident resolution by providing both accurate root cause identification and human-interpretable remediation guidance.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">41. <a href="https://arxiv.org/abs/2508.12787" rel="nofollow">Wavy Transformer</a> <a id="user-content-link41"></a>
</h2><a id="user-content-41-wavy-transformer-" class="anchor" aria-label="Permalink: 41. Wavy Transformer" href="#41-wavy-transformer-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12787
<strong>Authors:</strong> Satoshi Noguchi, Yoshinobu Kawahara</p>
<p><strong>Abstract:</strong> arXiv:2508.12787v1 Announce Type: new  Abstract: Transformers have achieved remarkable success across natural language processing (NLP) and computer vision (CV). However, deep transformer models often suffer from an over-smoothing issue, in which token representations converge to similar values as they pass through successive transformer blocks. In this paper, we establish an equivalence between the hidden-state dynamics induced by stacked attention layers and graph neural diffusion on a complete graph. From this perspective, over-smoothing can be interpreted as a consequence of the dissipative nature of the underlying diffusion dynamics. Motivated by this physical interpretation, we propose Wavy Transformer, which consists of a novel attention layer based on second-order wavy dynamics. We also introduce a feed-forward network and a normalization layer designed to preserve the physical state-velocity relationship under the chain rule, thereby extending the transformer architecture. We further validate our proposed techniques on various transformer models for NLP and CV tasks. The results consistently demonstrate that Wavy Transformer improves performance with minimal additional parameters and no extra hyperparameter tuning.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">42. <a href="https://arxiv.org/abs/2508.12247" rel="nofollow">STM3: Mixture of Multiscale Mamba for Long-Term Spatio-Temporal Time-Series Prediction</a> <a id="user-content-link42"></a>
</h2><a id="user-content-42-stm3-mixture-of-multiscale-mamba-for-long-term-spatio-temporal-time-series-prediction-" class="anchor" aria-label="Permalink: 42. STM3: Mixture of Multiscale Mamba for Long-Term Spatio-Temporal Time-Series Prediction" href="#42-stm3-mixture-of-multiscale-mamba-for-long-term-spatio-temporal-time-series-prediction-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12247
<strong>Authors:</strong> Haolong Chen, Liang Zhang, Zhengyuan Xin, Guangxu Zhu</p>
<p><strong>Abstract:</strong> arXiv:2508.12247v1 Announce Type: new  Abstract: Recently, spatio-temporal time-series prediction has developed rapidly, yet existing deep learning methods struggle with learning complex long-term spatio-temporal dependencies efficiently. The long-term spatio-temporal dependency learning brings two new challenges: 1) The long-term temporal sequence includes multiscale information naturally which is hard to extract efficiently; 2) The multiscale temporal information from different nodes is highly correlated and hard to model. To address these challenges, we propose an efficient \textit{\textbf{S}patio-\textbf{T}emporal \textbf{M}ultiscale \textbf{M}amba} (STM2) that includes a multiscale Mamba architecture to capture the multiscale information efficiently and simultaneously, and an adaptive graph causal convolution network to learn the complex multiscale spatio-temporal dependency. STM2 includes hierarchical information aggregation for different-scale information that guarantees their distinguishability. To capture diverse temporal dynamics across all spatial nodes more efficiently, we further propose an enhanced version termed \textit{\textbf{S}patio-\textbf{T}emporal \textbf{M}ixture of \textbf{M}ultiscale \textbf{M}amba} (STM3) that employs a special Mixture-of-Experts architecture, including a more stable routing strategy and a causal contrastive learning strategy to enhance the scale distinguishability. We prove that STM3 has much better routing smoothness and guarantees the pattern disentanglement for each expert successfully. Extensive experiments on real-world benchmarks demonstrate STM2/STM3's superior performance, achieving state-of-the-art results in long-term spatio-temporal time-series prediction.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">43. <a href="https://arxiv.org/abs/2508.12038" rel="nofollow">Fully Spiking Actor-Critic Neural Network for Robotic Manipulation</a> <a id="user-content-link43"></a>
</h2><a id="user-content-43-fully-spiking-actor-critic-neural-network-for-robotic-manipulation-" class="anchor" aria-label="Permalink: 43. Fully Spiking Actor-Critic Neural Network for Robotic Manipulation" href="#43-fully-spiking-actor-critic-neural-network-for-robotic-manipulation-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12038
<strong>Authors:</strong> Liwen Zhang, Heng Deng, Guanghui Sun</p>
<p><strong>Abstract:</strong> arXiv:2508.12038v1 Announce Type: new  Abstract: This study proposes a hybrid curriculum reinforcement learning (CRL) framework based on a fully spiking neural network (SNN) for 9-degree-of-freedom robotic arms performing target reaching and grasping tasks. To reduce network complexity and inference latency, the SNN architecture is simplified to include only an input and an output layer, which shows strong potential for resource-constrained environments. Building on the advantages of SNNs-high inference speed, low energy consumption, and spike-based biological plausibility, a temporal progress-partitioned curriculum strategy is integrated with the Proximal Policy Optimization (PPO) algorithm. Meanwhile, an energy consumption modeling framework is introduced to quantitatively compare the theoretical energy consumption between SNNs and conventional Artificial Neural Networks (ANNs). A dynamic two-stage reward adjustment mechanism and optimized observation space further improve learning efficiency and policy accuracy. Experiments on the Isaac Gym simulation platform demonstrate that the proposed method achieves superior performance under realistic physical constraints. Comparative evaluations with conventional PPO and ANN baselines validate the scalability and energy efficiency of the proposed approach in dynamic robotic manipulation tasks.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">44. <a href="https://arxiv.org/abs/2508.11894" rel="nofollow">QuarkMed Medical Foundation Model Technical Report</a> <a id="user-content-link44"></a>
</h2><a id="user-content-44-quarkmed-medical-foundation-model-technical-report-" class="anchor" aria-label="Permalink: 44. QuarkMed Medical Foundation Model Technical Report" href="#44-quarkmed-medical-foundation-model-technical-report-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.11894
<strong>Authors:</strong> Ao Li, Bin Yan, Bingfeng Cai, Chenxi Li, Cunzhong Zhao, Fugen Yao, Gaoqiang Liu, Guanjun Jiang, Jian Xu, Liang Dong, Liansheng Sun, Rongshen Zhang, Xiaolei Gui, Xin Liu, Xin Shang, Yao Wu, Yu Cao, Zhenxin Ma, Zhuang Jia</p>
<p><strong>Abstract:</strong> arXiv:2508.11894v1 Announce Type: new  Abstract: Recent advancements in large language models have significantly accelerated their adoption in healthcare applications, including AI-powered medical consultations, diagnostic report assistance, and medical search tools. However, medical tasks often demand highly specialized knowledge, professional accuracy, and customization capabilities, necessitating a robust and reliable foundation model. QuarkMed addresses these needs by leveraging curated medical data processing, medical-content Retrieval-Augmented Generation (RAG), and a large-scale, verifiable reinforcement learning pipeline to develop a high-performance medical foundation model. The model achieved 70% accuracy on the Chinese Medical Licensing Examination, demonstrating strong generalization across diverse medical benchmarks. QuarkMed offers a powerful yet versatile personal medical AI solution, already serving over millions of users at ai.quark.cn.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">45. <a href="https://arxiv.org/abs/2508.12611" rel="nofollow">An LLM + ASP Workflow for Joint Entity-Relation Extraction</a> <a id="user-content-link45"></a>
</h2><a id="user-content-45-an-llm--asp-workflow-for-joint-entity-relation-extraction-" class="anchor" aria-label="Permalink: 45. An LLM + ASP Workflow for Joint Entity-Relation Extraction" href="#45-an-llm--asp-workflow-for-joint-entity-relation-extraction-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12611
<strong>Authors:</strong> Trang Tran, Trung Hoang Le, Huiping Cao, Tran Cao Son</p>
<p><strong>Abstract:</strong> arXiv:2508.12611v1 Announce Type: new  Abstract: Joint entity-relation extraction (JERE) identifies both entities and their relationships simultaneously. Traditional machine-learning based approaches to performing this task require a large corpus of annotated data and lack the ability to easily incorporate domain specific information in the construction of the model. Therefore, creating a model for JERE is often labor intensive, time consuming, and elaboration intolerant. In this paper, we propose harnessing the capabilities of generative pretrained large language models (LLMs) and the knowledge representation and reasoning capabilities of Answer Set Programming (ASP) to perform JERE. We present a generic workflow for JERE using LLMs and ASP. The workflow is generic in the sense that it can be applied for JERE in any domain. It takes advantage of LLM's capability in natural language understanding in that it works directly with unannotated text. It exploits the elaboration tolerant feature of ASP in that no modification of its core program is required when additional domain specific knowledge, in the form of type specifications, is found and needs to be used. We demonstrate the usefulness of the proposed workflow through experiments with limited training data on three well-known benchmarks for JERE. The results of our experiments show that the LLM + ASP workflow is better than state-of-the-art JERE systems in several categories with only 10% of training data. It is able to achieve a 2.5 times (35% over 15%) improvement in the Relation Extraction task for the SciERC corpus, one of the most difficult benchmarks.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">46. <a href="https://arxiv.org/abs/2508.12673" rel="nofollow">Deploying Models to Non-participating Clients in Federated Learning without Fine-tuning: A Hypernetwork-based Approach</a> <a id="user-content-link46"></a>
</h2><a id="user-content-46-deploying-models-to-non-participating-clients-in-federated-learning-without-fine-tuning-a-hypernetwork-based-approach-" class="anchor" aria-label="Permalink: 46. Deploying Models to Non-participating Clients in Federated Learning without Fine-tuning: A Hypernetwork-based Approach" href="#46-deploying-models-to-non-participating-clients-in-federated-learning-without-fine-tuning-a-hypernetwork-based-approach-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12673
<strong>Authors:</strong> Yuhao Zhou, Jindi Lv, Yuxin Tian, Dan Si, Qing Ye, Jiancheng Lv</p>
<p><strong>Abstract:</strong> arXiv:2508.12673v1 Announce Type: new  Abstract: Federated Learning (FL) has emerged as a promising paradigm for privacy-preserving collaborative learning, yet data heterogeneity remains a critical challenge. While existing methods achieve progress in addressing data heterogeneity for participating clients, they fail to generalize to non-participating clients with in-domain distribution shifts and resource constraints. To mitigate this issue, we present HyperFedZero, a novel method that dynamically generates specialized models via a hypernetwork conditioned on distribution-aware embeddings. Our approach explicitly incorporates distribution-aware inductive biases into the model's forward pass, extracting robust distribution embeddings using a NoisyEmbed-enhanced extractor with a Balancing Penalty, effectively preventing feature collapse. The hypernetwork then leverages these embeddings to generate specialized models chunk-by-chunk for non-participating clients, ensuring adaptability to their unique data distributions. Extensive experiments on multiple datasets and models demonstrate HyperFedZero's remarkable performance, surpassing competing methods consistently with minimal computational, storage, and communication overhead. Moreover, ablation studies and visualizations further validate the necessity of each component, confirming meaningful adaptations and validating the effectiveness of HyperFedZero.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">47. <a href="https://arxiv.org/abs/2508.11954" rel="nofollow">UniCast: A Unified Multimodal Prompting Framework for Time Series Forecasting</a> <a id="user-content-link47"></a>
</h2><a id="user-content-47-unicast-a-unified-multimodal-prompting-framework-for-time-series-forecasting-" class="anchor" aria-label="Permalink: 47. UniCast: A Unified Multimodal Prompting Framework for Time Series Forecasting" href="#47-unicast-a-unified-multimodal-prompting-framework-for-time-series-forecasting-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.11954
<strong>Authors:</strong> Sehyuk Park, Soyeon Caren Han, Eduard Hovy</p>
<p><strong>Abstract:</strong> arXiv:2508.11954v1 Announce Type: new  Abstract: Time series forecasting is a foundational task across domains, such as finance, healthcare, and environmental monitoring. While recent advances in Time Series Foundation Models (TSFMs) have demonstrated strong generalisation through large-scale pretraining, existing models operate predominantly in a unimodal setting, ignoring the rich multimodal context, such as visual and textual signals, that often accompanies time series data in real-world scenarios. This paper introduces a novel parameter-efficient multimodal framework, UniCast, that extends TSFMs to jointly leverage time series, vision, and text modalities for enhanced forecasting performance. Our method integrates modality-specific embeddings from pretrained Vision and Text Encoders with a frozen TSFM via soft prompt tuning, enabling efficient adaptation with minimal parameter updates. This design not only preserves the generalisation strength of the foundation model but also enables effective cross-modal interaction. Extensive experiments across diverse time-series forecasting benchmarks demonstrate that UniCast consistently and significantly outperforms all existing TSFM baselines. The findings highlight the critical role of multimodal context in advancing the next generation of general-purpose time series forecasters.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">48. <a href="https://arxiv.org/abs/2508.12165" rel="nofollow">RLNVR: Reinforcement Learning from Non-Verified Real-World Rewards</a> <a id="user-content-link48"></a>
</h2><a id="user-content-48-rlnvr-reinforcement-learning-from-non-verified-real-world-rewards-" class="anchor" aria-label="Permalink: 48. RLNVR: Reinforcement Learning from Non-Verified Real-World Rewards" href="#48-rlnvr-reinforcement-learning-from-non-verified-real-world-rewards-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12165
<strong>Authors:</strong> Rohit Krishnan, Jon Evans</p>
<p><strong>Abstract:</strong> arXiv:2508.12165v1 Announce Type: new  Abstract: This paper introduces RLNVR (Reinforcement Learning from Non-Verified Rewards), a framework for training language models using noisy, real-world feedback signals without requiring explicit human verification. Traditional RLHF requires expensive, verified reward signals that are impractical in many real-world domains. RLNVR addresses this challenge through baseline normalization and semantic similarity-based reward transfer. We demonstrate RLNVR through Walter, a prototype system that optimizes social media content generation using actual engagement data from Bluesky. Our experimental results show significant improvements in content quality and training stability, with comprehensive evaluation planned for future work. Positioning: We present a practical framework that combines RLNVR with GSPO (Group Sequence Policy Optimization) and an optional UED (Unsupervised Environment Design) curriculum to improve stability and diversity under noisy, implicit rewards. To our knowledge, combining GSPO-style normalization with a UED-style curriculum for LLM content generation from implicit social engagement has not been previously documented in this applied setting; we frame this as an applied integration rather than a new algorithm.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">49. <a href="https://arxiv.org/abs/2508.12222" rel="nofollow">Distribution Matching via Generalized Consistency Models</a> <a id="user-content-link49"></a>
</h2><a id="user-content-49-distribution-matching-via-generalized-consistency-models-" class="anchor" aria-label="Permalink: 49. Distribution Matching via Generalized Consistency Models" href="#49-distribution-matching-via-generalized-consistency-models-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12222
<strong>Authors:</strong> Sagar Shrestha, Rajesh Shrestha, Tri Nguyen, Subash Timilsina</p>
<p><strong>Abstract:</strong> arXiv:2508.12222v1 Announce Type: new  Abstract: Recent advancement in generative models have demonstrated remarkable performance across various data modalities. Beyond their typical use in data synthesis, these models play a crucial role in distribution matching tasks such as latent variable modeling, domain translation, and domain adaptation. Generative Adversarial Networks (GANs) have emerged as the preferred method of distribution matching due to their efficacy in handling high-dimensional data and their flexibility in accommodating various constraints. However, GANs often encounter challenge in training due to their bi-level min-max optimization objective and susceptibility to mode collapse. In this work, we propose a novel approach for distribution matching inspired by the consistency models employed in Continuous Normalizing Flow (CNF). Our model inherits the advantages of CNF models, such as having a straight forward norm minimization objective, while remaining adaptable to different constraints similar to GANs. We provide theoretical validation of our proposed objective and demonstrate its performance through experiments on synthetic and real-world datasets.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">50. <a href="https://arxiv.org/abs/2508.12212" rel="nofollow">ProtTeX-CC: Activating In-Context Learning in Protein LLM via Two-Stage Instruction Compression</a> <a id="user-content-link50"></a>
</h2><a id="user-content-50-prottex-cc-activating-in-context-learning-in-protein-llm-via-two-stage-instruction-compression-" class="anchor" aria-label="Permalink: 50. ProtTeX-CC: Activating In-Context Learning in Protein LLM via Two-Stage Instruction Compression" href="#50-prottex-cc-activating-in-context-learning-in-protein-llm-via-two-stage-instruction-compression-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12212
<strong>Authors:</strong> Chuanliu Fan, Zicheng Ma, Jun Gao, Nan Yu, Jun Zhang, Ziqiang Cao, Yi Qin Gao, Guohong Fu</p>
<p><strong>Abstract:</strong> arXiv:2508.12212v1 Announce Type: new  Abstract: Recent advances in protein large language models, such as ProtTeX, represent both side-chain amino acids and backbone structure as discrete token sequences of residue length. While this design enables unified modeling of multimodal protein information, it suffers from two major limitations: (1) The concatenation of sequence and structure tokens approximately doubles the protein length and breaks the intrinsic residue-level alignment between modalities. (2) Constrained by the training corpus and limited context window, ProtTeX is typically trained on single-protein inputs, rendering it incompatible with in-context learning (ICL) and thus limiting its generalization capability. To address these issues, we propose ProtTeX-CC, a lightweight two-stage compression framework designed to enhance ProtTeX under few-shot settings. We first design a joint embedding compression mechanism that fuses sequence and structure representations at the residue level, effectively reducing the protein input length by half without sacrificing performance. Then we propose a self-compression module that aggregates each full demonstration into the latent space of the last few linguistic tokens, reducing the average demonstration length from 751 tokens to less than 16 tokens. Compared to the original ProtTeX, our self-compression approach achieves a compression ratio of approximately 93.68% in the total prompt length under the 16-shot setting. Without modifying the backbone model, ProtTeX-CC introduces only a small number of additional parameters through PEFT-based tuning in the joint embedding compression stage and a single trainable projection layer in the self-compression stage. Extensive experiments on protein function prediction show that ProtTeX-CC improves performance on the in-domain benchmark by 2%, and generalizes well to the out-of-domain dataset with a performance gain of 11%.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">51. <a href="https://arxiv.org/abs/2508.12566" rel="nofollow">Help or Hurdle? Rethinking Model Context Protocol-Augmented Large Language Models</a> <a id="user-content-link51"></a>
</h2><a id="user-content-51-help-or-hurdle-rethinking-model-context-protocol-augmented-large-language-models-" class="anchor" aria-label="Permalink: 51. Help or Hurdle? Rethinking Model Context Protocol-Augmented Large Language Models" href="#51-help-or-hurdle-rethinking-model-context-protocol-augmented-large-language-models-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12566
<strong>Authors:</strong> Wei Song, Haonan Zhong, Ziqi Ding, Jingling Xue, Yuekang Li</p>
<p><strong>Abstract:</strong> arXiv:2508.12566v1 Announce Type: new  Abstract: The Model Context Protocol (MCP) enables large language models (LLMs) to access external resources on demand. While commonly assumed to enhance performance, how LLMs actually leverage this capability remains poorly understood. We introduce MCPGAUGE, the first comprehensive evaluation framework for probing LLM-MCP interactions along four key dimensions: proactivity (self-initiated tool use), compliance (adherence to tool-use instructions), effectiveness (task performance post-integration), and overhead (computational cost incurred). MCPGAUGE comprises a 160-prompt suite and 25 datasets spanning knowledge comprehension, general reasoning, and code generation. Our large-scale evaluation, spanning six commercial LLMs, 30 MCP tool suites, and both one- and two-turn interaction settings, comprises around 20,000 API calls and over USD 6,000 in computational cost. This comprehensive study reveals four key findings that challenge prevailing assumptions about the effectiveness of MCP integration. These insights highlight critical limitations in current AI-tool integration and position MCPGAUGE as a principled benchmark for advancing controllable, tool-augmented LLMs.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">52. <a href="https://arxiv.org/abs/2508.12984" rel="nofollow">SL-ACC: A Communication-Efficient Split Learning Framework with Adaptive Channel-wise Compression</a> <a id="user-content-link52"></a>
</h2><a id="user-content-52-sl-acc-a-communication-efficient-split-learning-framework-with-adaptive-channel-wise-compression-" class="anchor" aria-label="Permalink: 52. SL-ACC: A Communication-Efficient Split Learning Framework with Adaptive Channel-wise Compression" href="#52-sl-acc-a-communication-efficient-split-learning-framework-with-adaptive-channel-wise-compression-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12984
<strong>Authors:</strong> Zehang Lin, Zheng Lin, Miao Yang, Jianhao Huang, Yuxin Zhang, Zihan Fang, Xia Du, Zhe Chen, Shunzhi Zhu, Wei Ni</p>
<p><strong>Abstract:</strong> arXiv:2508.12984v1 Announce Type: new  Abstract: The increasing complexity of neural networks poses a significant barrier to the deployment of distributed machine learning (ML) on resource-constrained devices, such as federated learning (FL). Split learning (SL) offers a promising solution by offloading the primary computing load from edge devices to a server via model partitioning. However, as the number of participating devices increases, the transmission of excessive smashed data (i.e., activations and gradients) becomes a major bottleneck for SL, slowing down the model training. To tackle this challenge, we propose a communication-efficient SL framework, named SL-ACC, which comprises two key components: adaptive channel importance identification (ACII) and channel grouping compression (CGC). ACII first identifies the contribution of each channel in the smashed data to model training using Shannon entropy. Following this, CGC groups the channels based on their entropy and performs group-wise adaptive compression to shrink the transmission volume without compromising training accuracy. Extensive experiments across various datasets validate that our proposed SL-ACC framework takes considerably less time to achieve a target accuracy than state-of-the-art benchmarks.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">53. <a href="https://arxiv.org/abs/2508.12116" rel="nofollow">DynamixSFT: Dynamic Mixture Optimization of Instruction Tuning Collections</a> <a id="user-content-link53"></a>
</h2><a id="user-content-53-dynamixsft-dynamic-mixture-optimization-of-instruction-tuning-collections-" class="anchor" aria-label="Permalink: 53. DynamixSFT: Dynamic Mixture Optimization of Instruction Tuning Collections" href="#53-dynamixsft-dynamic-mixture-optimization-of-instruction-tuning-collections-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12116
<strong>Authors:</strong> Haebin Shin, Lei Ji, Xiao Liu, Zhiwei Yu, Qi Chen, Yeyun Gong</p>
<p><strong>Abstract:</strong> arXiv:2508.12116v1 Announce Type: new  Abstract: As numerous instruction-tuning datasets continue to emerge during the post-training stage, dynamically balancing and optimizing their mixtures has become a critical challenge. To address this, we propose DynamixSFT, a dynamic and automated method for instruction-tuning dataset mixture optimization. We formulate the problem as a multi-armed bandit setup and introduce a Prior-scaled Boltzmann Exploration that softly anchors the updated sampling distribution to the original dataset proportions, thereby preserving the inherent diversity and coverage of the collection. Sampling probabilities are updated using a lightweight 1-Step Look-ahead Reward, reflecting how much the dataset contributes to improving the model's performance at its current state. When applied to the Tulu-v2-mixture collection comprising 16 instruction-tuning datasets, DynamixSFT achieves up to a 2.2% performance improvement across 10 benchmarks. Furthermore, we provide a comprehensive analysis and visualizations to offer deeper insights into the adaptive dynamics of our method.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">54. <a href="https://arxiv.org/abs/2508.12815" rel="nofollow">Learning to Steer: Input-dependent Steering for Multimodal LLMs</a> <a id="user-content-link54"></a>
</h2><a id="user-content-54-learning-to-steer-input-dependent-steering-for-multimodal-llms-" class="anchor" aria-label="Permalink: 54. Learning to Steer: Input-dependent Steering for Multimodal LLMs" href="#54-learning-to-steer-input-dependent-steering-for-multimodal-llms-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.12815
<strong>Authors:</strong> Jayneel Parekh, Pegah Khayatan, Mustafa Shukor, Arnaud Dapogny, Alasdair Newson, Matthieu Cord</p>
<p><strong>Abstract:</strong> arXiv:2508.12815v1 Announce Type: new  Abstract: Steering has emerged as a practical approach to enable post-hoc guidance of LLMs towards enforcing a specific behavior. However, it remains largely underexplored for multimodal LLMs (MLLMs); furthermore, existing steering techniques, such as mean steering, rely on a single steering vector, applied independently of the input query. This paradigm faces limitations when the desired behavior is dependent on the example at hand. For example, a safe answer may consist in abstaining from answering when asked for an illegal activity, or may point to external resources or consultation with an expert when asked about medical advice. In this paper, we investigate a fine-grained steering that uses an input-specific linear shift. This shift is computed using contrastive input-specific prompting. However, the input-specific prompts required for this approach are not known at test time. Therefore, we propose to train a small auxiliary module to predict the input-specific steering vector. Our approach, dubbed as L2S (Learn-to-Steer), demonstrates that it reduces hallucinations and enforces safety in MLLMs, outperforming other static baselines.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">55. <a href="https://arxiv.org/abs/2508.13088" rel="nofollow">Seeing the Many: Exploring Parameter Distributions Conditioned on Features in Surrogates</a> <a id="user-content-link55"></a>
</h2><a id="user-content-55-seeing-the-many-exploring-parameter-distributions-conditioned-on-features-in-surrogates-" class="anchor" aria-label="Permalink: 55. Seeing the Many: Exploring Parameter Distributions Conditioned on Features in Surrogates" href="#55-seeing-the-many-exploring-parameter-distributions-conditioned-on-features-in-surrogates-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.13088
<strong>Authors:</strong> Xiaohan Wang, Zhimin Li, Joshua A. Levine, Matthew Berger</p>
<p><strong>Abstract:</strong> arXiv:2508.13088v1 Announce Type: new  Abstract: Recently, neural surrogate models have emerged as a compelling alternative to traditional simulation workflows. This is accomplished by modeling the underlying function of scientific simulations, removing the need to run expensive simulations. Beyond just mapping from input parameter to output, surrogates have also been shown useful for inverse problems: output to input parameters. Inverse problems can be understood as search, where we aim to find parameters whose surrogate outputs contain a specified feature. Yet finding these parameters can be costly, especially for high-dimensional parameter spaces. Thus, existing surrogate-based solutions primarily focus on finding a small set of matching parameters, in the process overlooking the broader picture of plausible parameters. Our work aims to model and visualize the distribution of possible input parameters that produce a given output feature. To achieve this goal, we aim to address two challenges: (1) the approximation error inherent in the surrogate model and (2) forming the parameter distribution in an interactive manner. We model error via density estimation, reporting high density only if a given parameter configuration is close to training parameters, measured both over the input and output space. Our density estimate is used to form a prior belief on parameters, and when combined with a likelihood on features, gives us an efficient way to sample plausible parameter configurations that generate a target output feature. We demonstrate the usability of our solution through a visualization interface by performing feature-driven parameter analysis over the input parameter space of three simulation datasets. Source code is available at <a href="https://github.com/matthewberger/seeing-the-many">https://github.com/matthewberger/seeing-the-many</a></p>
<hr>
<hr>
<div class="markdown-heading"><h2 class="heading-element">Paper selection prompt</h2><a id="user-content-paper-selection-prompt" class="anchor" aria-label="Permalink: Paper selection prompt" href="#paper-selection-prompt"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<ol>
<li>Quantization, Pruning, and KVCache Compression for Efficient Large Language Models
<ul>
<li>Relevant: To optimize large language models (LLMs) for reduced memory and computational costs while maintaining performance, this research direction integrates quantization, pruning, and KVCache compression into a unified framework.</li>
</ul>
</li>
<li>Token-Level Expert Selection and Activation Calibration for Efficient Mixture-of-Experts Models
Relevant: To enhance the efficiency and performance of Mixture-of-Experts (MoE) models, this research direction investigates token-level expert selection strategies, sparse activation patterns, and calibration set optimization to improve routing decisions while minimizing computational overhead.
Key Focus Areas: Dynamic Token-to-Expert Assignment: Analyzing how input tokens are routed to experts, including top-k gating, noisy top-k, and learnable routing policies.
Activation Sparsity &amp; Load Balancing: Studying expert utilization and methods (e.g., auxiliary loss, expert choice routing) to prevent underused or overloaded experts.
Calibration for Robust Routing: Optimizing validation set selection and fine-tuning strategies to adapt routing behavior for downstream tasks.
Efficiency-Accuracy Trade-offs: Evaluating how different expert selection mechanisms impact model size, inference speed, and task performance.
In suggesting papers to your friend, remember that he enjoys papers on large language model (llm) compression, inference acceleration techniques, and related algorithms such as quantization and pruning. He is particularly interested in research that explores new methods for reducing large language model size and improving inference speed, as well as innovative approaches to optimizing large language model.</li>
</ol>
</div></div><div class="footer container-xl width-full p-responsive"><div class="position-relative flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between pt-4 pb-4 mt-6 f6 color-text-secondary border-top color-border-secondary text-center"><div class="footer-octicon d-lg-block mx-lg-4"><a title="LLIKKE/Arxiv_GPT_Assistant" href="https://github.com/LLIKKE/Arxiv_GPT_Assistant" target="_blank" rel="noreferrer noopener"><svg class="octicon octicon-mark-github gh-logo" width="36" height="36" viewBox="0 0 98 98" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"></path></svg></a></div><span class="mt-2 d-block footprint"><span>powered by </span><a href="https://github.com/wranders/markdown-to-pages-action" target="_blank" rel="noreferrer noopener">markdown-to-pages-action</a></span></div></div></body></html>