<!DOCTYPE html><html data-color-mode="light" data-light-theme="light" data-dark-theme="dark" lang="en-US"><head><title>LLIKKE/Arxiv_GPT_Assistant</title><meta charset="utf-8"><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="description" content="Deepseek based personalized ArXiv paper assistant bot"><link rel="canonical" href="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta property="og:type" content="website"><meta property="og:url" content="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:description" content="Deepseek based personalized ArXiv paper assistant bot"><meta property="og:locale" content="en_US"><meta property="og:site_name" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:description" content="Deepseek based personalized ArXiv paper assistant bot"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon.png" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon.svg" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon-dark.png" media="(prefers-color-scheme: dark)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon-dark.svg" media="(prefers-color-scheme: dark)"><link rel="mask-icon" href="https://github.githubassets.com/pinned-octocat.svg" color="#000000"><link href="index.css" rel="stylesheet"></head><body><div class="container-lg px-3 my-5 markdown-body"><div class="position-relative"><span class="profile-color-modes-toggle js-promo-color-modes-toggle" tabindex="0" aria-label="Toggle dark mode" aria-checked="true" role="checkbox"><div class="profile-color-modes-toggle-track" div></div><div class="profile-color-modes-toggle-thumb"><svg style="fill: var(--color-scale-yellow-0); margin: 7px 0 0 7px;" aria-hidden="true" width="14" height="13" viewBox="0 0 14 13" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.52208 7.71754C7.5782 7.71754 10.0557 5.24006 10.0557 2.18394C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961C9.95801 1.07727 10.3495 0.771159 10.6474 0.99992C12.1153 2.12716 13.0615 3.89999 13.0615 5.89383C13.0615 9.29958 10.3006 12.0605 6.89485 12.0605C3.95334 12.0605 1.49286 10.001 0.876728 7.24527C0.794841 6.87902 1.23668 6.65289 1.55321 6.85451C2.41106 7.40095 3.4296 7.71754 4.52208 7.71754Z"></path></svg></div></span></div><script type="text/javascript">(function() {
  var MODE_KEY = 'markdown_to_pages_dark_mode';
  function toggleMode() {
    var mode = document.documentElement.getAttribute('data-color-mode') === 'light' ? 'dark' : 'light';
    document.documentElement.setAttribute('data-color-mode', mode);
    localStorage.setItem(MODE_KEY, mode);
  }
  var mode = localStorage.getItem(MODE_KEY);
  if (mode == null) {
    var query = window.matchMedia('(prefers-color-scheme: dark)');
    mode = query.matches ? 'dark' : 'light';
  }
  document.documentElement.setAttribute('data-color-mode', mode);
  document.querySelector('.profile-color-modes-toggle').onclick = toggleMode;
})();</script><div><div class="markdown-heading"><h2 class="heading-element">在线伪平均转移注意力（PASA）用于稳健低精度大语言模型推理：算法与数值分析</h2><a id="user-content-在线伪平均转移注意力pasa用于稳健低精度大语言模型推理算法与数值分析" class="anchor" aria-label="Permalink: 在线伪平均转移注意力（PASA）用于稳健低精度大语言模型推理：算法与数值分析" href="#在线伪平均转移注意力pasa用于稳健低精度大语言模型推理算法与数值分析"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2503.01873v1 公告类型：新研究  摘要：在大模型中进行长序列推理任务（如文本或图像/视频生成）时，注意力计算极其耗时。为了加速这一过程，我们基于Flash Attention开发了一种低精度、数学等效的算法，名为PASA。PASA引入了两项新技术：在线伪平均移位和全局恢复。这些技术使得在整个Flash Attention过程中能够使用半精度计算，而不会引发溢出不稳定或不可接受的数值精度损失。该算法通过减少数据移动和增加计算浮点运算次数，提升了在内存受限的AI硬件架构（如升腾神经网络处理单元NPU）上的性能。算法通过设计的随机基准测试和真实大型模型进行了验证。我们发现，注意力输入数据的较大偏差和幅度是导致两类大型模型（Qwen2-7B语言模型和Stable-Video-Diffusion多模态模型）中数值溢出（半精度下&gt;65504）的关键因素。具体而言，溢出问题源于Stable-Video-Diffusion模型中序列维度上的大偏差以及查询与键在头维度之间的共振机制。共振机制被定义为查询矩阵与键矩阵之间的相位重合或180度相位偏移，这将显著放大注意力得分矩阵的元素值。此问题同样适用于Qwen模型。此外，通过均方根误差（RMSE）评估数值精度，并通过比较使用高精度注意力生成的最终文本和视频来进一步验证。</p>
<div class="markdown-heading"><h2 class="heading-element">通过后量化积分识别敏感权重</h2><a id="user-content-通过后量化积分识别敏感权重" class="anchor" aria-label="Permalink: 通过后量化积分识别敏感权重" href="#通过后量化积分识别敏感权重"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2503.01901v1 公告类型：新研究  摘要：服务大型语言模型（LLMs）成本高昂。然而，训练后权重量化可以通过压缩模型大小以适应有限的内存并节省带宽以加速来解决这一问题。由于并非所有权重维度都同等重要，这些方法通常依赖于一个敏感性指标，该指标反映了权重元素对损失函数的影响，并用于预处理原始权重以实现更好的量化。在本研究中，我们对敏感性指标的准确性进行了实证研究，发现现有的基于梯度和Hessian的指标非常不准确：它们低估了量化对损失函数的影响，误差可达数量级，这主要是由于局部二阶近似（即泰勒公式中的梯度和Hessian项）的收敛半径较小。为了解决这个问题，我们提出了后量化积分（Post-quantization Integral, PQI），这是一种以细粒度方式估计后验敏感性的准确指标。为了利用这一准确指标，我们进一步提出了ReQuant，这是一个简单而强大的框架，主要由两个密集-稀疏分离组件组成：自适应异常值选择和逐步重要权重分离。结果显示，ReQuant提升了最先进的训练后量化方法，在Llama 3.2 1B模型上使用QTIP时，困惑度显著提升了2.66。</p>
<div class="markdown-heading"><h2 class="heading-element">PaCA：部分连接适配以实现高效微调</h2><a id="user-content-paca部分连接适配以实现高效微调" class="anchor" aria-label="Permalink: PaCA：部分连接适配以实现高效微调" href="#paca部分连接适配以实现高效微调"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2503.01905v1 公告类型：新研究  摘要：先前的参数高效微调（PEFT）算法通过仅训练少量额外的适配器参数而非整个模型，减少了微调大型神经网络模型时的内存使用和计算成本。然而，PEFT带来的计算成本降低并不必然意味着训练时间的减少；尽管适配器层的计算成本远低于预训练层，但众所周知，这两类层在GPU上是顺序处理的，导致显著的延迟开销。LoRA及其变体在推理过程中将低秩适配器矩阵与预训练权重合并以避免延迟开销，但在训练期间，预训练权重保持冻结，而适配器矩阵持续更新，阻碍了这种合并。为解决此问题，我们提出了部分连接适应（PaCA），它微调预训练权重中随机选择的部分连接，而不是在模型中引入适配器层。PaCA不仅通过消除适配器层与预训练层顺序处理带来的时间开销提升了训练速度，还减少了激活内存，因为梯度计算只需存储部分激活而非全部激活。与LoRA相比，PaCA在保持各种微调场景（如在MMLU数据集上的微调和在Oasst1数据集上的指令调优）中相当准确度的同时，减少了22%的训练时间和16%的总内存使用。PaCA还可与量化结合，实现对LLaMA3.1-70B等大型模型的微调。此外，与LoRA相比，PaCA在NVIDIA A100 GPU和INTEL Gaudi2 HPU上分别实现了23%的序列长度增加和16%的吞吐量提升。代码可在<a href="https://github.com/WooSunghyeon/paca%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/WooSunghyeon/paca获取。</a></p>
</div></div><div class="footer container-xl width-full p-responsive"><div class="position-relative flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between pt-4 pb-4 mt-6 f6 color-text-secondary border-top color-border-secondary text-center"><div class="footer-octicon d-lg-block mx-lg-4"><a title="LLIKKE/Arxiv_GPT_Assistant" href="https://github.com/LLIKKE/Arxiv_GPT_Assistant" target="_blank" rel="noreferrer noopener"><svg class="octicon octicon-mark-github gh-logo" width="36" height="36" viewBox="0 0 98 98" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"></path></svg></a></div><span class="mt-2 d-block footprint"><span>powered by </span><a href="https://github.com/wranders/markdown-to-pages-action" target="_blank" rel="noreferrer noopener">markdown-to-pages-action</a></span></div></div></body></html>