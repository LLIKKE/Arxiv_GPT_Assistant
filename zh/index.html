<!DOCTYPE html><html data-color-mode="light" data-light-theme="light" data-dark-theme="dark" lang="en-US"><head><title>LLIKKE/Arxiv_GPT_Assistant</title><meta charset="utf-8"><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="description" content="Deepseek based personalized ArXiv paper assistant bot"><link rel="canonical" href="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta property="og:type" content="website"><meta property="og:url" content="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:description" content="Deepseek based personalized ArXiv paper assistant bot"><meta property="og:locale" content="en_US"><meta property="og:site_name" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:description" content="Deepseek based personalized ArXiv paper assistant bot"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon.png" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon.svg" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon-dark.png" media="(prefers-color-scheme: dark)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon-dark.svg" media="(prefers-color-scheme: dark)"><link rel="mask-icon" href="https://github.githubassets.com/pinned-octocat.svg" color="#000000"><link href="index.css" rel="stylesheet"></head><body><div class="container-lg px-3 my-5 markdown-body"><div class="position-relative"><span class="profile-color-modes-toggle js-promo-color-modes-toggle" tabindex="0" aria-label="Toggle dark mode" aria-checked="true" role="checkbox"><div class="profile-color-modes-toggle-track" div></div><div class="profile-color-modes-toggle-thumb"><svg style="fill: var(--color-scale-yellow-0); margin: 7px 0 0 7px;" aria-hidden="true" width="14" height="13" viewBox="0 0 14 13" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.52208 7.71754C7.5782 7.71754 10.0557 5.24006 10.0557 2.18394C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961C9.95801 1.07727 10.3495 0.771159 10.6474 0.99992C12.1153 2.12716 13.0615 3.89999 13.0615 5.89383C13.0615 9.29958 10.3006 12.0605 6.89485 12.0605C3.95334 12.0605 1.49286 10.001 0.876728 7.24527C0.794841 6.87902 1.23668 6.65289 1.55321 6.85451C2.41106 7.40095 3.4296 7.71754 4.52208 7.71754Z"></path></svg></div></span></div><script type="text/javascript">(function() {
  var MODE_KEY = 'markdown_to_pages_dark_mode';
  function toggleMode() {
    var mode = document.documentElement.getAttribute('data-color-mode') === 'light' ? 'dark' : 'light';
    document.documentElement.setAttribute('data-color-mode', mode);
    localStorage.setItem(MODE_KEY, mode);
  }
  var mode = localStorage.getItem(MODE_KEY);
  if (mode == null) {
    var query = window.matchMedia('(prefers-color-scheme: dark)');
    mode = query.matches ? 'dark' : 'light';
  }
  document.documentElement.setAttribute('data-color-mode', mode);
  document.querySelector('.profile-color-modes-toggle').onclick = toggleMode;
})();</script><div><div class="markdown-heading"><h2 class="heading-element">PsyLite技术报告</h2><a id="user-content-psylite技术报告" class="anchor" aria-label="Permalink: PsyLite技术报告" href="#psylite技术报告"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>（注：根据技术文档常见的命名规范，"Technical Report"译为"技术报告"；"PsyLite"作为专有名词采用音译加意译结合的方式处理，译为"PsyLite"保持产品名称一致性。整体采用简洁专业的科技文献标题风格，符合中文技术文档的表述习惯）</p>
<p>arXiv:2506.21536v1 公告类型：新研究<br>
摘要：随着数字技术的快速发展，AI驱动的心理咨询逐渐成为心理健康领域的重要研究方向。然而现有模型在对话安全性、细节场景处理与轻量化部署方面仍存在不足。为此，本研究基于基座模型InternLM2-7B-chat提出了轻量化心理咨询大语言模型智能体PsyLite，通过两阶段训练策略（混合蒸馏数据微调与ORPO偏好优化）增强模型的深度推理能力、心理咨询能力和安全对话能力。采用Ollama与Open WebUI部署后，通过Pipelines构建定制工作流，创新性地设计了条件式RAG机制，能在心理咨询过程中适时引入相声幽默元素以提升用户体验，并主动拒绝危险请求以强化对话安全性。评估显示PsyLite在中文通用评测（CEval）、心理咨询专业评测（CPsyCounE）和对话安全性评测（SafeDialBench）中均优于基线模型，尤其在心理咨询专业性（CPsyCounE分数提升47.6%）与对话安全性（\safe{}分数提升2.4%）方面表现突出。此外，模型通过量化技术（GGUF q4_k_m）实现了低硬件部署需求（5GB内存即可运行），为资源受限环境下的心理咨询应用提供了可行方案。</p>
<p>（注：根据学术论文摘要的翻译规范，对技术术语如"ORPO偏好优化"、"RAG机制"等保留英文缩写并添加中文注释；量化技术"GGUF q4_k_m"作为专有名词保留原格式；评测名称CEval/CPsyCounE等采用中英对照形式；特殊符号如"\safe{}"保留原格式以符合学术文献引用惯例）</p>
<div class="markdown-heading"><h2 class="heading-element">基于线性度的神经网络压缩</h2><a id="user-content-基于线性度的神经网络压缩" class="anchor" aria-label="Permalink: 基于线性度的神经网络压缩" href="#基于线性度的神经网络压缩"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2506.21146v1 公告类型：新研究<br>
摘要：在神经网络压缩领域，当前多数方法通过评估参数重要性与冗余度来削减不必要的参数。为了进一步增强现有高度优化的解决方案，我们提出了一种基于线性特性的新型神经网络权重压缩方法。该方法基于这样的洞察：当使用ReLU类激活函数时，那些几乎始终处于激活状态的神经元会表现出线性行为，这使得后续层的合并成为可能。我们阐述了支撑该压缩方法的理论基础，并通过实验验证了其有效性。这一创新方法在大多数测试模型中实现了无损压缩，压缩率可达原始模型大小的1/4。将本方法应用于已通过重要性剪枝的模型时，不同类型压缩技术之间几乎不存在干扰，这证明了多种技术成功组合的可能性。总体而言，我们的工作为一种新型压缩方法奠定了基础，该方法能实现更小、最终更高效的神经网络模型。</p>
<p>（注：根据学术文献翻译规范，对以下术语进行了专业处理：</p>
<ol>
<li>"ReLU-like activation functions"译为"ReLU类激活函数"以保持专业一致性</li>
<li>"lossless compression"译为"无损压缩"符合信息论术语</li>
<li>"importance-based pruned models"译为"通过重要性剪枝的模型"准确传达技术内涵</li>
<li>长难句采用拆分策略，如将原文最后一句拆分为两个中文句子以符合汉语表达习惯）</li>
</ol>
<div class="markdown-heading"><h2 class="heading-element">微观尺度格式下训练不稳定性的表征与缓解策略</h2><a id="user-content-微观尺度格式下训练不稳定性的表征与缓解策略" class="anchor" aria-label="Permalink: 微观尺度格式下训练不稳定性的表征与缓解策略" href="#微观尺度格式下训练不稳定性的表征与缓解策略"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2506.20752v1 公告类型：新研究<br>
摘要：训练大型语言模型是一个昂贵且受计算资源限制的过程，随着模型规模扩大、算法改进和新数据收集，这一过程必须重复进行。为应对此问题，下一代硬件加速器日益支持低精度算术格式，例如NVIDIA Blackwell架构引入的微缩放（MX）格式。这些格式通过在参数块内共享缩放因子来扩展可表示范围，并以降低的精度执行前向/反向GEMM运算以获得效率提升。本研究探讨了块缩放精度格式在模型训练中的挑战与可行性。通过对近千个从头训练的模型（计算预算从$2 \times 10^{17}$到$4.8 \times 10^{19}$ FLOPs，覆盖广泛的权重-激活精度组合）进行分析，我们一致观察到MX格式训练会出现损失函数的急剧随机不稳定，尤其在更大计算规模时。为解释该现象，我们在一个表现出类似行为的小型代理模型上进行对照实验与消融研究，遍历架构设置、超参数和精度格式。这些实验揭示了一个简单模型：由层归一化仿射参数及少量激活值量化引入的乘法梯度偏差可能引发失控性发散。通过在代理模型上进行原位干预实验，我们证明通过中途调整精度方案可避免或延迟不稳定现象。基于这些发现，我们在LLM场景下评估稳定策略，证明某些混合配置能恢复与全精度训练相当的性能。代码已发布于<a href="https://github.com/Hither1/systems-scaling%E3%80%82">https://github.com/Hither1/systems-scaling。</a></p>
<p>（注：根据学术规范，技术术语如GEMM/gradient bias等保留英文形式；公式单位FLOPs未翻译；URL保留原貌；层归一化（layer-norm）采用通用译法；被动语态转换为主动句式；长句合理切分以符合中文表达习惯）</p>
</div></div><div class="footer container-xl width-full p-responsive"><div class="position-relative flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between pt-4 pb-4 mt-6 f6 color-text-secondary border-top color-border-secondary text-center"><div class="footer-octicon d-lg-block mx-lg-4"><a title="LLIKKE/Arxiv_GPT_Assistant" href="https://github.com/LLIKKE/Arxiv_GPT_Assistant" target="_blank" rel="noreferrer noopener"><svg class="octicon octicon-mark-github gh-logo" width="36" height="36" viewBox="0 0 98 98" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"></path></svg></a></div><span class="mt-2 d-block footprint"><span>powered by </span><a href="https://github.com/wranders/markdown-to-pages-action" target="_blank" rel="noreferrer noopener">markdown-to-pages-action</a></span></div></div></body></html>