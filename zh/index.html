<!DOCTYPE html><html data-color-mode="light" data-light-theme="light" data-dark-theme="dark" lang="en-US"><head><title>LLIKKE/gpt_paper_assistant_ori</title><meta charset="utf-8"><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="description" content="Deepseek based personalized ArXiv paper assistant bot"><link rel="canonical" href="https://llikke.github.io/gpt_paper_assistant_ori/"><meta property="og:title" content="LLIKKE/gpt_paper_assistant_ori"><meta property="og:type" content="website"><meta property="og:url" content="https://llikke.github.io/gpt_paper_assistant_ori/"><meta property="og:description" content="Deepseek based personalized ArXiv paper assistant bot"><meta property="og:locale" content="en_US"><meta property="og:site_name" content="LLIKKE/gpt_paper_assistant_ori"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="LLIKKE/gpt_paper_assistant_ori"><meta name="twitter:description" content="Deepseek based personalized ArXiv paper assistant bot"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon.png" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon.svg" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon-dark.png" media="(prefers-color-scheme: dark)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon-dark.svg" media="(prefers-color-scheme: dark)"><link rel="mask-icon" href="https://github.githubassets.com/pinned-octocat.svg" color="#000000"><link href="index.css" rel="stylesheet"></head><body><div class="container-lg px-3 my-5 markdown-body"><div class="position-relative"><span class="profile-color-modes-toggle js-promo-color-modes-toggle" tabindex="0" aria-label="Toggle dark mode" aria-checked="true" role="checkbox"><div class="profile-color-modes-toggle-track" div></div><div class="profile-color-modes-toggle-thumb"><svg style="fill: var(--color-scale-yellow-0); margin: 7px 0 0 7px;" aria-hidden="true" width="14" height="13" viewBox="0 0 14 13" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.52208 7.71754C7.5782 7.71754 10.0557 5.24006 10.0557 2.18394C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961C9.95801 1.07727 10.3495 0.771159 10.6474 0.99992C12.1153 2.12716 13.0615 3.89999 13.0615 5.89383C13.0615 9.29958 10.3006 12.0605 6.89485 12.0605C3.95334 12.0605 1.49286 10.001 0.876728 7.24527C0.794841 6.87902 1.23668 6.65289 1.55321 6.85451C2.41106 7.40095 3.4296 7.71754 4.52208 7.71754Z"></path></svg></div></span></div><script type="text/javascript">(function() {
  var MODE_KEY = 'markdown_to_pages_dark_mode';
  function toggleMode() {
    var mode = document.documentElement.getAttribute('data-color-mode') === 'light' ? 'dark' : 'light';
    document.documentElement.setAttribute('data-color-mode', mode);
    localStorage.setItem(MODE_KEY, mode);
  }
  var mode = localStorage.getItem(MODE_KEY);
  if (mode == null) {
    var query = window.matchMedia('(prefers-color-scheme: dark)');
    mode = query.matches ? 'dark' : 'light';
  }
  document.documentElement.setAttribute('data-color-mode', mode);
  document.querySelector('.profile-color-modes-toggle').onclick = toggleMode;
})();</script><div><div class="markdown-heading"><h2 class="heading-element">双层ZOFO：连接参数高效与零阶技术的有效大型语言模型微调和元训练的桥梁</h2><a id="user-content-双层zofo连接参数高效与零阶技术的有效大型语言模型微调和元训练的桥梁" class="anchor" aria-label="Permalink: 双层ZOFO：连接参数高效与零阶技术的有效大型语言模型微调和元训练的桥梁" href="#双层zofo连接参数高效与零阶技术的有效大型语言模型微调和元训练的桥梁"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2502.03604v1 通告类型：新  摘要：使用一阶（FO）优化器对预训练的大型语言模型（LLMs）进行微调对于下游任务来说存在显著的计算挑战。为了解决这些挑战，已经提出了参数高效微调（PEFT）方法，通过冻结大多数模型参数，只训练一小部分子集。虽然PEFT效率高，但在需要高任务特定性能时，可能无法优于全量微调。零阶（ZO）方法通过仅使用前向传递来近似梯度，从而消除了第一阶方法中反向传播的计算负担，为对整个预训练模型进行微调提供了一种替代方案。然而，在实现ZO方法时，一个严格的提示至关重要，而依赖于简单、固定的严格提示可能不是最优的。在本文中，我们提出了一种双层次优化框架，该框架通过结合PEFT和ZO方法来减轻对严格提示的敏感性，同时有效地微调LLMs。我们的双层次ZOFO（零阶-一阶）方法采用双循环优化策略，其中只需要PEFT模型的梯度以及基础模型的前向传递。我们为双层次ZOFO提供了收敛保证。实证研究表明，在单任务设置中，双层次ZOFO优于PEFT和ZO方法，同时保持了类似的内存效率。此外，我们还展示了其在多任务学习中的强大潜力。与目前的多任务学习第一阶元训练算法相比，我们的方法在保持或提高性能的同时，具有显著更低的计算需求。</p>
<div class="markdown-heading"><h2 class="heading-element">TQ-DiT：扩散变换器的有效时间感知量化</h2><a id="user-content-tq-dit扩散变换器的有效时间感知量化" class="anchor" aria-label="Permalink: TQ-DiT：扩散变换器的有效时间感知量化" href="#tq-dit扩散变换器的有效时间感知量化"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2502.04056v1 公告类型：新发布  摘要：扩散变换器（DiT）将变换器架构与扩散模型相结合。然而，其计算复杂性对实时应用和AI系统的可持续性造成了重大限制。在本研究中，我们旨在通过模型量化来提高计算效率，量化表示使用较低精度的权重和激活值。多区域量化（MRQ）被引入，通过为子区域分配两个缩放参数来解决DiT块中网络值的不对称分布。此外，还提出了时间分组量化（TGQ）来减少由激活值的时间变化引起的量化误差。实验结果表明，所提出的方法在W8A8上仅增加了0.29的FID，但性能与原始全精度模型相当。此外，在W6A6上优于其他基线，从而证实了其在低比特量化中的适用性。这些结果突出了我们方法使高效实时生成模型成为可能的前景。</p>
<div class="markdown-heading"><h2 class="heading-element">无探针低秩激活干预</h2><a id="user-content-无探针低秩激活干预" class="anchor" aria-label="Permalink: 无探针低秩激活干预" href="#无探针低秩激活干预"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2502.04043v1 公告类型：新发表  摘要：语言模型（LMs）可以生成看似准确和连贯的文本，但可能包含虚假或有毒内容。在推理时编辑隐藏激活的方法在引导LMs生成期望内容方面显示出有希望的结果。现有的激活干预方法通常包括一个激活探测器来检测不期望的生成，从而触发激活修改以引导后续生成。本文提出了一种无探测器的干预方法FLORAIN，适用于特定激活层中的所有注意力头。它消除了为探测目的训练分类器的需求。干预函数由样本级非线性低秩映射参数化，通过最小化修改后的激活与其在期望内容流形上的投影之间的距离进行训练。在特定的流形和投影距离构造下，我们表明干预策略可以通过解决一个光滑优化问题来有效地计算。在多个基模型上的实证结果表明，FLORAIN在增强模型的真实性和质量方面，在生成和多项选择任务中始终优于几种基线方法。</p>
<div class="markdown-heading"><h2 class="heading-element">遮蔽扩散模型采样路径规划</h2><a id="user-content-遮蔽扩散模型采样路径规划" class="anchor" aria-label="Permalink: 遮蔽扩散模型采样路径规划" href="#遮蔽扩散模型采样路径规划"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2502.03540v1 通告类型：新内容  摘要：在这篇论文中，我们研究了在掩码扩散模型（MDMs）推理过程中，标记顺序的解掩码对生成质量的影响。我们推导出一个扩展的证据下界（ELBO），引入了一个规划者，负责在每个步骤选择解掩码的标记。我们的分析表明，替代解掩码策略可以提高生成性能。基于这些见解，我们提出了路径规划（P2），一个采样框架，它利用预训练的BERT或降噪器本身来指导解掩码决策。P2概括了所有已知的MDM采样策略，并在包括语言生成（情境学习、代码生成、故事填充、数学推理、反向诅咒纠正）和生物序列生成（蛋白质和RNA序列）在内的多个领域实现了显著的改进。</p>
<div class="markdown-heading"><h2 class="heading-element">排名也很重要：LLM微调中适配器专家混合的层次配置</h2><a id="user-content-排名也很重要llm微调中适配器专家混合的层次配置" class="anchor" aria-label="Permalink: 排名也很重要：LLM微调中适配器专家混合的层次配置" href="#排名也很重要llm微调中适配器专家混合的层次配置"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2502.03884v1 通知类型：新文章  摘要：大型语言模型（LLMs）在各种任务中取得了显著的成果，伴随着其参数规模的持续增加。参数高效的微调（PEFT）方法，如低秩适应（LoRA），通过显著减少可训练参数的数量来解决微调LLMs的挑战。最近的研究将LoRA与混合专家（MoE）架构相结合，利用多个适配器专家和门控机制来进一步提高微调性能。然而，现有方法主要关注调整每层的适配器专家分配以优化引入的可训练参数大小，而忽略了适配器秩的关键因素。为此，我们提出了一种专家分配和秩配置的分层方案，HILO，该方案动态调整层间适配器专家的数量和秩，匹配模型层在适配器粒度上的不同表示复杂性。在多个基准任务上的大量实验表明，HILO在准确度上优于现有方法，同时引入更少的可训练参数，为微调LLMs提供了一种高效实用的解决方案。</p>
</div></div><div class="footer container-xl width-full p-responsive"><div class="position-relative flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between pt-4 pb-4 mt-6 f6 color-text-secondary border-top color-border-secondary text-center"><div class="footer-octicon d-lg-block mx-lg-4"><a title="LLIKKE/gpt_paper_assistant_ori" href="https://github.com/LLIKKE/gpt_paper_assistant_ori" target="_blank" rel="noreferrer noopener"><svg class="octicon octicon-mark-github gh-logo" width="36" height="36" viewBox="0 0 98 98" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"></path></svg></a></div><span class="mt-2 d-block footprint"><span>powered by </span><a href="https://github.com/wranders/markdown-to-pages-action" target="_blank" rel="noreferrer noopener">markdown-to-pages-action</a></span></div></div></body></html>