<!DOCTYPE html><html data-color-mode="light" data-light-theme="light" data-dark-theme="dark" lang="en-US"><head><title>LLIKKE/Arxiv_GPT_Assistant</title><meta charset="utf-8"><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="description" content="Deepseek based personalized ArXiv paper assistant bot"><link rel="canonical" href="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta property="og:type" content="website"><meta property="og:url" content="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:description" content="Deepseek based personalized ArXiv paper assistant bot"><meta property="og:locale" content="en_US"><meta property="og:site_name" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:description" content="Deepseek based personalized ArXiv paper assistant bot"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon.png" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon.svg" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon-dark.png" media="(prefers-color-scheme: dark)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon-dark.svg" media="(prefers-color-scheme: dark)"><link rel="mask-icon" href="https://github.githubassets.com/pinned-octocat.svg" color="#000000"><link href="index.css" rel="stylesheet"></head><body><div class="container-lg px-3 my-5 markdown-body"><div class="position-relative"><span class="profile-color-modes-toggle js-promo-color-modes-toggle" tabindex="0" aria-label="Toggle dark mode" aria-checked="true" role="checkbox"><div class="profile-color-modes-toggle-track" div></div><div class="profile-color-modes-toggle-thumb"><svg style="fill: var(--color-scale-yellow-0); margin: 7px 0 0 7px;" aria-hidden="true" width="14" height="13" viewBox="0 0 14 13" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.52208 7.71754C7.5782 7.71754 10.0557 5.24006 10.0557 2.18394C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961C9.95801 1.07727 10.3495 0.771159 10.6474 0.99992C12.1153 2.12716 13.0615 3.89999 13.0615 5.89383C13.0615 9.29958 10.3006 12.0605 6.89485 12.0605C3.95334 12.0605 1.49286 10.001 0.876728 7.24527C0.794841 6.87902 1.23668 6.65289 1.55321 6.85451C2.41106 7.40095 3.4296 7.71754 4.52208 7.71754Z"></path></svg></div></span></div><script type="text/javascript">(function() {
  var MODE_KEY = 'markdown_to_pages_dark_mode';
  function toggleMode() {
    var mode = document.documentElement.getAttribute('data-color-mode') === 'light' ? 'dark' : 'light';
    document.documentElement.setAttribute('data-color-mode', mode);
    localStorage.setItem(MODE_KEY, mode);
  }
  var mode = localStorage.getItem(MODE_KEY);
  if (mode == null) {
    var query = window.matchMedia('(prefers-color-scheme: dark)');
    mode = query.matches ? 'dark' : 'light';
  }
  document.documentElement.setAttribute('data-color-mode', mode);
  document.querySelector('.profile-color-modes-toggle').onclick = toggleMode;
})();</script><div><div class="markdown-heading"><h2 class="heading-element">PC-Sampler：基于位置感知的掩码扩散模型解码偏差校准</h2><a id="user-content-pc-sampler基于位置感知的掩码扩散模型解码偏差校准" class="anchor" aria-label="Permalink: PC-Sampler：基于位置感知的掩码扩散模型解码偏差校准" href="#pc-sampler基于位置感知的掩码扩散模型解码偏差校准"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>（注：翻译时保留了专业术语"PC-Sampler"的英文形式以保持技术准确性，"Position-Aware"译为"基于位置感知"体现算法特性，"Calibration of Decoding Bias"采用"解码偏差校准"这一标准技术表述，整体结构符合中文技术文献标题的简洁规范。）</p>
<p>arXiv:2508.13021v1 公告类型：新成果<br>
摘要：掩码扩散模型（MDMs）的最新进展已确立其作为序列生成中强大的非自回归替代方案。然而，我们的初步实验表明，MDMs的生成质量仍对解码策略的选择高度敏感。特别是广泛采用的不确定性采样器存在两个关键局限：缺乏全局轨迹控制，以及在解码早期阶段对平凡令牌存在明显偏好。这些缺陷限制了MDMs的全部潜力。本研究提出位置感知置信度校准采样（PC-Sampler），这是一种将全局轨迹规划与内容感知信息最大化相统一的新型解码策略。PC-Sampler通过位置感知加权机制调控解码路径，并采用校准置信度分数抑制平凡令牌的过早选择。在涵盖逻辑推理和规划任务等七个挑战性基准测试中，对三种先进MDMs进行的广泛实验表明，PC-Sampler始终以平均超过10%的优势优于现有MDM解码策略，显著缩小了与最先进自回归模型的性能差距。所有代码已开源：<a href="https://github.com/NEUIR/PC-Sampler%E3%80%82">https://github.com/NEUIR/PC-Sampler。</a></p>
<div class="markdown-heading"><h2 class="heading-element">事件中心多传感器系统的时间与旋转校准</h2><a id="user-content-事件中心多传感器系统的时间与旋转校准" class="anchor" aria-label="Permalink: 事件中心多传感器系统的时间与旋转校准" href="#事件中心多传感器系统的时间与旋转校准"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.12564v1 公告类型：新研究<br>
摘要：事件相机通过响应像素级亮度变化生成异步信号，其理论微秒级延迟的传感范式能显著提升多传感器系统性能。外参标定是实现有效传感器融合的关键前提，但涉及事件相机的配置方案仍是研究不足的领域。本文提出一种基于运动的时空标定框架，专为事件中心型多传感器系统设计，无需专用标定目标。该方法分别利用事件相机与异构传感器获取的旋转运动估计值作为输入。不同于依赖事件-帧转换的传统方案，本方法通过从事件数据时空剖面提取的法向流观测值高效估算角速度。整体标定流程采用两步策略：首先通过典型相关分析（CCA）思想挖掘运动学关联来初始化时间偏移量与旋转外参，随后采用SO(3)连续时间参数化方法，通过联合非线性优化同时优化时间与旋转参数。在公开数据集与自采集数据集上的广泛实验表明，该方法在达到与靶标法相当标定精度的同时，展现出优于纯CCA方法的稳定性，并突显其精确性、鲁棒性与灵活性。为促进后续研究，我们将开源代码实现。代码地址：<a href="https://github.com/NAIL-HNU/EvMultiCalib%E3%80%82">https://github.com/NAIL-HNU/EvMultiCalib。</a></p>
<div class="markdown-heading"><h2 class="heading-element">抑郁障碍检测与诊断的人工智能模型：综述</h2><a id="user-content-抑郁障碍检测与诊断的人工智能模型综述" class="anchor" aria-label="Permalink: 抑郁障碍检测与诊断的人工智能模型：综述" href="#抑郁障碍检测与诊断的人工智能模型综述"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.12022v1 公告类型：新研究<br>
摘要：重度抑郁症是全球致残的主要原因之一，但其诊断仍主要依赖主观临床评估。人工智能（AI）的融合为开发客观、可扩展且及时的诊断工具带来了希望。本文通过对55项关键研究的系统回顾，全面综述了用于抑郁检测与诊断的最先进AI方法。我们提出了一种新颖的层次分类法，通过主要临床任务（诊断与预测）、数据模态（文本、语音、神经影像、多模态）和计算模型类别（如图神经网络、大语言模型、混合方法）对该领域进行结构化梳理。深度分析揭示三大趋势：图神经网络在脑连接建模中的主导地位、大语言模型在语言对话数据处理中的崛起，以及多模态融合、可解释性和算法公平性领域的新兴关注。除方法论洞见外，我们还概述了重要公共数据集和标准评估指标，为研究者提供实用指南。通过综合当前进展并突出开放挑战，本综述为计算精神病学领域的未来创新提供了全面路线图。</p>
<div class="markdown-heading"><h2 class="heading-element">雷达问答：气象雷达预报的多模态质量分析</h2><a id="user-content-雷达问答气象雷达预报的多模态质量分析" class="anchor" aria-label="Permalink: 雷达问答：气象雷达预报的多模态质量分析" href="#雷达问答气象雷达预报的多模态质量分析"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.12291v1 公告类型：新成果<br>
摘要：天气预报质量分析是气象学中的重要课题。虽然传统的基于评分的评估指标能够量化某些预报误差，但在描述能力、可解释性以及对动态演变过程的理解方面，仍远不及气象专家的水平。随着多模态大语言模型（MLLMs）的快速发展，这些模型成为克服上述挑战的潜在工具。本研究提出了一种基于MLLM的天气预报分析方法RadarQA，将关键物理属性与详细评估报告相融合。我们创新性地构建了一个涵盖单帧与序列、评分与评估场景的多模态质量分析任务范式。为支持训练与基准测试，设计了结合专家人工标注与自动化启发式规则的混合标注流程，并据此构建了包含不同难度等级的雷达预报质量评估大规模数据集RQA-70K。进一步提出多阶段训练策略，通过迭代方式逐阶段提升模型性能。大量实验表明，RadarQA在所有评估设置中均优于现有通用MLLMs，彰显了其在推进天气预报质量分析方面的潜力。</p>
<div class="markdown-heading"><h2 class="heading-element">扩展直通估计技术在模拟计算内存中实现鲁棒神经网络</h2><a id="user-content-扩展直通估计技术在模拟计算内存中实现鲁棒神经网络" class="anchor" aria-label="Permalink: 扩展直通估计技术在模拟计算内存中实现鲁棒神经网络" href="#扩展直通估计技术在模拟计算内存中实现鲁棒神经网络"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.11940v1 公告类型：新成果<br>
摘要：模拟存内计算（CIM）架构有望显著提升神经网络推理的能效，但其复杂的硬件噪声给部署带来重大挑战。虽然已有噪声感知训练方法被提出以解决该问题，但这些方法通常依赖于理想化且可微的噪声模型，无法完整捕捉模拟CIM硬件变异的复杂性。受量化领域中直通估计器（STE）框架的启发，我们将前向噪声模拟与反向梯度计算解耦，使得在模拟CIM系统中能够采用更精确但计算上难处理的噪声模型进行噪声感知训练。理论分析表明，该方法在保持计算可处理性和优化稳定性的同时，保留了关键的梯度方向信息。大量实验证明，相较于标准噪声感知训练方法，我们扩展的STE框架在图像分类任务中实现最高5.3%的准确率提升，文本生成任务中困惑度降低0.72，训练时间加快2.2倍，峰值内存使用量减少37.9%。</p>
<div class="markdown-heading"><h2 class="heading-element">L-SR1：习得式对称秩一预条件处理</h2><a id="user-content-l-sr1习得式对称秩一预条件处理" class="anchor" aria-label="Permalink: L-SR1：习得式对称秩一预条件处理" href="#l-sr1习得式对称秩一预条件处理"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.12270v1 公告类型：新成果<br>
摘要：端到端深度学习虽取得显著成果，但仍受限于对大标注数据集的依赖、对未见过场景的泛化能力差以及日益增长的计算需求。相比之下，经典优化方法具有数据高效和轻量化的优势，但往往收敛速度缓慢。虽然学习型优化器为两者的融合提供了有前景的解决方案，但现有研究多聚焦于一阶方法，对学习型二阶方法的探索仍处于空白。<br>
我们提出一种新型学习型二阶优化器，通过引入可训练预处理单元增强经典对称秩一（SR1）算法。该单元生成数据驱动向量，用于构建与割线约束通过学习投影保持对齐的半正定秩一矩阵。我们通过解析实验和在单目人体网格恢复（HMR）实际任务上的测试验证本方法，其表现优于现有基于学习优化的方案。该方法模型轻量化、无需标注数据或微调，具有强泛化能力，可无缝集成至更广泛的优化框架中。</p>
<div class="markdown-heading"><h2 class="heading-element">随机最优控制与推理路径空间中的信任域约束测度传输</h2><a id="user-content-随机最优控制与推理路径空间中的信任域约束测度传输" class="anchor" aria-label="Permalink: 随机最优控制与推理路径空间中的信任域约束测度传输" href="#随机最优控制与推理路径空间中的信任域约束测度传输"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>注：该翻译力求在专业术语准确性的基础上保持学术表达的严谨性，同时符合中文科技文献的表述习惯。关键术语处理如下：</p>
<ol>
<li>"Trust Region" 译为"信任域"（控制理论标准译法）</li>
<li>"Measure Transport" 采用"测度传输"（数学专业术语）</li>
<li>"Path Space" 译为"路径空间"（符合控制论领域表述）
整体句式结构根据中文科技论文标题特点进行了语序调整，确保专业性与可读性的平衡。</li>
</ol>
<p>arXiv:2508.12511v1 公告类型：新成果<br>
摘要：求解具有二次控制成本的随机最优控制问题可视为对目标路径空间测度的逼近过程，例如通过基于梯度的优化方法实现。然而在实际应用中，当目标测度与先验测度存在显著差异时，此类优化尤为困难。为此，本研究采用迭代求解约束问题的方法，通过引入信任区域机制，以系统化方式逐步逼近目标测度。研究发现，这种基于信任区域的策略可被理解为从先验测度到目标测度的几何退火过程，其中引入的信任区域为退火路径中的时间步长选择提供了原理性指导。我们在多个最优控制应用中验证了新方法的显著性能提升，包括基于扩散的采样、过渡路径采样以及扩散模型微调等任务。</p>
<div class="markdown-heading"><h2 class="heading-element">螳螂：基于仿真的疾病预测基础模型</h2><a id="user-content-螳螂基于仿真的疾病预测基础模型" class="anchor" aria-label="Permalink: 螳螂：基于仿真的疾病预测基础模型" href="#螳螂基于仿真的疾病预测基础模型"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.12260v1 公告类型：新成果<br>
摘要：在新发传染病暴发或资源匮乏地区，传染病预测一直受限于对特定疾病数据、定制化训练和专家调参的需求。我们推出完全基于机制模拟训练的基础模型Mantis，该模型能够跨疾病、跨区域、跨结果实现开箱即用的预测，甚至在历史数据有限的场景下也能胜任。Mantis建立在超过4亿模拟日的疫情动态数据基础上，涵盖多种病原体、传播方式、干预措施和监测伪影。尽管训练过程中未使用任何真实世界数据，Mantis在六种疾病的测试中全面超越了39个专家调参模型，包括美国疾控中心COVID-19预测中心的所有模型。该模型能泛化至新型流行病学体系，甚至对隐藏传播机制的疾病仍保持预测能力，证明其掌握了根本的传染动力学机制。关键在于Mantis具有机制可解释性，公共卫生决策者能据此识别预测背后的潜在驱动因素。最终，Mantis实现了8周预测窗口的精准预报，将多数模型的有效预测范围扩展两倍以上，为前瞻性公共卫生规划提供支持。这些能力共同使Mantis成为新一代疾病预测系统的基础：通用、可解释、可在传统模型失效的场景中部署。</p>
<div class="markdown-heading"><h2 class="heading-element">基于评分信息的神经算子用于增强基于排序的因果发现</h2><a id="user-content-基于评分信息的神经算子用于增强基于排序的因果发现" class="anchor" aria-label="Permalink: 基于评分信息的神经算子用于增强基于排序的因果发现" href="#基于评分信息的神经算子用于增强基于排序的因果发现"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.12650v1 公告类型：新成果<br>
摘要：基于排序的因果发现方法通过识别因果图的拓扑序，为组合搜索方法提供了可扩展的替代方案。在加性噪声模型（ANM）假设下，当前基于分数匹配的因果排序方法需要精确估计对数密度函数的Hessian矩阵对角线。然而，现有方法主要使用计算成本高且内存密集的Stein梯度估计器。虽然DiffAN通过用扩散模型替代基于核的估计缓解了这些限制，但由于分数模型的二阶导数问题，该方法仍存在数值不稳定性。为解决这些问题，我们提出分数感知神经算子（SciNO）——一种在平滑函数空间中的概率生成模型，能够稳定逼近Hessian对角线并在分数建模过程中保持结构信息。实证结果表明，在合成图数据上SciNO将排序发散度平均降低42.7%，在真实数据集上平均降低31.5%，同时保持内存效率和可扩展性。此外，我们提出一种用于自回归模型因果推理的概率控制算法，该算法将SciNO的概率估计与自回归模型先验相结合，实现了基于语义信息的可靠数据驱动因果排序。因此，所提方法无需额外微调或提示工程即可增强大语言模型的因果推理能力。</p>
<div class="markdown-heading"><h2 class="heading-element">跨上下文键值缓存稀疏注意力机制</h2><a id="user-content-跨上下文键值缓存稀疏注意力机制" class="anchor" aria-label="Permalink: 跨上下文键值缓存稀疏注意力机制" href="#跨上下文键值缓存稀疏注意力机制"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.11661v1 公告类型：新成果<br>
摘要：大语言模型在长序列推理中面临显著的成本挑战。为应对此问题，重用历史键值（KV）缓存以提升推理效率已成为主流方法。近期研究进一步通过稀疏注意力机制选择最相关的KV缓存来缩短序列长度，从而提升吞吐量。然而此类技术仅适用于单上下文场景——其历史KV缓存需通过因果注意力依赖关系按序计算。在检索增强生成（RAG）场景中，由于检索到的文档作为上下文是预先未知的，每个文档的KV缓存需独立计算和存储（称为多上下文KV缓存），缺乏上下文间的交叉注意力机制，导致现有方法失效。虽已有研究通过部分重计算多上下文KV缓存来缓解因缺失交叉注意力造成的精度损失，但该方法需全程保留全部KV缓存，无法降低内存开销。本文提出SamKV，首次探索多上下文KV缓存的注意力稀疏化方案：在稀疏化单个上下文时考虑其他上下文的互补信息，继而局部重计算被稀疏化的信息。实验表明，相比完全重计算的基线方法，本方案可将序列长度压缩至15%且保持精度无损，显著提升多上下文RAG场景的吞吐量。</p>
<div class="markdown-heading"><h2 class="heading-element">联邦元对齐：面向异构数据联邦小样本机器学习的一种相似性感知聚合与个性化流程</h2><a id="user-content-联邦元对齐面向异构数据联邦小样本机器学习的一种相似性感知聚合与个性化流程" class="anchor" aria-label="Permalink: 联邦元对齐：面向异构数据联邦小样本机器学习的一种相似性感知聚合与个性化流程" href="#联邦元对齐面向异构数据联邦小样本机器学习的一种相似性感知聚合与个性化流程"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>（注：译文采用技术文献常见的"流程/框架(Pipeline)"表述，通过"联邦元对齐"音意结合翻译Fed-Meta-Align，保留"TinyML"专业术语特征，并使用"小样本机器学习"准确传达资源受限场景。整体结构采用中文技术命名常用的破折号分层方式，确保专业性与可读性平衡。）</p>
<p>arXiv:2508.11794v1 公告类型：新研究<br>
摘要：在资源受限的物联网（IoT）设备中实现实时故障分类对工业安全至关重要，然而在此类异构环境中训练鲁棒模型仍面临重大挑战。标准联邦学习（FL）在非独立同分布数据条件下常出现模型发散问题。本文提出Fed-Meta-Align创新四阶段框架，通过精细化初始化与训练流程突破这些局限：首先基于通用公共数据集训练基础模型建立高起点；随后进入串行元初始化阶段，通过顺序训练物联网设备数据子集获得对异构性敏感的初始化参数，使模型处于损失空间的有利区域；该预训练模型在并行联邦学习阶段通过双标准聚合机制进一步优化——同时考量设备本地性能与余弦相似度对齐进行加权聚合；最终通过设备端个性化阶段，将收敛的全局模型适配为各物联网设备的专属专家。综合实验表明，Fed-Meta-Align在异构物联网设备上平均测试精度达91.27%，在电气与机械故障数据集上分别较个性化FedAvg和FedProx最高提升3.87%和3.37%。这种序列化初始化与自适应聚合的多阶段方法，为在多样化微型机器学习网络部署高性能智能提供了可靠路径。</p>
<div class="markdown-heading"><h2 class="heading-element">基于不确定性与重要性感知的推测解码实现高能效无线LLM推理</h2><a id="user-content-基于不确定性与重要性感知的推测解码实现高能效无线llm推理" class="anchor" aria-label="Permalink: 基于不确定性与重要性感知的推测解码实现高能效无线LLM推理" href="#基于不确定性与重要性感知的推测解码实现高能效无线llm推理"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>（注：在保持技术术语准确性的前提下，采用符合中文科技文献习惯的译法。将"Energy-Efficient"译为"高能效"以突出能效优化特性，"Uncertainty and Importance-Aware"译为"不确定性与重要性感知"准确传达双重感知机制，"Speculative Decoding"采用行业通用译法"推测解码"，并通过"实现"衔接使标题整体符合中文表达逻辑。）</p>
<p>arXiv:2508.12590v1 公告类型：新成果<br>
摘要：为满足资源受限环境中日益增长的设备端大语言模型（LLM）推理需求，混合语言模型（HLM）应运而生，其通过结合轻量级本地模型与强大的云端LLM实现高效推理。现有HLM研究主要聚焦于提升准确性与延迟性能，却常忽视通信与能效优化。本文提出一种面向能效优化的词元级过滤机制，基于认知不确定性和注意力权重的重要性感知，实现HLM的高效推理。该方法选择性上传信息量丰富的关键词元，显著降低LLM使用频率与通信开销。通过TinyLlama-1.1B与LLaMA-2-7B的实验验证，本方案在达到87.5% BERT评分和0.37词元/秒吞吐量的同时，较标准HLM节能40.7%。相较于先前提出的U-HLM基线模型，本方法将BERT评分从85.8%提升至87.0%，节能效果从31.6%增强至43.6%，吞吐量从0.36提升至0.40。该方案为带宽受限的边缘环境提供了高能效、高精度的LLM部署解决方案。</p>
<div class="markdown-heading"><h2 class="heading-element">FedSODA：基于相似性组剪枝与协同蒸馏对齐的大语言模型联邦微调方法</h2><a id="user-content-fedsoda基于相似性组剪枝与协同蒸馏对齐的大语言模型联邦微调方法" class="anchor" aria-label="Permalink: FedSODA：基于相似性组剪枝与协同蒸馏对齐的大语言模型联邦微调方法" href="#fedsoda基于相似性组剪枝与协同蒸馏对齐的大语言模型联邦微调方法"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>（注：翻译在保持技术术语准确性的同时，采用符合中文论文标题习惯的四六骈句结构："相似性组剪枝"对应Similarity Group Pruning，"协同蒸馏对齐"对应Orchestrated Distillation Alignment，并通过"联邦微调方法"完整传达Federated Fine-tuning概念。"FedSODA"保留原名体现技术品牌标识）</p>
<p>arXiv:2508.12727v1 公告类型：新成果<br>
摘要：联邦微调（FFT）作为大语言模型（LLM）领域适应性优化的重要解决方案，在保障数据隐私的同时实现了特定领域的模型适配。然而在资源受限的客户端进行FFT时，全模型微调带来的高昂计算与内存需求限制了其发展潜力。本文提出FedSODA框架，通过资源高效的FFT方案使客户端无需访问或存储完整模型即可实现LLM适配。具体而言：首先设计相似性分组剪枝（SGP）模块，通过剪除完整LLM中的冗余层并保留最关键层级以维持模型性能；进一步提出协同蒸馏对齐（ODA）模块，在FFT过程中降低子模型与完整模型之间的梯度差异。结合QLoRA技术，客户端仅需部署量化后的子模型并微调轻量级适配器，显著降低本地资源需求。我们在三个开源LLM上开展多下游任务实验，结果表明FedSODA平均降低70.6%通信开销，减少75.6%存储占用，并提升3.1%任务准确率，非常适合资源受限环境下的实际FFT应用。</p>
<div class="markdown-heading"><h2 class="heading-element">ENA：高效N维注意力机制</h2><a id="user-content-ena高效n维注意力机制" class="anchor" aria-label="Permalink: ENA：高效N维注意力机制" href="#ena高效n维注意力机制"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.11921v1 公告类型：新成果<br>
摘要：高效建模长序列高阶数据需要比Transformer更高效的架构。本文研究了将线性循环模型（尤其是最初为语言建模设计的模型）扩展至高阶数据（从一维到N维）的两个关键方面：扫描策略与注意力混合架构。实证结果表明扫描策略带来的效益有限，而注意力混合模型展现出良好前景。聚焦后者，我们进一步评估了注意力类型，发现平铺式高阶滑动窗口注意力（SWA）在理论和实践中均具高效性。我们将线性循环与高阶SWA的混合架构命名为高效N维注意力（ENA），并通过系列实验验证其有效性。ENA的核心思想在于：线性递归将全局信息压缩至状态中，而SWA通过强制严格局部建模形成补充。二者结合形成简洁框架，为超长高阶数据建模提供了实用且前景广阔的解决方案。</p>
<div class="markdown-heading"><h2 class="heading-element">自引导动作扩散</h2><a id="user-content-自引导动作扩散" class="anchor" aria-label="Permalink: 自引导动作扩散" href="#自引导动作扩散"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.12189v1 公告类型：新论文<br>
摘要：近期研究表明，在推理阶段对动作样本进行搜索能有效提升生成式机器人策略的性能。特别是通过双向解码优化跨片段连贯性的方法，已被证明能显著增强扩散策略的一致性和反应能力。然而，随着采样动作多样性的增加，这种方法的计算成本仍然高昂。本文提出自引导动作扩散——一种专为基于扩散的策略设计的、更高效的双向解码变体。我们的方法核心在于：基于先前的决策，在每个扩散步骤中引导提案分布。仿真实验表明，所提出的自引导机制能以可忽略的推理成本实现接近最优的性能。值得注意的是，在严格采样预算下，本方法在动态挑战性任务中比现有方案成功率提升高达70%。项目网站详见：<a href="https://rhea-mal.github.io/selfgad.github.io%E3%80%82" rel="nofollow">https://rhea-mal.github.io/selfgad.github.io。</a></p>
<div class="markdown-heading"><h2 class="heading-element">动态运动中的同步接触序列与接触面规划</h2><a id="user-content-动态运动中的同步接触序列与接触面规划" class="anchor" aria-label="Permalink: 动态运动中的同步接触序列与接触面规划" href="#动态运动中的同步接触序列与接触面规划"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.12928v1 公告类型：新研究<br>
摘要：腿式机器人具备通过灵巧机动穿越高度受限环境的潜力。然而，规划此类运动需要解决一个混合连续与离散决策变量的高难度优化问题。本文提出基于蒙特卡洛树搜索（MCTS）和全身轨迹优化（TO）的完整流程，可在高挑战性环境中实现同步接触序列与接触区域选择。通过大量仿真实验，我们证明该框架能快速生成多样化的动力学一致性运动方案。实验结果表明这些方案可成功迁移至真实四足机器人平台。进一步研究表明，该框架还能发现高度复杂的非周期性人形机器人机动策略。据我们所知，这是首次在四足机器人全身动力学框架下实现非周期性多接触运动的同步接触序列与接触区域选择。</p>
<div class="markdown-heading"><h2 class="heading-element">FlowMol3：面向三维全新小分子生成的流匹配技术</h2><a id="user-content-flowmol3面向三维全新小分子生成的流匹配技术" class="anchor" aria-label="Permalink: FlowMol3：面向三维全新小分子生成的流匹配技术" href="#flowmol3面向三维全新小分子生成的流匹配技术"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>（注：此处采用技术文档常见的翻译风格，将"Flow Matching"译为"流匹配技术"，"3D De Novo Small-Molecule Generation"译为"三维全新小分子生成"，既保持专业术语的准确性，又符合中文科技文献的表述习惯。冒号后的副标题采用解释性翻译，通过"面向"一词清晰体现技术应用领域，整体结构保持英文原题的简洁性。）</p>
<p>arXiv:2508.12629v1 公告类型：新成果<br>
摘要：能够生成具有特定性质的逼真分子样本的生成模型，有望在广泛的应用领域中加速化学发现进程。为实现这一目标，研究界重点开发了能够联合生成分子拓扑结构与三维构象的模型。我们提出FlowMol3——一个开源的多模态流匹配模型，该模型将全原子小分子生成技术推向了新的高度。相较于前代FlowMol版本，其显著性能提升并未依赖图神经网络架构或底层流匹配公式的改动，而是通过三项架构无关的技术实现：自条件生成、虚拟原子以及训练时几何畸变，这些技术仅带来可忽略的计算开销。FlowMol3在包含显式氢原子的类药物分子生成中实现了近100%的分子有效性，更精确地复现了训练数据的功能团组成与几何特征，且可学习参数数量比同类方法少一个数量级。我们推测这些技术有效缓解了基于输运的生成模型普遍存在的分布漂移问题，使其在推理过程中能够检测并修正这种漂移。本研究凸显了通过简洁可移植的策略，显著提升基于扩散和流方法的分子生成模型稳定性与生成质量的有效路径。</p>
<div class="markdown-heading"><h2 class="heading-element">FLARE：快速低秩注意力路由引擎</h2><a id="user-content-flare快速低秩注意力路由引擎" class="anchor" aria-label="Permalink: FLARE：快速低秩注意力路由引擎" href="#flare快速低秩注意力路由引擎"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.12594v1 公告类型：新成果<br>
摘要：自注意力机制的二次计算复杂度限制了其在大规模非结构化网格上的适用性和扩展性。我们提出快速低秩注意力路由引擎（FLARE），这是一种线性计算复杂度的自注意力机制，通过固定长度的潜在序列进行注意力路由。每个注意力头通过可学习的查询令牌将输入序列投影到长度为$M \ll N$的固定潜在序列上，实现$N$个令牌间的全局通信。通过瓶颈序列路由注意力，FLARE学会了以$O(NM)$成本应用的低秩注意力形式。FLARE不仅能够扩展到前所未有的问题规模，还在多个基准测试中超越了最先进的神经PDE代理模型的精度。我们还发布了一个新的增材制造数据集以推动进一步研究。代码已开源：<a href="https://github.com/vpuri3/FLARE.py%E3%80%82">https://github.com/vpuri3/FLARE.py。</a></p>
<div class="markdown-heading"><h2 class="heading-element">通过未来导向奖励的强化学习实现大型语言模型中的开放式情感支持对话</h2><a id="user-content-通过未来导向奖励的强化学习实现大型语言模型中的开放式情感支持对话" class="anchor" aria-label="Permalink: 通过未来导向奖励的强化学习实现大型语言模型中的开放式情感支持对话" href="#通过未来导向奖励的强化学习实现大型语言模型中的开放式情感支持对话"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.12935v1 公告类型：新成果<br>
摘要：情感支持对话（ESC）系统旨在缓解用户情绪困扰，提供长期系统化的情感健康支持。然而现有基于大语言模型（LLM）的ESC系统多依赖预定义策略，在复杂现实场景中的有效性受限。为实现对多样化情绪问题场景的灵活响应，本文提出新型端到端框架RLFF-ESC，通过强化学习直接习得可持续的情感支持响应技能。针对持续性情感支持需求，我们首先采用基于LLM的多智能体机制模拟未来对话轨迹并收集前瞻性奖励，继而训练面向未来的奖励模型，最终用于训练情感支持策略模型。此外，在响应生成过程中引入显式推理机制，进一步提升系统回复的质量、相关性与情境适配度。我们在Qwen2.5-7B-Instruct-1M和LLaMA3.1-8B-Instruct模型上对主干策略模型进行评估，并在两个公开ESC数据集上测试RLFF-ESC框架。实验结果表明，该框架在目标完成度和响应质量方面持续优于现有基线模型。</p>
<div class="markdown-heading"><h2 class="heading-element">e-boost：采用自适应启发式与精确求解的增强型E图提取技术</h2><a id="user-content-e-boost采用自适应启发式与精确求解的增强型e图提取技术" class="anchor" aria-label="Permalink: e-boost：采用自适应启发式与精确求解的增强型E图提取技术" href="#e-boost采用自适应启发式与精确求解的增强型e图提取技术"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.13020v1 公告类型：新成果<br>
摘要：E图在多个领域日益受到关注，尤其在逻辑综合与形式验证方面表现突出。E图提取是一个具有挑战性的NP难组合优化问题，需要从指数级数量的等价表达式中识别最优项，成为基于E图的优化任务中的主要性能瓶颈。然而传统提取方法面临关键权衡：启发式方法追求速度却牺牲最优性，而精确方法虽能提供最优解，却在实际问题中面临极高的计算成本。我们提出e-boost这一创新框架，通过三项关键技术突破实现平衡：(1) 并行化启发式提取利用弱数据依赖性实现DAG成本的并发计算，在保持提取质量的同时实现高效多线程性能；(2) 自适应搜索空间剪枝采用参数化阈值机制仅保留潜力候选，在维持近优解的同时显著压缩解空间；(3) 初始化精确求解将简化问题转化为具备热启动能力的整数线性规划，加速求解器获得高质量解。在形式验证和逻辑合成的多样化基准测试中，e-boost相比传统精确方法（ILP）实现558倍加速，较最先进提取框架（SmoothE）提升19.04%性能。在实际逻辑综合任务中，使用两种不同工艺库时，e-boost相较传统综合工具分别实现7.6%和8.1%的面积优化。项目地址：<a href="https://github.com/Yu-Maryland/e-boost%E3%80%82">https://github.com/Yu-Maryland/e-boost。</a></p>
<div class="markdown-heading"><h2 class="heading-element">OmniD：基于图像鸟瞰图表示的可泛化机器人操作策略</h2><a id="user-content-omnid基于图像鸟瞰图表示的可泛化机器人操作策略" class="anchor" aria-label="Permalink: OmniD：基于图像鸟瞰图表示的可泛化机器人操作策略" href="#omnid基于图像鸟瞰图表示的可泛化机器人操作策略"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.11898v1 公告类型：新论文<br>
摘要：视觉运动策略容易过拟合其训练数据集，例如固定的摄像机位置和背景。这种过拟合导致策略在分布内场景表现良好，但在分布外泛化中表现欠佳。此外，现有方法在融合多视角信息以生成有效的三维表征方面也存在困难。为解决这些问题，我们提出全视角扩散策略（OmniD），这是一个多视角融合框架，能将图像观测合成为统一的鸟瞰图（BEV）表征。我们引入基于可变形注意力的全视角特征生成器（OFG），选择性提取任务相关特征，同时抑制视角特异性噪声和背景干扰。在分布内、分布外和少样本实验中，OmniD分别以11%、17%和84%的平均提升率超越最佳基线模型。训练代码与仿真基准已开源：<a href="https://github.com/1mather/omnid.git">https://github.com/1mather/omnid.git</a></p>
<div class="markdown-heading"><h2 class="heading-element">生成式医疗事件模型随规模扩展而优化</h2><a id="user-content-生成式医疗事件模型随规模扩展而优化" class="anchor" aria-label="Permalink: 生成式医疗事件模型随规模扩展而优化" href="#生成式医疗事件模型随规模扩展而优化"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.12104v1 公告类型：新研究<br>
摘要：实现规模化个性化医疗需要从纵向患者旅程中提炼洞见，这类数据可视为一系列医疗事件的序列。基于大规模医疗事件数据预训练的基础模型为扩展真实世界证据生成和泛化至多样化下游任务提供了可行路径。我们利用Epic Cosmos数据集——该数据集涵盖310个医疗系统、超过3亿条独立患者记录中的163亿次诊疗遭遇的脱敏纵向健康记录——推出了Cosmos医疗事件Transformer模型系列（CoMET）。这是一组仅含解码器的Transformer模型，在代表1150亿个离散医疗事件（1510亿个标记）的1.18亿患者数据上进行预训练。我们开展了医疗数据领域最大规模的缩放定律研究，建立了预训练方法论并揭示了计算量、标记量和模型规模间的幂律缩放关系。基于此，我们预训练了参数规模达10亿的计算最优模型系列。CoMET能基于患者真实历史自回归生成下一医疗事件，模拟患者健康时间线。我们在78个真实世界任务（包括诊断预测、疾病预后和医疗运营）上进行测试：值得关注的是，这个采用通用预训练和基于模拟推理的基础模型，在无需任务特定微调或少样本示例的情况下，整体表现优于或匹配专门训练的监督模型。CoMET的预测能力随模型规模和预训练数据量持续提升。研究表明，CoMET作为生成式医疗事件基础模型，能有效捕捉复杂临床动态，为支持临床决策、优化医疗运营和改善患者预后提供可扩展且泛化性强的框架。</p>
<div class="markdown-heading"><h2 class="heading-element">公平感知的多视图证据学习与自适应先验</h2><a id="user-content-公平感知的多视图证据学习与自适应先验" class="anchor" aria-label="Permalink: 公平感知的多视图证据学习与自适应先验" href="#公平感知的多视图证据学习与自适应先验"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>（注：此翻译在保持原意的基础上进行了学术表达的优化："Fairness-Aware"译为"公平感知"符合机器学习领域术语习惯，"Multi-view"采用"多视图"这一计算机视觉/机器学习标准译法，"Evidential Learning"译为"证据学习"对应Dempster-Shafer理论框架，"Adaptive Prior"译为"自适应先验"符合贝叶斯统计术语规范。整体采用四字格结构增强学术文本的韵律感。）</p>
<p>arXiv:2508.12997v1 公告类型：新成果<br>
摘要：多视图证据学习旨在整合多个视角的信息以提升预测性能并提供可信的不确定性估计。现有方法大多默认视图特异性证据学习天然可靠，但实践中该过程常存在偏差。通过对真实数据的实证分析，我们发现样本往往被分配更多证据支持数据丰富的类别，导致预测中的不确定性估计不可靠。这一发现促使我们深入探究新型的"偏置证据多视图学习"（BEML）问题。为此，我们提出公平感知多视图证据学习框架（FAML）。FAML首先引入基于训练轨迹的自适应先验，作为正则化策略灵活校准有偏的证据学习过程；进一步显式融入基于类别证据方差的公平约束，促进证据分配的均衡性；在多视图融合阶段提出意见对齐机制，通过消除视图间特异性偏差促使证据实现一致且互增强的整合。在五个真实多视图数据集上的大量实验表明，相较于现有最优方法，FAML能实现更均衡的证据分配，同时在预测性能和不确定性估计可靠性方面均有提升。</p>
<div class="markdown-heading"><h2 class="heading-element">MAPF-World：多智能体路径规划的行动世界模型</h2><a id="user-content-mapf-world多智能体路径规划的行动世界模型" class="anchor" aria-label="Permalink: MAPF-World：多智能体路径规划的行动世界模型" href="#mapf-world多智能体路径规划的行动世界模型"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.12087v1 公告类型：新成果<br>
摘要：多智能体路径规划（MAPF）旨在为多个智能体规划从指定起点到目标位置的无冲突路径，是多机器人协同、机器人辅助物流及社会导航等现实任务的基础。近年出现的分散式可学习求解器在大规模MAPF任务中展现出巨大潜力，特别是在融合基础模型与大规模数据集时表现突出。然而这类智能体采用反应式策略模型，对环境时序动态和智能体间依赖关系的建模能力有限，导致其在复杂长期规划场景中性能下降。为此，我们提出MAPF-World——一种用于MAPF的自回归动作世界模型，将态势理解与动作生成相统一，能够超越局部即时观测进行决策指导。该模型通过预测未来状态与动作，显式建模包含空间特征和时序依赖的环境动态，从而提升态势感知能力。通过整合这些预测未来状态，MAPF-World可实现更具前瞻性、协调性和信息完备的决策，尤其在复杂多智能体场景中表现卓越。此外，我们基于真实场景开发自动地图生成器来扩展MAPF基准测试集，获取符合实际的地图布局用于训练和评估MAPF求解器。大量实验表明，MAPF-World在零样本泛化到分布外案例时优于当前最先进的可学习求解器，且模型尺寸减小96.5%，训练数据量降低92%。</p>
<div class="markdown-heading"><h2 class="heading-element">GraphCogent：通过多智能体协作突破大语言模型在复杂图理解中的工作记忆限制</h2><a id="user-content-graphcogent通过多智能体协作突破大语言模型在复杂图理解中的工作记忆限制" class="anchor" aria-label="Permalink: GraphCogent：通过多智能体协作突破大语言模型在复杂图理解中的工作记忆限制" href="#graphcogent通过多智能体协作突破大语言模型在复杂图理解中的工作记忆限制"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.12379v1 公告类型：新成果<br>
摘要：大语言模型（LLMs）在小规模图推理任务中表现出良好性能，但在处理具有复杂查询的真实世界图谱时却表现不佳。这一现象源于LLMs无法同时有效处理复杂图拓扑和执行多步推理。为突破这些局限，我们提出GraphCogent——一个受人类工作记忆模型启发的协同智能体框架，将图推理分解为三个专门化认知流程：感知（sense）、缓冲（buffer）和执行（execute）。该框架包含三大模块：感知模块通过子图采样标准化异构图文本表示，缓冲模块集成并索引多格式图数据，执行模块结合工具调用与模型生成实现高效推理。我们同步推出Graph4real基准测试集，涵盖网络、社交、交通和引文四大真实图域，包含21类图推理任务（分为结构查询、算法推理和预测建模三大类型），其图规模达到现有基准的10倍。实验表明，基于Llama3.1-8B的GraphCogent相较DeepSeek-R1（671B）等超大规模LLMs实现50%性能提升，较现有最先进的基于智能体的基线方法，在工具集内任务准确率提高20%的同时，令牌使用量减少80%，工具集外任务令牌消耗降低30%。代码将在评审后开源。</p>
<div class="markdown-heading"><h2 class="heading-element">混合专家系统的最大得分路由</h2><a id="user-content-混合专家系统的最大得分路由" class="anchor" aria-label="Permalink: 混合专家系统的最大得分路由" href="#混合专家系统的最大得分路由"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.12801v1 公告类型：新成果<br>
摘要：稀疏激活专家混合网络（MoE）通过可微分稀疏变换将输入令牌动态分配给top-k专家，在保持计算效率的同时实现了模型容量的可扩展性。传统MoE网络采用专家容量约束以确保GPU友好型计算，但这会导致容量饱和时的令牌丢弃问题，并因未充分利用专家的填充操作而降低硬件效率。移除容量约束虽能避免上述问题，却会破坏负载均衡与计算效率。为解决这一根本矛盾，我们提出最大分数路由（MaxScore）——一种将路由建模为最小成本最大流问题并整合SoftTopk算子的新型MoE路由范式。MaxScore从根本上解决了迭代重路由和最优传输方案的局限性，在相同FLOPs条件下，相比有约束和无约束基线方法均实现了更低的训练损失和更高的评估分数。具体实现细节与实验配置可从$\href{<a href="https://github.com/dongbw18/MaxScore.git%7D%7BMaxScore%7D$%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/dongbw18/MaxScore.git}{MaxScore}$获取。</a></p>
<div class="markdown-heading"><h2 class="heading-element">MDPO：弥合掩码扩散语言模型训练与推理间的鸿沟</h2><a id="user-content-mdpo弥合掩码扩散语言模型训练与推理间的鸿沟" class="anchor" aria-label="Permalink: MDPO：弥合掩码扩散语言模型训练与推理间的鸿沟" href="#mdpo弥合掩码扩散语言模型训练与推理间的鸿沟"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.13148v1 公告类型：新研究<br>
摘要：扩散语言模型作为传统自回归（AR）模型的有前景替代方案，能够实现更快的生成速度并支持对双向上下文进行更丰富的条件控制。然而，这类模型存在训练与推理的关键差异：在推理过程中，MDLMs通过逐步减少掩码标记的数量来揭示生成序列的结构，而训练时由于标记被随机掩码，这种结构信息被完全忽略。尽管这种差异可能导致次优性能，先前研究大多忽视了这一问题，使得弥合两个阶段间的差距成为待解难题。为此，我们将学习有效去噪轨迹的问题构建为序列决策问题，并运用强化学习框架提出新型掩码扩散策略优化（MDPO）方法。该方法利用扩散过程具备的马尔可夫特性，在推理采用的渐进细化调度下显式训练模型。MDPO仅用1/60的梯度更新量即达到先前最佳性能，在同等权重更新次数下，于MATH500和Countdown数据集上分别实现9.6%和54.2%的平均提升。此外，我们改进了MDLMs的重掩码策略作为即插即用的推理替代方案，以克服模型无法灵活优化标记的限制。这种名为RCR的训练免费策略不仅能持续提升性能，与MDPO结合时还可产生额外增益。我们的发现为探索MDLMs预训练与推理间的差异开辟了新路径。代码：<a href="https://github.com/autonomousvision/mdpo">https://github.com/autonomousvision/mdpo</a> 项目页：<a href="https://cli212.github.io/MDPO/" rel="nofollow">https://cli212.github.io/MDPO/</a></p>
<div class="markdown-heading"><h2 class="heading-element">通信高效的分布式异步ADMM</h2><a id="user-content-通信高效的分布式异步admm" class="anchor" aria-label="Permalink: 通信高效的分布式异步ADMM" href="#通信高效的分布式异步admm"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.12233v1 公告类型：新研究<br>
摘要：在分布式优化与联邦学习领域，异步交替方向乘子法（ADMM）因其能有效应对大规模优化、数据隐私保护、滞后节点处理以及多样化目标函数而成为理想选择。然而，当节点通信预算受限或需传输数据量过大时，通信成本可能成为主要瓶颈。本研究提出在异步ADMM的数据交换环节引入粗粒度量化机制，以显著降低大规模联邦学习及分布式优化应用中的通信开销。通过包括神经网络在内的多项分布式学习任务实验，我们验证了所提方法的收敛性能。</p>
<div class="markdown-heading"><h2 class="heading-element">CRoC：基于上下文重构对比的有限监督图异常检测方法</h2><a id="user-content-croc基于上下文重构对比的有限监督图异常检测方法" class="anchor" aria-label="Permalink: CRoC：基于上下文重构对比的有限监督图异常检测方法" href="#croc基于上下文重构对比的有限监督图异常检测方法"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>（注：此处采用意译策略，将专业术语"Context Refactoring Contrast"译为"上下文重构对比"，既保持技术准确性又符合中文表达习惯。"Limited Supervision"译为"有限监督"是领域标准译法，整体采用"方法"作为结尾词符合中文论文标题命名规范。）</p>
<p>arXiv:2508.12278v1 公告类型：新研究<br>
摘要：图神经网络（GNNs）作为分析图结构数据的有效引擎，已被广泛应用于各类图相关任务。然而，训练鲁棒的GNN通常需要大量标注数据，这在实际应用中构成关键瓶颈。这一限制严重阻碍了图异常检测（GAD）领域的进展——因为异常本身具有稀缺性、标注成本高昂，且可能主动伪装模式以逃避检测。为解决这些问题，我们提出上下文重构对比框架（CRoC），通过联合利用有限标注数据和海量未标注数据来训练GAD专用的GNN。与现有研究不同，CRoC利用GAD中固有的类别不平衡特性重构节点上下文：通过重组节点属性构建增强图，同时保持其交互模式不变。该框架还分别编码异构关系并将其融入消息传递过程，增强模型捕获复杂交互语义的能力。这些操作在保留节点语义的同时提升了对对抗性伪装的鲁棒性，使GNN能够揭示复杂的异常案例。在训练阶段，CRoC进一步与对比学习范式结合，使GNN在联合训练中有效利用未标注数据，生成更丰富、判别力更强的节点嵌入。我们在七个不同规模的真实GAD数据集上评估CRoC，大量实验表明：在有限标注设置下，CRoC相比基线GNN最高提升14%的AUC指标，并显著优于当前最先进的GAD方法。</p>
<div class="markdown-heading"><h2 class="heading-element">FedUNet：一种用于异构模型联邦学习的轻量级加法式U-Net模块</h2><a id="user-content-fedunet一种用于异构模型联邦学习的轻量级加法式u-net模块" class="anchor" aria-label="Permalink: FedUNet：一种用于异构模型联邦学习的轻量级加法式U-Net模块" href="#fedunet一种用于异构模型联邦学习的轻量级加法式u-net模块"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>（注：FedUNet保留了技术术语的英文原名以保持专业性；"Lightweight Additive"采用"轻量级加法式"的译法准确传达模块特性；"Federated Learning with Heterogeneous Models"译为"异构模型联邦学习"符合计算机领域术语规范，整体翻译在保持专业性的同时确保中文表达流畅。）</p>
<p>arXiv:2508.12740v1 公告类型：新成果<br>
摘要：联邦学习（FL）能够在无需共享本地数据的情况下实现去中心化模型训练。然而，现有方法大多假设客户端采用相同模型架构，这限制了其在异构现实环境中的适用性。为此，我们提出FedUNet——一种轻量级且架构无关的FL框架，通过为每个客户端骨干网络附加受U-Net启发的增广模块。仅共享U-Net的紧凑瓶颈层，FedUNet即可在不要求结构对齐的情况下实现高效知识迁移。U-Net中的编码器-解码器设计和跳跃连接有助于捕捉低层与高层特征，促进客户端不变表征的提取。这使得骨干网络与增广模块能够以极低的通信成本实现协同学习。基于VGG变体的实验表明，FedUNet在仅产生0.89MB低通信开销的情况下，完整版达到93.11%准确率，紧凑版（即轻量化版本）达到92.68%准确率。</p>
<div class="markdown-heading"><h2 class="heading-element">循环神经网络中状态与参数的时间尺度耦合</h2><a id="user-content-循环神经网络中状态与参数的时间尺度耦合" class="anchor" aria-label="Permalink: 循环神经网络中状态与参数的时间尺度耦合" href="#循环神经网络中状态与参数的时间尺度耦合"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.12121v1 公告类型：新研究<br>
摘要：本研究探讨了循环神经网络（RNN）中的门控机制如何隐式地诱导自适应学习率行为，即使在采用固定全局学习率进行训练时也是如此。这种现象源于梯度下降过程中状态空间时间尺度（由门控参数化）与参数空间动力学之间的耦合关系。通过推导泄漏积分器和门控RNN的精确雅可比矩阵，我们获得了一阶展开式，明确揭示了恒定门控、标量门控和多维门控如何重塑梯度传播、调节有效步长，并在参数更新中引入各向异性。这些发现表明，门控不仅控制隐藏状态中的记忆保留，还充当数据驱动的预处理器，自适应地调整参数空间中的优化轨迹。我们进一步与学习率调度、动量法以及Adam等自适应方法建立形式化类比，证明这些优化行为天然地源于门控机制。数值实验验证了我们的扰动分析的有效性，支持了门控诱导的修正量虽小但对训练动力学产生系统性影响的观点。总体而言，本研究提供了统一的动力学系统视角，阐明门控如何将状态演化与参数更新相耦合，从而解释了门控架构在实践中实现稳健可训练性和稳定性的内在机制。</p>
<div class="markdown-heading"><h2 class="heading-element">基于测地线追踪的流形网格上滚动与滑动接触运动学积分方法用于灵巧手内操作</h2><a id="user-content-基于测地线追踪的流形网格上滚动与滑动接触运动学积分方法用于灵巧手内操作" class="anchor" aria-label="Permalink: 基于测地线追踪的流形网格上滚动与滑动接触运动学积分方法用于灵巧手内操作" href="#基于测地线追踪的流形网格上滚动与滑动接触运动学积分方法用于灵巧手内操作"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.12439v1 公告类型：新成果<br>
摘要：滚动与滑动接触（简称滚滑接触）的推理对于涉及复杂几何结构的灵巧操控任务至关重要。但现有关于滚滑接触的研究大多集中于具有可微分参数化的连续形状。本研究将滚滑接触建模拓展至流形网格领域，提出基于测地线追踪的积分方案，首次实现直接在网格上进行滚滑接触的一阶时间积分，使灵巧操控能够基于物体真实几何的高保真离散表征进行推理。通过该方法，我们在仿真中规划了多指机械手对五个物体进行手内操控的灵巧运动——采用最小二乘优化器进行运动规划，通过最小化接触滑动与旋转来维持最稳定的瞬时抓取。随后，我们将本方法与基于碰撞检测的基线方法及基于原始几何形状的基线方法进行对比评估。结果表明：即使在粗糙网格上，我们的方法仍在准确性与精确度方面表现最优。最后我们展望未来工作，讨论如何融合多触点与接触力以实现精准鲁棒的基于网格的表面接触建模。</p>
<div class="markdown-heading"><h2 class="heading-element">带评分标准锚点的强化学习</h2><a id="user-content-带评分标准锚点的强化学习" class="anchor" aria-label="Permalink: 带评分标准锚点的强化学习" href="#带评分标准锚点的强化学习"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.12790v1 公告类型：新成果<br>
摘要：可验证奖励强化学习（RLVR）已成为增强大语言模型（LLMs）能力的重要范式，OpenAI的o系列模型成功印证了这一点。在RLVR中，奖励源自可验证信号——例如代码生成中通过单元测试，或数学推理中匹配正确答案。虽然有效，但这一要求使RLVR主要局限于可自动验证结果的领域。为突破此限制，我们通过引入基于量规的奖励机制，将RLVR范式扩展至开放式任务领域，其中精心设计的量规作为结构化、模型可解释的准则，用于对主观输出进行自动评分。据我们所知，我们构建了迄今最大的量规奖励系统，包含超过10,000条由人类设计、LLM生成或人机协作创建的评估量规。实现基于量规的强化学习面临诸多挑战；我们通过清晰框架解决这些问题，并开源了Qwen-30B-A3B模型，其显著优势包括：1）仅使用5,000+样本，我们的系统在开放式基准测试（尤其是人文学科）上提升5.2%，以2.4%优势超越671B参数的DeepSeek-V3模型，同时保持通用与推理能力；2）该方法提供细粒度风格控制，以量规为锚点缓解"AI腔调"，生成更类人、富有表现力的回应。我们分享了量规构建、数据筛选和训练的核心经验，并讨论了局限性及未来发布计划。</p>
<div class="markdown-heading"><h2 class="heading-element">少说轻飞：基于大语言模型的无人机群自主语义压缩通信</h2><a id="user-content-少说轻飞基于大语言模型的无人机群自主语义压缩通信" class="anchor" aria-label="Permalink: 少说轻飞：基于大语言模型的无人机群自主语义压缩通信" href="#少说轻飞基于大语言模型的无人机群自主语义压缩通信"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.12043v1 公告类型：新成果<br>
摘要：大型语言模型（LLM）在无人系统中的快速应用显著增强了无人机集群的语义理解与自主任务执行能力。然而，有限的通信带宽和高频交互需求对集群内语义信息传输构成严峻挑战。本文探索了LLM驱动的无人机集群实现自主语义压缩通信的可行性，旨在保留关键任务语义的同时降低通信负载。为此，我们构建了四种不同环境复杂度的二维仿真场景，设计了融合系统提示与任务指令提示的通信-执行管道。在此基础上，系统评估了九种主流LLM在不同场景下的语义压缩性能，并通过环境复杂度和集群规模的消融实验分析了其适应性与稳定性。实验结果表明，基于LLM的无人机集群有望在带宽受限和多跳链路条件下实现高效协同通信。</p>
<div class="markdown-heading"><h2 class="heading-element">SparseMap：基于进化策略的稀疏张量加速器框架</h2><a id="user-content-sparsemap基于进化策略的稀疏张量加速器框架" class="anchor" aria-label="Permalink: SparseMap：基于进化策略的稀疏张量加速器框架" href="#sparsemap基于进化策略的稀疏张量加速器框架"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.12906v1 公告类型：新研究<br>
摘要：机器学习和大数据领域对稀疏张量代数（SpTA）日益增长的需求，推动了各类稀疏张量加速器的发展。然而现有手动设计的加速器大多局限于特定场景，且场景变更时需要耗费大量时间调整众多设计参数。实现SpTA加速器的自动化设计至关重要。但既往研究仅聚焦于映射策略（即在时空维度上划分通信与计算）或稀疏策略（即跳过零元素提升效率），缺乏对二者的统筹考量导致设计结果欠佳。亟需构建能协同优化两者的统一框架。然而映射策略与稀疏策略的融合会引发设计空间的组合爆炸（例如对于计算任务$P_{32 \times 64} \times Q_{64 \times 48} = Z_{32 \times 48}$，空间规模高达$O(10^{41})$量级）。这一庞大搜索空间使传统优化方法（如粒子群算法、强化学习、蒙特卡洛树搜索）普遍失效。为此，我们提出基于进化策略的稀疏张量加速器优化框架SparseMap，通过构建同时涵盖映射策略与稀疏策略的完整设计空间，并改进遗传编码与进化算子，使其能高效探索这一高维异构设计空间。定量对比表明，SparseMap相较现有研究和经典优化方法能持续获得更优解。</p>
<div class="markdown-heading"><h2 class="heading-element">基于LoRA的多模态生物医学图像增量学习对比正则化方法</h2><a id="user-content-基于lora的多模态生物医学图像增量学习对比正则化方法" class="anchor" aria-label="Permalink: 基于LoRA的多模态生物医学图像增量学习对比正则化方法" href="#基于lora的多模态生物医学图像增量学习对比正则化方法"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>这个翻译采用了以下处理方式：</p>
<ol>
<li>专业术语准确对应："Contrastive Regularization"译为"对比正则化"，"LoRA"保持技术缩写原貌，"Multimodal Biomedical Image"译为"多模态生物医学图像"，"Incremental Learning"译为"增量学习"</li>
<li>句式结构调整：将英语名词短语转换为中文常用的"基于...的..."学术表达句式</li>
<li>领域适应性：确保术语符合医学影像和机器学习领域的专业表达习惯</li>
<li>简洁性处理：在保持专业性的同时避免冗长表达，符合中文技术文献标题的简洁要求</li>
</ol>
<p>arXiv:2508.11673v1 公告类型：新成果<br>
摘要：多模态生物医学图像增量学习（MBIIL）对于处理生物医学领域多样化的任务和模态至关重要，因为为每种模态或任务单独训练模型会显著增加推理成本。现有增量学习方法主要关注单一模态内的任务扩展，而MBIIL致力于跨模态逐步训练统一模型。MBIIL面临两大挑战：I）如何在增量更新过程中保留已学知识？II）如何有效利用现有模态获取的知识来支持新模态？为解决这些挑战，我们提出MSLoRA-CR方法，通过微调模态特定的LoRA模块并引入对比正则化，以增强模态内知识共享并促进模态间知识分化。该方法基于大型视觉语言模型（LVLM）构建，保持预训练模型冻结状态，同时为每个模态或任务增量适配新的LoRA模块。在生物医学图像增量学习的实验中，MSLoRA-CR不仅优于为各模态单独训练模型的先进（SOTA）方法，也超越了通用增量学习方法（逐步微调LoRA）。具体而言，在保持计算效率的同时，MSLoRA-CR相比无约束增量学习方法实现了1.88%的整体性能提升。代码已开源：<a href="https://github.com/VentusAislant/MSLoRA_CR%E3%80%82">https://github.com/VentusAislant/MSLoRA_CR。</a></p>
<p>（注：根据学术规范要求，关键术语如"LoRA"（Low-Rank Adaptation）和"SOTA"（State-of-the-Art）保留英文缩写形式，确保专业领域的准确性；技术术语"contrastive regularization"采用"对比正则化"的学界通用译法；长难句按中文表达习惯进行合理切分，如将英文复合句拆解为多个短句；机构名称"arXiv"按惯例不翻译；URL链接保持原格式完整呈现。）</p>
<div class="markdown-heading"><h2 class="heading-element">照亮LLM编程智能体：通过可视化分析实现深度理解与优化</h2><a id="user-content-照亮llm编程智能体通过可视化分析实现深度理解与优化" class="anchor" aria-label="Permalink: 照亮LLM编程智能体：通过可视化分析实现深度理解与优化" href="#照亮llm编程智能体通过可视化分析实现深度理解与优化"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.12555v1 公告类型：新研究<br>
摘要：基于大语言模型（LLM）的编程智能体通过最小化人工干预的迭代问题解决方式，在自动化代码生成领域日益受到关注。尽管已出现多种框架（如LangChain、AutoML和AIDE），机器学习科学家仍难以有效审查和调整智能体的编程过程。当前依赖人工逐个检查输出的方式效率低下，导致代码演进轨迹难以追踪、编程迭代版本无法系统对比、改进机会不易识别。为应对这一挑战，我们开发了可视化分析系统，旨在增强对编程智能体行为的审视能力。以AIDE框架为研究对象，该系统支持三个层面的对比分析：（1）代码级分析——揭示智能体如何通过迭代调试优化代码；（2）过程级分析——对比智能体探索的不同解决方案路径；（3）LLM级分析——凸显不同大语言模型间的编程行为差异。通过整合这三重视角，本系统帮助机器学习科学家建立对智能体行为的结构化认知，从而更高效地进行调试和提示词工程。我们通过使用编程智能体解决热门Kaggle竞赛的案例研究，展示了该系统如何为迭代式编程过程提供关键洞察。</p>
<div class="markdown-heading"><h2 class="heading-element">FedUHD：基于超维度计算的无监督联邦学习</h2><a id="user-content-feduhd基于超维度计算的无监督联邦学习" class="anchor" aria-label="Permalink: FedUHD：基于超维度计算的无监督联邦学习" href="#feduhd基于超维度计算的无监督联邦学习"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.12021v1  公告类型：新成果<br>
摘要：无监督联邦学习（UFL）作为一种隐私保护的分布式机器学习方法，因无需人工标注数据而受到关注。然而UFL在实际应用中面临三大挑战：(1)设备间非独立同分布(non-iid)的数据分布，(2)边缘端高昂的计算与通信成本，(3)通信噪声敏感性问题。现有UFL方案依赖深度神经网络(NN)，导致计算与通信开销巨大。本文提出首个基于超维度计算(HDC)的UFL框架FedUHD。HDC作为一种脑启发计算范式，具有轻量化训练/推理、极小模型尺寸和噪声鲁棒性等优势。FedUHD通过两项创新设计提升UFL性能：客户端采用基于k近邻的聚类超向量剔除机制处理非iid数据中的异常样本；服务器端引入加权HDC聚合技术平衡跨客户端的非iid数据分布。实验表明，FedUHD在训练阶段分别实现173.6倍和612.7倍的加速比与能效提升，通信成本降低271倍，在不同设置下平均准确率提高15.50%，相较于最先进的基于神经网络的UFL方案展现出更优异的噪声鲁棒性。</p>
<div class="markdown-heading"><h2 class="heading-element">BUILDA：面向迁移学习的热力学建筑数据生成框架</h2><a id="user-content-builda面向迁移学习的热力学建筑数据生成框架" class="anchor" aria-label="Permalink: BUILDA：面向迁移学习的热力学建筑数据生成框架" href="#builda面向迁移学习的热力学建筑数据生成框架"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.12703v1 公告类型：新成果<br>
摘要：迁移学习（TL）能够提升建筑热力学数据驱动建模的效果。因此，该领域涌现出许多新兴研究方向，例如如何为迁移学习选择适宜的源模型。然而这些研究方向需要大量建筑热力学数据作为支撑，而当前数据储备严重不足——无论是公开数据集还是现有数据生成器，都无法满足迁移学习研究对数据质量与数量的需求。现有数据生成方法通常还需依赖建筑模拟领域的专业知识。我们提出BuilDa框架，该热力学建筑数据生成框架能产出质量与数量俱佳的合成数据，以支持迁移学习研究。该框架无需深厚的建筑模拟知识即可批量生成数据，采用单区域Modelica模型导出为功能 mock-up单元（FMU）并在Python环境中进行仿真。我们通过生成数据并应用于预训练与微调迁移学习模型的案例，验证了BuilDa框架的有效性。</p>
<div class="markdown-heading"><h2 class="heading-element">EvoCut：通过进化引导语言模型强化整数规划</h2><a id="user-content-evocut通过进化引导语言模型强化整数规划" class="anchor" aria-label="Permalink: EvoCut：通过进化引导语言模型强化整数规划" href="#evocut通过进化引导语言模型强化整数规划"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.11850v1 公告类型：新成果<br>
摘要：整数规划作为组合优化核心任务的关键技术，因其NP难特性始终面临求解挑战。当前实践中提升求解效率的有效手段是人工设计加速割（即能提升求解器性能的不等式约束），但这一创造性过程需要深厚专业素养且尚未实现自动化。我们提出的EvoCut框架通过融合大语言模型（LLMs）与进化搜索，实现了加速割的自动生成：首先通过基于LLM的初始化代理生成多样化候选割集合；随后针对每个割方案，在验证集上实证评估其保持最优解的能力与切割分数解的有效性；最后通过进化交叉和变异代理迭代优化种群。我们以求解器最优间隙的相对缩减率量化割的有效性，与标准整数规划实践对比显示，EvoCut在固定时间内将最优间隙降低17-57%，最快以4倍速度获得同等解，并在相同时限内得到更优解。该框架无需专家干预即可自动生成、改进并实证验证具有泛化能力的割方案。代码已开源：<a href="https://github.com/milad1378yz/EvoCut%E3%80%82">https://github.com/milad1378yz/EvoCut。</a></p>
<div class="markdown-heading"><h2 class="heading-element">GALA：图增强大语言模型代理工作流能否提升根因分析效能？</h2><a id="user-content-gala图增强大语言模型代理工作流能否提升根因分析效能" class="anchor" aria-label="Permalink: GALA：图增强大语言模型代理工作流能否提升根因分析效能？" href="#gala图增强大语言模型代理工作流能否提升根因分析效能"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.12472v1 公告类型：新论文<br>
摘要：微服务系统中的根因分析（RCA）具有挑战性，需要值班工程师快速通过指标、日志和追踪等异构遥测数据诊断故障。传统RCA方法通常仅关注单一模态或简单罗列可疑服务，难以提供具备可操作诊断洞见和修复指导的方案。本文提出GALA——一种创新多模态框架，将统计因果推断与LLM驱动的迭代推理相结合以增强RCA能力。在开源基准测试中，GALA相较现有最优方法实现高达42.22%的准确率提升。我们提出的人工引导式LLM评估分数表明，GALA生成的诊断结果比现有方法具有显著更强的因果逻辑性和可操作性。通过全面实验和案例研究，证明GALA既能实现精准的根因定位，又能提供人类可理解的修复指导，从而弥合自动化故障诊断与实际事故处理之间的鸿沟。</p>
<div class="markdown-heading"><h2 class="heading-element">波浪式变压器</h2><a id="user-content-波浪式变压器" class="anchor" aria-label="Permalink: 波浪式变压器" href="#波浪式变压器"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.12787v1 公告类型：新成果<br>
摘要：Transformer模型在自然语言处理（NLP）和计算机视觉（CV）领域取得了显著成功。然而，深层Transformer模型常面临过度平滑问题——当表征通过连续的Transformer块传递时，词元表示会逐渐收敛至相似值。本文通过建立堆叠注意力层诱导的隐状态动力学与完全图上图神经扩散的等价关系，从动力学视角将过度平滑现象解释为底层扩散过程耗散特性的必然结果。受此物理诠释启发，我们提出基于二阶波动动力学的新型注意力层构建Wavy Transformer，同时设计能保持链式法则下物理状态-速度关系的前馈网络与归一化层，从而扩展Transformer架构。在多种NLP和CV任务的Transformer模型上验证表明，该方法能以极少的参数量增长且无需额外超参数调优持续提升模型性能。</p>
<div class="markdown-heading"><h2 class="heading-element">STM3：用于长期时空时间序列预测的多尺度Mamba混合模型</h2><a id="user-content-stm3用于长期时空时间序列预测的多尺度mamba混合模型" class="anchor" aria-label="Permalink: STM3：用于长期时空时间序列预测的多尺度Mamba混合模型" href="#stm3用于长期时空时间序列预测的多尺度mamba混合模型"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.12247v1 公告类型：新成果<br>
摘要：时空时间序列预测研究近期发展迅速，但现有深度学习方法难以高效学习复杂的长期时空依赖关系。长期时空依赖学习面临两大新挑战：1）长期时间序列天然包含难以高效提取的多尺度信息；2）不同节点间的多尺度时序信息高度关联且难以建模。为此，我们提出高效的"时空多尺度Mamba模型"（STM2），其包含多尺度Mamba架构以同步高效捕获多尺度信息，并采用自适应图因果卷积网络学习复杂多尺度时空依赖。STM2通过分层信息聚合机制保障不同尺度信息的可区分性。为更高效捕捉全域空间节点的多样化时序动态，我们进一步提出增强版本"时空多尺度混合专家Mamba模型"（STM3），采用特殊混合专家架构：通过更稳定的路由策略和因果对比学习策略增强尺度区分能力。我们证明STM3具有更优的路由平滑度，并成功保障各专家的模式解耦能力。在真实场景基准测试中的大量实验表明，STM2/STM3在长期时空时间序列预测中实现最优性能，达到当前最先进水平。</p>
<div class="markdown-heading"><h2 class="heading-element">全脉冲演员-评论家神经网络在机器人操控中的应用</h2><a id="user-content-全脉冲演员-评论家神经网络在机器人操控中的应用" class="anchor" aria-label="Permalink: 全脉冲演员-评论家神经网络在机器人操控中的应用" href="#全脉冲演员-评论家神经网络在机器人操控中的应用"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.12038v1 公告类型：新研究<br>
摘要：本研究提出了一种基于全脉冲神经网络（SNN）的混合课程强化学习（CRL）框架，用于控制9自由度机械臂执行目标抓取任务。为降低网络复杂度和推理延迟，SNN架构被简化为仅包含输入层和输出层，展现出在资源受限环境中的巨大潜力。基于SNN高推理速度、低能耗和脉冲生物合理性等优势，研究将时序进度分区课程策略与近端策略优化（PPO）算法相结合。同时引入能耗建模框架，定量比较SNN与传统人工神经网络（ANN）的理论能耗。动态双阶段奖励调整机制和优化观测空间进一步提升了学习效率与策略精度。在Isaac Gym仿真平台上的实验表明，该方法在真实物理约束下实现了卓越性能。与传统PPO和ANN基线的对比验证了该方案在动态机器人操作任务中的可扩展性与能效优势。</p>
<div class="markdown-heading"><h2 class="heading-element">夸克医疗基础模型技术报告</h2><a id="user-content-夸克医疗基础模型技术报告" class="anchor" aria-label="Permalink: 夸克医疗基础模型技术报告" href="#夸克医疗基础模型技术报告"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>（注：QuarkMed可译为"夸克医疗"，既保留Quark的音译"夸克"（物理学基本粒子名，寓意基础性与前沿性），又通过"医疗"明确机构领域。"Medical Foundation Model"译为"医疗基础模型"准确体现技术属性，"Technical Report"采用行业通用译法"技术报告"。整体译文在保持专业性的同时兼顾中文表达习惯。）</p>
<p>arXiv:2508.11894v1 公告类型：新成果<br>
摘要：大型语言模型的最新进展显著加速了其在医疗健康领域的应用，包括AI问诊、诊断报告辅助和医学检索工具等场景。然而医疗任务通常需要高度专业化的知识、专业精准度及定制化能力，这要求基础模型必须具备强大的可靠性与鲁棒性。QuarkMed通过构建精细化医疗数据处理体系、医学内容检索增强生成技术（RAG）以及大规模可验证的强化学习 pipeline，成功开发出高性能医疗基础模型。该模型在中华人民共和国执业医师资格考试中达到70%的准确率，并在多项医学基准测试中展现出卓越的泛化能力。QuarkMed提供了强大而灵活的个人医疗AI解决方案，目前已在ai.quark.cn平台为超百万用户提供服务。</p>
<div class="markdown-heading"><h2 class="heading-element">联合实体-关系抽取的LLM+ASP工作流</h2><a id="user-content-联合实体-关系抽取的llmasp工作流" class="anchor" aria-label="Permalink: 联合实体-关系抽取的LLM+ASP工作流" href="#联合实体-关系抽取的llmasp工作流"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.12611v1 公告类型：新研究<br>
摘要：联合实体关系抽取（JERE）旨在同时识别文本中的实体及其关系。传统基于机器学习的方法需要大量标注数据，且难以在模型构建中灵活融入领域特定信息，导致JERE模型的创建往往耗时费力、缺乏扩展弹性。本文提出结合生成式预训练大语言模型（LLMs）的语言理解能力与回答集编程（ASP）的知识表示推理机制来实现JERE。我们设计了一个通用工作流，其优势在于：适用于任意领域的JERE任务，直接处理未标注文本以发挥LLMs的自然语言理解优势，利用ASP的扩展容忍特性——当需要补充领域知识（如类型规范）时无需修改核心程序。通过在三个知名JERE基准上的小规模训练实验证明，该工作流仅用10%训练数据即在多项指标上超越现有最优系统。在最具挑战性的SciERC语料库关系抽取任务中，实现了从15%到35%的显著提升（2.5倍性能增益）。</p>
<div class="markdown-heading"><h2 class="heading-element">无需微调将模型部署至非参与客户端的联邦学习：一种基于超网络的方法</h2><a id="user-content-无需微调将模型部署至非参与客户端的联邦学习一种基于超网络的方法" class="anchor" aria-label="Permalink: 无需微调将模型部署至非参与客户端的联邦学习：一种基于超网络的方法" href="#无需微调将模型部署至非参与客户端的联邦学习一种基于超网络的方法"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.12673v1 公告类型：新论文<br>
摘要：联邦学习（FL）已成为隐私保护协同学习的重要范式，但数据异质性仍是关键挑战。现有方法虽在解决参与客户端的数据异质性方面取得进展，却难以泛化至存在域内分布偏移和资源约束的非参与客户端。为此，我们提出HyperFedZero——一种通过基于分布感知嵌入的超网络动态生成专用模型的新方法。该方法显式地将分布感知归纳偏置融入模型前向传播过程，利用带平衡惩罚项的NoisyEmbed增强提取器获取鲁棒的分布嵌入，有效防止特征坍缩。超网络随后逐块生成适配非参与客户端独特数据分布的专用模型。在多数据集和模型上的大量实验表明，HyperFedZero以极小的计算、存储和通信开销持续超越现有方法，展现出卓越性能。消融研究和可视化分析进一步验证了各组件的必要性，证实了模型具有有意义的适应能力，证明了HyperFedZero的有效性。</p>
<div class="markdown-heading"><h2 class="heading-element">UniCast：面向时间序列预测的统一多模态提示框架</h2><a id="user-content-unicast面向时间序列预测的统一多模态提示框架" class="anchor" aria-label="Permalink: UniCast：面向时间序列预测的统一多模态提示框架" href="#unicast面向时间序列预测的统一多模态提示框架"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.11954v1 公告类型：新论文<br>
摘要：时间序列预测是金融、医疗健康和环境监测等领域的基础性任务。尽管时间序列基础模型（TSFMs）通过大规模预训练展现出强大的泛化能力，但现有模型主要局限于单模态设定，忽略了现实场景中常伴随时间序列数据的丰富多模态语境（如视觉与文本信号）。本文提出了一种新颖的参数高效多模态框架UniCast，将TSFMs扩展至联合利用时间序列、视觉和文本模态以提升预测性能。我们的方法通过软提示调优技术，将预训练视觉编码器和文本编码器的模态特定嵌入与冻结的TSFM相融合，仅需极少的参数更新即可实现高效适配。这一设计既保留了基础模型的泛化优势，又实现了有效的跨模态交互。在多样化时间序列预测基准上的大量实验表明，UniCast始终显著优于所有现有TSFM基线模型。研究结果凸显了多模态语境在推动新一代通用时间序列预测器发展中的关键作用。</p>
<div class="markdown-heading"><h2 class="heading-element">RLNVR：基于非验证现实世界奖励的强化学习</h2><a id="user-content-rlnvr基于非验证现实世界奖励的强化学习" class="anchor" aria-label="Permalink: RLNVR：基于非验证现实世界奖励的强化学习" href="#rlnvr基于非验证现实世界奖励的强化学习"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.12165v1 公告类型：新论文<br>
摘要：本文提出RLNVR（非验证奖励强化学习）框架，该框架能够利用未经人工验证的嘈杂现实世界反馈信号训练语言模型。传统RLHF方法依赖成本高昂的验证奖励信号，这在许多现实场景中难以实施。RLNVR通过基线标准化和基于语义相似度的奖励迁移解决这一难题。我们通过Walter原型系统展示该框架——该系统利用Bluesky平台的实际互动数据优化社交媒体内容生成。实验结果显示内容质量和训练稳定性显著提升，完整评估将在未来工作中展开。<br>
定位：我们提出将RLNVR与GSPO（群组序列策略优化）及可选UED（无监督环境设计）课程相结合的实用框架，以提升嘈杂隐式奖励下的稳定性和多样性。据我们所知，在基于隐式社交互动的LLM内容生成场景中，将GSPO式标准化与UED式课程相结合的应用尚未见文献记载；我们将其定位为应用集成方案而非新算法。</p>
<div class="markdown-heading"><h2 class="heading-element">通过广义一致性模型实现分布匹配</h2><a id="user-content-通过广义一致性模型实现分布匹配" class="anchor" aria-label="Permalink: 通过广义一致性模型实现分布匹配" href="#通过广义一致性模型实现分布匹配"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.12222v1 公告类型：新成果<br>
摘要：生成模型的最新进展在各种数据模态中展现出卓越性能。除了在数据合成中的典型应用外，这些模型在潜在变量建模、领域转换和领域适应等分布匹配任务中发挥着关键作用。生成对抗网络（GANs）因其处理高维数据的有效性及适应不同约束的灵活性，已成为分布匹配的首选方法。然而，由于双层级最小-最大优化目标及对模式坍塌的敏感性，GANs在训练过程中常面临挑战。本研究受连续归一化流（CNF）中一致性模型的启发，提出了一种创新的分布匹配方法。我们的模型既继承了CNF模型的优势（如具有直观的范数最小化目标），又保持了类似GANs适应不同约束的能力。我们通过理论验证证明了所提出目标的有效性，并在合成数据集和真实数据集上通过实验验证了其性能。</p>
<div class="markdown-heading"><h2 class="heading-element">ProtTeX-CC：通过两阶段指令压缩激活蛋白质大语言模型中的上下文学习能力</h2><a id="user-content-prottex-cc通过两阶段指令压缩激活蛋白质大语言模型中的上下文学习能力" class="anchor" aria-label="Permalink: ProtTeX-CC：通过两阶段指令压缩激活蛋白质大语言模型中的上下文学习能力" href="#prottex-cc通过两阶段指令压缩激活蛋白质大语言模型中的上下文学习能力"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>（注：翻译时对技术术语进行了以下处理：</p>
<ol>
<li>"ProtTeX-CC" 保留原名不译，符合技术术语惯例</li>
<li>"In-Context Learning" 译为"上下文学习"，这是机器学习领域的标准译法</li>
<li>"Protein LLM" 扩展译为"蛋白质大语言模型"，明确领域属性</li>
<li>"Two-Stage Instruction Compression" 采用"两阶段指令压缩"的直译，准确传达技术概念
译文在保持专业性的同时，通过"激活...能力"的句式增强中文表达流畅度）</li>
</ol>
<p>arXiv:2508.12212v1 公告类型：新成果<br>
摘要：近期蛋白质大语言模型（如ProtTeX）的突破性进展，将侧链氨基酸和主链结构统一表示为残基层级的离散标记序列。虽然这种设计实现了多模态蛋白质信息的统一建模，但存在两大核心缺陷：（1）序列与结构标记的拼接使蛋白质长度近乎翻倍，破坏了多模态间固有的残基级对齐关系；（2）受限于训练语料库和有限上下文窗口，ProtTeX通常仅接受单蛋白输入，导致其无法支持上下文学习（ICL），从而制约了泛化能力。为解决这些问题，我们提出ProtTeX-CC——一个轻量级双阶段压缩框架，旨在少样本场景下增强ProtTeX的性能。我们首先设计联合嵌入压缩机制，在残基层级融合序列与结构表征，在不损失性能的前提下将蛋白质输入长度压缩一半；继而提出自压缩模块，将每个完整样本演示聚合至最后若干语言标记的潜空间中，使平均演示长度从751个标记缩减至16个标记以内。相较于原始ProtTeX，我们的自压缩方法在16样本设置下实现了总提示长度93.68%的压缩率。该框架无需修改骨干模型，仅通过联合嵌入压缩阶段基于PEFT的微调引入少量参数，并在自压缩阶段使用单一可训练投影层。在蛋白质功能预测上的大量实验表明，ProtTeX-CC在领域内基准测试中性能提升2%，在领域外数据集上泛化能力显著，性能增益达11%。</p>
<div class="markdown-heading"><h2 class="heading-element">助力还是阻碍？重新审视模型上下文协议增强的大型语言模型</h2><a id="user-content-助力还是阻碍重新审视模型上下文协议增强的大型语言模型" class="anchor" aria-label="Permalink: 助力还是阻碍？重新审视模型上下文协议增强的大型语言模型" href="#助力还是阻碍重新审视模型上下文协议增强的大型语言模型"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.12566v1  公告类型：新成果<br>
摘要：模型上下文协议（MCP）使大语言模型（LLM）能够按需访问外部资源。虽然普遍认为该协议能提升性能，但学界对LLM实际如何利用这种能力仍知之甚少。我们推出首个全面评估框架MCPGAUGE，从四个关键维度探究LLM与MCP的交互机制：主动性（自主发起工具使用）、依从性（遵循工具使用指令）、有效性（集成后的任务表现）及开销（产生的计算成本）。该框架包含160个提示词套件和25个数据集，覆盖知识理解、通用推理和代码生成三大领域。我们通过对6个商用LLM、30套MCP工具组合、单双轮交互场景的大规模评估（约2万次API调用，计算成本超6000美元），得出四项颠覆当前MCP集成效能认知的关键发现。这些发现揭示了现有AI工具集成的重要局限，并将MCPGAUGE确立为推进可控工具增强型LLM发展的原则性基准。</p>
<div class="markdown-heading"><h2 class="heading-element">SL-ACC：一种通信高效的拆分学习框架，具备自适应通道压缩能力</h2><a id="user-content-sl-acc一种通信高效的拆分学习框架具备自适应通道压缩能力" class="anchor" aria-label="Permalink: SL-ACC：一种通信高效的拆分学习框架，具备自适应通道压缩能力" href="#sl-acc一种通信高效的拆分学习框架具备自适应通道压缩能力"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>（注：在技术文献翻译中，SL-ACC作为专有名词保留原缩写形式；"Adaptive Channel-wise Compression"采用意译"自适应通道压缩能力"以符合中文技术文献表达习惯，同时通过增译"具备...能力"保持术语完整性和专业度；"Communication-Efficient"译为"通信高效"符合通信领域术语规范）</p>
<p>arXiv:2508.12984v1 公告类型：新研究<br>
摘要：神经网络日益增长的复杂性对分布式机器学习（ML）在资源受限设备（如联邦学习FL）上的部署构成显著障碍。分割学习（SL）通过将主要计算负载通过模型划分转移至服务器，为这一问题提供了有前景的解决方案。然而随着参与设备数量增加，过度的破碎数据（即激活值和梯度）传输成为SL的主要瓶颈，显著拖慢模型训练速度。为应对这一挑战，我们提出名为SL-ACC的高效通信SL框架，其包含两个核心组件：自适应通道重要性识别（ACII）和通道分组压缩（CGC）。ACII首先基于香农熵量化破碎数据中各通道对模型训练的贡献度，随后CGC根据熵值对通道分组并执行分组自适应压缩，在保持训练精度的同时有效缩减传输量。跨多个数据集的广泛实验表明，相较于现有最优基准方案，我们提出的SL-ACC框架达到目标精度所需的训练时间显著减少。</p>
<div class="markdown-heading"><h2 class="heading-element">DynamixSFT：指令调优集合的动态混合优化</h2><a id="user-content-dynamixsft指令调优集合的动态混合优化" class="anchor" aria-label="Permalink: DynamixSFT：指令调优集合的动态混合优化" href="#dynamixsft指令调优集合的动态混合优化"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.12116v1 公告类型：新成果<br>
摘要：随着后训练阶段持续涌现大量指令微调数据集，如何动态平衡和优化其混合比例已成为关键挑战。为此，我们提出DynamixSFT——一种动态自动化的指令微调数据集混合优化方法。我们将该问题构建为多臂老虎机框架，并提出先验缩放玻尔兹曼探索策略，通过将更新后的采样分布柔性锚定至原始数据集比例，有效保持数据集合的固有多样性和覆盖范围。采样概率采用轻量级单步前瞻奖励机制进行更新，该机制能动态反映各数据集对当前模型性能提升的贡献程度。在包含16个指令微调数据集的Tulu-v2混合集合上应用时，DynamixSFT在10个基准测试中实现了最高2.2%的性能提升。此外，我们通过全面分析和可视化呈现，为该方法的自适应动态机制提供了更深入的解读。</p>
<div class="markdown-heading"><h2 class="heading-element">学会驾驭：多模态大语言模型的输入依赖性转向机制</h2><a id="user-content-学会驾驭多模态大语言模型的输入依赖性转向机制" class="anchor" aria-label="Permalink: 学会驾驭：多模态大语言模型的输入依赖性转向机制" href="#学会驾驭多模态大语言模型的输入依赖性转向机制"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.12815v1 公告类型：新研究<br>
摘要：导向技术已成为一种实用方法，能够对大型语言模型（LLM）进行事后引导，使其执行特定行为。然而，该技术在多模态LLM（MLLM）中的应用仍待深入探索；现有导向方法（如均值导向）依赖单一导向向量，且独立于输入查询实施。当期望行为需根据具体示例调整时，这种范式存在局限——例如安全应答可能需要在被询问非法活动时拒绝回答，或在涉及医疗建议时指引外部资源或专家咨询。本文研究了一种采用输入特异性线性偏移的细粒度导向方法，该偏移通过对比性输入特异性提示计算得出。由于测试时无法获知所需的输入特异性提示，我们提出训练小型辅助模块来预测输入特异性导向向量。这项名为L2S（学习导向）的方法证明可有效减少MLLM的幻觉输出并增强安全性，其性能优于其他静态基线方案。</p>
<div class="markdown-heading"><h2 class="heading-element">见多识广：探索代理模型中基于特征的参数分布</h2><a id="user-content-见多识广探索代理模型中基于特征的参数分布" class="anchor" aria-label="Permalink: 见多识广：探索代理模型中基于特征的参数分布" href="#见多识广探索代理模型中基于特征的参数分布"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.13088v1 公告类型：新研究<br>
摘要：近年来，神经代理模型已成为传统仿真工作流程的革新性替代方案。该方法通过建模科学仿真的底层函数，避免了运行昂贵仿真过程的需求。除了实现从输入参数到输出的映射外，代理模型还被证明能有效解决逆问题：即从输出反推输入参数。逆问题可视为搜索过程，其目标是寻找能使代理输出包含特定特征的参数。然而在高维参数空间中，这类搜索成本极高。现有基于代理的解决方案主要聚焦于寻找少量匹配参数，却忽略了更广泛的合理参数分布全景。本研究致力于建模并可视化能产生特定输出特征的可能输入参数分布。为实现这一目标，我们着力解决两大挑战：(1) 代理模型固有的近似误差；(2) 以交互方式构建参数分布。我们通过密度估计对误差进行建模，仅当参数配置在输入和输出空间均接近训练参数时才报告高密度值。该密度估计用于形成参数的先验信念，结合特征似然函数后，可高效采样生成目标输出特征的合理参数配置。我们通过可视化界面在三组仿真数据集的输入参数空间上进行特征驱动参数分析，验证了方案的实用性。源代码详见：<a href="https://github.com/matthewberger/seeing-the-many">https://github.com/matthewberger/seeing-the-many</a></p>
</div></div><div class="footer container-xl width-full p-responsive"><div class="position-relative flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between pt-4 pb-4 mt-6 f6 color-text-secondary border-top color-border-secondary text-center"><div class="footer-octicon d-lg-block mx-lg-4"><a title="LLIKKE/Arxiv_GPT_Assistant" href="https://github.com/LLIKKE/Arxiv_GPT_Assistant" target="_blank" rel="noreferrer noopener"><svg class="octicon octicon-mark-github gh-logo" width="36" height="36" viewBox="0 0 98 98" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"></path></svg></a></div><span class="mt-2 d-block footprint"><span>powered by </span><a href="https://github.com/wranders/markdown-to-pages-action" target="_blank" rel="noreferrer noopener">markdown-to-pages-action</a></span></div></div></body></html>