<!DOCTYPE html><html data-color-mode="light" data-light-theme="light" data-dark-theme="dark" lang="en-US"><head><title>LLIKKE/Arxiv_GPT_Assistant</title><meta charset="utf-8"><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="description" content="Deepseek based personalized ArXiv paper assistant bot"><link rel="canonical" href="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta property="og:type" content="website"><meta property="og:url" content="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:description" content="Deepseek based personalized ArXiv paper assistant bot"><meta property="og:locale" content="en_US"><meta property="og:site_name" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:description" content="Deepseek based personalized ArXiv paper assistant bot"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon.png" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon.svg" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon-dark.png" media="(prefers-color-scheme: dark)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon-dark.svg" media="(prefers-color-scheme: dark)"><link rel="mask-icon" href="https://github.githubassets.com/pinned-octocat.svg" color="#000000"><link href="index.css" rel="stylesheet"></head><body><div class="container-lg px-3 my-5 markdown-body"><div class="position-relative"><span class="profile-color-modes-toggle js-promo-color-modes-toggle" tabindex="0" aria-label="Toggle dark mode" aria-checked="true" role="checkbox"><div class="profile-color-modes-toggle-track" div></div><div class="profile-color-modes-toggle-thumb"><svg style="fill: var(--color-scale-yellow-0); margin: 7px 0 0 7px;" aria-hidden="true" width="14" height="13" viewBox="0 0 14 13" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.52208 7.71754C7.5782 7.71754 10.0557 5.24006 10.0557 2.18394C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961C9.95801 1.07727 10.3495 0.771159 10.6474 0.99992C12.1153 2.12716 13.0615 3.89999 13.0615 5.89383C13.0615 9.29958 10.3006 12.0605 6.89485 12.0605C3.95334 12.0605 1.49286 10.001 0.876728 7.24527C0.794841 6.87902 1.23668 6.65289 1.55321 6.85451C2.41106 7.40095 3.4296 7.71754 4.52208 7.71754Z"></path></svg></div></span></div><script type="text/javascript">(function() {
  var MODE_KEY = 'markdown_to_pages_dark_mode';
  function toggleMode() {
    var mode = document.documentElement.getAttribute('data-color-mode') === 'light' ? 'dark' : 'light';
    document.documentElement.setAttribute('data-color-mode', mode);
    localStorage.setItem(MODE_KEY, mode);
  }
  var mode = localStorage.getItem(MODE_KEY);
  if (mode == null) {
    var query = window.matchMedia('(prefers-color-scheme: dark)');
    mode = query.matches ? 'dark' : 'light';
  }
  document.documentElement.setAttribute('data-color-mode', mode);
  document.querySelector('.profile-color-modes-toggle').onclick = toggleMode;
})();</script><div><div class="markdown-heading"><h2 class="heading-element">MSQ：高效记忆的位稀疏化量化</h2><a id="user-content-msq高效记忆的位稀疏化量化" class="anchor" aria-label="Permalink: MSQ：高效记忆的位稀疏化量化" href="#msq高效记忆的位稀疏化量化"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>随着深度神经网络（DNN）在移动和边缘设备上的部署日益增多，模型效率优化变得至关重要。混合精度量化因其在效率与精度间优于均匀量化的平衡特性而广受青睐，但确定各层最优精度仍具挑战性。近期利用比特级稀疏性的研究虽展现出潜力，却常伴随显著的训练复杂度与高昂的GPU内存需求。本文提出"内存高效比特稀疏化量化"（MSQ）这一创新方法以突破这些局限：通过采用舍入-钳位量化器实现模型权重最低有效位（LSB）的可微计算，并利用正则化诱导LSB稀疏性，从而无需显式比特级参数分割即可实现有效精度降低。此外，MSQ融合Hessian矩阵信息实现多LSB同步剪枝，进一步提升了训练效率。实验表明，相比现有比特级量化方法，MSQ可减少高达8倍的训练参数量与86%的训练时长，同时保持具有竞争力的精度与压缩率，为资源受限设备的高效DNN训练提供了实用解决方案。</p>
<div class="markdown-heading"><h2 class="heading-element">KLLM：基于K均值量化的快速大语言模型推理</h2><a id="user-content-kllm基于k均值量化的快速大语言模型推理" class="anchor" aria-label="Permalink: KLLM：基于K均值量化的快速大语言模型推理" href="#kllm基于k均值量化的快速大语言模型推理"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>大语言模型（LLM）推理因其巨大的内存与计算需求面临严峻挑战。权重和激活量化（WAQ）通过降低内存占用与算术复杂度提供了可行解决方案，但现有WAQ设计仍存在两大关键挑战：（1）传统WAQ设计采用基于整数的均匀量化以实现硬件效率，但低精度下往往导致显著精度损失。基于K-Means的非均匀量化技术虽能通过匹配LLM中权重与激活的类高斯分布获得更高精度，但其非均匀特性使得无法直接在低精度计算单元执行，推理时需进行反量化与浮点矩阵乘法（MatMuls）；（2）激活异常值进一步阻碍低精度WAQ的有效实施——离线阈值检测方法会导致模型性能显著下降，而现有在线检测技术又会引入巨大运行时开销。</p>
<p>为突破上述限制，充分释放K-Means量化WAQ在LLM推理中的潜力，本文提出软硬件协同设计框架KLLM。其创新在于：首先设计基于索引的计算方案，可高效执行K-Means量化数据的矩阵乘法与非线性运算，规避大部分反量化与全精度计算；其次集成新型异常值检测引擎Orizuru，能在在线推理时实时识别激活数据流中最大/最小的前k个元素。</p>
<p>实验表明：相较于A100 GPU和Atom处理器，KLLM平均分别实现9.67倍、7.03倍加速，以及229.50倍、150.21倍的能效提升。</p>
</div></div><div class="footer container-xl width-full p-responsive"><div class="position-relative flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between pt-4 pb-4 mt-6 f6 color-text-secondary border-top color-border-secondary text-center"><div class="footer-octicon d-lg-block mx-lg-4"><a title="LLIKKE/Arxiv_GPT_Assistant" href="https://github.com/LLIKKE/Arxiv_GPT_Assistant" target="_blank" rel="noreferrer noopener"><svg class="octicon octicon-mark-github gh-logo" width="36" height="36" viewBox="0 0 98 98" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"></path></svg></a></div><span class="mt-2 d-block footprint"><span>powered by </span><a href="https://github.com/wranders/markdown-to-pages-action" target="_blank" rel="noreferrer noopener">markdown-to-pages-action</a></span></div></div></body></html>