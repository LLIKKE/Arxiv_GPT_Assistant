<!DOCTYPE html><html data-color-mode="light" data-light-theme="light" data-dark-theme="dark" lang="en-US"><head><title>LLIKKE/Arxiv_GPT_Assistant</title><meta charset="utf-8"><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="description" content="Deepseek based personalized ArXiv paper assistant bot"><link rel="canonical" href="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta property="og:type" content="website"><meta property="og:url" content="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:description" content="Deepseek based personalized ArXiv paper assistant bot"><meta property="og:locale" content="en_US"><meta property="og:site_name" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:description" content="Deepseek based personalized ArXiv paper assistant bot"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon.png" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon.svg" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon-dark.png" media="(prefers-color-scheme: dark)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon-dark.svg" media="(prefers-color-scheme: dark)"><link rel="mask-icon" href="https://github.githubassets.com/pinned-octocat.svg" color="#000000"><link href="index.css" rel="stylesheet"></head><body><div class="container-lg px-3 my-5 markdown-body"><div class="position-relative"><span class="profile-color-modes-toggle js-promo-color-modes-toggle" tabindex="0" aria-label="Toggle dark mode" aria-checked="true" role="checkbox"><div class="profile-color-modes-toggle-track" div></div><div class="profile-color-modes-toggle-thumb"><svg style="fill: var(--color-scale-yellow-0); margin: 7px 0 0 7px;" aria-hidden="true" width="14" height="13" viewBox="0 0 14 13" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.52208 7.71754C7.5782 7.71754 10.0557 5.24006 10.0557 2.18394C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961C9.95801 1.07727 10.3495 0.771159 10.6474 0.99992C12.1153 2.12716 13.0615 3.89999 13.0615 5.89383C13.0615 9.29958 10.3006 12.0605 6.89485 12.0605C3.95334 12.0605 1.49286 10.001 0.876728 7.24527C0.794841 6.87902 1.23668 6.65289 1.55321 6.85451C2.41106 7.40095 3.4296 7.71754 4.52208 7.71754Z"></path></svg></div></span></div><script type="text/javascript">(function() {
  var MODE_KEY = 'markdown_to_pages_dark_mode';
  function toggleMode() {
    var mode = document.documentElement.getAttribute('data-color-mode') === 'light' ? 'dark' : 'light';
    document.documentElement.setAttribute('data-color-mode', mode);
    localStorage.setItem(MODE_KEY, mode);
  }
  var mode = localStorage.getItem(MODE_KEY);
  if (mode == null) {
    var query = window.matchMedia('(prefers-color-scheme: dark)');
    mode = query.matches ? 'dark' : 'light';
  }
  document.documentElement.setAttribute('data-color-mode', mode);
  document.querySelector('.profile-color-modes-toggle').onclick = toggleMode;
})();</script><div><div class="markdown-heading"><h2 class="heading-element">DuoGPT：基于激活感知剪枝的大语言模型免训练双稀疏化方法</h2><a id="user-content-duogpt基于激活感知剪枝的大语言模型免训练双稀疏化方法" class="anchor" aria-label="Permalink: DuoGPT：基于激活感知剪枝的大语言模型免训练双稀疏化方法" href="#duogpt基于激活感知剪枝的大语言模型免训练双稀疏化方法"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>（注：翻译说明：</p>
<ol>
<li>"Training-free" 译为"免训练"，强调该方法不需要额外训练过程</li>
<li>"Dual Sparsity" 译为"双稀疏化"，指代同时实现两种稀疏性（通常指权重和激活的稀疏）</li>
<li>"Activation-aware Pruning" 译为"激活感知剪枝"，准确表达根据激活模式进行剪枝的技术特性</li>
<li>"in LLMs" 补充为"大语言模型"，既保留英文缩写又便于中文读者理解</li>
<li>整体采用技术论文标题常用的名词化结构，符合学术翻译规范）</li>
</ol>
<p>arXiv:2506.20194v1 公告类型：新论文<br>
摘要：大语言模型（LLMs）虽展现出强大性能，却因高昂的内存与计算成本难以部署。传统剪枝方法虽能降低需求，但大多忽略了运行时观察到的激活稀疏性。我们创新性地将激活稀疏性重新解读为动态结构化权重稀疏性，并提出DuoGPT框架——该框架通过结合非结构化权重剪枝与激活稀疏性，构建了双稀疏（spMspV）计算负载。为保持模型精度，我们扩展了最优脑压缩（OBC）框架，引入激活感知校准技术，并采用稠密模型的输出残差作为修正项。此外，我们还针对GPU执行效率优化了解决方案，使其可扩展至数十亿参数的LLMs。在LLaMA-2和LLaMA-3上的评估表明：相较于基准稠密模型，DuoGPT在1.39倍等速加速条件下，以最高9.17%的准确度优势超越了当前最先进的结构化剪枝方法。</p>
<p>（注：spMspV为专业术语，指"稀疏矩阵-稀疏向量"计算模式，在学术文献中通常保留英文缩写形式）</p>
<div class="markdown-heading"><h2 class="heading-element">DipSVD：双重重要性保护的奇异值分解技术，助力高效大语言模型压缩</h2><a id="user-content-dipsvd双重重要性保护的奇异值分解技术助力高效大语言模型压缩" class="anchor" aria-label="Permalink: DipSVD：双重重要性保护的奇异值分解技术，助力高效大语言模型压缩" href="#dipsvd双重重要性保护的奇异值分解技术助力高效大语言模型压缩"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2506.20353v1 公告类型：新论文<br>
摘要：大型语言模型（LLM）持续增长的计算需求与部署成本催生了众多压缩方法。与量化和非结构化剪枝相比，奇异值分解（SVD）压缩具有更优的硬件兼容性与理论保障。然而现有基于SVD的方法仅关注原始矩阵与压缩矩阵的整体差异，却忽视了矩阵内部关键成分的保护，导致压缩后模型性能下降。本文提出双重重要性保护机制以增强SVD压缩方法：（1）局部重要性保护：通过通道加权数据白化技术保留每个权重矩阵中最关键的奇异向量；（2）全局重要性保护：通过启发式或优化分配策略，使次要层级承担更多压缩负担，从而最大限度降低压缩对关键层的影响。大量实验表明，DipSVD在多个基准测试中优于现有SVD压缩方法，尤其在较高压缩率下仍能保持卓越的模型性能。</p>
<p>（注：根据学术论文翻译规范，对部分术语进行了标准化处理：</p>
<ol>
<li>"channel-weighted data whitening"译为"通道加权数据白化"（计算机视觉领域通用译法）</li>
<li>"heuristic or optimization-based approach"译为"启发式或优化分配策略"（体现方法论的实质）</li>
<li>保留"SVD"等专业缩写以符合中文计算机论文惯例</li>
<li>采用"奇异值分解"全称与缩写混用以确保首次出现时的清晰性）</li>
</ol>
<div class="markdown-heading"><h2 class="heading-element">Q-resafe：量化大语言模型的安全风险评估与量化感知安全补丁</h2><a id="user-content-q-resafe量化大语言模型的安全风险评估与量化感知安全补丁" class="anchor" aria-label="Permalink: Q-resafe：量化大语言模型的安全风险评估与量化感知安全补丁" href="#q-resafe量化大语言模型的安全风险评估与量化感知安全补丁"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2506.20251v1 公告类型：新研究<br>
摘要：量化大型语言模型（LLMs）因其在资源受限环境中的部署潜力而日益受到关注。然而，最新针对少数无需校准数据集的量化方法研究表明，量化可能损害LLMs的安全防护能力，这凸显了系统化安全评估与有效缓解策略的迫切需求。本文通过广泛认可的安全基准测试，对多种主流量化技术和多样化校准数据集进行了全面的安全评估。针对发现的安全漏洞，我们提出了一种量化感知的安全修补框架Q-resafe，该框架能高效恢复量化后LLMs的安全能力，同时将对模型效用的负面影响降至最低。大量实验结果表明，即使在严苛的评估场景下，Q-resafe也能成功使量化LLMs的安全性与原始模型重新对齐。项目页面详见：<a href="https://github.com/Thecommonirin/Qresafe%E3%80%82">https://github.com/Thecommonirin/Qresafe。</a></p>
<p>（注：根据学术规范，arXiv标识符"arXiv:2506.20251v1"保留原文格式；技术术语如"quantization-aware"译为"量化感知"符合计算机领域惯例；长句按中文表达习惯拆分为短句；项目URL保留原始链接确保可追溯性。）</p>
</div></div><div class="footer container-xl width-full p-responsive"><div class="position-relative flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between pt-4 pb-4 mt-6 f6 color-text-secondary border-top color-border-secondary text-center"><div class="footer-octicon d-lg-block mx-lg-4"><a title="LLIKKE/Arxiv_GPT_Assistant" href="https://github.com/LLIKKE/Arxiv_GPT_Assistant" target="_blank" rel="noreferrer noopener"><svg class="octicon octicon-mark-github gh-logo" width="36" height="36" viewBox="0 0 98 98" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"></path></svg></a></div><span class="mt-2 d-block footprint"><span>powered by </span><a href="https://github.com/wranders/markdown-to-pages-action" target="_blank" rel="noreferrer noopener">markdown-to-pages-action</a></span></div></div></body></html>