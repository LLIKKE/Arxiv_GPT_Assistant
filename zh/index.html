<!DOCTYPE html><html data-color-mode="light" data-light-theme="light" data-dark-theme="dark" lang="en-US"><head><title>LLIKKE/Arxiv_GPT_Assistant</title><meta charset="utf-8"><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="description" content="Deepseek based personalized ArXiv paper assistant bot"><link rel="canonical" href="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta property="og:type" content="website"><meta property="og:url" content="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:description" content="Deepseek based personalized ArXiv paper assistant bot"><meta property="og:locale" content="en_US"><meta property="og:site_name" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:description" content="Deepseek based personalized ArXiv paper assistant bot"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon.png" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon.svg" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon-dark.png" media="(prefers-color-scheme: dark)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon-dark.svg" media="(prefers-color-scheme: dark)"><link rel="mask-icon" href="https://github.githubassets.com/pinned-octocat.svg" color="#000000"><link href="index.css" rel="stylesheet"></head><body><div class="container-lg px-3 my-5 markdown-body"><div class="position-relative"><span class="profile-color-modes-toggle js-promo-color-modes-toggle" tabindex="0" aria-label="Toggle dark mode" aria-checked="true" role="checkbox"><div class="profile-color-modes-toggle-track" div></div><div class="profile-color-modes-toggle-thumb"><svg style="fill: var(--color-scale-yellow-0); margin: 7px 0 0 7px;" aria-hidden="true" width="14" height="13" viewBox="0 0 14 13" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.52208 7.71754C7.5782 7.71754 10.0557 5.24006 10.0557 2.18394C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961C9.95801 1.07727 10.3495 0.771159 10.6474 0.99992C12.1153 2.12716 13.0615 3.89999 13.0615 5.89383C13.0615 9.29958 10.3006 12.0605 6.89485 12.0605C3.95334 12.0605 1.49286 10.001 0.876728 7.24527C0.794841 6.87902 1.23668 6.65289 1.55321 6.85451C2.41106 7.40095 3.4296 7.71754 4.52208 7.71754Z"></path></svg></div></span></div><script type="text/javascript">(function() {
  var MODE_KEY = 'markdown_to_pages_dark_mode';
  function toggleMode() {
    var mode = document.documentElement.getAttribute('data-color-mode') === 'light' ? 'dark' : 'light';
    document.documentElement.setAttribute('data-color-mode', mode);
    localStorage.setItem(MODE_KEY, mode);
  }
  var mode = localStorage.getItem(MODE_KEY);
  if (mode == null) {
    var query = window.matchMedia('(prefers-color-scheme: dark)');
    mode = query.matches ? 'dark' : 'light';
  }
  document.documentElement.setAttribute('data-color-mode', mode);
  document.querySelector('.profile-color-modes-toggle').onclick = toggleMode;
})();</script><div><div class="markdown-heading"><h2 class="heading-element">KV-Distill：面向大型语言模型的近乎无损可学习上下文压缩技术</h2><a id="user-content-kv-distill面向大型语言模型的近乎无损可学习上下文压缩技术" class="anchor" aria-label="Permalink: KV-Distill：面向大型语言模型的近乎无损可学习上下文压缩技术" href="#kv-distill面向大型语言模型的近乎无损可学习上下文压缩技术"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>序列到序列任务通常受益于长上下文，但标准Transformer中自注意力机制的二次复杂度使得这一优势难以实现。在生成过程中，临时表示——存储在所谓的KV缓存中——占据了GPU内存使用的大部分，并且随着上下文长度的增加而线性扩展。我们引入了KV-Distill，这是一个Transformer压缩框架，它以与问题无关的方式将长上下文的KV缓存蒸馏成显著更短的表示。KV-Distill可以作为预训练模型的参数高效适配器进行训练，并且能够在保持预训练模型能力的同时，压缩上下文的任意片段。我们将压缩与未压缩的缓存视为学生-教师配对，并应用KL型散度来匹配生成的输出。在最坏情况的抽取任务中，KV-Distill优于其他压缩技术，在长上下文问答和摘要任务中接近未压缩的性能，并且可以在特定领域的上下文中进行微调，将长度减少多达99%，同时保持下游性能。我们展示了KV-Distill在各种模型大小和架构上的通用性。</p>
<div class="markdown-heading"><h2 class="heading-element">协同推测推理助力高效大型语言模型推理服务</h2><a id="user-content-协同推测推理助力高效大型语言模型推理服务" class="anchor" aria-label="Permalink: 协同推测推理助力高效大型语言模型推理服务" href="#协同推测推理助力高效大型语言模型推理服务"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>推测推理是一种颇具前景的范式，它利用小型推测模型（SSMs）作为起草者生成草稿令牌，随后由目标大型语言模型（LLM）并行验证。这种方法通过减少LLM推理延迟和成本，同时保持生成质量，提升了推理服务的效率。然而，现有的推测方法面临关键挑战，包括资源利用效率低下和草稿接受度有限，这限制了它们的可扩展性和整体效果。为了克服这些障碍，我们提出了CoSine，一个新颖的推测推理系统，它将顺序推测解码与并行验证解耦，实现了多个节点间的高效协作。具体而言，CoSine根据起草者的专长将推理请求路由至专门的起草者，并引入基于置信度的令牌融合机制，综合来自协作起草者的输出，确保高质量的草稿生成。此外，CoSine以流水线方式动态编排推测解码和验证的执行，采用批量调度选择性分组请求，并通过自适应推测控制最小化空闲时间。通过异构节点协作优化并行工作流，CoSine实时平衡草稿生成与验证吞吐量，从而最大化资源利用率。实验结果表明，与最先进的推测方法相比，CoSine展现出卓越的性能。值得注意的是，在同等资源成本下，CoSine相比基线方法实现了高达23.2%的延迟降低和32.5%的吞吐量提升。</p>
<div class="markdown-heading"><h2 class="heading-element">雷达：为任何Transformer实现快速长上下文解码</h2><a id="user-content-雷达为任何transformer实现快速长上下文解码" class="anchor" aria-label="Permalink: 雷达：为任何Transformer实现快速长上下文解码" href="#雷达为任何transformer实现快速长上下文解码"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>Transformer模型在众多应用领域展现了卓越的性能。尽管点积注意力机制构成了Transformer模型的基础，但它对长上下文数据的处理能力并不理想，因为其所需时间随上下文长度呈二次方增长。在本研究中，我们提出了Radar，一种无需训练的方法，通过动态搜索最重要的上下文标记来加速推理过程。对于任何预训练的Transformer模型，Radar都能在不进行额外训练或启发式剔除标记的情况下，降低解码的时间复杂度。此外，我们为该方法提供了理论依据，证明Radar能够以高概率可靠地识别出最重要的标记。我们在多种任务上与前人方法进行了广泛比较，结果表明，Radar在不同架构上均实现了最先进的性能，同时降低了时间复杂度，为Transformer模型高效处理长上下文提供了一种实用解决方案。</p>
</div></div><div class="footer container-xl width-full p-responsive"><div class="position-relative flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between pt-4 pb-4 mt-6 f6 color-text-secondary border-top color-border-secondary text-center"><div class="footer-octicon d-lg-block mx-lg-4"><a title="LLIKKE/Arxiv_GPT_Assistant" href="https://github.com/LLIKKE/Arxiv_GPT_Assistant" target="_blank" rel="noreferrer noopener"><svg class="octicon octicon-mark-github gh-logo" width="36" height="36" viewBox="0 0 98 98" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"></path></svg></a></div><span class="mt-2 d-block footprint"><span>powered by </span><a href="https://github.com/wranders/markdown-to-pages-action" target="_blank" rel="noreferrer noopener">markdown-to-pages-action</a></span></div></div></body></html>