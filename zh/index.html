<!DOCTYPE html><html data-color-mode="light" data-light-theme="light" data-dark-theme="dark" lang="en-US"><head><title>LLIKKE/Arxiv_GPT_Assistant</title><meta charset="utf-8"><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="description" content="Deepseek based personalized ArXiv paper assistant bot"><link rel="canonical" href="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta property="og:type" content="website"><meta property="og:url" content="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:description" content="Deepseek based personalized ArXiv paper assistant bot"><meta property="og:locale" content="en_US"><meta property="og:site_name" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:description" content="Deepseek based personalized ArXiv paper assistant bot"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon.png" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon.svg" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon-dark.png" media="(prefers-color-scheme: dark)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon-dark.svg" media="(prefers-color-scheme: dark)"><link rel="mask-icon" href="https://github.githubassets.com/pinned-octocat.svg" color="#000000"><link href="index.css" rel="stylesheet"></head><body><div class="container-lg px-3 my-5 markdown-body"><div class="position-relative"><span class="profile-color-modes-toggle js-promo-color-modes-toggle" tabindex="0" aria-label="Toggle dark mode" aria-checked="true" role="checkbox"><div class="profile-color-modes-toggle-track" div></div><div class="profile-color-modes-toggle-thumb"><svg style="fill: var(--color-scale-yellow-0); margin: 7px 0 0 7px;" aria-hidden="true" width="14" height="13" viewBox="0 0 14 13" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.52208 7.71754C7.5782 7.71754 10.0557 5.24006 10.0557 2.18394C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961C9.95801 1.07727 10.3495 0.771159 10.6474 0.99992C12.1153 2.12716 13.0615 3.89999 13.0615 5.89383C13.0615 9.29958 10.3006 12.0605 6.89485 12.0605C3.95334 12.0605 1.49286 10.001 0.876728 7.24527C0.794841 6.87902 1.23668 6.65289 1.55321 6.85451C2.41106 7.40095 3.4296 7.71754 4.52208 7.71754Z"></path></svg></div></span></div><script type="text/javascript">(function() {
  var MODE_KEY = 'markdown_to_pages_dark_mode';
  function toggleMode() {
    var mode = document.documentElement.getAttribute('data-color-mode') === 'light' ? 'dark' : 'light';
    document.documentElement.setAttribute('data-color-mode', mode);
    localStorage.setItem(MODE_KEY, mode);
  }
  var mode = localStorage.getItem(MODE_KEY);
  if (mode == null) {
    var query = window.matchMedia('(prefers-color-scheme: dark)');
    mode = query.matches ? 'dark' : 'light';
  }
  document.documentElement.setAttribute('data-color-mode', mode);
  document.querySelector('.profile-color-modes-toggle').onclick = toggleMode;
})();</script><div><div class="markdown-heading"><h2 class="heading-element">内在与外在的有组织注意：Softmax不变性与网络稀疏性</h2><a id="user-content-内在与外在的有组织注意softmax不变性与网络稀疏性" class="anchor" aria-label="Permalink: 内在与外在的有组织注意：Softmax不变性与网络稀疏性" href="#内在与外在的有组织注意softmax不变性与网络稀疏性"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>我们研究了Transformer中自注意力机制的内在（注意力头内部）与外在（注意力头之间）结构。通过运用仿微分算子理论（并辅以计算实例佐证），我们获得了自注意力机制对softmax激活具有不变性的理论证据，这一特性源于注意力头内在的组织方式。此外，我们采用现有的张量层次组织方法，通过沿网络三维张量的查询轴、键轴和头轴构建层次划分树来解析网络结构。这种组织结构具有重要价值，它使得我们能够在呈现规律性的网络三维张量几何空间上高效执行常规信号处理任务。我们通过双重方式对此进行例证：定性方面，可视化由注意力头构成的层次树结构及其扩散图嵌入；定量方面，通过分析网络稀疏性——分别基于查询、键和头空间的双哈尔基与三哈尔基，考察单个注意力头及整个网络的展开系数。为展示理论与方法学发现的应用价值，我们提供了视觉与语言Transformer的计算实例。这些发现具有双重意义：（1）从理论上为可解释性分析的后续步骤提供了依据，并可在下游可解释性任务中加以实证利用；（2）网络三维张量组织结构可应用于模型剪枝（基于网络稀疏性）和网络架构比较等实际网络任务。</p>
<div class="markdown-heading"><h2 class="heading-element">基于Kronecker适应的大型语言模型奇异值分解</h2><a id="user-content-基于kronecker适应的大型语言模型奇异值分解" class="anchor" aria-label="Permalink: 基于Kronecker适应的大型语言模型奇异值分解" href="#基于kronecker适应的大型语言模型奇异值分解"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>大规模预训练的Transformer模型在各类语言与推理任务中取得了最先进的性能，但完整微调会带来巨大的存储、内存和计算开销。参数高效微调（PEFT）方法通过学习少量任务特定参数来降低这些成本，然而现有方案要么会引入推理延迟（适配器模块），要么存在收敛欠佳问题（随机初始化的低秩更新），或依赖于可能不匹配任务复杂度的固定秩选择（基于Kronecker积的分解）。我们提出SoKA（基于Kronecker适应的SVD分解），这是一种新颖的PEFT策略，将Kronecker积张量分解与SVD驱动的初始化、频谱感知动态秩选择相结合。我们的Kronecker积SVD（KPSVD）流程将完整权重更新的主成分提取为紧凑的Kronecker因子，同时自适应秩选择算法通过能量阈值和肘点准则来修剪可忽略的分量。在LLaMA2-7B模型上针对算术推理（GSM8K）、形式数学（MATH）和代码生成（MBPP）任务的实验表明，SoKA仅需0.99M可训练参数，比LoRA/PiSSA减少25%，同时达到或超越基线性能。此外，SoKA展现出更快的收敛速度和更稳定的梯度，凸显了其在大规模模型适配中的鲁棒性与高效性。</p>
<div class="markdown-heading"><h2 class="heading-element">MoTE：面向内存高效大型多模态模型的三元专家混合架构</h2><a id="user-content-mote面向内存高效大型多模态模型的三元专家混合架构" class="anchor" aria-label="Permalink: MoTE：面向内存高效大型多模态模型的三元专家混合架构" href="#mote面向内存高效大型多模态模型的三元专家混合架构"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>大规模多模态混合专家模型（MoEs）通过扩展模型规模提升性能，同时保持固定的激活参数量。然而既有研究在稀疏升级周期中主要采用全精度专家，虽在终端任务上表现优异，但海量专家导致内存占用激增，为边缘设备部署带来严峻挑战。本研究提出MoTE方案——一种基于稠密检查点训练三值化混合专家模型的可扩展内存优化方法。我们突破传统"少量高精度专家"的训练范式，在升级周期中转而训练"大量低精度专家"。具体而言，我们将预训练前馈网络（FFN）作为共享专家，同时训练参数取值限于{-1, 0, 1}的三值路由专家。大量实验表明，该方法随模型规模扩大呈现良好的扩展趋势：MoTE在保持与全精度基线模型MoE-LLaVA相当性能的同时，显著降低了内存占用。此外，本方案与训练后量化方法高度兼容，当内存约束更严格时优势进一步放大。在专家内存占用同为3.4GB的条件下，结合训练后量化技术，MoTE在终端任务上的平均准确率较MoE-LLaVA提升4.3%，充分证明了其在内存受限设备上的有效性与应用潜力。</p>
<div class="markdown-heading"><h2 class="heading-element">《通过分布匹配增强向量量化：一项理论与实证研究》</h2><a id="user-content-通过分布匹配增强向量量化一项理论与实证研究" class="anchor" aria-label="Permalink: 《通过分布匹配增强向量量化：一项理论与实证研究》" href="#通过分布匹配增强向量量化一项理论与实证研究"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>注：</p>
<ol>
<li>"Enhancing"译为"增强"，体现技术改进的主动性</li>
<li>"Vector Quantization"采用专业术语"向量量化"，保持计算机领域术语一致性</li>
<li>"Distributional Matching"译为"分布匹配"，准确表达概率分布对齐的数学概念</li>
<li>副标题采用学术论文常见译法"理论与实证研究"，其中"empirical"对应"实证"更符合中文社科研究表述习惯</li>
<li>整体采用书名号《》标注，符合中文出版物标题规范</li>
<li>保留原文的冒号分隔主副标题结构，维持学术标题的严谨层次感</li>
</ol>
<p>自回归模型的成功很大程度上依赖于向量量化的有效性，该技术通过将连续特征映射至可学习码本中的最近邻码向量来实现特征离散化。现有向量量化方法存在两个关键问题：训练不稳定性和码本坍塌。训练不稳定性源于直通估计器引入的梯度差异（在量化误差较大时尤为明显），而码本坍塌则表现为训练过程中仅激活少量码向量。深入分析表明，这些问题主要由特征分布与码向量分布失配所驱动，导致码向量缺乏代表性且压缩过程中存在显著数据信息损失。为此，我们采用Wasserstein距离对齐这两个分布，实现了接近100%的码本利用率并显著降低量化误差。实证分析与理论验证均证实了该方法的有效性。</p>
</div></div><div class="footer container-xl width-full p-responsive"><div class="position-relative flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between pt-4 pb-4 mt-6 f6 color-text-secondary border-top color-border-secondary text-center"><div class="footer-octicon d-lg-block mx-lg-4"><a title="LLIKKE/Arxiv_GPT_Assistant" href="https://github.com/LLIKKE/Arxiv_GPT_Assistant" target="_blank" rel="noreferrer noopener"><svg class="octicon octicon-mark-github gh-logo" width="36" height="36" viewBox="0 0 98 98" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"></path></svg></a></div><span class="mt-2 d-block footprint"><span>powered by </span><a href="https://github.com/wranders/markdown-to-pages-action" target="_blank" rel="noreferrer noopener">markdown-to-pages-action</a></span></div></div></body></html>