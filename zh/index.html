<!DOCTYPE html><html data-color-mode="light" data-light-theme="light" data-dark-theme="dark" lang="en-US"><head><title>LLIKKE/Arxiv_GPT_Assistant</title><meta charset="utf-8"><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="description" content="Deepseek based personalized ArXiv paper assistant bot"><link rel="canonical" href="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta property="og:type" content="website"><meta property="og:url" content="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:description" content="Deepseek based personalized ArXiv paper assistant bot"><meta property="og:locale" content="en_US"><meta property="og:site_name" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:description" content="Deepseek based personalized ArXiv paper assistant bot"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon.png" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon.svg" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon-dark.png" media="(prefers-color-scheme: dark)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon-dark.svg" media="(prefers-color-scheme: dark)"><link rel="mask-icon" href="https://github.githubassets.com/pinned-octocat.svg" color="#000000"><link href="index.css" rel="stylesheet"></head><body><div class="container-lg px-3 my-5 markdown-body"><div class="position-relative"><span class="profile-color-modes-toggle js-promo-color-modes-toggle" tabindex="0" aria-label="Toggle dark mode" aria-checked="true" role="checkbox"><div class="profile-color-modes-toggle-track" div></div><div class="profile-color-modes-toggle-thumb"><svg style="fill: var(--color-scale-yellow-0); margin: 7px 0 0 7px;" aria-hidden="true" width="14" height="13" viewBox="0 0 14 13" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.52208 7.71754C7.5782 7.71754 10.0557 5.24006 10.0557 2.18394C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961C9.95801 1.07727 10.3495 0.771159 10.6474 0.99992C12.1153 2.12716 13.0615 3.89999 13.0615 5.89383C13.0615 9.29958 10.3006 12.0605 6.89485 12.0605C3.95334 12.0605 1.49286 10.001 0.876728 7.24527C0.794841 6.87902 1.23668 6.65289 1.55321 6.85451C2.41106 7.40095 3.4296 7.71754 4.52208 7.71754Z"></path></svg></div></span></div><script type="text/javascript">(function() {
  var MODE_KEY = 'markdown_to_pages_dark_mode';
  function toggleMode() {
    var mode = document.documentElement.getAttribute('data-color-mode') === 'light' ? 'dark' : 'light';
    document.documentElement.setAttribute('data-color-mode', mode);
    localStorage.setItem(MODE_KEY, mode);
  }
  var mode = localStorage.getItem(MODE_KEY);
  if (mode == null) {
    var query = window.matchMedia('(prefers-color-scheme: dark)');
    mode = query.matches ? 'dark' : 'light';
  }
  document.documentElement.setAttribute('data-color-mode', mode);
  document.querySelector('.profile-color-modes-toggle').onclick = toggleMode;
})();</script><div><div class="markdown-heading"><h2 class="heading-element">基于LoRA的资源受限环境下教育指导大语言模型微调方法</h2><a id="user-content-基于lora的资源受限环境下教育指导大语言模型微调方法" class="anchor" aria-label="Permalink: 基于LoRA的资源受限环境下教育指导大语言模型微调方法" href="#基于lora的资源受限环境下教育指导大语言模型微调方法"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2504.15610v1 公告类型：新研究<br>
摘要：本研究提出了一种经济高效的方法，旨在使大型语言模型（LLMs）适应留学背景下的学术咨询需求，并应用于低资源的文化适应场景。通过采用Mistral-7B-Instruct模型结合低秩自适应（LoRA）方法和4位量化技术，研究分两个阶段进行训练以增强领域特异性，同时保持计算效率。第一阶段通过Gemini Pro API使用合成数据集对模型进行条件训练；第二阶段利用StudyAbroadGPT项目手动整理的数据集进行训练，以实现更具情境化的增强响应。技术创新包括内存高效量化、参数高效自适应，以及通过Weights &amp; Biases平台实现的持续训练分析。训练完成后，研究显示训练损失降低52.7%，领域特定建议准确率达92%，支持95%的Markdown格式输出，并在商用GPU设备上实现每秒100样本的中位处理速率。这些发现验证了指令调优LLMs在教育顾问场景中的有效性，尤其适用于资源有限的机构环境。局限性包括模型泛化能力下降及合成数据集的应用，但该框架可扩展至新增多语言增强和实时学术咨询流程。未来方向可能包括整合检索增强生成技术、实施动态量化方案，以及连接实时学术数据库以提升适应性与准确性。</p>
<div class="markdown-heading"><h2 class="heading-element">KeDiff：资源受限环境下基于键相似性的KV缓存驱逐策略，助力长上下文LLM推理</h2><a id="user-content-kediff资源受限环境下基于键相似性的kv缓存驱逐策略助力长上下文llm推理" class="anchor" aria-label="Permalink: KeDiff：资源受限环境下基于键相似性的KV缓存驱逐策略，助力长上下文LLM推理" href="#kediff资源受限环境下基于键相似性的kv缓存驱逐策略助力长上下文llm推理"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>（注：翻译说明）</p>
<ol>
<li>"Key Similarity-Based"译为"基于键相似性的"：精准保留技术术语，同时符合中文定语前置习惯。</li>
<li>"KV Cache Eviction"译为"KV缓存驱逐策略"：补充"策略"二字明确技术方案属性，KV保持英文缩写因其在技术领域的通用性。</li>
<li>长标题采用分句处理：用逗号分隔技术方法与场景限定，保持中文表达流畅性。</li>
<li>"Resource-Constrained Environments"译为"资源受限环境"：使用四字格言简意赅，符合科技文本特征。</li>
<li>"Long-Context LLM Inference"译为"长上下文LLM推理"：保留LLM缩写确保专业受众识别度，"长上下文"准确传达技术特征。</li>
</ol>
<p>arXiv:2504.15364v1 公告类型：新研究<br>
摘要：本研究发现，大语言模型（LLM）推理过程中具有区分度的关键键（key）往往会产生较高的注意力分数。基于此现象，我们提出了一种无需重新训练、基于键相似度的KV缓存淘汰方法——KeyDiff。该方法可在内存和计算资源受限的环境中，高效部署需要处理长输入提示的LLM应用。与现有KV缓存淘汰方案不同，KeyDiff能在严格资源限制下处理任意长度的提示文本，并保持响应生成效率。我们通过理论分析证明，KeyDiff通过最大化键多样性来求解KV缓存选择问题的最优解。值得注意的是，KeyDiff不依赖注意力分数，因此可与FlashAttention等优化注意力机制兼容。在Llama 3.1-8B和Llama 3.2-3B模型的LongBench基准测试中，KeyDiff在8K缓存预算（约减少23% KV缓存）下的性能差距与非淘汰基线相比不足0.04%，其有效性在多任务和多模型场景中均得到验证。</p>
<p>（注：根据学术文献翻译规范，对技术术语进行了如下处理：</p>
<ol>
<li>"KV cache"保留专业缩写形式"KV缓存"</li>
<li>"FlashAttention"作为专有名词保留不译</li>
<li>"LongBench"基准测试名称保留英文</li>
<li>数学符号"$\sim$"转换为中文波浪号"约"</li>
<li>模型版本号"Llama 3.1-8B"等保持原格式</li>
<li>百分比数值统一使用中文百分号"%"）</li>
</ol>
</div></div><div class="footer container-xl width-full p-responsive"><div class="position-relative flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between pt-4 pb-4 mt-6 f6 color-text-secondary border-top color-border-secondary text-center"><div class="footer-octicon d-lg-block mx-lg-4"><a title="LLIKKE/Arxiv_GPT_Assistant" href="https://github.com/LLIKKE/Arxiv_GPT_Assistant" target="_blank" rel="noreferrer noopener"><svg class="octicon octicon-mark-github gh-logo" width="36" height="36" viewBox="0 0 98 98" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"></path></svg></a></div><span class="mt-2 d-block footprint"><span>powered by </span><a href="https://github.com/wranders/markdown-to-pages-action" target="_blank" rel="noreferrer noopener">markdown-to-pages-action</a></span></div></div></body></html>