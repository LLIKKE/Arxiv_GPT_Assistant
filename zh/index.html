<!DOCTYPE html><html data-color-mode="light" data-light-theme="light" data-dark-theme="dark" lang="en-US"><head><title>LLIKKE/gpt_paper_assistant_ori</title><meta charset="utf-8"><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="description" content="Deepseek based personalized ArXiv paper assistant bot"><link rel="canonical" href="https://llikke.github.io/gpt_paper_assistant_ori/"><meta property="og:title" content="LLIKKE/gpt_paper_assistant_ori"><meta property="og:type" content="website"><meta property="og:url" content="https://llikke.github.io/gpt_paper_assistant_ori/"><meta property="og:description" content="Deepseek based personalized ArXiv paper assistant bot"><meta property="og:locale" content="en_US"><meta property="og:site_name" content="LLIKKE/gpt_paper_assistant_ori"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="LLIKKE/gpt_paper_assistant_ori"><meta name="twitter:description" content="Deepseek based personalized ArXiv paper assistant bot"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon.png" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon.svg" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon-dark.png" media="(prefers-color-scheme: dark)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon-dark.svg" media="(prefers-color-scheme: dark)"><link rel="mask-icon" href="https://github.githubassets.com/pinned-octocat.svg" color="#000000"><link href="index.css" rel="stylesheet"></head><body><div class="container-lg px-3 my-5 markdown-body"><div class="position-relative"><span class="profile-color-modes-toggle js-promo-color-modes-toggle" tabindex="0" aria-label="Toggle dark mode" aria-checked="true" role="checkbox"><div class="profile-color-modes-toggle-track" div></div><div class="profile-color-modes-toggle-thumb"><svg style="fill: var(--color-scale-yellow-0); margin: 7px 0 0 7px;" aria-hidden="true" width="14" height="13" viewBox="0 0 14 13" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.52208 7.71754C7.5782 7.71754 10.0557 5.24006 10.0557 2.18394C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961C9.95801 1.07727 10.3495 0.771159 10.6474 0.99992C12.1153 2.12716 13.0615 3.89999 13.0615 5.89383C13.0615 9.29958 10.3006 12.0605 6.89485 12.0605C3.95334 12.0605 1.49286 10.001 0.876728 7.24527C0.794841 6.87902 1.23668 6.65289 1.55321 6.85451C2.41106 7.40095 3.4296 7.71754 4.52208 7.71754Z"></path></svg></div></span></div><script type="text/javascript">(function() {
  var MODE_KEY = 'markdown_to_pages_dark_mode';
  function toggleMode() {
    var mode = document.documentElement.getAttribute('data-color-mode') === 'light' ? 'dark' : 'light';
    document.documentElement.setAttribute('data-color-mode', mode);
    localStorage.setItem(MODE_KEY, mode);
  }
  var mode = localStorage.getItem(MODE_KEY);
  if (mode == null) {
    var query = window.matchMedia('(prefers-color-scheme: dark)');
    mode = query.matches ? 'dark' : 'light';
  }
  document.documentElement.setAttribute('data-color-mode', mode);
  document.querySelector('.profile-color-modes-toggle').onclick = toggleMode;
})();</script><div><div class="markdown-heading"><h2 class="heading-element">bilevel ZOFO：连接参数高效和零阶技术，以实现高效的大语言模型微调和元训练</h2><a id="user-content-bilevel-zofo连接参数高效和零阶技术以实现高效的大语言模型微调和元训练" class="anchor" aria-label="Permalink: bilevel ZOFO：连接参数高效和零阶技术，以实现高效的大语言模型微调和元训练" href="#bilevel-zofo连接参数高效和零阶技术以实现高效的大语言模型微调和元训练"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2502.03604v1 公告类型：新内容 摘要：使用一阶（FO）优化器对预训练的大型语言模型（LLMs）进行微调，在下游任务中面临着显著的计算挑战。参数高效的微调（PEFT）方法已被提出，通过冻结大多数模型参数，仅训练一小部分参数来解决这些挑战。尽管PEFT效率高，但在需要高任务特定性能的情况下，它可能无法超越全量微调。零阶（ZO）方法通过仅使用前向传递来近似梯度，从而消除了第一阶方法中反向传播的计算负担，为微调整个预训练模型提供了另一种选择。然而，在实现ZO方法时，一个硬提示至关重要，而依赖于简单、固定的硬提示可能不是最优的。在本文中，我们提出了一种双层优化框架，该框架通过结合PEFT和ZO方法来减轻对硬提示的敏感性，从而有效地和高效地微调LLMs。我们的双层ZOFO（零阶-一阶）方法采用双循环优化策略，其中只需要PEFT模型的梯度以及基础模型的前向传递。我们为双层ZOFO提供了收敛保证。经验上，我们证明了在单任务设置中，双层ZOFO优于PEFT和ZO方法，同时保持了类似的内存效率。此外，我们还展示了它在多任务学习中的强大潜力。与当前的多任务学习第一阶元训练算法相比，我们的方法在保持或提高性能的同时，计算需求显著降低。</p>
<div class="markdown-heading"><h2 class="heading-element">TQ-DiT：扩散变换器的高效时间感知量化</h2><a id="user-content-tq-dit扩散变换器的高效时间感知量化" class="anchor" aria-label="Permalink: TQ-DiT：扩散变换器的高效时间感知量化" href="#tq-dit扩散变换器的高效时间感知量化"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2502.04056v1 通知类型：新发表  摘要：扩散变压器（DiTs）将变压器架构与扩散模型结合。然而，其计算复杂度对实时应用和AI系统的可持续性造成重大限制。在这项研究中，我们旨在通过模型量化来提高计算效率，模型量化用低精度表示权重和激活值。为了解决DiT块中网络值的非对称分布，引入了多区域量化（MRQ），它将两个缩放参数分配给子区域。此外，还提出了时间分组量化（TGQ），以减少激活值时间变化引起的量化误差。实验结果表明，所提出的算法在W8A8处的性能与原始全精度模型相当，FID仅增加0.29。此外，它在W6A6处优于其他基线，从而证实了其在低比特量化中的适用性。这些结果突出了我们方法使高效实时生成模型成为可能的潜力。</p>
<div class="markdown-heading"><h2 class="heading-element">自适应语义提示缓存与VectorQ</h2><a id="user-content-自适应语义提示缓存与vectorq" class="anchor" aria-label="Permalink: 自适应语义提示缓存与VectorQ" href="#自适应语义提示缓存与vectorq"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2502.03771v1 公告类型：新发布  摘要：语义提示缓存通过重复使用缓存中LLM生成的响应来处理语义相似的提示，从而降低了大型语言模型（LLM）推理的延迟和成本。向量相似度指标为嵌入提示与其在缓存中最近邻之间的相似度分配一个数值分数。现有系统依赖于一个静态阈值来分类相似度分数是否足够高以导致缓存命中。我们表明，这种一刀切的标准阈值在不同提示中是不够的。我们提出了VectorQ，这是一个框架，用于学习特定嵌入的阈值区域，以适应嵌入的复杂性和不确定性。通过在四个不同数据集的组合上进行评估，我们表明VectorQ在所有静态阈值上均优于最先进的系统，实现了缓存命中率的最高12倍增长和错误率降低至92%。</p>
</div></div><div class="footer container-xl width-full p-responsive"><div class="position-relative flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between pt-4 pb-4 mt-6 f6 color-text-secondary border-top color-border-secondary text-center"><div class="footer-octicon d-lg-block mx-lg-4"><a title="LLIKKE/gpt_paper_assistant_ori" href="https://github.com/LLIKKE/gpt_paper_assistant_ori" target="_blank" rel="noreferrer noopener"><svg class="octicon octicon-mark-github gh-logo" width="36" height="36" viewBox="0 0 98 98" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"></path></svg></a></div><span class="mt-2 d-block footprint"><span>powered by </span><a href="https://github.com/wranders/markdown-to-pages-action" target="_blank" rel="noreferrer noopener">markdown-to-pages-action</a></span></div></div></body></html>