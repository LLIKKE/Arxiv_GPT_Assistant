<!DOCTYPE html><html data-color-mode="light" data-light-theme="light" data-dark-theme="dark" lang="en-US"><head><title>LLIKKE/Arxiv_GPT_Assistant</title><meta charset="utf-8"><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="description" content="Deepseek based personalized ArXiv paper assistant bot"><link rel="canonical" href="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta property="og:type" content="website"><meta property="og:url" content="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:description" content="Deepseek based personalized ArXiv paper assistant bot"><meta property="og:locale" content="en_US"><meta property="og:site_name" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:description" content="Deepseek based personalized ArXiv paper assistant bot"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon.png" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon.svg" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon-dark.png" media="(prefers-color-scheme: dark)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon-dark.svg" media="(prefers-color-scheme: dark)"><link rel="mask-icon" href="https://github.githubassets.com/pinned-octocat.svg" color="#000000"><link href="index.css" rel="stylesheet"></head><body><div class="container-lg px-3 my-5 markdown-body"><div class="position-relative"><span class="profile-color-modes-toggle js-promo-color-modes-toggle" tabindex="0" aria-label="Toggle dark mode" aria-checked="true" role="checkbox"><div class="profile-color-modes-toggle-track" div></div><div class="profile-color-modes-toggle-thumb"><svg style="fill: var(--color-scale-yellow-0); margin: 7px 0 0 7px;" aria-hidden="true" width="14" height="13" viewBox="0 0 14 13" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.52208 7.71754C7.5782 7.71754 10.0557 5.24006 10.0557 2.18394C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961C9.95801 1.07727 10.3495 0.771159 10.6474 0.99992C12.1153 2.12716 13.0615 3.89999 13.0615 5.89383C13.0615 9.29958 10.3006 12.0605 6.89485 12.0605C3.95334 12.0605 1.49286 10.001 0.876728 7.24527C0.794841 6.87902 1.23668 6.65289 1.55321 6.85451C2.41106 7.40095 3.4296 7.71754 4.52208 7.71754Z"></path></svg></div></span></div><script type="text/javascript">(function() {
  var MODE_KEY = 'markdown_to_pages_dark_mode';
  function toggleMode() {
    var mode = document.documentElement.getAttribute('data-color-mode') === 'light' ? 'dark' : 'light';
    document.documentElement.setAttribute('data-color-mode', mode);
    localStorage.setItem(MODE_KEY, mode);
  }
  var mode = localStorage.getItem(MODE_KEY);
  if (mode == null) {
    var query = window.matchMedia('(prefers-color-scheme: dark)');
    mode = query.matches ? 'dark' : 'light';
  }
  document.documentElement.setAttribute('data-color-mode', mode);
  document.querySelector('.profile-color-modes-toggle').onclick = toggleMode;
})();</script><div><div class="markdown-heading"><h2 class="heading-element">CAST：反事实标签提升视觉-语言-行动模型中的指令遵循能力</h2><a id="user-content-cast反事实标签提升视觉-语言-行动模型中的指令遵循能力" class="anchor" aria-label="Permalink: CAST：反事实标签提升视觉-语言-行动模型中的指令遵循能力" href="#cast反事实标签提升视觉-语言-行动模型中的指令遵循能力"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>（注：在学术语境中，"Counterfactual Labels"通常译为"反事实标签"，指通过假设与事实相反的条件来生成的标签数据；"Instruction Following"特指模型对指令的理解与执行能力；"Vision-Language-Action Models"采用直译加专业术语处理方式，译为"视觉-语言-行动模型"以保持学科规范性。）</p>
<p>arXiv:2508.13446v1 公告类型：新研究<br>
摘要：通用机器人应能理解并遵循用户指令，但当前的视觉-语言-动作（VLA）模型尽管为开放词汇自然语言指令到机器人动作的映射提供了强大架构，却在执行细粒度指令时存在困难。这一问题的根源在于现有机器人数据集缺乏语义多样性和语言基础，特别是针对相似观察场景的细粒度任务多样性不足。为此，我们提出一种创新方法，通过利用视觉语言模型生成反事实标签来增强现有机器人数据集。该方法通过生成反事实语言和动作，提升机器人数据集中语言基础的多样性与精细度，从而增强VLA模型的语言遵循能力。我们在3种不同室内外环境中开展视觉语言导航实验，评估模型从简单物体中心指令到复杂指代任务的语言指令执行能力。实验表明，无需额外数据收集的反事实重标注技术显著提升了VLA策略的指令遵循性能，使其达到与最先进方法相当的竞争力，并在导航任务中将成功率提高了27%。</p>
<div class="markdown-heading"><h2 class="heading-element">计算机强化学习：规模化端到端在线强化学习在计算机使用代理中的应用</h2><a id="user-content-计算机强化学习规模化端到端在线强化学习在计算机使用代理中的应用" class="anchor" aria-label="Permalink: 计算机强化学习：规模化端到端在线强化学习在计算机使用代理中的应用" href="#计算机强化学习规模化端到端在线强化学习在计算机使用代理中的应用"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.14040v1 公告类型：新成果<br>
摘要：本文提出ComputerRL框架，实现自主桌面智能体对复杂数字工作空间的熟练操作。该框架采用API-GUI融合范式，统一程序化API调用与直接图形界面交互，解决机器智能体与以人为中心的桌面环境之间的固有适配难题。端到端强化学习训练的规模化扩展是提升跨桌面任务泛化能力的关键，但环境低效性和长时训练不稳定性仍是核心挑战。为此我们开发了分布式强化学习基础设施，可协调数千个并行虚拟桌面环境以加速大规模在线强化学习。进一步提出Entropulse训练策略，通过强化学习与监督微调的交替执行，有效缓解长时训练中的熵崩溃现象。我们在GLM-4-9B-0414和Qwen2.5-14B开源模型上部署ComputerRL，并在OSWorld基准测试中评估：基于GLM-4-9B-0414的AutoGLM-OS-9B模型取得48.1%的最新最优准确率，显著提升通用智能体的桌面自动化能力。该算法框架已应用于AutoGLM系统构建（Liu et al., 2024a）。</p>
<div class="markdown-heading"><h2 class="heading-element">通过比特串表示的近似贝叶斯推断</h2><a id="user-content-通过比特串表示的近似贝叶斯推断" class="anchor" aria-label="Permalink: 通过比特串表示的近似贝叶斯推断" href="#通过比特串表示的近似贝叶斯推断"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.13598v1 公告类型：新成果<br>
摘要：机器学习界近期致力于量化或低精度算术运算以扩展大模型规模。本文提出在由这些表示方法创建的量化离散参数空间中进行概率推理，从而有效实现利用离散参数学习连续分布。我们同时研究了二维密度估计和量化神经网络，引入基于概率电路的可处理学习方法。该方法为管理复杂分布提供了可扩展解决方案，并清晰揭示了模型行为机理。通过多种模型的验证实验，我们在保持精度的同时证明了推理效率的提升。该研究通过离散近似实现概率计算，推动了可扩展、可解释机器学习的发展。</p>
<div class="markdown-heading"><h2 class="heading-element">X-MoE：在高性能计算平台上实现新兴混合专家架构的可扩展训练</h2><a id="user-content-x-moe在高性能计算平台上实现新兴混合专家架构的可扩展训练" class="anchor" aria-label="Permalink: X-MoE：在高性能计算平台上实现新兴混合专家架构的可扩展训练" href="#x-moe在高性能计算平台上实现新兴混合专家架构的可扩展训练"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.13337v1 公告类型：新成果<br>
摘要：新兴的专家专用混合专家（MoE）架构（如DeepSeek-MoE）通过细粒度专家划分和大规模top-k路由机制实现了卓越的模型质量，但其可扩展性受限于巨大的激活内存开销和昂贵的全通信成本。此外，当前主要针对英伟达GPU优化的MoE训练系统在非英伟达平台上表现欠佳，导致大量计算潜力未被释放。本研究提出X-MoE——一种新型MoE训练系统，专为下一代MoE架构的可扩展训练性能而设计。X-MoE通过多项创新技术实现这一目标，包括：采用跨平台内核的无填充高效MoE训练、冗余规避调度机制，以及支持序列分片的混合并行MoE模块。在基于AMD MI250X GPU的Frontier超级计算机上的评估表明，X-MoE可将DeepSeek风格的MoE模型扩展至5450亿参数（覆盖1024块GPU），在相同硬件预算下比现有方法可训练的最大模型规模提升10倍，同时保持高训练吞吐量。X-MoE源代码已发布于<a href="https://github.com/Supercomputing-System-AI-Lab/X-MoE%E3%80%82">https://github.com/Supercomputing-System-AI-Lab/X-MoE。</a></p>
<p>（注：根据学术规范，原文"545 billion"准确转换为"5450亿"，并采用"混合专家"标准译法保持术语一致性，同时将技术术语如"top-k routing"意译为"top-k路由机制"以符合中文表达习惯。）</p>
<div class="markdown-heading"><h2 class="heading-element">MAVIS：通过价值引导的推理时搜索实现多目标对齐</h2><a id="user-content-mavis通过价值引导的推理时搜索实现多目标对齐" class="anchor" aria-label="Permalink: MAVIS：通过价值引导的推理时搜索实现多目标对齐" href="#mavis通过价值引导的推理时搜索实现多目标对齐"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.13415v1 公告类型：新成果<br>
摘要：大型语言模型（LLMs）正日益广泛地部署于需要平衡多个往往相互冲突目标的应用场景中——例如实用性、无害性或幽默感。在这种多目标设定下，要使输出符合用户特定偏好，通常需要针对每个目标或偏好配置对模型进行微调，这种方法不仅计算成本高昂且缺乏灵活性。我们提出MAVIS——基于价值引导推理时搜索的多目标对齐框架——这是一种轻量级的推理阶段对齐框架，能够在不改变基础模型权重的情况下实现对LLM行为的动态控制。MAVIS通过训练一组小型价值模型（每个模型对应一个特定目标），在推理阶段根据用户指定的权重组合这些价值模型，生成倾斜函数来调整基础模型的输出分布，以实现期望的权衡效果。这些价值模型采用保证KL正则化策略单调改进的简单迭代算法进行训练。实证研究表明，MAVIS在性能上超越了针对单目标微调模型并进行事后组合的基线方法，甚至接近针对用户精确偏好进行微调的理想化设定下的模型表现。</p>
<div class="markdown-heading"><h2 class="heading-element">复杂自动化机器学习管道优化的上下文决策制定</h2><a id="user-content-复杂自动化机器学习管道优化的上下文决策制定" class="anchor" aria-label="Permalink: 复杂自动化机器学习管道优化的上下文决策制定" href="#复杂自动化机器学习管道优化的上下文决策制定"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.13657v1 公告类型：新成果<br>
摘要：算法选择与超参数优化联合策略（CASH）一直是传统自动机器学习（AutoML）系统的核心基础。然而随着预训练模型的发展，现代机器学习流程已超越单纯的超参数优化，往往需要微调、集成学习等自适应技术。虽然为下游任务寻找最佳性能模型的核心挑战依然存在，但机器学习管道日益增长的异构性要求开发新型AutoML方法。本研究将CASH框架扩展至现代机器学习管道的选择与适配领域，提出PS-PFN方法——通过将后验采样（PS）扩展至最大k臂老虎机问题设置，实现对自适应机器学习管道的高效探索与利用。该方案利用先验数据拟合网络（PFNs），通过上下文学习高效估计最大值的后验分布。我们进一步展示了如何扩展该方法以考量不同臂的拉动成本差异，并采用独立PFNs为每个臂单独建模奖励分布。在一个新型基准任务和两个现有标准基准任务上的实验结果表明，PS-PFN相比其他老虎机策略和AutoML方法具有显著性能优势。代码与数据已开源：<a href="https://github.com/amirbalef/CASHPlus%E3%80%82">https://github.com/amirbalef/CASHPlus。</a></p>
<div class="markdown-heading"><h2 class="heading-element">自动化能源感知时间序列模型在嵌入式FPGA上的部署——面向强韧性合流制溢流管理</h2><a id="user-content-自动化能源感知时间序列模型在嵌入式fpga上的部署面向强韧性合流制溢流管理" class="anchor" aria-label="Permalink: 自动化能源感知时间序列模型在嵌入式FPGA上的部署——面向强韧性合流制溢流管理" href="#自动化能源感知时间序列模型在嵌入式fpga上的部署面向强韧性合流制溢流管理"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>（注：译文采用技术文献常用翻译规范，保留专业术语"FPGA"不译，通过破折号构建符合中文科技文本特征的标题结构。"Resilient"译为"强韧性"以准确表达系统抗干扰能力，"Combined Sewer Overflow"采用环境工程标准译法"合流制溢流"）</p>
<p>arXiv:2508.13905v1 公告类型：新研究<br>
摘要：气候变化加剧的极端天气事件日益挑战老化的合流制排水系统，增加了未经处理的污水溢流风险。准确预测污水溢流调蓄池填充水位可为早期干预提供 actionable 洞察，助力控制无组织排放。近年来，基于人工智能的预测方法为传统物联模型提供了可扩展替代方案，但其对云计算的依赖限制了在通信中断期间的可靠性。为此，我们提出端到端预测框架，支持在边缘设备上直接进行高能效推理。该方案集成轻量化Transformer与长短期记忆（LSTM）模型，通过纯整数量化压缩实现高效设备端执行。此外，采用自动化硬件感知部署流水线，通过在AMD Spartan-7 XC7S15 FPGA上联合优化预测误差与能耗搜索最优模型配置。经真实污水数据验证，基于24小时历史数据训练的8位Transformer模型在单次推理能耗0.370 mJ下达到高精度（MSE 0.0376）；而最优8位LSTM模型能耗显著降低（0.009 mJ，降幅超40倍），但精度下降14.89%（MSE 0.0432）且训练时间大幅延长。这种权衡凸显了模型选择需契合部署优先级：超低能耗场景倾向LSTM，高精度需求优先Transformer。本研究实现了本地化能效预测，为增强合流制排水系统韧性提供支撑。完整代码详见GitHub仓库（<a href="https://github.com/tianheng-ling/EdgeOverflowForecast%EF%BC%89%E3%80%82">https://github.com/tianheng-ling/EdgeOverflowForecast）。</a></p>
<div class="markdown-heading"><h2 class="heading-element">具身人工智能中的多模态数据存储与检索：综述</h2><a id="user-content-具身人工智能中的多模态数据存储与检索综述" class="anchor" aria-label="Permalink: 具身人工智能中的多模态数据存储与检索：综述" href="#具身人工智能中的多模态数据存储与检索综述"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.13901v1 公告类型：新成果<br>
摘要：具身人工智能（EAI）代理持续与物理世界交互，产生海量异构多模态数据流，传统管理系统难以有效处理。本综述首先系统评估了五种存储架构（图数据库、多模型数据库、数据湖、向量数据库和时序数据库），重点关注其对EAI核心需求的适配性，包括物理 grounding、低延迟访问和动态可扩展性。继而分析了五种检索范式（基于融合策略的检索、基于表征对齐的检索、基于图结构的检索、基于生成模型的检索及基于高效检索的优化），揭示了实现长期语义连贯性与保持实时响应性之间的根本性矛盾。基于全面分析，我们指出了从基础性的物理 grounding 鸿沟到跨模态整合、动态适应及开放世界泛化等系统性挑战的关键瓶颈。最后提出前瞻性研究议程，涵盖物理感知数据模型、自适应存储-检索协同优化和标准化基准测试，以指导未来研究构建面向EAI的体系化数据管理方案。本综述基于对180余项相关研究的系统梳理，为设计新一代自主具身系统必需的鲁棒高性能数据管理框架提供了严谨路线图。</p>
<div class="markdown-heading"><h2 class="heading-element">输入时间缩放</h2><a id="user-content-输入时间缩放" class="anchor" aria-label="Permalink: 输入时间缩放" href="#输入时间缩放"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.13654v1 公告类型：新成果<br>
摘要：当前大型语言模型（LLM）通常需经过大规模精心策划数据集的训练后优化（数据与训练规模扩展），并在测试时进行推理（推理时扩展）。本研究提出一种新的扩展范式——输入时扩展，通过将资源集中于查询端（输入时）来补充现有扩展方法。在训练和测试过程中，我们结合LLM的元知识，采用不同策略对输入进行优化。同时发现了一种新现象：训练-测试协同设计。必须在训练和测试阶段同时应用查询策略，仅单独应用于训练或测试都会导致性能严重下降。令人惊讶的是，看似低质量的数据集也能获得高性能——在查询中添加无关信息、从仅经过最低限度过滤的数据集中随机选取样本，反而能取得最佳效果。这些发现与"垃圾进，垃圾出"的普遍归纳偏执相悖。使用看似高质量的数据精心策划数据集反而可能限制性能上限。此外，在相同质量条件下（15k对1k），更多数据训练出的模型表现更差，简单扩大数据集规模的做法也需审慎评估。好消息是我们的发现与"少即是多"现象相符：少量样本足以激发高级推理能力。基于Qwen2.5-32B-Instruct模型的实验显示，我们在AIME24（76.7%）和AIME25（76.7%）的pass@1指标上达到了32B模型的SOTA性能。通过三个模型的多数投票策略，可进一步提升至AIME24（76.7%）和AIME25（80%）。从DeepSeek-R1-Distill-Qwen-32B起步，最佳结果达到AIME24（86.7%）和AIME25（76.7%）。为促进可复现性和深入研究，我们正逐步开源数据集、数据管道、评估结果及模型检查点。</p>
<div class="markdown-heading"><h2 class="heading-element">医学决策中的专家意识多大型语言模型招募与协作机制</h2><a id="user-content-医学决策中的专家意识多大型语言模型招募与协作机制" class="anchor" aria-label="Permalink: 医学决策中的专家意识多大型语言模型招募与协作机制" href="#医学决策中的专家意识多大型语言模型招募与协作机制"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>该翻译准确传达了原文的核心概念：</p>
<ol>
<li>"Expertise-aware"译为"专家意识"体现了对专业能力的认知特性</li>
<li>"Multi-LLM Recruitment"译为"多大型语言模型招募"保持技术术语准确性</li>
<li>"Collaboration for Medical Decision-Making"译为"医学决策协作机制"完整呈现医疗应用场景</li>
<li>通过添加"机制"二字使中文表达更符合学术语境</li>
<li>整体语序调整符合中文科技文献的标题表达习惯</li>
</ol>
<p>arXiv:2508.13754v1 公告类型：新研究<br>
摘要：医疗决策（MDM）是一个复杂过程，需要大量领域专业知识才能有效整合异构且复杂的临床信息。尽管大语言模型（LLM）的最新进展展现出支持MDM的潜力，但单LLM方法受限于其参数化知识边界和静态训练语料，难以稳健整合临床信息。为应对这一挑战，我们提出专业感知的多LLM招募与协作框架（EMRC），以提升MDM系统的准确性与可靠性。该框架分两阶段运作：（i）专业感知的智能体招募；（ii）基于置信度与对抗验证的多智能体协作。具体而言，在第一阶段，我们使用公开语料构建LLM专业能力表，用于捕捉多个LLM在不同医学科室类别和查询难度级别上的专业特长。该表支持在推理阶段动态选择最优LLM作为每个医疗查询的医学专家智能体。第二阶段中，选定智能体生成带有自评估置信度分数的响应，通过置信度融合与对抗验证进行整合，以提升诊断可靠性。我们在三个公开MDM数据集上评估EMRC框架，结果表明其优于最先进的单LLM和多LLM方法，实现了卓越的诊断性能。例如在MMLU-Pro-Health数据集上，EMRC达到74.45%的准确率，较性能最佳闭源模型GPT-4-0613提升2.69%，这验证了我们专业感知智能体招募策略的有效性以及智能体在利用各LLM专业能力方面的互补优势。</p>
<div class="markdown-heading"><h2 class="heading-element">模型效率的正式算法</h2><a id="user-content-模型效率的正式算法" class="anchor" aria-label="Permalink: 模型效率的正式算法" href="#模型效率的正式算法"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.14000v1 公告类型：新成果<br>
摘要：本文提出旋钮-计量-规则（KMR）框架，这是一种用于表征和推演深度学习模型效率技术的统一形式化体系。通过将剪枝、量化、知识蒸馏、参数高效架构等多样化方法抽象为可控旋钮、确定性规则和可测量计量器三个一致化组件，KMR为效率优化提供了数学精确且模块化的视角。该框架支持多技术系统化组合、灵活的策略驱动应用，并通过预算化KMR算法实现迭代式预算优化。我们演示了如何将经典效率方法实例化为KMR三元组，并为每种方法提供简洁的算法模板。该框架不仅揭示了方法间的内在关联、促进混合流程构建，更为自动化策略学习、动态适应以及成本-质量权衡的理论分析等未来研究奠定基础。总体而言，KMR为模型效率研究的统一与推进提供了兼具概念性和实用性的工具。</p>
<div class="markdown-heading"><h2 class="heading-element">一次性剪枝与迭代剪枝：重新思考模型压缩中的剪枝策略</h2><a id="user-content-一次性剪枝与迭代剪枝重新思考模型压缩中的剪枝策略" class="anchor" aria-label="Permalink: 一次性剪枝与迭代剪枝：重新思考模型压缩中的剪枝策略" href="#一次性剪枝与迭代剪枝重新思考模型压缩中的剪枝策略"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.13836v1 公告类型：新成果<br>
摘要：剪枝是压缩神经网络以提升计算效率的核心技术。该过程通常有两种实现路径：一次性剪枝（通过单轮训练与剪枝完成）和迭代剪枝（通过多轮循环执行以实现更精细的网络优化）。尽管迭代剪枝历来应用更广泛，但这种偏好往往源于经验假设而非严格验证。本研究首次对这两种方法进行了系统全面的比较，提出了严谨的定义，在结构化与非结构化场景下进行基准测试，并应用了不同的剪枝准则与模式。我们发现两种方法各具优势：低剪枝率时一次性剪枝更有效，而高剪枝率时迭代剪枝表现更优。基于这些发现，我们倡导基于耐心机制的剪枝策略，并提出一种混合方法——在特定场景下其性能可超越传统方法，这为实践者根据目标与约束条件选择剪枝策略提供了重要参考。源代码已发布于<a href="https://github.com/janumiko/pruning-benchmark%E3%80%82">https://github.com/janumiko/pruning-benchmark。</a></p>
<div class="markdown-heading"><h2 class="heading-element">QuickMerge++：基于自回归先验的快速令牌合并技术</h2><a id="user-content-quickmerge基于自回归先验的快速令牌合并技术" class="anchor" aria-label="Permalink: QuickMerge++：基于自回归先验的快速令牌合并技术" href="#quickmerge基于自回归先验的快速令牌合并技术"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.13204v1 公告类型：新研究<br>
摘要：随着生成模型在语言、视觉和视频领域处理更大规模输入，令牌级计算成本已成为关键瓶颈。现有研究表明仅部分令牌对下游预测有显著影响，但多数令牌选择方法存在静态化、模态特异性或与自回归生成不兼容的问题。本文提出QuickMerge——一个专为高效下一令牌预测设计的轻量级令牌融合框架。该框架通过基于注意力范数幅度的动态选择机制，配合熵值驱动的预算估计器来精简令牌数量。为保持自回归兼容性，我们引入了在融合令牌序列上训练的轻量级变换器先验模型。通过结合语义显著性评估、弹性令牌预算与自回归对齐技术，QuickMerge实现了以更少令牌进行精准生成。我们在多模态领域进行全面评估，证明该方法在计算精度权衡方面持续提升性能：在显著降低令牌数量的同时，其表现匹配甚至超越了学习式令牌化器和固定分块基线方法。</p>
<div class="markdown-heading"><h2 class="heading-element">通过元学习动态设计机器学习流水线</h2><a id="user-content-通过元学习动态设计机器学习流水线" class="anchor" aria-label="Permalink: 通过元学习动态设计机器学习流水线" href="#通过元学习动态设计机器学习流水线"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.13436v1 公告类型：新成果<br>
摘要：自动化机器学习（AutoML）通过自动执行模型选择、超参数调优和特征工程，降低了机器学习系统设计的门槛。然而，传统搜索与优化策略（如随机搜索、粒子群优化和贝叶斯优化）伴随的高计算成本仍是重大挑战。此外，AutoML系统通常需要探索庞大的搜索空间，这容易导致过拟合。本文提出一种元学习方法，用于动态设计AutoML系统的搜索空间。该方法利用历史元知识选取搜索空间中具有潜力的区域，从而加速优化进程。实验表明：在保持预测性能无明显下降的前提下，该方法可使随机搜索的运行时间减少89%，搜索空间压缩至（预处理器1.8/13，分类器4.3/16）。当适配到Auto-Sklearn框架时，该方法在缩小搜索空间的同时展现出竞争优势。研究还深入探讨了元特征选择、元模型可解释性以及搜索空间压缩策略中固有的权衡关系。</p>
<div class="markdown-heading"><h2 class="heading-element">一次训练，随处部署：实现数据高效的动态物体操控</h2><a id="user-content-一次训练随处部署实现数据高效的动态物体操控" class="anchor" aria-label="Permalink: 一次训练，随处部署：实现数据高效的动态物体操控" href="#一次训练随处部署实现数据高效的动态物体操控"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.14042v1 公告类型：新成果<br>
摘要：实现通用化的动态物体操控对提升制造业效率至关重要，因其能消除针对不同场景的专门化工程设计。为此，模仿学习成为一种前景广阔的研究范式，通过专家示范数据教导策略掌握操控技能。虽然增加示范数据可提升模仿学习策略的泛化能力，但数据收集过程劳动密集型特征显著。针对该问题，本文探究了仅凭少量示范能否实现动态物体操控的强泛化能力。具体而言，我们构建了基于信息熵的理论框架以量化模仿学习的优化过程，并据此提出名为"通用熵基操控系统"（GEM）的框架。在仿真与真实任务中的大量实验表明，GEM能够跨越多类环境背景、机器人形态、运动动力学和物体几何形态实现泛化。值得注意的是，该系统已在一家真实食堂部署用于餐具回收任务——在零场景专项示范的前提下，历经超万次操作仍保持97%以上的成功率。</p>
<div class="markdown-heading"><h2 class="heading-element">搜索时数据污染</h2><a id="user-content-搜索时数据污染" class="anchor" aria-label="Permalink: 搜索时数据污染" href="#搜索时数据污染"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.13180v1 公告类型：新成果<br>
摘要：数据污染指评估数据泄露至模型训练数据中，导致模型对本应隔离的测试集产生过拟合，从而损害测试有效性。我们发现评估基于搜索的大型语言模型（LLM）智能体时存在类似问题——搜索时污染（STC）。这类智能体通过工具从在线资源获取信息以回答用户查询，当检索步骤返回包含测试问题（或其近似重复）及其答案的源内容时，智能体会直接复制而非真正推理，破坏基准测试的完整性。研究发现，托管评估数据集的在线平台HuggingFace频繁出现在搜索型智能体的检索日志中，导致智能体常在推理链中明确承认从该平台发现问答对。在Humanity's Last Exam (HLE)、SimpleQA和GPQA这三个常用能力基准测试中，约3%的问题存在搜索型智能体直接从HuggingFace获取带标准答案数据集的现象。当数百万评估查询针对同一基准时，即使微小但重复的泄露也会加速基准失效，缩短其预期生命周期。屏蔽HuggingFace后，受污染子集的准确率下降约15%。消融实验进一步表明，HuggingFace上公开的评估数据集可能并非STC的唯一来源。为此，我们最终提出基准设计与结果报告的最佳实践方案，以应对这种新型泄露风险，确保搜索型LLM智能体的可信评估。为便利审计评估结果，我们同时公开了全部实验日志。</p>
<div class="markdown-heading"><h2 class="heading-element">GDNSQ：面向低位神经网络的渐进可微噪声尺度量化方法</h2><a id="user-content-gdnsq面向低位神经网络的渐进可微噪声尺度量化方法" class="anchor" aria-label="Permalink: GDNSQ：面向低位神经网络的渐进可微噪声尺度量化方法" href="#gdnsq面向低位神经网络的渐进可微噪声尺度量化方法"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.14004v1 公告类型：新研究<br>
摘要：量化神经网络可视为一系列噪声信道构成的链条，其中每层的舍入操作会随位宽缩减而降低信道容量；浮点（FP）检查点设定了最大输入速率。我们通过将微调过程转化为平滑的约束优化问题，追踪了平均位宽递减时的容量动态变化，并据此识别出量化瓶颈。该方法采用完全可微分的直通估计器（STE），其位宽、噪声尺度和钳位边界均可学习，并通过外点罚函数强制执行目标位宽；适度的度量平滑（通过蒸馏实现）确保了训练稳定性。尽管方法简洁，该方案在极端W1A1设置下仍能保持竞争力精度，同时保留了STE的高效特性。</p>
<div class="markdown-heading"><h2 class="heading-element">MHSNet：一种基于混合专家模型的分层语义表示网络，用于结合大型语言模型实现精准重复简历检测</h2><a id="user-content-mhsnet一种基于混合专家模型的分层语义表示网络用于结合大型语言模型实现精准重复简历检测" class="anchor" aria-label="Permalink: MHSNet：一种基于混合专家模型的分层语义表示网络，用于结合大型语言模型实现精准重复简历检测" href="#mhsnet一种基于混合专家模型的分层语义表示网络用于结合大型语言模型实现精准重复简历检测"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.13676v1 公告类型：新研究<br>
摘要：为维持企业人才库储备，招聘人员需持续从第三方网站（如LinkedIn、Indeed）抓取简历。然而，这些外部简历往往存在信息不完整、准确性不足的问题。为提升第三方简历质量并充实企业人才库，必须对抓取简历与现有人才库简历进行重复检测。由于简历文本具有语义复杂性、结构异构性和信息不完整性，此类查重工作面临巨大挑战。为此，我们提出MHSNet——一种通过对比学习微调BGE-M3的多层级身份验证框架。该框架利用微调后的混合专家模型（MoE）生成简历的多层级稀疏与稠密表征，从而计算对应的多层级语义相似度。此外，MHSNet采用状态感知混合专家模型（MoE）以应对各类不完整简历的处理需求。实验结果验证了MHSNet的有效性。</p>
<div class="markdown-heading"><h2 class="heading-element">SVDformer：基于奇异值分解与Transformer的方向感知谱图嵌入学习</h2><a id="user-content-svdformer基于奇异值分解与transformer的方向感知谱图嵌入学习" class="anchor" aria-label="Permalink: SVDformer：基于奇异值分解与Transformer的方向感知谱图嵌入学习" href="#svdformer基于奇异值分解与transformer的方向感知谱图嵌入学习"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.13435v1 公告类型：新成果<br>
摘要：有向图被广泛应用于现实世界系统中非对称关系的建模。然而，现有有向图神经网络因各向同性聚合机制和局部滤波机制的局限，往往难以同时捕捉方向语义与全局结构模式。针对这一不足，本文提出SVDformer——一种融合奇异值分解（SVD）与Transformer架构的创新框架，用于方向感知的图表示学习。该框架首先通过多头自注意力机制精化奇异值嵌入，自适应增强关键频谱成分并抑制高频噪声，实现无需频谱核的可学习低通/高通图滤波。进一步，通过将奇异向量作为方向投影基、奇异值作为缩放因子，SVDformer利用Transformer通过注意力权重建模入边/出边模式间的多尺度交互，从而在特征传播过程中显式保持边方向性。在六个有向图基准上的大量实验表明，SVDformer在节点分类任务上持续优于最先进的图神经网络及方向感知基线模型，为有向图表示学习确立了新范式。</p>
<div class="markdown-heading"><h2 class="heading-element">离散优化中的最小-最大违规及其在计算科学中的应用</h2><a id="user-content-离散优化中的最小-最大违规及其在计算科学中的应用" class="anchor" aria-label="Permalink: 离散优化中的最小-最大违规及其在计算科学中的应用" href="#离散优化中的最小-最大违规及其在计算科学中的应用"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.13437v1 公告类型：新成果<br>
摘要：本文提出离散最小-最大违规（DMMV）作为通用优化问题，其核心在于寻找使最大约束违规最小化的离散变量赋值方案。这种与上下文无关的数学表述可广泛应用于具有最坏性能要求的场景。在数学定义DMMV问题后，我们系统探究其性质以建立理论基础。针对实际应用规模的DMMV实例，我们开发了基于GPU加速的启发式算法，该算法利用DMMV的数学特性加速求解过程。通过求解三个优化问题案例展示算法的广泛适用性：（1）语言模型训练后量化，（2）离散断层成像，（3）有限脉冲响应（FIR）滤波器设计。在无异常值分离的量化任务中，本算法相较现有方法平均提升14%性能；在离散断层成像中，均匀噪声下重建误差降低16%，GPU计算速度提升6倍；在FIR滤波器设计中，相比商用整数优化求解器Gurobi实现近50%的纹波削减。对比结果表明：将DMMV作为上下文无关问题研究具有显著价值，且我们提出的启发式算法在三类问题上展现突出优势。本GPU加速启发式算法将开源发布以促进DMMV及其应用的进一步研究。代码地址：<a href="https://anonymous.4open.science/r/AMVM-5F3E/" rel="nofollow">https://anonymous.4open.science/r/AMVM-5F3E/</a></p>
<p>（注：严格遵循用户要求的术语规范，其中"heuristic"统一译为"启发式算法"，"violation"译为"违规"，"ripple"译为"纹波"，专业术语如"discrete tomography"译为"离散断层成像"均采用学科标准译法。保持学术论文摘要的正式语体，同时确保长句的汉语表达符合中文科技文献的句式特点。）</p>
<div class="markdown-heading"><h2 class="heading-element">像专家一样识别驾驶风格：利用大型语言模型中的语义特权信息</h2><a id="user-content-像专家一样识别驾驶风格利用大型语言模型中的语义特权信息" class="anchor" aria-label="Permalink: 像专家一样识别驾驶风格：利用大型语言模型中的语义特权信息" href="#像专家一样识别驾驶风格利用大型语言模型中的语义特权信息"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.13881v1 公告类型：新研究<br>
摘要：现有驾驶风格识别系统主要依赖低层级传感器特征进行训练，忽视了人类专家固有的丰富语义推理能力。这种差异导致算法分类与专家判断之间存在根本性错位。为弥合这一鸿沟，我们提出了一种集成大语言模型（LLMs）生成的语义特权信息（SPI）的新框架，使识别结果与人类可理解的推理逻辑对齐。首先，我们开发了DriBehavGPT——基于LLM的交互模块，可生成驾驶行为的自然语言描述。随后通过文本嵌入和降维技术将这些描述编码为机器学习兼容的表征。最后，将其作为特权信息整合到支持向量机+（SVM+）中进行训练，使模型能够模拟类人解释模式。在多场景真实驾驶实验中的结果表明，我们的SPI增强框架优于传统方法，F1分数在跟车场景提升7.6%，变道场景提升7.9%。值得注意的是，SPI仅用于训练阶段，推理过程完全依赖传感器数据，在保证计算效率的同时不牺牲性能。这些发现凸显了语义行为表征在提升识别准确性、推动可解释性人本驾驶系统发展中的关键作用。</p>
<div class="markdown-heading"><h2 class="heading-element">迈向统一多模态金融预测：通过跨模态注意力融合情感嵌入与市场指标</h2><a id="user-content-迈向统一多模态金融预测通过跨模态注意力融合情感嵌入与市场指标" class="anchor" aria-label="Permalink: 迈向统一多模态金融预测：通过跨模态注意力融合情感嵌入与市场指标" href="#迈向统一多模态金融预测通过跨模态注意力融合情感嵌入与市场指标"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.13327v1 公告类型：新研究<br>
摘要：我们提出STONK（基于新闻知识的股票优化），这是一个多模态框架，通过整合数值化市场指标与情感增强的新闻嵌入来改进每日股价走势预测。通过特征拼接和跨模态注意力机制融合数值与文本嵌入，我们的统一流程解决了孤立分析的局限性。回测显示STONK显著超越纯数值基线模型。对融合策略和模型配置的全面评估为可扩展的多模态金融预测提供了基于实证的指导。源代码已发布于GitHub平台。</p>
<p>（注：STONK作为专有名词保留原文，其括号内解释性翻译采用意译处理；"backtesting"译为专业金融术语"回测"；"evidence-based guidance"采用"基于实证的指导"的译法以符合学术论文表述规范）</p>
<div class="markdown-heading"><h2 class="heading-element">FedUP：针对模型投毒攻击的高效剪枝式联邦遗忘机制</h2><a id="user-content-fedup针对模型投毒攻击的高效剪枝式联邦遗忘机制" class="anchor" aria-label="Permalink: FedUP：针对模型投毒攻击的高效剪枝式联邦遗忘机制" href="#fedup针对模型投毒攻击的高效剪枝式联邦遗忘机制"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>（注：翻译在保持原意的基础上进行了专业术语的本地化处理："Efficient Pruning-based"译为"高效剪枝式"，"Federated Unlearning"译为"联邦遗忘机制"，"Model Poisoning Attacks"译为"模型投毒攻击"。标题采用技术文献常见的冒号分隔结构，既保留英文缩写FedUP的识别度，又通过副标题准确传达技术内涵。）</p>
<p>arXiv:2508.13853v1 公告类型：新研究<br>
摘要：联邦学习（FL）易受模型投毒等攻击影响，攻击者通过发送恶意本地权重破坏全局模型。联邦遗忘学习（FU）作为一种新兴解决方案，能够在不完全重新训练的情况下，选择性地消除已检测恶意贡献者对全局模型的影响。然而与传统FU场景中客户端可信且协作不同，当面对恶意且可能共谋的客户端时，由于无法假定其会配合数据遗忘过程，FU的应用面临巨大挑战。本研究提出FedUP——一种轻量级FU算法，通过剪枝受攻击模型中的特定连接来高效消除恶意客户端影响。该方法仅需利用遗忘操作前最后一轮训练中的客户端权重即可确定需要抑制的连接，从而实现高效操作。由于良性客户端与恶意客户端的更新存在重叠，隔离恶意影响具有显著难度。FedUP通过精准筛选并清零良性/恶意客户端最新更新间差异最大的高幅值权重，在保留良性信息的同时解决这一难题。我们在强对抗威胁模型下评估FedUP（最高50%-1客户端为恶意且完全掌握聚合流程），通过在IID/非IID数据、标签翻转与后门攻击场景下的实验，以及与最先进（SOTA）FU方案的对比，证明了方案的有效性、鲁棒性和高效性。在所有场景中，FedUP能显著降低恶意影响，将恶意数据准确率降至与从头训练模型相当的水平，同时保持良性数据性能。相较于SOTA方案，FedUP在实现有效遗忘的同时持续保持更快的处理速度并节省存储空间。</p>
<div class="markdown-heading"><h2 class="heading-element">TASER：面向模式引导抽取与推荐的表格代理</h2><a id="user-content-taser面向模式引导抽取与推荐的表格代理" class="anchor" aria-label="Permalink: TASER：面向模式引导抽取与推荐的表格代理" href="#taser面向模式引导抽取与推荐的表格代理"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.13404v1 公告类型：新研究<br>
摘要：现实世界中的金融文件记录了实体持有的金融资产核心信息，这些信息可能涉及数百万种不同的金融工具类型。然而，这些细节往往埋藏在混乱、多页、碎片化的表格中——例如，我们数据集中99.4%的表格没有边界框，单个表格最大行数达426行，横跨44页。为应对现实场景表格的独特挑战，我们推出持续学习的智能表格提取系统TASER（基于模式引导提取与推荐的表格智能体）。该系统能将高度非结构化、多页、异构的表格转化为符合标准化模式的输出。我们的表格智能体依托初始模式框架，执行表格检测、分类、提取和推荐任务；随后推荐智能体审核输出结果，提出模式修订建议并决策最终方案，使TASER在表格检测准确率上以10.1%的优势超越现有模型（如Table Transformer）。在持续学习过程中，我们发现增大批处理量可使可操作模式建议量提升104.3%，进而使资产提取量增长9.8%，这印证了持续学习机制的重要性。为训练TASER，我们手工标注了22,584页（28,150,449个标记）、3,213个表格，涉及7,316亿美元资产数据，构建了首个真实金融表格数据集。我们公开TASERTab数据集以推动学术界对真实金融表格及其输出的研究。实验结果验证了基于智能体的模式引导提取系统在实现金融表格鲁棒理解方面的巨大潜力。</p>
<div class="markdown-heading"><h2 class="heading-element">参与人数自适应的通信高效联邦学习</h2><a id="user-content-参与人数自适应的通信高效联邦学习" class="anchor" aria-label="Permalink: 参与人数自适应的通信高效联邦学习" href="#参与人数自适应的通信高效联邦学习"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.13803v1 公告类型：新成果<br>
摘要：深度学习模型的快速扩展虽在多领域实现了性能提升，却也带来了诸多挑战。联邦学习（FL）作为一种通过分布式训练应对这些问题的框架应运而生。然而通信效率仍是FL的关键瓶颈，尤其在异构且动态的客户端参与环境下。现有方法如FedAvg、FedProx或客户端选择策略试图降低通信成本，但如何确定每轮训练的客户端数量仍属深度未探索领域。我们提出智能参与者选择机制（ISP），这种自适应方法能动态确定每轮最优客户端数量，在保证模型精度的同时提升通信效率。通过在视觉Transformer、真实世界心电图分类及梯度压缩训练等多样化场景中的验证，ISP可稳定节省高达30%的通信开销且不损失最终质量。将ISP应用于不同现实心电图分类场景时，客户端数量的选择凸显出作为联邦学习中独立任务的重要性。</p>
<div class="markdown-heading"><h2 class="heading-element">ASDFormer：一种集成池化分类器专家机制的Transformer模型，用于稳健的自闭症诊断与生物标志物发现</h2><a id="user-content-asdformer一种集成池化分类器专家机制的transformer模型用于稳健的自闭症诊断与生物标志物发现" class="anchor" aria-label="Permalink: ASDFormer：一种集成池化分类器专家机制的Transformer模型，用于稳健的自闭症诊断与生物标志物发现" href="#asdformer一种集成池化分类器专家机制的transformer模型用于稳健的自闭症诊断与生物标志物发现"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.14005v1 公告类型：新研究<br>
摘要：自闭症谱系障碍（ASD）是一种复杂的神经发育状况，以大脑连接性异常为特征。功能磁共振成像（fMRI）通过测量全脑血氧水平依赖（BOLD）信号，为大规模神经动力学提供了无创观测窗口。这些信号可建模为感兴趣区域（ROIs）间的相互作用，这些区域根据其在大脑功能中的基础作用被分组为功能社区。新近证据表明，这些社区内部及社区间的连接模式对ASD相关改变尤为敏感。有效捕捉这些模式并识别偏离典型发育轨道的相互作用，对于改进ASD诊断和实现生物标志物发现至关重要。本研究提出ASDFormer——一种基于Transformer的架构，融合混合池化-分类专家系统（MoE）来捕获ASD相关的神经特征。通过将多个专业化专家分支与注意力机制相结合，ASDFormer能自适应地强化与自闭症相关的不同脑区及连接模式，既提升了分类性能，又实现了更具可解释性的疾病相关生物标志物识别。在ABIDE数据集上的应用表明，ASDFormer实现了最先进的诊断精度，并揭示了与ASD相关的功能连接中断的重要发现，凸显其作为生物标志物发现工具的潜力。</p>
</div></div><div class="footer container-xl width-full p-responsive"><div class="position-relative flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between pt-4 pb-4 mt-6 f6 color-text-secondary border-top color-border-secondary text-center"><div class="footer-octicon d-lg-block mx-lg-4"><a title="LLIKKE/Arxiv_GPT_Assistant" href="https://github.com/LLIKKE/Arxiv_GPT_Assistant" target="_blank" rel="noreferrer noopener"><svg class="octicon octicon-mark-github gh-logo" width="36" height="36" viewBox="0 0 98 98" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"></path></svg></a></div><span class="mt-2 d-block footprint"><span>powered by </span><a href="https://github.com/wranders/markdown-to-pages-action" target="_blank" rel="noreferrer noopener">markdown-to-pages-action</a></span></div></div></body></html>