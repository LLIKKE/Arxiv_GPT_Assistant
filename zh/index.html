<!DOCTYPE html><html data-color-mode="light" data-light-theme="light" data-dark-theme="dark" lang="en-US"><head><title>LLIKKE/Arxiv_GPT_Assistant</title><meta charset="utf-8"><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="description" content="Deepseek based personalized ArXiv paper assistant bot"><link rel="canonical" href="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta property="og:type" content="website"><meta property="og:url" content="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:description" content="Deepseek based personalized ArXiv paper assistant bot"><meta property="og:locale" content="en_US"><meta property="og:site_name" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:description" content="Deepseek based personalized ArXiv paper assistant bot"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon.png" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon.svg" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon-dark.png" media="(prefers-color-scheme: dark)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon-dark.svg" media="(prefers-color-scheme: dark)"><link rel="mask-icon" href="https://github.githubassets.com/pinned-octocat.svg" color="#000000"><link href="index.css" rel="stylesheet"></head><body><div class="container-lg px-3 my-5 markdown-body"><div class="position-relative"><span class="profile-color-modes-toggle js-promo-color-modes-toggle" tabindex="0" aria-label="Toggle dark mode" aria-checked="true" role="checkbox"><div class="profile-color-modes-toggle-track" div></div><div class="profile-color-modes-toggle-thumb"><svg style="fill: var(--color-scale-yellow-0); margin: 7px 0 0 7px;" aria-hidden="true" width="14" height="13" viewBox="0 0 14 13" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.52208 7.71754C7.5782 7.71754 10.0557 5.24006 10.0557 2.18394C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961C9.95801 1.07727 10.3495 0.771159 10.6474 0.99992C12.1153 2.12716 13.0615 3.89999 13.0615 5.89383C13.0615 9.29958 10.3006 12.0605 6.89485 12.0605C3.95334 12.0605 1.49286 10.001 0.876728 7.24527C0.794841 6.87902 1.23668 6.65289 1.55321 6.85451C2.41106 7.40095 3.4296 7.71754 4.52208 7.71754Z"></path></svg></div></span></div><script type="text/javascript">(function() {
  var MODE_KEY = 'markdown_to_pages_dark_mode';
  function toggleMode() {
    var mode = document.documentElement.getAttribute('data-color-mode') === 'light' ? 'dark' : 'light';
    document.documentElement.setAttribute('data-color-mode', mode);
    localStorage.setItem(MODE_KEY, mode);
  }
  var mode = localStorage.getItem(MODE_KEY);
  if (mode == null) {
    var query = window.matchMedia('(prefers-color-scheme: dark)');
    mode = query.matches ? 'dark' : 'light';
  }
  document.documentElement.setAttribute('data-color-mode', mode);
  document.querySelector('.profile-color-modes-toggle').onclick = toggleMode;
})();</script><div><div class="markdown-heading"><h2 class="heading-element">PRIOT：面向嵌入式系统的基于剪枝的纯整数迁移学习</h2><a id="user-content-priot面向嵌入式系统的基于剪枝的纯整数迁移学习" class="anchor" aria-label="Permalink: PRIOT：面向嵌入式系统的基于剪枝的纯整数迁移学习" href="#priot面向嵌入式系统的基于剪枝的纯整数迁移学习"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2503.16860v1 公告类型：新研究<br>
摘要：设备端迁移学习对于将通用主干模型适配至各边缘设备的独特环境至关重要。树莓派Pico等微型微控制器是设备端学习的关键目标平台，但其通常缺少浮点运算单元，必须依赖纯整数训练。现有研究采用的动态量化比例因子计算方法会产生高昂计算开销。为此，本研究聚焦于采用静态比例因子的纯整数训练——这对现有训练方法构成严峻挑战。我们提出名为PRIOT的新型训练方法，通过修剪选定连接而非更新权重来优化网络，从而实现静态比例因子下的有效训练。修剪模式由边缘弹出算法确定：该算法训练分配给每条连接的"分数"参数（而非原始参数），并在推理前剪除低分连接。此外，我们推出内存优化版本PRIOT-S，仅对少量连接分配分数参数。我们在树莓派Pico上实现了PRIOT与PRIOT-S，使用微型CNN模型（旋转MNIST数据集）和VGG11模型（旋转CIFAR-10数据集）评估其精度与计算成本。实验表明：PRIOT相较现有方法精度提升8.08至33.75个百分点，而PRIOT-S在几乎不损失精度的情况下显著降低了内存占用。</p>
<p>（翻译说明：</p>
<ol>
<li>专业术语处理："edge-popup algorithm"译为"边缘弹出算法"保持技术一致性</li>
<li>被动语态转换：将"is determined by"等被动结构转为"由...确定"的主动表达</li>
<li>长句拆分：将原文复合句按中文习惯分解为多个短句，如方法描述部分</li>
<li>数据呈现优化：百分比数字保留原文精确值，增加"个百分点"符合中文计量规范</li>
<li>技术概念显化："score"译为带引号的"分数"参数以突出其特殊含义</li>
<li>逻辑连接显性化：添加"为此"等连接词增强段落连贯性）</li>
</ol>
<div class="markdown-heading"><h2 class="heading-element">利用2:4激活稀疏性加速Transformer推理与训练</h2><a id="user-content-利用24激活稀疏性加速transformer推理与训练" class="anchor" aria-label="Permalink: 利用2:4激活稀疏性加速Transformer推理与训练" href="#利用24激活稀疏性加速transformer推理与训练"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2503.16672v1 公告类型：新论文<br>
摘要：本文展示了如何利用2:4稀疏性（一种受GPU硬件加速支持的流行稀疏模式）来优化激活函数，从而加速大语言模型的训练与推理。我们关键性地挖掘了Squared-ReLU激活函数中固有的稀疏特性，在不损失模型精度的前提下实现加速。该方法在前向传播和反向传播中使前馈神经网络（FFN）速度提升最高达1.3倍。这项研究揭示了稀疏性在加速大语言模型训练与推理中的关键潜力。</p>
<p>（注：根据学术文献翻译规范，对部分术语进行了标准化处理：</p>
<ol>
<li>"2:4 sparsity"译为"2:4稀疏性"（保留技术参数比例）</li>
<li>"Squared-ReLU"保持英文形式（专有激活函数名称）</li>
<li>"Feed Forward Network"译为"前馈神经网络"并保留缩写FFN</li>
<li>"forwards and backwards pass"译为"前向传播和反向传播"（深度学习标准术语）</li>
<li>被动语态转为中文主动表述（如"we exploit..."译为"我们挖掘..."））</li>
</ol>
<div class="markdown-heading"><h2 class="heading-element">大型语言模型通过嵌套式激活感知分解进行压缩</h2><a id="user-content-大型语言模型通过嵌套式激活感知分解进行压缩" class="anchor" aria-label="Permalink: 大型语言模型通过嵌套式激活感知分解进行压缩" href="#大型语言模型通过嵌套式激活感知分解进行压缩"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2503.17101v1 公告类型：新研究<br>
摘要：本文针对大型语言模型（LLMs）压缩这一关键挑战展开研究，旨在促进其实际部署与广泛应用。我们提出了一种新颖的训练后压缩范式，其核心在于对LLM权重进行低秩分解。通过分析，我们揭示了该任务面临的两大主要挑战：LLM激活分布的显著差异性，以及处理来自不同数据集和模型的未见激活模式的困难。</p>
<p>为解决这些问题，我们创新性地设计了嵌套式激活感知框架（NSVD）。这一免训练方法通过根据激活分布和原始权重矩阵变换权重矩阵，有效管理激活异常值，从而提升低秩分解的精度。该技术能将异常值吸收至变换后的权重矩阵中，显著改善分解效果。我们在涵盖三大LLM家族的六个模型、八个数据集上的全面评估表明，NSVD在中高压缩比场景或多语言、多任务环境下，性能显著优于当前最先进方法。</p>
<p>（注：根据学术论文摘要的文体特点，译文在保持专业性的同时：</p>
<ol>
<li>将"post-training compression paradigm"译为"训练后压缩范式"以突出技术阶段特性</li>
<li>采用"嵌套式激活感知框架"既保留NSVD首字母缩写又体现架构特征</li>
<li>"activation outliers"译为"激活异常值"符合机器学习领域术语惯例</li>
<li>通过"显著差异性""免训练方法"等措辞保持学术文本的严谨性与简洁性）</li>
</ol>
</div></div><div class="footer container-xl width-full p-responsive"><div class="position-relative flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between pt-4 pb-4 mt-6 f6 color-text-secondary border-top color-border-secondary text-center"><div class="footer-octicon d-lg-block mx-lg-4"><a title="LLIKKE/Arxiv_GPT_Assistant" href="https://github.com/LLIKKE/Arxiv_GPT_Assistant" target="_blank" rel="noreferrer noopener"><svg class="octicon octicon-mark-github gh-logo" width="36" height="36" viewBox="0 0 98 98" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"></path></svg></a></div><span class="mt-2 d-block footprint"><span>powered by </span><a href="https://github.com/wranders/markdown-to-pages-action" target="_blank" rel="noreferrer noopener">markdown-to-pages-action</a></span></div></div></body></html>