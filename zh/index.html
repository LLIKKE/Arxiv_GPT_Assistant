<!DOCTYPE html><html data-color-mode="light" data-light-theme="light" data-dark-theme="dark" lang="en-US"><head><title>LLIKKE/Arxiv_GPT_Assistant</title><meta charset="utf-8"><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="description" content="Deepseek based personalized ArXiv paper assistant bot"><link rel="canonical" href="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta property="og:type" content="website"><meta property="og:url" content="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:description" content="Deepseek based personalized ArXiv paper assistant bot"><meta property="og:locale" content="en_US"><meta property="og:site_name" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:description" content="Deepseek based personalized ArXiv paper assistant bot"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon.png" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon.svg" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon-dark.png" media="(prefers-color-scheme: dark)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon-dark.svg" media="(prefers-color-scheme: dark)"><link rel="mask-icon" href="https://github.githubassets.com/pinned-octocat.svg" color="#000000"><link href="index.css" rel="stylesheet"></head><body><div class="container-lg px-3 my-5 markdown-body"><div class="position-relative"><span class="profile-color-modes-toggle js-promo-color-modes-toggle" tabindex="0" aria-label="Toggle dark mode" aria-checked="true" role="checkbox"><div class="profile-color-modes-toggle-track" div></div><div class="profile-color-modes-toggle-thumb"><svg style="fill: var(--color-scale-yellow-0); margin: 7px 0 0 7px;" aria-hidden="true" width="14" height="13" viewBox="0 0 14 13" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.52208 7.71754C7.5782 7.71754 10.0557 5.24006 10.0557 2.18394C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961C9.95801 1.07727 10.3495 0.771159 10.6474 0.99992C12.1153 2.12716 13.0615 3.89999 13.0615 5.89383C13.0615 9.29958 10.3006 12.0605 6.89485 12.0605C3.95334 12.0605 1.49286 10.001 0.876728 7.24527C0.794841 6.87902 1.23668 6.65289 1.55321 6.85451C2.41106 7.40095 3.4296 7.71754 4.52208 7.71754Z"></path></svg></div></span></div><script type="text/javascript">(function() {
  var MODE_KEY = 'markdown_to_pages_dark_mode';
  function toggleMode() {
    var mode = document.documentElement.getAttribute('data-color-mode') === 'light' ? 'dark' : 'light';
    document.documentElement.setAttribute('data-color-mode', mode);
    localStorage.setItem(MODE_KEY, mode);
  }
  var mode = localStorage.getItem(MODE_KEY);
  if (mode == null) {
    var query = window.matchMedia('(prefers-color-scheme: dark)');
    mode = query.matches ? 'dark' : 'light';
  }
  document.documentElement.setAttribute('data-color-mode', mode);
  document.querySelector('.profile-color-modes-toggle').onclick = toggleMode;
})();</script><div><div class="markdown-heading"><h2 class="heading-element">块状稀疏模型的高效训练算法</h2><a id="user-content-块状稀疏模型的高效训练算法" class="anchor" aria-label="Permalink: 块状稀疏模型的高效训练算法" href="#块状稀疏模型的高效训练算法"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2503.21928v1 公告类型：新研究<br>
摘要：大规模机器学习（ML）模型正日益广泛应用于教育、信贷、招聘、医疗、刑事司法等关键领域。然而，这些模型的训练、部署和应用需要消耗大量计算资源。为降低计算与内存成本，学术界广泛采用具有稀疏权重矩阵的机器学习模型。在各类稀疏模型中，具有特殊稀疏结构（如块状稀疏权重矩阵）的模型能更好地适配硬件加速器，从而减少推理过程中的内存与计算开销。遗憾的是，尽管现有多种高效训练方法，但均未针对块状稀疏模型的高效训练进行专门设计。因此，当前训练这类模型的方法仍始于完整稠密模型，导致训练效率低下。</p>
<p>本研究聚焦于训练具有\textit{块状稀疏矩阵}的模型，提出一种高效训练算法以同步降低训练和推理阶段的计算与内存成本。此外，我们将证明所提方法能在训练过程中智能确定最佳稀疏模式的块尺寸。大量实证与理论分析表明，相较于基线方法，我们的算法可显著降低计算与内存开销，同时保持模型性能无衰减。</p>
<div class="markdown-heading"><h2 class="heading-element">STADE：以标准差作为剪枝度量标准</h2><a id="user-content-stade以标准差作为剪枝度量标准" class="anchor" aria-label="Permalink: STADE：以标准差作为剪枝度量标准" href="#stade以标准差作为剪枝度量标准"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2503.22451v1 公告类型：新研究<br>
摘要：近年来，大语言模型（LLMs）的应用日益广泛，被用于解决各类任务。为成功应对这些任务，LLMs需要更长的训练时间和更大的模型规模。这使得LLMs成为剪枝方法的理想对象——在保持性能的同时降低计算需求。传统方法在剪枝后需通过重训练阶段来维持原始模型性能，但当前最先进的剪枝方法（如Wanda）无需重训练即可完成剪枝，使过程更快速高效。本研究基于Wanda的工作，从理论上阐释了该方法的有效性，并利用这些洞见优化剪枝流程。具体而言，通过对剪枝问题的理论分析，我们揭示了Wanda作为最优剪枝方法的常见机器学习场景。进一步分析发现，当Wanda不再最优时，基于输入标准差的新方法STADE应运而生。理论研究表明，STADE在不同场景下具有更优的泛化性。最后，在Llama和开源预训练变换模型（OPT）上的大量实验验证了理论预测：根据训练条件的不同，Wanda的最优性能会如理论框架预期般变化。这些发现为剪枝策略及其实际应用提供了更坚实的理论基础。代码已开源：<a href="https://github.com/Coello-dev/STADE/">https://github.com/Coello-dev/STADE/</a></p>
<p>（注：根据学术文献翻译规范，对部分术语进行了统一处理，如"retraining phase"译为"重训练阶段"而非字面的"再训练阶段"；"standard deviation"采用统计学通用译法"标准差"；模型名称Wanda/STADE保留不译以符合技术文献惯例；长句按中文表达习惯拆分为短句，并调整了被动语态为主动表述。）</p>
<div class="markdown-heading"><h2 class="heading-element">AdaRank：自适应等级剪枝以增强模型融合</h2><a id="user-content-adarank自适应等级剪枝以增强模型融合" class="anchor" aria-label="Permalink: AdaRank：自适应等级剪枝以增强模型融合" href="#adarank自适应等级剪枝以增强模型融合"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2503.22178v1 公告类型：新研究<br>
摘要：模型融合已成为将独立微调模型统一为集成框架的重要方法，显著提升了多任务学习中的计算效率。近期基于奇异值分解（SVD）的技术通过利用低秩结构增强融合效果，但其依赖人工设计的秩选择常导致跨任务干扰和次优性能。本文提出AdaRank——一种自适应选择任务向量最有效奇异方向的新型模型融合框架。我们通过实验证明：任务向量的主导奇异成分会引发关键性任务干扰，而跨任务与跨层的简单截断会损害性能。相比之下，AdaRank通过熵最小化在测试时动态剪枝干扰性奇异成分，并为每个任务向量提供最优信息量。分析表明该方法能有效缓解任务间的有害重叠，实证结果显示AdaRank在不同骨干网络和任务数量下均保持最先进性能，将微调模型间的性能差距缩小至近1%。</p>
<p>（注：根据学术文献翻译规范，对部分术语进行了如下处理：</p>
<ol>
<li>"SVD-based techniques"译为"基于奇异值分解的技术"以保持专业术语准确性</li>
<li>"task vectors"统一译为"任务向量"确保概念一致性</li>
<li>"entropy minimization"译为"熵最小化"符合信息论术语惯例</li>
<li>长难句采用分译法处理，如将原文最后复合句拆分为"分析表明..."和"实证结果显示..."两个独立句，符合中文表达习惯）</li>
</ol>
</div></div><div class="footer container-xl width-full p-responsive"><div class="position-relative flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between pt-4 pb-4 mt-6 f6 color-text-secondary border-top color-border-secondary text-center"><div class="footer-octicon d-lg-block mx-lg-4"><a title="LLIKKE/Arxiv_GPT_Assistant" href="https://github.com/LLIKKE/Arxiv_GPT_Assistant" target="_blank" rel="noreferrer noopener"><svg class="octicon octicon-mark-github gh-logo" width="36" height="36" viewBox="0 0 98 98" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"></path></svg></a></div><span class="mt-2 d-block footprint"><span>powered by </span><a href="https://github.com/wranders/markdown-to-pages-action" target="_blank" rel="noreferrer noopener">markdown-to-pages-action</a></span></div></div></body></html>