<!DOCTYPE html><html data-color-mode="light" data-light-theme="light" data-dark-theme="dark" lang="en-US"><head><title>LLIKKE/Arxiv_GPT_Assistant</title><meta charset="utf-8"><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="description" content="Deepseek based personalized ArXiv paper assistant bot"><link rel="canonical" href="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta property="og:type" content="website"><meta property="og:url" content="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:description" content="Deepseek based personalized ArXiv paper assistant bot"><meta property="og:locale" content="en_US"><meta property="og:site_name" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:description" content="Deepseek based personalized ArXiv paper assistant bot"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon.png" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon.svg" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon-dark.png" media="(prefers-color-scheme: dark)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon-dark.svg" media="(prefers-color-scheme: dark)"><link rel="mask-icon" href="https://github.githubassets.com/pinned-octocat.svg" color="#000000"><link href="index.css" rel="stylesheet"></head><body><div class="container-lg px-3 my-5 markdown-body"><div class="position-relative"><span class="profile-color-modes-toggle js-promo-color-modes-toggle" tabindex="0" aria-label="Toggle dark mode" aria-checked="true" role="checkbox"><div class="profile-color-modes-toggle-track" div></div><div class="profile-color-modes-toggle-thumb"><svg style="fill: var(--color-scale-yellow-0); margin: 7px 0 0 7px;" aria-hidden="true" width="14" height="13" viewBox="0 0 14 13" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.52208 7.71754C7.5782 7.71754 10.0557 5.24006 10.0557 2.18394C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961C9.95801 1.07727 10.3495 0.771159 10.6474 0.99992C12.1153 2.12716 13.0615 3.89999 13.0615 5.89383C13.0615 9.29958 10.3006 12.0605 6.89485 12.0605C3.95334 12.0605 1.49286 10.001 0.876728 7.24527C0.794841 6.87902 1.23668 6.65289 1.55321 6.85451C2.41106 7.40095 3.4296 7.71754 4.52208 7.71754Z"></path></svg></div></span></div><script type="text/javascript">(function() {
  var MODE_KEY = 'markdown_to_pages_dark_mode';
  function toggleMode() {
    var mode = document.documentElement.getAttribute('data-color-mode') === 'light' ? 'dark' : 'light';
    document.documentElement.setAttribute('data-color-mode', mode);
    localStorage.setItem(MODE_KEY, mode);
  }
  var mode = localStorage.getItem(MODE_KEY);
  if (mode == null) {
    var query = window.matchMedia('(prefers-color-scheme: dark)');
    mode = query.matches ? 'dark' : 'light';
  }
  document.documentElement.setAttribute('data-color-mode', mode);
  document.querySelector('.profile-color-modes-toggle').onclick = toggleMode;
})();</script><div><div class="markdown-heading"><h2 class="heading-element">尽管可行，未必应当：利用大语言模型进行数据拟合的反思</h2><a id="user-content-尽管可行未必应当利用大语言模型进行数据拟合的反思" class="anchor" aria-label="Permalink: 尽管可行，未必应当：利用大语言模型进行数据拟合的反思" href="#尽管可行未必应当利用大语言模型进行数据拟合的反思"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.19563v1 公告类型：新研究<br>
摘要：大语言模型（LLM）正被应用于各种场景，远超典型的语言导向用例。尤其值得注意的是，LLM越来越多地被用作即插即用的数据拟合与预测生成工具。已有研究表明，通过上下文学习或监督微调，LLM在预测性能上可与许多表格监督学习技术相媲美。然而，我们发现LLM用于数据拟合存在一个关键脆弱性——对数据表征进行与底层学习任务完全无关的改动，会显著改变LLM对相同数据的预测结果。例如在某些场景中，仅更改变量名称就可使预测误差波动高达82%。这种针对任务无关变动的预测敏感性，同时存在于上下文学习和监督微调两种模式下，且对闭源和开源通用大语言模型均有影响。通过分析开源LLM的注意力分数，我们发现了一种非均匀注意力模式：恰好占据提示文本特定位置的训练样本及变量名称/数值在生成输出标记时会获得更多关注，尽管理论上不同位置本应获得近似均衡的注意力。这在一定程度上解释了任务无关变动引发敏感性的原因。我们还测试了专为数据拟合训练的最先进表格基础模型（TabPFN）。尽管该模型明确设计了预测鲁棒性目标，但仍无法完全免疫于任务无关变动的影响。总体而言，尽管LLM具有令人印象深刻的预测能力，但目前其缺乏作为规范化数据拟合工具所需的最基本鲁棒性。</p>
<div class="markdown-heading"><h2 class="heading-element">基于梯度估计的上下文学习中线性时间演示选择</h2><a id="user-content-基于梯度估计的上下文学习中线性时间演示选择" class="anchor" aria-label="Permalink: 基于梯度估计的上下文学习中线性时间演示选择" href="#基于梯度估计的上下文学习中线性时间演示选择"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.19999v1 公告类型：新成果<br>
摘要：本文提出一种针对查询集进行上下文学习的示例选择算法。给定包含$n$个示例的集合，如何快速选取其中$k$个最优样本作为下游推理的条件？该问题在提示调优和思维链推理中具有广泛应用。由于上下文学习过程中模型权重固定不变，前人研究主要基于词嵌入相似度设计选择方法。本研究创新性地提出基于输入嵌入空间中输出梯度的新方案：通过梯度计算实现输出值的一阶近似估计，将此估计应用于多个随机采样子集，最终聚合采样结果形成每个示例的影响力评分，并选取$k$个最相关样本。该方法仅需预先计算一次模型输出和梯度，其时间复杂度与模型及训练集规模呈线性关系。在多模型和多数据集上的大量实验验证了本方案的高效性——梯度估计程序在六个数据集上实现误差小于$\mathbf{1}%$的完整推理近似，使得子集选择效率较完整推理提升最高达$\mathbf{37.7}$倍（适用于参数量达340亿的模型），并较基于输入嵌入的现有选择方法平均提升$\mathbf{11}%$的性能表现。</p>
<div class="markdown-heading"><h2 class="heading-element">快速三维扩散实现可扩展颗粒介质合成</h2><a id="user-content-快速三维扩散实现可扩展颗粒介质合成" class="anchor" aria-label="Permalink: 快速三维扩散实现可扩展颗粒介质合成" href="#快速三维扩散实现可扩展颗粒介质合成"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.19752v1 公告类型：新研究<br>
摘要：使用离散元法模拟颗粒介质是一项计算密集型任务。在初始化阶段尤其如此，由于涉及大位移及相关动能，该阶段占据了总模拟时间的主导地位。我们通过基于3D扩散模型的新型生成流程突破了这一瓶颈，能够直接合成任意规模、具有最终物理真实构型的颗粒集合体。该方法将问题构建为3D生成建模任务，采用两阶段流程：首先训练扩散模型生成代表颗粒介质的独立3D体素网格；其次采用基于掩码输入从2D修复技术适配的3D修复模型，将这些网格无缝拼接，实现具有物理真实结构的大样本合成。该修复模型通过训练网络从噪声张量、掩码和掩码张量组成的输入通道推断体素网格缺失部分，探索了多种底层UNet输入的掩码策略。模型还适配了2D重绘技术，将噪声调度器输出与真实数据重新注入，为3D模型提供强引导。结合加权损失函数，这一机制确保了掩码区域生成长程连贯性。两个模型均在从小规模DEM模拟提取的相同二值化3D占据网格上训练，实现了计算时间随样本大小的线性缩放。量化数据显示，合成相当于3小时DEM模拟的1.2米长有砟轨道仅需20秒以内。生成的体素网格还可后处理提取颗粒几何形态以保持DEM兼容性，为工业应用提供物理连贯、实时可扩展的颗粒介质合成方案。</p>
<div class="markdown-heading"><h2 class="heading-element">利用张量分解参数化高效生成多维热量计数据</h2><a id="user-content-利用张量分解参数化高效生成多维热量计数据" class="anchor" aria-label="Permalink: 利用张量分解参数化高效生成多维热量计数据" href="#利用张量分解参数化高效生成多维热量计数据"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.19443v1 公告类型：新成果<br>
摘要：生成大型复杂仿真数据集通常是一项耗时且资源密集的任务。尤其在实验成本极高的情况下，采用合成数据支持下游任务正成为更合理的选择。近期相关方法可能涉及使用生成对抗网络或扩散模型等生成式机器学习模型。随着这些生成模型在产出有效数据方面效率不断提升，我们进一步将内部张量分解技术引入生成模型以进一步降低成本。具体而言，针对多维数据（即张量），我们通过生成较小的张量因子而非完整张量，显著缩减模型输出量和总体参数规模。这种方法有效降低了生成复杂仿真数据的成本，实验表明生成数据仍保持实用性。由此可见，张量分解技术有望提升生成模型效率，特别是在生成多维数据（张量）时表现尤为突出。</p>
<div class="markdown-heading"><h2 class="heading-element">FARM：基于物理的高动态人形控制中的帧加速增强与残差专家混合策略</h2><a id="user-content-farm基于物理的高动态人形控制中的帧加速增强与残差专家混合策略" class="anchor" aria-label="Permalink: FARM：基于物理的高动态人形控制中的帧加速增强与残差专家混合策略" href="#farm基于物理的高动态人形控制中的帧加速增强与残差专家混合策略"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.19926v1 公告类型：新成果<br>
摘要：统一基于物理的人形控制器对机器人技术和角色动画至关重要，但擅长处理温和日常动作的模型在爆发性动作上仍存在困难，阻碍了实际应用。我们通过FARM（帧加速增强与残差专家混合）框架填补这一空白，该端到端系统包含帧加速增强、鲁棒的基础控制器和残差专家混合模块（MoE）。帧加速增强通过扩大帧间间隔使模型接触高速姿态变化，基础控制器可靠跟踪日常低动态运动，而残差MoE自适应分配额外网络容量处理高动态动作，显著提升跟踪精度。针对公开基准数据的缺失，我们策划了包含3593个物理合理片段的高动态人形运动（HDHM）数据集。在HDHM测试中，FARM相比基线模型将跟踪失败率降低42.8%，全局关节平均位置误差减少14.6%，同时保持对低动态动作的近完美精度。这些成果确立了FARM作为高动态人形控制的新基准，并首次为此挑战推出开放基准测试平台。代码与数据集将在<a href="https://github.com/Colin-Jing/FARM">https://github.com/Colin-Jing/FARM</a> 发布。</p>
<div class="markdown-heading"><h2 class="heading-element">Bi-LoRA：面向大规模模型微调的高效锐度感知最小化方法</h2><a id="user-content-bi-lora面向大规模模型微调的高效锐度感知最小化方法" class="anchor" aria-label="Permalink: Bi-LoRA：面向大规模模型微调的高效锐度感知最小化方法" href="#bi-lora面向大规模模型微调的高效锐度感知最小化方法"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>（注：Bi-LoRA可保留不译，因其为专有技术名称。译文采用技术文献常用表达方式，将"Efficient Sharpness-Aware Minimization"译为"高效锐度感知最小化"，符合计算机领域术语规范。"Fine-Tuning Large-Scale Models"采用动宾结构译为"面向大规模模型微调"，使技术指向性更明确。）</p>
<p>arXiv:2508.19564v1 公告类型：新研究<br>
摘要：在有限数据条件下微调大规模预训练模型对泛化能力提出了重大挑战。虽然锐度感知最小化（SAM）通过寻找平坦最小值被证明能有效提升泛化性能，但其巨大的额外内存和计算开销使其难以应用于大型模型。将SAM与参数高效微调方法（如低秩自适应LoRA）相结合是一个前景广阔的方向。然而，我们发现直接将SAM应用于LoRA参数会将锐度优化限制在有限子空间内，影响其有效性。为解决这一局限，我们提出双向低秩自适应（Bi-LoRA），通过引入辅助LoRA模块来建模SAM的对抗性权重扰动。该设计将SAM的权重扰动与LoRA优化解耦：主LoRA模块通过标准梯度下降适应具体任务，而辅助模块通过梯度上升捕捉损失景观的锐度。这种双模块设计使Bi-LoRA能捕获更广泛的锐度以实现更平坦的最小值，同时保持内存效率。另一重要优势是双模块设计支持同步进行优化和扰动，消除了SAM的双倍训练成本。跨多种任务和架构的大规模实验证明了Bi-LoRA在提升泛化能力方面的效率与有效性。</p>
<div class="markdown-heading"><h2 class="heading-element">SCAR：多模态数据集的特征描述方案</h2><a id="user-content-scar多模态数据集的特征描述方案" class="anchor" aria-label="Permalink: SCAR：多模态数据集的特征描述方案" href="#scar多模态数据集的特征描述方案"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.19659v1 公告类型：新研究<br>
摘要：基础模型在多样化任务中展现出卓越的泛化能力，这主要得益于其训练数据的特性。近期以数据为中心的方法（如剪枝和压缩）虽能优化训练过程，但关于数据属性如何影响泛化能力（尤其是样本扩展中的数据特征）的理论认知仍显不足。传统视角过度聚焦于数据量和训练效率，往往忽视数据质量的结构性维度，进一步制约了该领域的进展。本研究提出SCAR框架——一种通过规模（Scale）、覆盖度（Coverage）、真实性（Authenticity）和丰富度（Richness）四个核心指标系统化表征数据集内在结构特性的原理性方案。与先前以数据为中心的度量方法不同，SCAR能捕捉数据集扩展过程中保持稳定的本质特征，为数据理解提供稳健的通用基础。基于这些结构特性，我们提出"基础数据"（Foundation Data）概念：即无需模型特定重训练即可保持完整数据集泛化行为的最小数据子集。通过将单模态任务建模为阶跃函数，我们估算了基础数据规模的分布规律，以捕捉目标多模态数据集中跨模态的阶梯式泛化偏差。最终，我们基于该泛化偏差开发了SCAR指导的数据补全策略，可实现多模态数据集中模态特定特征的高效、感知模态类型的扩展。在多模态数据集和模型架构上的实验验证了SCAR在预测数据效用和指导数据获取方面的有效性。代码已开源：<a href="https://github.com/McAloma/SCAR%E3%80%82">https://github.com/McAloma/SCAR。</a></p>
<p>（注：翻译过程中对专业术语进行了统一处理，如"pruning"译作"剪枝"，"modality"译作"模态"，并采用学术论文常见的四字结构（规模、覆盖度等）保持术语一致性。长难句按中文表达习惯进行了拆分重组，同时保留了原文的技术严谨性。）</p>
<div class="markdown-heading"><h2 class="heading-element">大语言模型后门防御的剪枝策略</h2><a id="user-content-大语言模型后门防御的剪枝策略" class="anchor" aria-label="Permalink: 大语言模型后门防御的剪枝策略" href="#大语言模型后门防御的剪枝策略"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.20032v1 公告类型：新研究<br>
摘要：后门攻击对预训练语言模型的性能与完整性构成重大威胁。尽管这类模型通常会针对下游NLP任务进行微调，但最新研究表明，它们仍难以抵御能够经受常规微调的后门攻击。由于终端用户通常不了解攻击触发器，此类防御尤为困难。这类攻击通过隐蔽的句法或风格操控植入恶意触发器，可绕过传统检测手段长期潜伏于模型中，使得事后净化变得至关重要。本研究探索了在不知晓攻击触发器且无清洁参考模型的情况下，能否通过注意力头剪枝来缓解此类威胁。为此，我们设计并实现了六种剪枝策略：（i）基于梯度的剪枝；（ii）分层方差剪枝；（iii）结合L1/L2结构化稀疏化的梯度剪枝；（iv）随机集成剪枝；（v）强化学习引导剪枝；（vi）贝叶斯不确定性剪枝。每种方法在迭代移除信息量最低的注意力头时，均通过验证准确率监控以避免过度剪枝。实验评估表明：基于梯度的剪枝在防御句法触发器时表现最佳，而强化学习与贝叶斯剪枝能更有效抵御风格化攻击。</p>
<div class="markdown-heading"><h2 class="heading-element">神经网络组件的无损压缩：低精度格式下的权重、检查点与键值缓存</h2><a id="user-content-神经网络组件的无损压缩低精度格式下的权重检查点与键值缓存" class="anchor" aria-label="Permalink: 神经网络组件的无损压缩：低精度格式下的权重、检查点与键值缓存" href="#神经网络组件的无损压缩低精度格式下的权重检查点与键值缓存"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.19263v1 公告类型：新成果<br>
摘要：随着深度学习模型的不断扩展及其应用部署的日益广泛，降低神经网络权重的存储与传输成本变得愈发重要。尽管先前的研究（如ZipNN）已证明无损压缩方法——特别是基于霍夫曼编码浮点数指数的技术——能显著减小模型体积，但这些方法主要应用于较高精度的格式（如FP32和BF16）。本研究将ZipNN方法扩展至低精度浮点格式（尤其是当前高效推理中日益流行的FP8和FP4），设计出一种通过熵编码分别压缩指数和尾数分量的压缩方案。评估显示，该方法在BF16格式上实现最高62%的压缩率，在FP8格式上达到83%。我们还探究了大语言模型（LLM）中键值（K/V）缓存张量的可压缩性，发现其同样存在可压缩模式，可在部署过程中实现内存优化。</p>
<div class="markdown-heading"><h2 class="heading-element">交响曲：一个去中心化的多智能体框架，旨在实现可扩展的集体智能</h2><a id="user-content-交响曲一个去中心化的多智能体框架旨在实现可扩展的集体智能" class="anchor" aria-label="Permalink: 交响曲：一个去中心化的多智能体框架，旨在实现可扩展的集体智能" href="#交响曲一个去中心化的多智能体框架旨在实现可扩展的集体智能"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.20019v1 公告类型：新研究<br>
摘要：现有基于大语言模型（LLM）的智能体框架多采用中心化编排机制，存在部署成本高、通信拓扑僵化及适应性有限等问题。为应对这些挑战，我们推出Symphony——一个去中心化的多智能体系统，使消费级GPU上的轻量级LLM能够协同工作。该系统引入三大核心机制：（1）记录智能体能力的分布式账本；（2）实现动态任务分配的Beacon选择协议；（3）基于思维链（CoT）的加权结果投票机制。该设计形成了低开销、隐私保护性强、可扩展且容错性高的编排体系。实证表明，Symphony在推理基准测试中优于现有基线模型，显著提升准确率，并在不同规模的模型间展现出强劲的鲁棒性。</p>
<div class="markdown-heading"><h2 class="heading-element">通过模型合并实现高效多源知识迁移</h2><a id="user-content-通过模型合并实现高效多源知识迁移" class="anchor" aria-label="Permalink: 通过模型合并实现高效多源知识迁移" href="#通过模型合并实现高效多源知识迁移"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.19353v1 公告类型：新成果<br>
摘要：尽管迁移学习是一种优势策略，但它忽略了利用线上众多可用模型知识的机会。解决这一多源迁移学习问题是提升适应性和降低再训练成本的有效途径。然而，现有方法本质上是粗粒度的，既缺乏细粒度知识提取所需的精度，又难以高效聚合来自大量源模型或高参数量模型的知识。我们通过奇异值分解（SVD）技术应对这些局限：首先将每个源模型分解为基础的单秩分量，随后在聚合阶段仅从所有源中筛选最显著的分量，从而突破先前效率与精度的限制。为最大限度保留并利用合成知识库，我们的方法通过仅微调合并矩阵的主奇异值来适应目标任务——本质上仅重新校准顶级SVD分量的权重。该框架实现了高效迁移学习，对输入级和参数空间的扰动（如噪声或剪枝的源模型）具有鲁棒性，且计算扩展性优异。</p>
<div class="markdown-heading"><h2 class="heading-element">深度生成模型中的量子潜在分布</h2><a id="user-content-深度生成模型中的量子潜在分布" class="anchor" aria-label="Permalink: 深度生成模型中的量子潜在分布" href="#深度生成模型中的量子潜在分布"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.19857v1 公告类型：新成果<br>
摘要：许多成功的生成模型家族利用低维潜在分布映射到数据分布。虽然通常采用简单潜在分布，但研究表明更复杂的分布能提升性能。例如，近期研究探索使用量子处理器产生的分布，并发现了实证性改进。然而，量子处理器产生的潜在分布在何种条件下能提升性能，以及这些改进是否具有可复现性，仍是待解问题。本研究证明，在特定条件下，这类"量子潜在分布"能使生成模型产生经典潜在分布无法高效生成的数据分布。我们还提出了可操作的直观判断原则，以识别现实场景中量子优势可能出现的场景。通过在合成量子数据集和QM9分子数据集上开展基准测试实验（使用模拟和真实光量子处理器），我们的结果表明：相较于一系列经典基线方法，量子潜在分布能提升生成对抗网络（GAN）的生成性能。我们还探索了扩散模型与流匹配模型，确定了与量子潜在分布兼容的架构。这项工作证实了近量子处理器能够扩展深度生成模型的能力边界。</p>
<div class="markdown-heading"><h2 class="heading-element">基于本体的放射学报告检索与标注概念提炼</h2><a id="user-content-基于本体的放射学报告检索与标注概念提炼" class="anchor" aria-label="Permalink: 基于本体的放射学报告检索与标注概念提炼" href="#基于本体的放射学报告检索与标注概念提炼"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.19915v1 公告类型：新成果<br>
摘要：基于放射学报告的检索增强学习已成为提升长尾医学影像任务（如胸部X光罕见疾病检测）性能的新兴方向。现有方法多依赖于对比CLIP或CXR-BERT等高维文本嵌入向量，但这些方法往往存在可解释性差、计算成本高且与医学知识结构化特性契合度不足的问题。我们提出一种基于统一医学语言系统（UMLS）临床基础概念的新型本体驱动方案，用于放射学报告文本比对。该方法通过基于RadGraph-XL和SapBERT构建的增强流程，从自由文本报告中提取标准化医学实体，并将其链接至UMLS概念（CUI），形成透明可解释的集合式报告表征。我们进一步基于改进版加权特弗斯基指数定义了任务自适应相似度度量，该指标综合考虑医学术语的同义关系、否定表达及层级关联，实现高效且具有语义意义的报告相似度比对。在MIMIC-CXR影像分类任务中，本方法尤其在长尾场景下优于当前最先进的基于嵌入向量的检索方法。此外，我们利用该流程为MIMIC-CXR生成本体支持的疾病标签，为下游学习任务提供宝贵的新资源。本研究为临床AI系统提供了更具可解释性、可靠性及任务特异性的检索策略，特别适用于需强调可解释性与领域知识融合的关键场景。代码已开源：<a href="https://github.com/Felix-012/ontology-concept-distillation">https://github.com/Felix-012/ontology-concept-distillation</a></p>
<div class="markdown-heading"><h2 class="heading-element">图神经网络中的记忆机制</h2><a id="user-content-图神经网络中的记忆机制" class="anchor" aria-label="Permalink: 图神经网络中的记忆机制" href="#图神经网络中的记忆机制"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.19352v1 公告类型：新研究<br>
摘要：深度神经网络（DNNs）已被证明会记忆其训练数据，然而针对图神经网络（GNNs）的类似分析仍很大程度上未被探索。我们提出了NCMemo（节点分类记忆量化框架），这是首个量化半监督节点分类中标签记忆现象的框架。首先，我们建立了记忆效应与图同配性（即相连节点共享相似标签/特征的属性）之间的反向关系：同配性越低，记忆效应越显著，表明GNNs依赖记忆机制来学习同配性较低的图结构。其次，我们分析了GNN的训练动态特性，发现低同配性图中增强的记忆效应与GNN学习过程中隐式偏重使用图结构密切相关。在同配性较低的场景下，图结构信息性减弱，导致模型通过记忆节点标签来最小化训练损失。最后，我们证明特征空间邻域内标签一致性较低的节点明显更容易被记忆。基于对图同配性与记忆效应关联的深入理解，我们探索了通过图重构技术来抑制记忆效应。实验结果表明，该方法能有效降低记忆效应且不损害模型性能，同时在实际应用中降低了先前被记忆数据点的隐私风险。因此，本研究不仅深化了对GNN学习机制的理解，还为构建更具隐私保护能力的GNN部署方案提供了支持。</p>
<div class="markdown-heading"><h2 class="heading-element">多模态强化学习中基于反事实奖励模型训练以缓解偏见</h2><a id="user-content-多模态强化学习中基于反事实奖励模型训练以缓解偏见" class="anchor" aria-label="Permalink: 多模态强化学习中基于反事实奖励模型训练以缓解偏见" href="#多模态强化学习中基于反事实奖励模型训练以缓解偏见"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.19567v1 公告类型：新研究<br>
摘要：在人类反馈强化学习（RLHF）中，奖励模型能够有效学习并放大多模态数据集中的潜在偏见，这可能导致通过有缺陷的奖励信号进行不完美的策略优化，并降低公平性。现有偏见缓解研究通常采用被动约束方法，但在因果混淆情境下可能失效。本文提出一种反事实奖励模型，通过结合因果推理与多模态表征学习，提供无需监督、具备偏见抵抗能力的奖励信号。核心贡献是反事实信任评分——一个由四个组件构成的聚合评分：（1）反事实偏移量，用于分解政治框架偏见与主题偏见；（2）反事实扰动过程中的重构不确定性；（3）每个受保护属性可论证的公平规则违反情况；（4）与动态信任度量对齐的时序奖励偏移。我们在呈现框架偏见、类别不平衡和分布漂移的多模态真假新闻数据集上评估该框架，借鉴基于表征距离的无监督漂移检测[1]与语言模型时序鲁棒性基准测试[2]的方法论，还在连续批次中注入合成偏见以测试鲁棒性。最终系统在假新闻检测中达到89.12%的准确率，优于基线奖励模型，更重要的是减少了伪相关性和不公平的强化信号。该 pipeline 为公平感知的RLHF提供了可解释的鲁棒方法，提供可调节的偏见削减阈值，并增强动态实时决策的可靠性。</p>
<div class="markdown-heading"><h2 class="heading-element">MS-ConTab：多尺度对比学习突变特征用于泛癌表征与分层</h2><a id="user-content-ms-contab多尺度对比学习突变特征用于泛癌表征与分层" class="anchor" aria-label="Permalink: MS-ConTab：多尺度对比学习突变特征用于泛癌表征与分层" href="#ms-contab多尺度对比学习突变特征用于泛癌表征与分层"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.19424v1 公告类型：新研究<br>
摘要：<br>
研究动机：解析泛癌种突变图谱能为肿瘤发生的分子机制提供关键见解。虽然患者层面的机器学习技术已被广泛用于识别肿瘤亚型，但基于共享分子特征对整个癌症类型进行分组的队列层面聚类研究仍主要依赖经典统计方法。</p>
<p>研究成果：本研究引入了一种新型无监督对比学习框架，基于COSMIC数据库的编码突变数据对43种癌症类型进行聚类。针对每种癌症类型，我们构建了两个互补的突变特征：一是基因层面特征谱，捕获高频突变基因的核苷酸替换模式；二是染色体层面特征谱，呈现染色体归一化替换频率。通过TabNet编码器对这两个视角进行编码，并采用多尺度对比学习目标（NT-Xent损失函数）进行优化，最终学习到统一的癌症类型嵌入表示。实验证明，所得潜在表征能够生成具有生物学意义的癌症类型聚类，这些聚类与已知的突变过程和组织起源相吻合。本研究首次将对比学习应用于队列级癌症聚类，为突变驱动的癌症亚型分型提供了可扩展且可解释的分析框架。</p>
<div class="markdown-heading"><h2 class="heading-element">量化却欺骗？量化大语言模型的多维度真实性评估</h2><a id="user-content-量化却欺骗量化大语言模型的多维度真实性评估" class="anchor" aria-label="Permalink: 量化却欺骗？量化大语言模型的多维度真实性评估" href="#量化却欺骗量化大语言模型的多维度真实性评估"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.19432v1 公告类型：新成果<br>
摘要：量化技术通过显著降低内存和计算成本，使大语言模型（LLM）在资源受限环境中得以高效部署。虽然量化后的LLM在困惑度和零样本任务上通常能保持性能，但其对真实性（即生成真实或欺骗性回答的影响）仍属未知领域。本研究提出TruthfulnessEval评估框架，从三个维度系统评估量化LLM的真实性：（1）逻辑推理真实性；（2）常识真实性；（3）模仿性虚假陈述真实性。基于该框架，我们对多种开源LLM的主流量化技术（从4比特到极端2比特）进行检验。出乎意料的是，尽管量化模型内部保持真实表征，但在误导性提示下更容易产生虚假输出。为探究这一脆弱性，我们测试了15种重构版本的"诚实"、"中性"和"欺骗性"提示词，发现"欺骗性"提示会覆盖真实一致行为，而"诚实"与"中性"提示能保持稳定输出。通过分层探测和PCA可视化进一步揭示：量化模型内部"知晓"真相，却在"欺骗性"提示引导下仍输出虚假内容。本研究为未来量化对齐技术和真实性干预措施的设计提供了重要洞见。</p>
<div class="markdown-heading"><h2 class="heading-element">通过协同记忆回放在线持续学习中规避稳定性-可塑性困境的运动预测方法</h2><a id="user-content-通过协同记忆回放在线持续学习中规避稳定性-可塑性困境的运动预测方法" class="anchor" aria-label="Permalink: 通过协同记忆回放在线持续学习中规避稳定性-可塑性困境的运动预测方法" href="#通过协同记忆回放在线持续学习中规避稳定性-可塑性困境的运动预测方法"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>（注：译文采用学术论文标题的常见结构，通过"通过..."的句式清晰呈现方法论，同时将专业术语"Stability-Plasticity Dilemma"准确译为"稳定性-可塑性困境"，"Synergetic Memory Rehearsal"译为"协同记忆回放"，既保持专业准确性又符合中文表达习惯。）</p>
<p>arXiv:2508.19571v1 公告类型：新成果<br>
摘要：深度神经网络（DNN）在运动预测领域取得了显著成功。然而，大多数基于DNN的方法存在灾难性遗忘问题，在适应新数据后难以维持先前学习场景的性能。近期持续学习（CL）研究试图通过增强DNN的记忆稳定性（即保留已学知识的能力）来缓解这一问题。但过度强调记忆稳定性往往会损害学习可塑性（即DNN有效获取新信息的能力）。为解决这种稳定性-可塑性困境，本研究提出了一种新颖的持续学习方法——协同记忆回放（SyReM），用于基于DNN的运动预测。SyReM通过维护紧凑的记忆缓冲区来表征已学知识，为保障记忆稳定性，采用不等式约束限制记忆缓冲区平均损失的增量；协同地，通过设计选择性记忆回放机制，从记忆缓冲区选取与近期观测数据最相似的样本，以损失梯度的在线余弦相似度为选择依据，实现精准定向的记忆回放。由于回放样本源自已学场景，该机制不会损害记忆稳定性。我们在在线持续学习范式下验证SyReM（训练样本以单次流形式从多场景抵达），基于INTERACTION的11个自然驾驶数据集实验表明：相较于非持续学习及持续学习基线方法，SyReM在显著缓解旧场景灾难性遗忘的同时，提升了新场景的预测精度。代码已开源：<a href="https://github.com/BIT-Jack/SyReM%E3%80%82">https://github.com/BIT-Jack/SyReM。</a></p>
<div class="markdown-heading"><h2 class="heading-element">长视距视觉语言动作模型：释放机器人操作中的长程能力潜力</h2><a id="user-content-长视距视觉语言动作模型释放机器人操作中的长程能力潜力" class="anchor" aria-label="Permalink: 长视距视觉语言动作模型：释放机器人操作中的长程能力潜力" href="#长视距视觉语言动作模型释放机器人操作中的长程能力潜力"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>（注：此处"Long-VLA"采用意译"长视距视觉语言动作模型"，既保留原缩写结构又准确传达技术特性；"Unleashing Long-Horizon Capability"译为"释放长程能力潜力"，通过添加"潜力"二字增强中文表达张力；"Robot Manipulation"译为"机器人操作"符合中文机器人学术界的通用术语规范。）</p>
<p>arXiv:2508.19958v1 公告类型：新成果<br>
摘要：视觉-语言-动作（VLA）模型通过利用大规模多模态数据实现鲁棒且可扩展的控制，已成为机器人策略学习的核心架构。然而，现有VLA框架主要针对短时程任务，由于技能链与子任务依赖关系的复杂性，其在长时程多步骤机器人操作中的有效性仍受限。本研究提出Long-VLA——首个专为长时程机器人任务设计的端到端VLA模型。我们的方法采用创新的相位感知输入掩码策略，将每个子任务自适应分割为移动与交互相位，使模型能聚焦相位相关的感知线索并增强子任务兼容性。这一统一策略保持了VLA训练的可扩展性和数据效率，且我们的架构无关模块可无缝集成到现有VLA模型中。我们进一步提出L-CALVIN基准来系统评估长时程操作任务。在仿真与真实场景的大量实验表明，Long-VLA显著优于现有最优方法，为长时程机器人控制确立了新基准。</p>
</div></div><div class="footer container-xl width-full p-responsive"><div class="position-relative flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between pt-4 pb-4 mt-6 f6 color-text-secondary border-top color-border-secondary text-center"><div class="footer-octicon d-lg-block mx-lg-4"><a title="LLIKKE/Arxiv_GPT_Assistant" href="https://github.com/LLIKKE/Arxiv_GPT_Assistant" target="_blank" rel="noreferrer noopener"><svg class="octicon octicon-mark-github gh-logo" width="36" height="36" viewBox="0 0 98 98" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"></path></svg></a></div><span class="mt-2 d-block footprint"><span>powered by </span><a href="https://github.com/wranders/markdown-to-pages-action" target="_blank" rel="noreferrer noopener">markdown-to-pages-action</a></span></div></div></body></html>