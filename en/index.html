<!DOCTYPE html><html data-color-mode="light" data-light-theme="light" data-dark-theme="dark" lang="en-US"><head><title>LLIKKE/Arxiv_GPT_Assistant</title><meta charset="utf-8"><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="description" content="Deepseek based personalized ArXiv paper assistant bot"><link rel="canonical" href="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta property="og:type" content="website"><meta property="og:url" content="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:description" content="Deepseek based personalized ArXiv paper assistant bot"><meta property="og:locale" content="en_US"><meta property="og:site_name" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:description" content="Deepseek based personalized ArXiv paper assistant bot"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon.png" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon.svg" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon-dark.png" media="(prefers-color-scheme: dark)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon-dark.svg" media="(prefers-color-scheme: dark)"><link rel="mask-icon" href="https://github.githubassets.com/pinned-octocat.svg" color="#000000"><link href="index.css" rel="stylesheet"></head><body><div class="container-lg px-3 my-5 markdown-body"><div class="position-relative"><span class="profile-color-modes-toggle js-promo-color-modes-toggle" tabindex="0" aria-label="Toggle dark mode" aria-checked="true" role="checkbox"><div class="profile-color-modes-toggle-track" div></div><div class="profile-color-modes-toggle-thumb"><svg style="fill: var(--color-scale-yellow-0); margin: 7px 0 0 7px;" aria-hidden="true" width="14" height="13" viewBox="0 0 14 13" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.52208 7.71754C7.5782 7.71754 10.0557 5.24006 10.0557 2.18394C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961C9.95801 1.07727 10.3495 0.771159 10.6474 0.99992C12.1153 2.12716 13.0615 3.89999 13.0615 5.89383C13.0615 9.29958 10.3006 12.0605 6.89485 12.0605C3.95334 12.0605 1.49286 10.001 0.876728 7.24527C0.794841 6.87902 1.23668 6.65289 1.55321 6.85451C2.41106 7.40095 3.4296 7.71754 4.52208 7.71754Z"></path></svg></div></span></div><script type="text/javascript">(function() {
  var MODE_KEY = 'markdown_to_pages_dark_mode';
  function toggleMode() {
    var mode = document.documentElement.getAttribute('data-color-mode') === 'light' ? 'dark' : 'light';
    document.documentElement.setAttribute('data-color-mode', mode);
    localStorage.setItem(MODE_KEY, mode);
  }
  var mode = localStorage.getItem(MODE_KEY);
  if (mode == null) {
    var query = window.matchMedia('(prefers-color-scheme: dark)');
    mode = query.matches ? 'dark' : 'light';
  }
  document.documentElement.setAttribute('data-color-mode', mode);
  document.querySelector('.profile-color-modes-toggle').onclick = toggleMode;
})();</script><div><div class="markdown-heading"><h1 class="heading-element">Personalized Daily Arxiv Papers 08/29/2025</h1><a id="user-content-personalized-daily-arxiv-papers-08292025" class="anchor" aria-label="Permalink: Personalized Daily Arxiv Papers 08/29/2025" href="#personalized-daily-arxiv-papers-08292025"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>Total relevant papers: 23</p>
<p>Paper selection prompt and criteria at the bottom</p>
<p>Table of contents with paper titles:</p>
<ol start="0">
<li>
<p><a href="#link0">MERIT: Maximum-normalized Element-wise Ratio for Language Model Large-batch Training</a>
<strong>Authors:</strong> Yang Luo, Zangwei Zheng, Ziheng Qin, Zirui Zhu, Yong Liu, Yang You</p>
</li>
<li>
<p><a href="#link1">Self-Composing Neural Operators with Depth and Accuracy Scaling via Adaptive Train-and-Unroll Approach</a>
<strong>Authors:</strong> Juncai He, Xinliang Liu, Jinchao Xu</p>
</li>
<li>
<p><a href="#link2">Turning Tabular Foundation Models into Graph Foundation Models</a>
<strong>Authors:</strong> Dmitry Eremeev, Gleb Bazhenov, Oleg Platonov, Artem Babenko, Liudmila Prokhorenkova</p>
</li>
<li>
<p><a href="#link3">The Role of Teacher Calibration in Knowledge Distillation</a>
<strong>Authors:</strong> Suyoung Kim, Seonguk Park, Junhoo Lee, Nojun Kwak</p>
</li>
<li>
<p><a href="#link4">DFAMS: Dynamic-flow guided Federated Alignment based Multi-prototype Search</a>
<strong>Authors:</strong> Zhibang Yang, Xinke Jiang, Rihong Qiu, Ruiqing Li, Yihang Zhang, Yue Fang, Yongxin Xu, Hongxin Ding, Xu Chu, Junfeng Zhao, Yasha Wang</p>
</li>
<li>
<p><a href="#link5">Dimension Agnostic Testing of Survey Data Credibility through the Lens of Regression</a>
<strong>Authors:</strong> Debabrota Basu, Sourav Chakraborty, Debarshi Chanda, Buddha Dev Das, Arijit Ghosh, Arnab Ray</p>
</li>
<li>
<p><a href="#link6">ATM-GAD: Adaptive Temporal Motif Graph Anomaly Detection for Financial Transaction Networks</a>
<strong>Authors:</strong> Zeyue Zhang, Lin Song, Erkang Bao, Xiaoling Lv, Xinyue Wang</p>
</li>
<li>
<p><a href="#link7">GPT-FT: An Efficient Automated Feature Transformation Using GPT for Sequence Reconstruction and Performance Enhancement</a>
<strong>Authors:</strong> Yang Gao, Dongjie Wang, Scott Piersall, Ye Zhang, Liqiang Wang</p>
</li>
<li>
<p><a href="#link8">Re4: Scientific Computing Agent with Rewriting, Resolution, Review and Revision</a>
<strong>Authors:</strong> Ao Cheng, Lei Zhang, Guowei He</p>
</li>
<li>
<p><a href="#link9">Learning Primitive Embodied World Models: Towards Scalable Robotic Learning</a>
<strong>Authors:</strong> Qiao Sun, Liujia Yang, Wei Tang, Wei Huang, Kaixin Xu, Yongchao Chen, Mingyu Liu, Jiange Yang, Haoyi Zhu, Yating Wang, Tong He, Yilun Chen, Xili Dai, Nanyang Ye, Qinying Gu</p>
</li>
<li>
<p><a href="#link10">Latent Variable Modeling for Robust Causal Effect Estimation</a>
<strong>Authors:</strong> Tetsuro Morimura, Tatsushi Oka, Yugo Suzuki, Daisuke Moriwaki</p>
</li>
<li>
<p><a href="#link11">Rethinking Transformer Connectivity: TLinFormer, A Path to Exact, Full Context-Aware Linear Attention</a>
<strong>Authors:</strong> Zhongpan Tang</p>
</li>
<li>
<p><a href="#link12">Efficient Neuro-Symbolic Learning of Constraints and Objective</a>
<strong>Authors:</strong> Marianne Defresne, Romain Gambardella, Sophie Barbe, Thomas Schiex</p>
</li>
<li>
<p><a href="#link13">Token Buncher: Shielding LLMs from Harmful Reinforcement Learning Fine-Tuning</a>
<strong>Authors:</strong> Weitao Feng, Lixu Wang, Tianyi Wei, Jie Zhang, Chongyang Gao, Sinong Zhan, Peizhuo Lv, Wei Dong</p>
</li>
<li>
<p><a href="#link14">Single Agent Robust Deep Reinforcement Learning for Bus Fleet Control</a>
<strong>Authors:</strong> Yifan Zhang</p>
</li>
<li>
<p><a href="#link15">Coresets from Trajectories: Selecting Data via Correlation of Loss Differences</a>
<strong>Authors:</strong> Manish Nagaraj, Deepak Ravikumar, Kaushik Roy</p>
</li>
<li>
<p><a href="#link16">VarDiU: A Variational Diffusive Upper Bound for One-Step Diffusion Distillation</a>
<strong>Authors:</strong> Leyang Wang, Mingtian Zhang, Zijing Ou, David Barber</p>
</li>
<li>
<p><a href="#link17">Inference-Time Alignment Control for Diffusion Models with Reinforcement Learning Guidance</a>
<strong>Authors:</strong> Luozhijie Jin, Zijie Qiu, Jie Liu, Zijie Diao, Lifeng Qiao, Ning Ding, Alex Lamb, Xipeng Qiu</p>
</li>
<li>
<p><a href="#link18">What can we learn from signals and systems in a transformer? Insights for probabilistic modeling and inference architecture</a>
<strong>Authors:</strong> Heng-Sheng Chang, Prashant G. Mehta</p>
</li>
<li>
<p><a href="#link19">FORGE: Foundational Optimization Representations from Graph Embeddings</a>
<strong>Authors:</strong> Zohair Shafi, Serdar Kadioglu</p>
</li>
<li>
<p><a href="#link20">Beacon: Post-Training Quantization with Integrated Grid Selection</a>
<strong>Authors:</strong> Shihao Zhang, Rayan Saab</p>
</li>
<li>
<p><a href="#link21">BiListing: Modality Alignment for Listings</a>
<strong>Authors:</strong> Guillaume Guy, Mihajlo Grbovic, Chun How Tan, Han Zhao</p>
</li>
<li>
<p><a href="#link22">AI-SearchPlanner: Modular Agentic Search via Pareto-Optimal Multi-Objective Reinforcement Learning</a>
<strong>Authors:</strong> Lang Mei, Zhihan Yang, Chong Chen</p>
</li>
</ol>
<hr>
<div class="markdown-heading"><h2 class="heading-element">0. <a href="https://arxiv.org/abs/2508.20577" rel="nofollow">MERIT: Maximum-normalized Element-wise Ratio for Language Model Large-batch Training</a> <a id="user-content-link0"></a>
</h2><a id="user-content-0-merit-maximum-normalized-element-wise-ratio-for-language-model-large-batch-training-" class="anchor" aria-label="Permalink: 0. MERIT: Maximum-normalized Element-wise Ratio for Language Model Large-batch Training" href="#0-merit-maximum-normalized-element-wise-ratio-for-language-model-large-batch-training-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.20577
<strong>Authors:</strong> Yang Luo, Zangwei Zheng, Ziheng Qin, Zirui Zhu, Yong Liu, Yang You</p>
<p><strong>Abstract:</strong> arXiv:2508.20577v1 Announce Type: new  Abstract: Large-batch training has become a cornerstone in accelerating the training of deep neural networks, yet it poses challenges in optimization and generalization. Existing optimizers like AdamW present performance degradation during language models' large-batch training, due to the information bottleneck in attention layers caused by the sharp increase of max attention logit. While the LAMB optimizer partially addresses this issue, some attention layers still face this issue. The reason is that $l_2$-norm-based trust ratios in LAMB are less effective in directly influencing the max value of query/key weights. Furthermore, the weight-wise trust ratio in LAMB is error-prone as it overlooks relationships of weight values within rows or columns. Building on these observations, we propose a novel optimizer, MERIT, which leverages the max-norm to calculate the trust ratio to constrain the max attention logit more effectively. Moreover, we further construct element-wise trust ratios to provide more robust update scaling by focusing on local weight structures. Extensive experiments of large-batch training across various sizes of GPT-2 models demonstrate the superior performance of MERIT. Notably, during the training of GPT-2 Medium, MERIT enables a 6k batch size without any performance degradation compared to the standard batch size (480) with 48B training tokens. This work highlights the importance of considering the max attention logit and finer-granularity trust ratio in large-batch training. It successfully improves the training stability and paves the way for larger batch usage, enabling faster development and iteration of large language models. Code is available at <a href="https://github.com/NUS-HPC-AI-Lab/MERIT">https://github.com/NUS-HPC-AI-Lab/MERIT</a>.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">1. <a href="https://arxiv.org/abs/2508.20650" rel="nofollow">Self-Composing Neural Operators with Depth and Accuracy Scaling via Adaptive Train-and-Unroll Approach</a> <a id="user-content-link1"></a>
</h2><a id="user-content-1-self-composing-neural-operators-with-depth-and-accuracy-scaling-via-adaptive-train-and-unroll-approach-" class="anchor" aria-label="Permalink: 1. Self-Composing Neural Operators with Depth and Accuracy Scaling via Adaptive Train-and-Unroll Approach" href="#1-self-composing-neural-operators-with-depth-and-accuracy-scaling-via-adaptive-train-and-unroll-approach-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.20650
<strong>Authors:</strong> Juncai He, Xinliang Liu, Jinchao Xu</p>
<p><strong>Abstract:</strong> arXiv:2508.20650v1 Announce Type: new  Abstract: In this work, we propose a novel framework to enhance the efficiency and accuracy of neural operators through self-composition, offering both theoretical guarantees and practical benefits. Inspired by iterative methods in solving numerical partial differential equations (PDEs), we design a specific neural operator by repeatedly applying a single neural operator block, we progressively deepen the model without explicitly adding new blocks, improving the model's capacity. To train these models efficiently, we introduce an adaptive train-and-unroll approach, where the depth of the neural operator is gradually increased during training. This approach reveals an accuracy scaling law with model depth and offers significant computational savings through our adaptive training strategy. Our architecture achieves state-of-the-art (SOTA) performance on standard benchmarks. We further demonstrate its efficacy on a challenging high-frequency ultrasound computed tomography (USCT) problem, where a multigrid-inspired backbone enables superior performance in resolving complex wave phenomena. The proposed framework provides a computationally tractable, accurate, and scalable solution for large-scale data-driven scientific machine learning applications.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">2. <a href="https://arxiv.org/abs/2508.20906" rel="nofollow">Turning Tabular Foundation Models into Graph Foundation Models</a> <a id="user-content-link2"></a>
</h2><a id="user-content-2-turning-tabular-foundation-models-into-graph-foundation-models-" class="anchor" aria-label="Permalink: 2. Turning Tabular Foundation Models into Graph Foundation Models" href="#2-turning-tabular-foundation-models-into-graph-foundation-models-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.20906
<strong>Authors:</strong> Dmitry Eremeev, Gleb Bazhenov, Oleg Platonov, Artem Babenko, Liudmila Prokhorenkova</p>
<p><strong>Abstract:</strong> arXiv:2508.20906v1 Announce Type: new  Abstract: While foundation models have revolutionized such fields as natural language processing and computer vision, their application and potential within graph machine learning remain largely unexplored. One of the key challenges in designing graph foundation models (GFMs) is handling diverse node features that can vary across different graph datasets. Although many works on GFMs have been focused exclusively on text-attributed graphs, the problem of handling arbitrary features of other types in GFMs has not been fully addressed. However, this problem is not unique to the graph domain, as it also arises in the field of machine learning for tabular data. In this work, motivated by the recent success of tabular foundation models like TabPFNv2, we propose G2T-FM, a simple graph foundation model that employs TabPFNv2 as a backbone. Specifically, G2T-FM augments the original node features with neighborhood feature aggregation, adds structural embeddings, and then applies TabPFNv2 to the constructed node representations. Even in a fully in-context regime, our model achieves strong results, significantly outperforming publicly available GFMs and performing on par with well-tuned GNNs trained from scratch. Moreover, after finetuning, G2T-FM surpasses well-tuned GNN baselines, highlighting the potential of the proposed approach. More broadly, our paper reveals a previously overlooked direction of utilizing tabular foundation models for graph machine learning tasks.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">3. <a href="https://arxiv.org/abs/2508.20224" rel="nofollow">The Role of Teacher Calibration in Knowledge Distillation</a> <a id="user-content-link3"></a>
</h2><a id="user-content-3-the-role-of-teacher-calibration-in-knowledge-distillation-" class="anchor" aria-label="Permalink: 3. The Role of Teacher Calibration in Knowledge Distillation" href="#3-the-role-of-teacher-calibration-in-knowledge-distillation-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.20224
<strong>Authors:</strong> Suyoung Kim, Seonguk Park, Junhoo Lee, Nojun Kwak</p>
<p><strong>Abstract:</strong> arXiv:2508.20224v1 Announce Type: new  Abstract: Knowledge Distillation (KD) has emerged as an effective model compression technique in deep learning, enabling the transfer of knowledge from a large teacher model to a compact student model. While KD has demonstrated significant success, it is not yet fully understood which factors contribute to improving the student's performance. In this paper, we reveal a strong correlation between the teacher's calibration error and the student's accuracy. Therefore, we claim that the calibration of the teacher model is an important factor for effective KD. Furthermore, we demonstrate that the performance of KD can be improved by simply employing a calibration method that reduces the teacher's calibration error. Our algorithm is versatile, demonstrating effectiveness across various tasks from classification to detection. Moreover, it can be easily integrated with existing state-of-the-art methods, consistently achieving superior performance.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">4. <a href="https://arxiv.org/abs/2508.20353" rel="nofollow">DFAMS: Dynamic-flow guided Federated Alignment based Multi-prototype Search</a> <a id="user-content-link4"></a>
</h2><a id="user-content-4-dfams-dynamic-flow-guided-federated-alignment-based-multi-prototype-search-" class="anchor" aria-label="Permalink: 4. DFAMS: Dynamic-flow guided Federated Alignment based Multi-prototype Search" href="#4-dfams-dynamic-flow-guided-federated-alignment-based-multi-prototype-search-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.20353
<strong>Authors:</strong> Zhibang Yang, Xinke Jiang, Rihong Qiu, Ruiqing Li, Yihang Zhang, Yue Fang, Yongxin Xu, Hongxin Ding, Xu Chu, Junfeng Zhao, Yasha Wang</p>
<p><strong>Abstract:</strong> arXiv:2508.20353v1 Announce Type: new  Abstract: Federated Retrieval (FR) routes queries across multiple external knowledge sources, to mitigate hallucinations of LLMs, when necessary external knowledge is distributed. However, existing methods struggle to retrieve high-quality and relevant documents for ambiguous queries, especially in cross-domain scenarios, which significantly limits their effectiveness in supporting downstream generation tasks. Inspired by dynamic information flow (DIF), we propose DFAMS, a novel framework that leverages DIF to identify latent query intents and construct semantically aligned knowledge partitions for accurate retrieval across heterogeneous sources. Specifically, DFAMS probes the DIF in LLMs by leveraging gradient signals from a few annotated queries and employing Shapley value-based attribution to trace neuron activation paths associated with intent recognition and subdomain boundary detection. Then, DFAMS leverages DIF to train an alignment module via multi-prototype contrastive learning, enabling fine-grained intra-source modeling and inter-source semantic alignment across knowledge bases. Experimental results across five benchmarks show that DFAMS outperforms advanced FR methods by up to 14.37% in knowledge classification accuracy, 5.38% in retrieval recall, and 6.45% in downstream QA accuracy, demonstrating its effectiveness in complex FR scenarios.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">5. <a href="https://arxiv.org/abs/2508.20616" rel="nofollow">Dimension Agnostic Testing of Survey Data Credibility through the Lens of Regression</a> <a id="user-content-link5"></a>
</h2><a id="user-content-5-dimension-agnostic-testing-of-survey-data-credibility-through-the-lens-of-regression-" class="anchor" aria-label="Permalink: 5. Dimension Agnostic Testing of Survey Data Credibility through the Lens of Regression" href="#5-dimension-agnostic-testing-of-survey-data-credibility-through-the-lens-of-regression-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.20616
<strong>Authors:</strong> Debabrota Basu, Sourav Chakraborty, Debarshi Chanda, Buddha Dev Das, Arijit Ghosh, Arnab Ray</p>
<p><strong>Abstract:</strong> arXiv:2508.20616v1 Announce Type: new  Abstract: Assessing whether a sample survey credibly represents the population is a critical question for ensuring the validity of downstream research. Generally, this problem reduces to estimating the distance between two high-dimensional distributions, which typically requires a number of samples that grows exponentially with the dimension. However, depending on the model used for data analysis, the conclusions drawn from the data may remain consistent across different underlying distributions. In this context, we propose a task-based approach to assess the credibility of sampled surveys. Specifically, we introduce a model-specific distance metric to quantify this notion of credibility. We also design an algorithm to verify the credibility of survey data in the context of regression models. Notably, the sample complexity of our algorithm is independent of the data dimension. This efficiency stems from the fact that the algorithm focuses on verifying the credibility of the survey data rather than reconstructing the underlying regression model. Furthermore, we show that if one attempts to verify credibility by reconstructing the regression model, the sample complexity scales linearly with the dimensionality of the data. We prove the theoretical correctness of our algorithm and numerically demonstrate our algorithm's performance.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">6. <a href="https://arxiv.org/abs/2508.20829" rel="nofollow">ATM-GAD: Adaptive Temporal Motif Graph Anomaly Detection for Financial Transaction Networks</a> <a id="user-content-link6"></a>
</h2><a id="user-content-6-atm-gad-adaptive-temporal-motif-graph-anomaly-detection-for-financial-transaction-networks-" class="anchor" aria-label="Permalink: 6. ATM-GAD: Adaptive Temporal Motif Graph Anomaly Detection for Financial Transaction Networks" href="#6-atm-gad-adaptive-temporal-motif-graph-anomaly-detection-for-financial-transaction-networks-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.20829
<strong>Authors:</strong> Zeyue Zhang, Lin Song, Erkang Bao, Xiaoling Lv, Xinyue Wang</p>
<p><strong>Abstract:</strong> arXiv:2508.20829v1 Announce Type: new  Abstract: Financial fraud detection is essential to safeguard billions of dollars, yet the intertwined entities and fast-changing transaction behaviors in modern financial systems routinely defeat conventional machine learning models. Recent graph-based detectors make headway by representing transactions as networks, but they still overlook two fraud hallmarks rooted in time: (1) temporal motifs--recurring, telltale subgraphs that reveal suspicious money flows as they unfold--and (2) account-specific intervals of anomalous activity, when fraud surfaces only in short bursts unique to each entity. To exploit both signals, we introduce ATM-GAD, an adaptive graph neural network that leverages temporal motifs for financial anomaly detection. A Temporal Motif Extractor condenses each account's transaction history into the most informative motifs, preserving both topology and temporal patterns. These motifs are then analyzed by dual-attention blocks: IntraA reasons over interactions within a single motif, while InterA aggregates evidence across motifs to expose multi-step fraud schemes. In parallel, a differentiable Adaptive Time-Window Learner tailors the observation window for every node, allowing the model to focus precisely on the most revealing time slices. Experiments on four real-world datasets show that ATM-GAD consistently outperforms seven strong anomaly-detection baselines, uncovering fraud patterns missed by earlier methods.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">7. <a href="https://arxiv.org/abs/2508.20824" rel="nofollow">GPT-FT: An Efficient Automated Feature Transformation Using GPT for Sequence Reconstruction and Performance Enhancement</a> <a id="user-content-link7"></a>
</h2><a id="user-content-7-gpt-ft-an-efficient-automated-feature-transformation-using-gpt-for-sequence-reconstruction-and-performance-enhancement-" class="anchor" aria-label="Permalink: 7. GPT-FT: An Efficient Automated Feature Transformation Using GPT for Sequence Reconstruction and Performance Enhancement" href="#7-gpt-ft-an-efficient-automated-feature-transformation-using-gpt-for-sequence-reconstruction-and-performance-enhancement-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.20824
<strong>Authors:</strong> Yang Gao, Dongjie Wang, Scott Piersall, Ye Zhang, Liqiang Wang</p>
<p><strong>Abstract:</strong> arXiv:2508.20824v1 Announce Type: new  Abstract: Feature transformation plays a critical role in enhancing machine learning model performance by optimizing data representations. Recent state-of-the-art approaches address this task as a continuous embedding optimization problem, converting discrete search into a learnable process. Although effective, these methods often rely on sequential encoder-decoder structures that cause high computational costs and parameter requirements, limiting scalability and efficiency. To address these limitations, we propose a novel framework that accomplishes automated feature transformation through four steps: transformation records collection, embedding space construction with a revised Generative Pre-trained Transformer (GPT) model, gradient-ascent search, and autoregressive reconstruction. In our approach, the revised GPT model serves two primary functions: (a) feature transformation sequence reconstruction and (b) model performance estimation and enhancement for downstream tasks by constructing the embedding space. Such a multi-objective optimization framework reduces parameter size and accelerates transformation processes. Experimental results on benchmark datasets show that the proposed framework matches or exceeds baseline performance, with significant gains in computational efficiency. This work highlights the potential of transformer-based architectures for scalable, high-performance automated feature transformation.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">8. <a href="https://arxiv.org/abs/2508.20729" rel="nofollow">Re4: Scientific Computing Agent with Rewriting, Resolution, Review and Revision</a> <a id="user-content-link8"></a>
</h2><a id="user-content-8-re4-scientific-computing-agent-with-rewriting-resolution-review-and-revision-" class="anchor" aria-label="Permalink: 8. Re4: Scientific Computing Agent with Rewriting, Resolution, Review and Revision" href="#8-re4-scientific-computing-agent-with-rewriting-resolution-review-and-revision-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.20729
<strong>Authors:</strong> Ao Cheng, Lei Zhang, Guowei He</p>
<p><strong>Abstract:</strong> arXiv:2508.20729v1 Announce Type: new  Abstract: Large language models (LLMs) serve as an active and promising field of generative artificial intelligence and have demonstrated abilities to perform complex tasks in multiple domains, including mathematical and scientific reasoning. In this work, we construct a novel agent framework for solving representative problems in scientific computing. The proposed agent, incorporating a "rewriting-resolution-review-revision" logical chain via three reasoning LLMs (functioning as the Consultant, Reviewer, and Programmer, respectively), is integrated in a collaborative and interactive manner. The Consultant module endows the agent with knowledge transfer capabilities to link problems to professional domain insights, thereby rewriting problem descriptions through text augmentation. The Programmer module is responsible for generating and executing well-structured code to deliver the problem resolution. The Reviewer module equips the agent with the capacity for self-debugging and self-refinement through interactive feedback with code runtime outputs. By leveraging the end-to-end review mechanism, the executable code provided by the Programmer attains the iterative revision. A comprehensive evaluation is conducted on the performance of the proposed agent framework in solving PDEs, ill-conditioned linear systems, and data-driven physical analysis problems. Compared to single-model, this collaborative framework significantly improves the bug-free code generation rate and reduces the occurrence of non-physical solutions, thereby establishing a highly reliable framework for autonomous code generation based on natural language descriptions. The review mechanism improved the average execution success (bug-free code and non-NaN solutions) rate of the latest reasoning models. In summary, our agent framework establishes automatic code generation and review as a promising scientific computing paradigm.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">9. <a href="https://arxiv.org/abs/2508.20840" rel="nofollow">Learning Primitive Embodied World Models: Towards Scalable Robotic Learning</a> <a id="user-content-link9"></a>
</h2><a id="user-content-9-learning-primitive-embodied-world-models-towards-scalable-robotic-learning-" class="anchor" aria-label="Permalink: 9. Learning Primitive Embodied World Models: Towards Scalable Robotic Learning" href="#9-learning-primitive-embodied-world-models-towards-scalable-robotic-learning-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.20840
<strong>Authors:</strong> Qiao Sun, Liujia Yang, Wei Tang, Wei Huang, Kaixin Xu, Yongchao Chen, Mingyu Liu, Jiange Yang, Haoyi Zhu, Yating Wang, Tong He, Yilun Chen, Xili Dai, Nanyang Ye, Qinying Gu</p>
<p><strong>Abstract:</strong> arXiv:2508.20840v1 Announce Type: new  Abstract: While video-generation-based embodied world models have gained increasing attention, their reliance on large-scale embodied interaction data remains a key bottleneck. The scarcity, difficulty of collection, and high dimensionality of embodied data fundamentally limit the alignment granularity between language and actions and exacerbate the challenge of long-horizon video generation--hindering generative models from achieving a "GPT moment" in the embodied domain. There is a naive observation: the diversity of embodied data far exceeds the relatively small space of possible primitive motions. Based on this insight, we propose a novel paradigm for world modeling--Primitive Embodied World Models (PEWM). By restricting video generation to fixed short horizons, our approach 1) enables fine-grained alignment between linguistic concepts and visual representations of robotic actions, 2) reduces learning complexity, 3) improves data efficiency in embodied data collection, and 4) decreases inference latency. By equipping with a modular Vision-Language Model (VLM) planner and a Start-Goal heatmap Guidance mechanism (SGG), PEWM further enables flexible closed-loop control and supports compositional generalization of primitive-level policies over extended, complex tasks. Our framework leverages the spatiotemporal vision priors in video models and the semantic awareness of VLMs to bridge the gap between fine-grained physical interaction and high-level reasoning, paving the way toward scalable, interpretable, and general-purpose embodied intelligence.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">10. <a href="https://arxiv.org/abs/2508.20259" rel="nofollow">Latent Variable Modeling for Robust Causal Effect Estimation</a> <a id="user-content-link10"></a>
</h2><a id="user-content-10-latent-variable-modeling-for-robust-causal-effect-estimation-" class="anchor" aria-label="Permalink: 10. Latent Variable Modeling for Robust Causal Effect Estimation" href="#10-latent-variable-modeling-for-robust-causal-effect-estimation-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.20259
<strong>Authors:</strong> Tetsuro Morimura, Tatsushi Oka, Yugo Suzuki, Daisuke Moriwaki</p>
<p><strong>Abstract:</strong> arXiv:2508.20259v1 Announce Type: new  Abstract: Latent variable models provide a powerful framework for incorporating and inferring unobserved factors in observational data. In causal inference, they help account for hidden factors influencing treatment or outcome, thereby addressing challenges posed by missing or unmeasured covariates. This paper proposes a new framework that integrates latent variable modeling into the double machine learning (DML) paradigm to enable robust causal effect estimation in the presence of such hidden factors. We consider two scenarios: one where a latent variable affects only the outcome, and another where it may influence both treatment and outcome. To ensure tractability, we incorporate latent variables only in the second stage of DML, separating representation learning from latent inference. We demonstrate the robustness and effectiveness of our method through extensive experiments on both synthetic and real-world datasets.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">11. <a href="https://arxiv.org/abs/2508.20407" rel="nofollow">Rethinking Transformer Connectivity: TLinFormer, A Path to Exact, Full Context-Aware Linear Attention</a> <a id="user-content-link11"></a>
</h2><a id="user-content-11-rethinking-transformer-connectivity-tlinformer-a-path-to-exact-full-context-aware-linear-attention-" class="anchor" aria-label="Permalink: 11. Rethinking Transformer Connectivity: TLinFormer, A Path to Exact, Full Context-Aware Linear Attention" href="#11-rethinking-transformer-connectivity-tlinformer-a-path-to-exact-full-context-aware-linear-attention-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.20407
<strong>Authors:</strong> Zhongpan Tang</p>
<p><strong>Abstract:</strong> arXiv:2508.20407v1 Announce Type: new  Abstract: The Transformer architecture has become a cornerstone of modern artificial intelligence, but its core self-attention mechanism suffers from a complexity bottleneck that scales quadratically with sequence length, severely limiting its application in long-sequence tasks. To address this challenge, existing linear attention methods typically sacrifice model performance by relying on data-agnostic kernel approximations or restrictive context selection. This paper returns to the first principles of connectionism, starting from the topological structure of information flow, to introduce a novel linear attention architecture-\textbf{TLinFormer}. By reconfiguring neuron connection patterns, TLinFormer achieves strict linear complexity while computing exact attention scores and ensuring information flow remains aware of the full historical context. This design aims to bridge the performance gap prevalent between existing efficient attention methods and standard attention. Through a series of experiments, we systematically evaluate the performance of TLinFormer against a standard Transformer baseline on long-sequence inference tasks. The results demonstrate that TLinFormer exhibits overwhelming advantages in key metrics such as \textbf{inference latency}, \textbf{KV cache efficiency}, \textbf{memory footprint}, and \textbf{overall speedup}.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">12. <a href="https://arxiv.org/abs/2508.20978" rel="nofollow">Efficient Neuro-Symbolic Learning of Constraints and Objective</a> <a id="user-content-link12"></a>
</h2><a id="user-content-12-efficient-neuro-symbolic-learning-of-constraints-and-objective-" class="anchor" aria-label="Permalink: 12. Efficient Neuro-Symbolic Learning of Constraints and Objective" href="#12-efficient-neuro-symbolic-learning-of-constraints-and-objective-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.20978
<strong>Authors:</strong> Marianne Defresne, Romain Gambardella, Sophie Barbe, Thomas Schiex</p>
<p><strong>Abstract:</strong> arXiv:2508.20978v1 Announce Type: new  Abstract: In the ongoing quest for hybridizing discrete reasoning with neural nets, there is an increasing interest in neural architectures that can learn how to solve discrete reasoning or optimization problems from natural inputs, a task that Large Language Models seem to struggle with.   Objectives: We introduce a differentiable neuro-symbolic architecture and a loss function dedicated to learning how to solve NP-hard reasoning problems.   Methods: Our new probabilistic loss allows for learning both the constraints and the objective, thus delivering a complete model that can be scrutinized and completed with side constraints. By pushing the combinatorial solver out of the training loop, our architecture also offers scalable training while exact inference gives access to maximum accuracy.   Results: We empirically show that it can efficiently learn how to solve NP-hard reasoning problems from natural inputs. On three variants of the Sudoku benchmark -- symbolic, visual, and many-solution --, our approach requires a fraction of training time of other hybrid methods. On a visual Min-Cut/Max-cut task, it optimizes the regret better than a Decision-Focused-Learning regret-dedicated loss. Finally, it efficiently learns the energy optimization formulation of the large real-world problem of designing proteins.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">13. <a href="https://arxiv.org/abs/2508.20697" rel="nofollow">Token Buncher: Shielding LLMs from Harmful Reinforcement Learning Fine-Tuning</a> <a id="user-content-link13"></a>
</h2><a id="user-content-13-token-buncher-shielding-llms-from-harmful-reinforcement-learning-fine-tuning-" class="anchor" aria-label="Permalink: 13. Token Buncher: Shielding LLMs from Harmful Reinforcement Learning Fine-Tuning" href="#13-token-buncher-shielding-llms-from-harmful-reinforcement-learning-fine-tuning-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.20697
<strong>Authors:</strong> Weitao Feng, Lixu Wang, Tianyi Wei, Jie Zhang, Chongyang Gao, Sinong Zhan, Peizhuo Lv, Wei Dong</p>
<p><strong>Abstract:</strong> arXiv:2508.20697v1 Announce Type: new  Abstract: As large language models (LLMs) continue to grow in capability, so do the risks of harmful misuse through fine-tuning. While most prior studies assume that attackers rely on supervised fine-tuning (SFT) for such misuse, we systematically demonstrate that reinforcement learning (RL) enables adversaries to more effectively break safety alignment and facilitate advanced harmful task assistance, under matched computational budgets. To counter this emerging threat, we propose TokenBuncher, the first effective defense specifically targeting RL-based harmful fine-tuning. TokenBuncher suppresses the foundation on which RL relies: model response uncertainty. By constraining uncertainty, RL-based fine-tuning can no longer exploit distinct reward signals to drive the model toward harmful behaviors. We realize this defense through entropy-as-reward RL and a Token Noiser mechanism designed to prevent the escalation of expert-domain harmful capabilities. Extensive experiments across multiple models and RL algorithms show that TokenBuncher robustly mitigates harmful RL fine-tuning while preserving benign task utility and finetunability. Our results highlight that RL-based harmful fine-tuning poses a greater systemic risk than SFT, and that TokenBuncher provides an effective and general defense.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">14. <a href="https://arxiv.org/abs/2508.20784" rel="nofollow">Single Agent Robust Deep Reinforcement Learning for Bus Fleet Control</a> <a id="user-content-link14"></a>
</h2><a id="user-content-14-single-agent-robust-deep-reinforcement-learning-for-bus-fleet-control-" class="anchor" aria-label="Permalink: 14. Single Agent Robust Deep Reinforcement Learning for Bus Fleet Control" href="#14-single-agent-robust-deep-reinforcement-learning-for-bus-fleet-control-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.20784
<strong>Authors:</strong> Yifan Zhang</p>
<p><strong>Abstract:</strong> arXiv:2508.20784v1 Announce Type: new  Abstract: Bus bunching remains a challenge for urban transit due to stochastic traffic and passenger demand. Traditional solutions rely on multi-agent reinforcement learning (MARL) in loop-line settings, which overlook realistic operations characterized by heterogeneous routes, timetables, fluctuating demand, and varying fleet sizes. We propose a novel single-agent reinforcement learning (RL) framework for bus holding control that avoids the data imbalance and convergence issues of MARL under near-realistic simulation. A bidirectional timetabled network with dynamic passenger demand is constructed. The key innovation is reformulating the multi-agent problem into a single-agent one by augmenting the state space with categorical identifiers (vehicle ID, station ID, time period) in addition to numerical features (headway, occupancy, velocity). This high-dimensional encoding enables single-agent policies to capture inter-agent dependencies, analogous to projecting non-separable inputs into a higher-dimensional space. We further design a structured reward function aligned with operational goals: instead of exponential penalties on headway deviations, a ridge-shaped reward balances uniform headways and schedule adherence. Experiments show that our modified soft actor-critic (SAC) achieves more stable and superior performance than benchmarks, including MADDPG (e.g., -430k vs. -530k under stochastic conditions). These results demonstrate that single-agent deep RL, when enhanced with categorical structuring and schedule-aware rewards, can effectively manage bus holding in non-loop, real-world contexts. This paradigm offers a robust, scalable alternative to MARL frameworks, particularly where agent-specific experiences are imbalanced.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">15. <a href="https://arxiv.org/abs/2508.20230" rel="nofollow">Coresets from Trajectories: Selecting Data via Correlation of Loss Differences</a> <a id="user-content-link15"></a>
</h2><a id="user-content-15-coresets-from-trajectories-selecting-data-via-correlation-of-loss-differences-" class="anchor" aria-label="Permalink: 15. Coresets from Trajectories: Selecting Data via Correlation of Loss Differences" href="#15-coresets-from-trajectories-selecting-data-via-correlation-of-loss-differences-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.20230
<strong>Authors:</strong> Manish Nagaraj, Deepak Ravikumar, Kaushik Roy</p>
<p><strong>Abstract:</strong> arXiv:2508.20230v1 Announce Type: new  Abstract: Deep learning models achieve state-of-the-art performance across domains but face scalability challenges in real-time or resource-constrained scenarios. To address this, we propose Correlation of Loss Differences (CLD), a simple and scalable metric for coreset selection that identifies the most impactful training samples by measuring their alignment with the loss trajectories of a held-out validation set. CLD is highly efficient, requiring only per-sample loss values computed at training checkpoints, and avoiding the costly gradient and curvature computations used in many existing subset selection methods. We develop a general theoretical framework that establishes convergence guarantees for CLD-based coresets, demonstrating that the convergence error is upper-bounded by the alignment of the selected samples and the representativeness of the validation set. On CIFAR-100 and ImageNet-1k, CLD-based coresets typically outperform or closely match state-of-the-art methods across subset sizes, and remain within 1% of more computationally expensive baselines even when not leading. CLD transfers effectively across architectures (ResNet, VGG, DenseNet), enabling proxy-to-target selection with &lt;1% degradation. Moreover, CLD is stable when using only early checkpoints, incurring negligible accuracy loss. Finally, CLD exhibits inherent bias reduction via per-class validation alignment, obviating the need for additional stratified sampling. Together, these properties make CLD a principled, efficient, stable, and transferable tool for scalable dataset optimization.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">16. <a href="https://arxiv.org/abs/2508.20646" rel="nofollow">VarDiU: A Variational Diffusive Upper Bound for One-Step Diffusion Distillation</a> <a id="user-content-link16"></a>
</h2><a id="user-content-16-vardiu-a-variational-diffusive-upper-bound-for-one-step-diffusion-distillation-" class="anchor" aria-label="Permalink: 16. VarDiU: A Variational Diffusive Upper Bound for One-Step Diffusion Distillation" href="#16-vardiu-a-variational-diffusive-upper-bound-for-one-step-diffusion-distillation-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.20646
<strong>Authors:</strong> Leyang Wang, Mingtian Zhang, Zijing Ou, David Barber</p>
<p><strong>Abstract:</strong> arXiv:2508.20646v1 Announce Type: new  Abstract: Recently, diffusion distillation methods have compressed thousand-step teacher diffusion models into one-step student generators while preserving sample quality. Most existing approaches train the student model using a diffusive divergence whose gradient is approximated via the student's score function, learned through denoising score matching (DSM). Since DSM training is imperfect, the resulting gradient estimate is inevitably biased, leading to sub-optimal performance. In this paper, we propose VarDiU (pronounced /va:rdju:/), a Variational Diffusive Upper Bound that admits an unbiased gradient estimator and can be directly applied to diffusion distillation. Using this objective, we compare our method with Diff-Instruct and demonstrate that it achieves higher generation quality and enables a more efficient and stable training procedure for one-step diffusion distillation.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">17. <a href="https://arxiv.org/abs/2508.21016" rel="nofollow">Inference-Time Alignment Control for Diffusion Models with Reinforcement Learning Guidance</a> <a id="user-content-link17"></a>
</h2><a id="user-content-17-inference-time-alignment-control-for-diffusion-models-with-reinforcement-learning-guidance-" class="anchor" aria-label="Permalink: 17. Inference-Time Alignment Control for Diffusion Models with Reinforcement Learning Guidance" href="#17-inference-time-alignment-control-for-diffusion-models-with-reinforcement-learning-guidance-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.21016
<strong>Authors:</strong> Luozhijie Jin, Zijie Qiu, Jie Liu, Zijie Diao, Lifeng Qiao, Ning Ding, Alex Lamb, Xipeng Qiu</p>
<p><strong>Abstract:</strong> arXiv:2508.21016v1 Announce Type: new  Abstract: Denoising-based generative models, particularly diffusion and flow matching algorithms, have achieved remarkable success. However, aligning their output distributions with complex downstream objectives, such as human preferences, compositional accuracy, or data compressibility, remains challenging. While reinforcement learning (RL) fine-tuning methods, inspired by advances in RL from human feedback (RLHF) for large language models, have been adapted to these generative frameworks, current RL approaches are suboptimal for diffusion models and offer limited flexibility in controlling alignment strength after fine-tuning. In this work, we reinterpret RL fine-tuning for diffusion models through the lens of stochastic differential equations and implicit reward conditioning. We introduce Reinforcement Learning Guidance (RLG), an inference-time method that adapts Classifier-Free Guidance (CFG) by combining the outputs of the base and RL fine-tuned models via a geometric average. Our theoretical analysis shows that RLG's guidance scale is mathematically equivalent to adjusting the KL-regularization coefficient in standard RL objectives, enabling dynamic control over the alignment-quality trade-off without further training. Extensive experiments demonstrate that RLG consistently improves the performance of RL fine-tuned models across various architectures, RL algorithms, and downstream tasks, including human preferences, compositional control, compressibility, and text rendering. Furthermore, RLG supports both interpolation and extrapolation, thereby offering unprecedented flexibility in controlling generative alignment. Our approach provides a practical and theoretically sound solution for enhancing and controlling diffusion model alignment at inference. The source code for RLG is publicly available at the Github: <a href="https://github.com/jinluo12345/Reinforcement-learning-guidance">https://github.com/jinluo12345/Reinforcement-learning-guidance</a>.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">18. <a href="https://arxiv.org/abs/2508.20211" rel="nofollow">What can we learn from signals and systems in a transformer? Insights for probabilistic modeling and inference architecture</a> <a id="user-content-link18"></a>
</h2><a id="user-content-18-what-can-we-learn-from-signals-and-systems-in-a-transformer-insights-for-probabilistic-modeling-and-inference-architecture-" class="anchor" aria-label="Permalink: 18. What can we learn from signals and systems in a transformer? Insights for probabilistic modeling and inference architecture" href="#18-what-can-we-learn-from-signals-and-systems-in-a-transformer-insights-for-probabilistic-modeling-and-inference-architecture-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.20211
<strong>Authors:</strong> Heng-Sheng Chang, Prashant G. Mehta</p>
<p><strong>Abstract:</strong> arXiv:2508.20211v1 Announce Type: new  Abstract: In the 1940s, Wiener introduced a linear predictor, where the future prediction is computed by linearly combining the past data. A transformer generalizes this idea: it is a nonlinear predictor where the next-token prediction is computed by nonlinearly combining the past tokens. In this essay, we present a probabilistic model that interprets transformer signals as surrogates of conditional measures, and layer operations as fixed-point updates. An explicit form of the fixed-point update is described for the special case when the probabilistic model is a hidden Markov model (HMM). In part, this paper is in an attempt to bridge the classical nonlinear filtering theory with modern inference architectures.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">19. <a href="https://arxiv.org/abs/2508.20330" rel="nofollow">FORGE: Foundational Optimization Representations from Graph Embeddings</a> <a id="user-content-link19"></a>
</h2><a id="user-content-19-forge-foundational-optimization-representations-from-graph-embeddings-" class="anchor" aria-label="Permalink: 19. FORGE: Foundational Optimization Representations from Graph Embeddings" href="#19-forge-foundational-optimization-representations-from-graph-embeddings-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.20330
<strong>Authors:</strong> Zohair Shafi, Serdar Kadioglu</p>
<p><strong>Abstract:</strong> arXiv:2508.20330v1 Announce Type: new  Abstract: Combinatorial optimization problems are ubiquitous in science and engineering, yet learning-based approaches to accelerate their solution often require solving a large number of hard-to-solve optimization instances to collect training data, incurring significant computational overhead. Existing methods require training dedicated models for each problem distribution for each downstream task, severely limiting their scalability and generalization. In this work, we introduce Forge, a method of pre-training a vector-quantized graph autoencoder on a large and diverse collection of mixed-integer programming (MIP) instances in an unsupervised fashion without dependency on their solution. The vector quantization process creates discrete code assignments that act as a vocabulary to represent optimization instances. We evaluate our approach under both supervised and unsupervised settings. For the unsupervised setting, we demonstrate that Forge embeddings effectively differentiate and cluster unseen instances. For the supervised setting, we fine-tune Forge embeddings and show that a single model predicts both the variables for warm-starts and integrality gaps for cut-generation across multiple problem type distributions. Both predictions help improve performance of a state-of-the-art, commercial optimization solver. Finally, we release our code and pre-trained Forge weights to encourage further research and practical use of instance-level MIP embeddings at <a href="https://github.com/skadio/forge/">https://github.com/skadio/forge/</a></p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">20. <a href="https://arxiv.org/abs/2508.20293" rel="nofollow">Beacon: Post-Training Quantization with Integrated Grid Selection</a> <a id="user-content-link20"></a>
</h2><a id="user-content-20-beacon-post-training-quantization-with-integrated-grid-selection-" class="anchor" aria-label="Permalink: 20. Beacon: Post-Training Quantization with Integrated Grid Selection" href="#20-beacon-post-training-quantization-with-integrated-grid-selection-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.20293
<strong>Authors:</strong> Shihao Zhang, Rayan Saab</p>
<p><strong>Abstract:</strong> arXiv:2508.20293v1 Announce Type: new  Abstract: Quantization is a widely used compression technique for reducing the memory and computation costs of large pre-trained models. A key challenge in per-channel post-training quantization (PTQ) is selecting appropriate scaling factors to replace weight values with values from a scaled quantization grid. Existing methods typically fix the scale at the outset via heuristic tuning or grid search. In this note, we propose Beacon, a simple and effective algorithm that eliminates the need for such manual tuning. Beacon performs per-channel PTQ directly using a fixed non-scaled alphabet and automatically determines the optimal scaling factors by exploiting the geometry of symmetric scalar quantization. It supports both symmetric and asymmetric quantization with minimal modifications and does not rely on back-propagation or large calibration sets. Despite its simplicity and tuning-free nature, Beacon achieves competitive performance compared to state-of-the-art methods, making it a practical solution for efficient model deployment.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">21. <a href="https://arxiv.org/abs/2508.20396" rel="nofollow">BiListing: Modality Alignment for Listings</a> <a id="user-content-link21"></a>
</h2><a id="user-content-21-bilisting-modality-alignment-for-listings-" class="anchor" aria-label="Permalink: 21. BiListing: Modality Alignment for Listings" href="#21-bilisting-modality-alignment-for-listings-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.20396
<strong>Authors:</strong> Guillaume Guy, Mihajlo Grbovic, Chun How Tan, Han Zhao</p>
<p><strong>Abstract:</strong> arXiv:2508.20396v1 Announce Type: new  Abstract: Airbnb is a leader in offering travel accommodations. Airbnb has historically relied on structured data to understand, rank, and recommend listings to guests due to the limited capabilities and associated complexity arising from extracting meaningful information from text and images. With the rise of representation learning, leveraging rich information from text and photos has become easier. A popular approach has been to create embeddings for text documents and images to enable use cases of computing similarities between listings or using embeddings as features in an ML model.   However, an Airbnb listing has diverse unstructured data: multiple images, various unstructured text documents such as title, description, and reviews, making this approach challenging. Specifically, it is a non-trivial task to combine multiple embeddings of different pieces of information to reach a single representation.   This paper proposes BiListing, for Bimodal Listing, an approach to align text and photos of a listing by leveraging large-language models and pretrained language-image models. The BiListing approach has several favorable characteristics: capturing unstructured data into a single embedding vector per listing and modality, enabling zero-shot capability to search inventory efficiently in user-friendly semantics, overcoming the cold start problem, and enabling listing-to-listing search along a single modality, or both.   We conducted offline and online tests to leverage the BiListing embeddings in the Airbnb search ranking model, and successfully deployed it in production, achieved 0.425% of NDCB gain, and drove tens of millions in incremental revenue.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">22. <a href="https://arxiv.org/abs/2508.20368" rel="nofollow">AI-SearchPlanner: Modular Agentic Search via Pareto-Optimal Multi-Objective Reinforcement Learning</a> <a id="user-content-link22"></a>
</h2><a id="user-content-22-ai-searchplanner-modular-agentic-search-via-pareto-optimal-multi-objective-reinforcement-learning-" class="anchor" aria-label="Permalink: 22. AI-SearchPlanner: Modular Agentic Search via Pareto-Optimal Multi-Objective Reinforcement Learning" href="#22-ai-searchplanner-modular-agentic-search-via-pareto-optimal-multi-objective-reinforcement-learning-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.20368
<strong>Authors:</strong> Lang Mei, Zhihan Yang, Chong Chen</p>
<p><strong>Abstract:</strong> arXiv:2508.20368v1 Announce Type: new  Abstract: Recent studies have explored integrating Large Language Models (LLMs) with search engines to leverage both the LLMs' internal pre-trained knowledge and external information. Specially, reinforcement learning (RL) has emerged as a promising paradigm for enhancing LLM reasoning through multi-turn interactions with search engines. However, existing RL-based search agents rely on a single LLM to handle both search planning and question-answering (QA) tasks in an end-to-end manner, which limits their ability to optimize both capabilities simultaneously. In practice, sophisticated AI search systems often employ a large, frozen LLM (e.g., GPT-4, DeepSeek-R1) to ensure high-quality QA. Thus, a more effective and efficient approach is to utilize a small, trainable LLM dedicated to search planning. In this paper, we propose \textbf{AI-SearchPlanner}, a novel reinforcement learning framework designed to enhance the performance of frozen QA models by focusing on search planning. Specifically, our approach introduces three key innovations: 1) Decoupling the Architecture of the Search Planner and Generator, 2) Dual-Reward Alignment for Search Planning, and 3) Pareto Optimization of Planning Utility and Cost, to achieve the objectives. Extensive experiments on real-world datasets demonstrate that AI SearchPlanner outperforms existing RL-based search agents in both effectiveness and efficiency, while exhibiting strong generalization capabilities across diverse frozen QA models and data domains.</p>
<hr>
<hr>
<div class="markdown-heading"><h2 class="heading-element">Paper selection prompt</h2><a id="user-content-paper-selection-prompt" class="anchor" aria-label="Permalink: Paper selection prompt" href="#paper-selection-prompt"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<ol>
<li>Quantization, Pruning, and KVCache Compression for Efficient Large Language Models
<ul>
<li>Relevant: To optimize large language models (LLMs) for reduced memory and computational costs while maintaining performance, this research direction integrates quantization, pruning, and KVCache compression into a unified framework.
In suggesting papers to your friend, remember that he enjoys papers on large language model (llm) compression, inference acceleration techniques, and related algorithms such as quantization and pruning. He is particularly interested in research that explores new methods for reducing large language model size and improving inference speed, as well as innovative approaches to optimizing large language model. Furthermore, it incorporates Mixture-of-Experts (MoE) architectures to significantly decrease deployment overhead and accelerate inference speed, enabling more efficient and scalable model serving in resource-constrained environments.</li>
</ul>
</li>
</ol>
</div></div><div class="footer container-xl width-full p-responsive"><div class="position-relative flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between pt-4 pb-4 mt-6 f6 color-text-secondary border-top color-border-secondary text-center"><div class="footer-octicon d-lg-block mx-lg-4"><a title="LLIKKE/Arxiv_GPT_Assistant" href="https://github.com/LLIKKE/Arxiv_GPT_Assistant" target="_blank" rel="noreferrer noopener"><svg class="octicon octicon-mark-github gh-logo" width="36" height="36" viewBox="0 0 98 98" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"></path></svg></a></div><span class="mt-2 d-block footprint"><span>powered by </span><a href="https://github.com/wranders/markdown-to-pages-action" target="_blank" rel="noreferrer noopener">markdown-to-pages-action</a></span></div></div></body></html>