<!DOCTYPE html><html data-color-mode="light" data-light-theme="light" data-dark-theme="dark" lang="en-US"><head><title>LLIKKE/Arxiv_GPT_Assistant</title><meta charset="utf-8"><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="description" content="Deepseek based personalized ArXiv paper assistant bot"><link rel="canonical" href="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta property="og:type" content="website"><meta property="og:url" content="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:description" content="Deepseek based personalized ArXiv paper assistant bot"><meta property="og:locale" content="en_US"><meta property="og:site_name" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:description" content="Deepseek based personalized ArXiv paper assistant bot"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon.png" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon.svg" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon-dark.png" media="(prefers-color-scheme: dark)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon-dark.svg" media="(prefers-color-scheme: dark)"><link rel="mask-icon" href="https://github.githubassets.com/pinned-octocat.svg" color="#000000"><link href="index.css" rel="stylesheet"></head><body><div class="container-lg px-3 my-5 markdown-body"><div class="position-relative"><span class="profile-color-modes-toggle js-promo-color-modes-toggle" tabindex="0" aria-label="Toggle dark mode" aria-checked="true" role="checkbox"><div class="profile-color-modes-toggle-track" div></div><div class="profile-color-modes-toggle-thumb"><svg style="fill: var(--color-scale-yellow-0); margin: 7px 0 0 7px;" aria-hidden="true" width="14" height="13" viewBox="0 0 14 13" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.52208 7.71754C7.5782 7.71754 10.0557 5.24006 10.0557 2.18394C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961C9.95801 1.07727 10.3495 0.771159 10.6474 0.99992C12.1153 2.12716 13.0615 3.89999 13.0615 5.89383C13.0615 9.29958 10.3006 12.0605 6.89485 12.0605C3.95334 12.0605 1.49286 10.001 0.876728 7.24527C0.794841 6.87902 1.23668 6.65289 1.55321 6.85451C2.41106 7.40095 3.4296 7.71754 4.52208 7.71754Z"></path></svg></div></span></div><script type="text/javascript">(function() {
  var MODE_KEY = 'markdown_to_pages_dark_mode';
  function toggleMode() {
    var mode = document.documentElement.getAttribute('data-color-mode') === 'light' ? 'dark' : 'light';
    document.documentElement.setAttribute('data-color-mode', mode);
    localStorage.setItem(MODE_KEY, mode);
  }
  var mode = localStorage.getItem(MODE_KEY);
  if (mode == null) {
    var query = window.matchMedia('(prefers-color-scheme: dark)');
    mode = query.matches ? 'dark' : 'light';
  }
  document.documentElement.setAttribute('data-color-mode', mode);
  document.querySelector('.profile-color-modes-toggle').onclick = toggleMode;
})();</script><div><div class="markdown-heading"><h2 class="heading-element">利用安全导向自压缩优化深度神经网络</h2><a id="user-content-利用安全导向自压缩优化深度神经网络" class="anchor" aria-label="Permalink: 利用安全导向自压缩优化深度神经网络" href="#利用安全导向自压缩优化深度神经网络"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2505.00350v1 公告类型：新研究<br>
摘要：在资源受限设备上部署深度神经网络需要有效的模型压缩策略，以明智地平衡模型规模缩减与性能保持之间的关系。本研究提出了一种新颖的安全驱动量化框架，通过利用保护集对神经网络权重进行系统性剪枝和量化，从而在不牺牲精度的前提下优化模型复杂度。该方案在卷积神经网络（CNN）和基于注意力的语言模型上进行了严格验证，证明了其跨不同架构范式的适用性。实验结果表明，本框架在维持初始模型体积60%的同时，相较于原始未量化模型实现了最高2.5%的测试准确率提升。与传统量化技术相比，该方法不仅通过消除参数噪声和保留关键权重增强了泛化能力，还降低了方差，从而确保模型核心特征得以保留。这些发现印证了安全驱动量化作为一种鲁棒可靠的策略，能有效优化深度学习模型。本框架的实现代码及完整实验评估已在GitHub公开。</p>
<p>（注：根据学术文献翻译规范，对部分术语进行了标准化处理：</p>
<ol>
<li>"preservation sets"译为"保护集"以保持计算机领域术语一致性</li>
<li>"judiciously balance"译为"明智地平衡"以准确传达决策权衡含义</li>
<li>"parameter noise"译为"参数噪声"遵循信号处理领域术语</li>
<li>保持"CNN"和"GitHub"等专业缩写不变</li>
<li>将长复合句合理切分为符合中文表达习惯的短句）</li>
</ol>
<div class="markdown-heading"><h2 class="heading-element">稀疏注意力混合：基于内容的可学习稀疏注意力通过专家选择路由实现</h2><a id="user-content-稀疏注意力混合基于内容的可学习稀疏注意力通过专家选择路由实现" class="anchor" aria-label="Permalink: 稀疏注意力混合：基于内容的可学习稀疏注意力通过专家选择路由实现" href="#稀疏注意力混合基于内容的可学习稀疏注意力通过专家选择路由实现"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2505.00315v1 公告类型：新研究<br>
摘要：大语言模型的最新进展揭示了自注意力机制中过高的二次方计算成本问题。尽管已有大量研究投入，次二次方注意力方法在实际应用中仍存在性能不足的问题。我们提出假设：动态的、基于学习的内容稀疏化可以催生更高效的注意力机制。为此，我们提出稀疏注意力混合机制（Mixture of Sparse Attention, MoSA），这一创新方法受专家混合（Mixture of Experts, MoE）中专家选择路由机制的启发。MoSA为每个注意力头动态选择token，从而支持任意的稀疏注意力模式。通过从长度为T的序列中选择k个token，MoSA将每个注意力头的计算复杂度从O(T²)降至O(k² + T)。这使得在相同计算预算下能使用更多注意力头，从而提升专业化程度。实验表明，在所有测试的稀疏注意力变体中，MoSA是唯一能超越密集基线的方法，在相同计算预算下有时能获得高达27%的困惑度提升。相较于密集自注意力，MoSA还能降低资源消耗。尽管当前采用未经优化的torch实现，但在达到同等困惑度时，MoSA模型不仅实际运行速度更快、训练内存需求更低，其KV缓存大小较密集Transformer基线也实现了显著缩减。</p>
<p>（注：根据学术文献翻译规范，对部分术语进行了标准化处理：</p>
<ol>
<li>"wall-clock time"译为"实际运行时间"而非字面直译</li>
<li>"KV-cache"保留专业缩写形式并补充说明</li>
<li>复杂数学表达式保持原格式</li>
<li>技术术语如"perplexity"统一译为"困惑度"</li>
<li>长难句按中文习惯拆分重组，如将"despite..."状语从句转为独立陈述句）</li>
</ol>
</div></div><div class="footer container-xl width-full p-responsive"><div class="position-relative flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between pt-4 pb-4 mt-6 f6 color-text-secondary border-top color-border-secondary text-center"><div class="footer-octicon d-lg-block mx-lg-4"><a title="LLIKKE/Arxiv_GPT_Assistant" href="https://github.com/LLIKKE/Arxiv_GPT_Assistant" target="_blank" rel="noreferrer noopener"><svg class="octicon octicon-mark-github gh-logo" width="36" height="36" viewBox="0 0 98 98" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"></path></svg></a></div><span class="mt-2 d-block footprint"><span>powered by </span><a href="https://github.com/wranders/markdown-to-pages-action" target="_blank" rel="noreferrer noopener">markdown-to-pages-action</a></span></div></div></body></html>