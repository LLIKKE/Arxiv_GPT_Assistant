<!DOCTYPE html><html data-color-mode="light" data-light-theme="light" data-dark-theme="dark" lang="en-US"><head><title>LLIKKE/Arxiv_GPT_Assistant</title><meta charset="utf-8"><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="description" content="Deepseek based personalized ArXiv paper assistant bot"><link rel="canonical" href="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta property="og:type" content="website"><meta property="og:url" content="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:description" content="Deepseek based personalized ArXiv paper assistant bot"><meta property="og:locale" content="en_US"><meta property="og:site_name" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:description" content="Deepseek based personalized ArXiv paper assistant bot"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon.png" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon.svg" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon-dark.png" media="(prefers-color-scheme: dark)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon-dark.svg" media="(prefers-color-scheme: dark)"><link rel="mask-icon" href="https://github.githubassets.com/pinned-octocat.svg" color="#000000"><link href="index.css" rel="stylesheet"></head><body><div class="container-lg px-3 my-5 markdown-body"><div class="position-relative"><span class="profile-color-modes-toggle js-promo-color-modes-toggle" tabindex="0" aria-label="Toggle dark mode" aria-checked="true" role="checkbox"><div class="profile-color-modes-toggle-track" div></div><div class="profile-color-modes-toggle-thumb"><svg style="fill: var(--color-scale-yellow-0); margin: 7px 0 0 7px;" aria-hidden="true" width="14" height="13" viewBox="0 0 14 13" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.52208 7.71754C7.5782 7.71754 10.0557 5.24006 10.0557 2.18394C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961C9.95801 1.07727 10.3495 0.771159 10.6474 0.99992C12.1153 2.12716 13.0615 3.89999 13.0615 5.89383C13.0615 9.29958 10.3006 12.0605 6.89485 12.0605C3.95334 12.0605 1.49286 10.001 0.876728 7.24527C0.794841 6.87902 1.23668 6.65289 1.55321 6.85451C2.41106 7.40095 3.4296 7.71754 4.52208 7.71754Z"></path></svg></div></span></div><script type="text/javascript">(function() {
  var MODE_KEY = 'markdown_to_pages_dark_mode';
  function toggleMode() {
    var mode = document.documentElement.getAttribute('data-color-mode') === 'light' ? 'dark' : 'light';
    document.documentElement.setAttribute('data-color-mode', mode);
    localStorage.setItem(MODE_KEY, mode);
  }
  var mode = localStorage.getItem(MODE_KEY);
  if (mode == null) {
    var query = window.matchMedia('(prefers-color-scheme: dark)');
    mode = query.matches ? 'dark' : 'light';
  }
  document.documentElement.setAttribute('data-color-mode', mode);
  document.querySelector('.profile-color-modes-toggle').onclick = toggleMode;
})();</script><div><div class="markdown-heading"><h2 class="heading-element">EGGS-PTP：一种基于扩展图引导的大型语言模型结构化训练后剪枝方法</h2><a id="user-content-eggs-ptp一种基于扩展图引导的大型语言模型结构化训练后剪枝方法" class="anchor" aria-label="Permalink: EGGS-PTP：一种基于扩展图引导的大型语言模型结构化训练后剪枝方法" href="#eggs-ptp一种基于扩展图引导的大型语言模型结构化训练后剪枝方法"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.09471v1 公告类型：新成果<br>
摘要：随着大语言模型（LLMs）的广泛应用和规模扩张，部署这些巨型基础模型所面临的计算与内存挑战日益严峻。这迫切要求开发更高效的模型变体。面对这一挑战，本研究提出EGGS-PTP方法——一种基于扩展图引导的结构化训练后剪枝技术。该创新方案运用图论来指导N:M结构化剪枝的设计，有效缩减模型规模并降低计算需求。通过引入扩展图的概念，EGGS-PTP能确保剪枝后网络中的信息流动，保留模型的核心功能。大量实验数据表明，EGGS-PTP不仅凭借结构化稀疏性实现了显著的加速效果和内存节省，更在各类大语言模型的准确率指标上超越了现有结构化剪枝技术。</p>
<p>（注：根据学术文本翻译规范，对部分术语进行了标准化处理：</p>
<ol>
<li>"Expander-Graph"译为"扩展图"（图论标准译法）</li>
<li>"Post-training Pruning"译为"训练后剪枝"（机器学习领域通用译法）</li>
<li>保持"N:M"原写法以符合技术文献惯例</li>
<li>"structured sparsity"译为"结构化稀疏性"以准确传达其数学特性）</li>
</ol>
<div class="markdown-heading"><h2 class="heading-element">DQT：基于无去量化嵌套整数运算的动态量化训练</h2><a id="user-content-dqt基于无去量化嵌套整数运算的动态量化训练" class="anchor" aria-label="Permalink: DQT：基于无去量化嵌套整数运算的动态量化训练" href="#dqt基于无去量化嵌套整数运算的动态量化训练"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.09176v1 公告类型：新研究<br>
摘要：在资源受限设备上部署深度神经网络依赖于量化技术。传统的静态均匀量化对所有输入采用固定位宽，无法适应其复杂度变化。基于实例的动态混合精度量化通过按需分配更高精度，有望实现更优的精度-效率权衡。然而，现有方法存在一个关键瓶颈：改变精度时需要昂贵的"反量化-浮点运算-再量化"循环，这不仅打破了纯整数硬件范式，更削弱了性能收益。本文提出的动态量化训练框架（DQT）通过创新设计消除了这一瓶颈。DQT的核心是嵌套整数表示法——将低位宽数值以位级方式嵌入高位宽容器中。该设计结合定制化的纯整数运算，可通过近乎零成本的位移操作实现实时位宽切换。这使得DQT成为首个同时支持以下特性的量化框架：骨干网络的免反量化静态混合精度，以及通过轻量级运行时控制器实现真正高效的实例级动态量化。我们在CIFAR-10数据集（ResNet18）和ImageNet数据集（ResNet50）上验证了DQT的领先性能。在ImageNet上，4位动态量化的ResNet50达到77.00% top-1准确率，优于同类静态方法（LSQ 76.70%）和动态方法（DQNET 76.94%），且计算量（BitOPs）相当。最关键的是，DQT实现位宽转换仅需2820万次简单位移操作，相比先前动态方法所需的5660万次高成本浮点乘累加（MAC）运算，开创了高效自适应AI的新纪元。</p>
<div class="markdown-heading"><h2 class="heading-element">MoQE：通过混合量化专家提升量化模型性能</h2><a id="user-content-moqe通过混合量化专家提升量化模型性能" class="anchor" aria-label="Permalink: MoQE：通过混合量化专家提升量化模型性能" href="#moqe通过混合量化专家提升量化模型性能"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.09204v1 公告类型：新研究<br>
摘要：量化方法在提升模型效率、降低部署成本方面具有关键作用，使得深度学习模型能够在资源受限设备上广泛应用。然而量化过程不可避免地会引发精度损失。本文提出基于混合专家架构的量化推理框架MoQE（量化专家混合体），旨在协同提升量化模型的性能表现。该框架将全精度模型的多个量化变体组合为专业化的"量化专家"，并根据输入数据特征动态路由至最合适的专家节点。通过这种专家模型专业化分工，MoQE有效缓解了单一量化模型常见的性能下降问题。我们针对CV和NLP任务分别设计了轻量级、结构感知的路由器模型。在ResNet、LLaMA和Qwen模型家族上的实验评估表明，在ImageNet、WikiText、C4和OpenWebText等基准数据集上，MoQE达到了与当前最优量化模型相当的性能水平，且未显著增加推理延迟。</p>
<p>（注：根据学术文献翻译规范，对部分术语进行了标准化处理：</p>
<ol>
<li>"SOTA"译为"当前最优"而非字面直译</li>
<li>模型名称LLaMA/Qwen保留原名不译</li>
<li>技术术语"router models"译为"路由器模型"以保持架构一致性</li>
<li>数据集名称统一采用英文原名</li>
<li>"specialization quantization expert models"采用意译"专家模型专业化分工"以符合中文表达习惯）</li>
</ol>
<div class="markdown-heading"><h2 class="heading-element">MiCo：面向边缘AI的端到端混合精度神经网络协同探索框架</h2><a id="user-content-mico面向边缘ai的端到端混合精度神经网络协同探索框架" class="anchor" aria-label="Permalink: MiCo：面向边缘AI的端到端混合精度神经网络协同探索框架" href="#mico面向边缘ai的端到端混合精度神经网络协同探索框架"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2508.09500v1 公告类型：新成果<br>
摘要：极低比特位宽的量化神经网络（QNN）已被证实在边缘设备的高效存储与计算方面具有显著优势。为在提升加速比的同时进一步降低精度损失，分层混合精度量化（MPQ）逐渐成为主流解决方案。然而现有MPQ方案搜索算法在灵活性与效率上存在局限——传统方法难以全面评估不同MPQ方案对训练后量化与量化感知训练结果的复杂影响。此外，当前研究尚缺乏支持MPQ模型优化与部署的端到端框架。</p>
<p>本文提出MiCo框架，这是面向边缘AI应用的混合精度量化全流程解决方案。该框架采用创新优化算法搜索满足时延约束条件下的最优量化方案，通过为不同硬件目标构建时延感知模型实现快速方案探索。探索完成后，框架支持从PyTorch MPQ模型直接部署为裸机C代码，在实现端到端加速的同时将精度损失控制在最小范围。</p>
<p>（注：根据学术文献翻译规范，对部分术语进行了专业处理：</p>
<ol>
<li>"bare-metal C codes"译为"裸机C代码"以体现直接运行在硬件层的特性</li>
<li>"holistic"译为"全流程"突出框架的完整性</li>
<li>将原文两个长句拆分为符合中文阅读习惯的短句结构</li>
<li>保留专业缩写QNN/MPQ并在首次出现时标注全称</li>
<li>"latency constraints"统一译为"时延约束"保持术语一致性）</li>
</ol>
</div></div><div class="footer container-xl width-full p-responsive"><div class="position-relative flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between pt-4 pb-4 mt-6 f6 color-text-secondary border-top color-border-secondary text-center"><div class="footer-octicon d-lg-block mx-lg-4"><a title="LLIKKE/Arxiv_GPT_Assistant" href="https://github.com/LLIKKE/Arxiv_GPT_Assistant" target="_blank" rel="noreferrer noopener"><svg class="octicon octicon-mark-github gh-logo" width="36" height="36" viewBox="0 0 98 98" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"></path></svg></a></div><span class="mt-2 d-block footprint"><span>powered by </span><a href="https://github.com/wranders/markdown-to-pages-action" target="_blank" rel="noreferrer noopener">markdown-to-pages-action</a></span></div></div></body></html>