<!DOCTYPE html><html data-color-mode="light" data-light-theme="light" data-dark-theme="dark" lang="en-US"><head><title>LLIKKE/Arxiv_GPT_Assistant</title><meta charset="utf-8"><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="description" content="Deepseek based personalized ArXiv paper assistant bot"><link rel="canonical" href="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta property="og:type" content="website"><meta property="og:url" content="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:description" content="Deepseek based personalized ArXiv paper assistant bot"><meta property="og:locale" content="en_US"><meta property="og:site_name" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:description" content="Deepseek based personalized ArXiv paper assistant bot"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon.png" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon.svg" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon-dark.png" media="(prefers-color-scheme: dark)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon-dark.svg" media="(prefers-color-scheme: dark)"><link rel="mask-icon" href="https://github.githubassets.com/pinned-octocat.svg" color="#000000"><link href="index.css" rel="stylesheet"></head><body><div class="container-lg px-3 my-5 markdown-body"><div class="position-relative"><span class="profile-color-modes-toggle js-promo-color-modes-toggle" tabindex="0" aria-label="Toggle dark mode" aria-checked="true" role="checkbox"><div class="profile-color-modes-toggle-track" div></div><div class="profile-color-modes-toggle-thumb"><svg style="fill: var(--color-scale-yellow-0); margin: 7px 0 0 7px;" aria-hidden="true" width="14" height="13" viewBox="0 0 14 13" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.52208 7.71754C7.5782 7.71754 10.0557 5.24006 10.0557 2.18394C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961C9.95801 1.07727 10.3495 0.771159 10.6474 0.99992C12.1153 2.12716 13.0615 3.89999 13.0615 5.89383C13.0615 9.29958 10.3006 12.0605 6.89485 12.0605C3.95334 12.0605 1.49286 10.001 0.876728 7.24527C0.794841 6.87902 1.23668 6.65289 1.55321 6.85451C2.41106 7.40095 3.4296 7.71754 4.52208 7.71754Z"></path></svg></div></span></div><script type="text/javascript">(function() {
  var MODE_KEY = 'markdown_to_pages_dark_mode';
  function toggleMode() {
    var mode = document.documentElement.getAttribute('data-color-mode') === 'light' ? 'dark' : 'light';
    document.documentElement.setAttribute('data-color-mode', mode);
    localStorage.setItem(MODE_KEY, mode);
  }
  var mode = localStorage.getItem(MODE_KEY);
  if (mode == null) {
    var query = window.matchMedia('(prefers-color-scheme: dark)');
    mode = query.matches ? 'dark' : 'light';
  }
  document.documentElement.setAttribute('data-color-mode', mode);
  document.querySelector('.profile-color-modes-toggle').onclick = toggleMode;
})();</script><div><div class="markdown-heading"><h2 class="heading-element">安全修剪LoRA：大语言模型适应中基于距离引导的鲁棒性修剪以保障安全对齐</h2><a id="user-content-安全修剪lora大语言模型适应中基于距离引导的鲁棒性修剪以保障安全对齐" class="anchor" aria-label="Permalink: 安全修剪LoRA：大语言模型适应中基于距离引导的鲁棒性修剪以保障安全对齐" href="#安全修剪lora大语言模型适应中基于距离引导的鲁棒性修剪以保障安全对齐"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2506.18931v1 公告类型：新研究<br>
摘要：采用低秩自适应（LoRA）对大型语言模型（LLM）进行微调，能在降低计算成本的同时提升模型适应性。然而，微调过程可能破坏模型的安全对齐性——即使使用良性数据也会增加有害输出的风险。现有安全对齐方法难以捕捉复杂的参数变化，导致安全性与实用性的权衡失衡。为此，我们提出安全剪枝LoRA（SPLoRA），通过选择性移除削弱安全对齐的LoRA层，在保持性能的同时提升安全性。其核心是创新性提出的E-DIEM评估指标，这种维度不敏感的相似性度量能有效检测LoRA适配模型的安全偏差。我们在混合恶意/良性数据及纯良性数据微调的LLMs上进行了全面实验，从实用性、安全性和可靠性多维度评估SPLoRA。结果表明，SPLoRA显著优于现有安全对齐技术，在维持或提升模型性能的同时大幅降低安全风险。此外，SPLoRA还能减少推理开销，为部署更安全可靠的LLM提供了可扩展的高效解决方案。代码已开源：<a href="https://github.com/AoShuang92/SPLoRA">https://github.com/AoShuang92/SPLoRA</a></p>
<p>（注：E-DIEM保留英文缩写形式以符合学术惯例，首次出现时补充说明"Empirical-DIEM"；"dimension-insensitive similarity metric"译为"维度不敏感的相似性度量"以准确传达技术特性；长复合句按中文表达习惯拆分为短句，如将原文核心方法描述重组为"其核心是..."的递进句式；专业术语如"Low-Rank Adaptation"沿用业界通用译名"低秩自适应"。）</p>
<div class="markdown-heading"><h2 class="heading-element">异常值安全的预训练：面向大语言模型稳健4位量化的方法</h2><a id="user-content-异常值安全的预训练面向大语言模型稳健4位量化的方法" class="anchor" aria-label="Permalink: 异常值安全的预训练：面向大语言模型稳健4位量化的方法" href="#异常值安全的预训练面向大语言模型稳健4位量化的方法"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2506.19697v1 公告类型：新研究<br>
摘要：大语言模型（LLMs）中的极端激活异常值会严重降低量化性能，阻碍高效的设备端部署。尽管通道级操作和自适应梯度缩放已被确认为成因，但实际缓解仍具挑战性。我们提出"异常值安全预训练"（OSP），这是一套主动预防异常值形成的实用准则，而非依赖事后补救。OSP融合了三大创新：（1）Muon优化器，在保持训练效率的同时消除特权基向量；（2）单尺度RMSNorm，防止通道级放大效应；（3）可学习的嵌入投影，重新分配源自嵌入矩阵的激活强度。我们通过在1万亿token上训练14亿参数模型验证OSP，这是首个无此类异常值的生产级LLM。在激进的4比特量化下，OSP模型在10个基准测试中平均得分达35.7（对比Adam训练模型的26.5），仅带来2%的训练开销。值得注意的是，OSP模型的超额峰度接近零（0.04），而标准模型该值极高（1818.56），从根本上改变了LLM的量化行为。我们的工作证明异常值并非LLM固有特性，而是训练策略的产物，为更高效的LLM部署铺平道路。源代码与预训练模型见<a href="https://github.com/dmis-lab/Outlier-Safe-Pre-Training%E3%80%82">https://github.com/dmis-lab/Outlier-Safe-Pre-Training。</a></p>
<p>（注：根据学术文献翻译规范，技术术语如"RMSNorm"、"kurtosis"等保留英文原名；长句按中文表达习惯拆分；被动语态转为主动表述；项目名称"OSP"首次出现时标注全称；URL保留原格式以确保可访问性）</p>
<div class="markdown-heading"><h2 class="heading-element">预算有限也能玩转大模型？试试HOLA</h2><a id="user-content-预算有限也能玩转大模型试试hola" class="anchor" aria-label="Permalink: 预算有限也能玩转大模型？试试HOLA" href="#预算有限也能玩转大模型试试hola"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>arXiv:2506.18952v1 公告类型：新成果<br>
摘要：在边缘设备上运行大语言模型（LLM）受限于高计算量和内存需求，这阻碍了医疗、教育和嵌入式系统等领域实时应用的发展。现有解决方案如量化、剪枝和检索增强生成（RAG）仅能实现局部优化，且往往需要牺牲速度或准确性。我们提出HOLA——一个面向高效LLM部署的端到端优化框架。其内部采用分层推测解码（HSD）技术实现无损加速推理；外部通过AdaComp-RAG动态调整检索复杂度以适应上下文需求。结合融合结构化剪枝（LoRA）与量化的LoBi技术，HOLA实现了显著性能提升：在GSM8K基准上获得17.6%的EMA提升，ARC基准上MCA提升10.5%，并在Jetson Nano等边缘设备上降低延迟与内存占用，兼具可扩展性与生产环境就绪性。</p>
<p>（注：专业术语处理说明：</p>
<ol>
<li>EMA/MCA保留英文缩写+中文全称（指数移动平均/多选准确率）</li>
<li>LoRA/LoBi等技术术语首次出现时保留英文缩写+括号注释</li>
<li>"production-ready"译为"生产环境就绪性"符合技术文档惯例</li>
<li>长难句拆分重构，如将"Together with..."独立为短句保持中文表达习惯）</li>
</ol>
</div></div><div class="footer container-xl width-full p-responsive"><div class="position-relative flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between pt-4 pb-4 mt-6 f6 color-text-secondary border-top color-border-secondary text-center"><div class="footer-octicon d-lg-block mx-lg-4"><a title="LLIKKE/Arxiv_GPT_Assistant" href="https://github.com/LLIKKE/Arxiv_GPT_Assistant" target="_blank" rel="noreferrer noopener"><svg class="octicon octicon-mark-github gh-logo" width="36" height="36" viewBox="0 0 98 98" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"></path></svg></a></div><span class="mt-2 d-block footprint"><span>powered by </span><a href="https://github.com/wranders/markdown-to-pages-action" target="_blank" rel="noreferrer noopener">markdown-to-pages-action</a></span></div></div></body></html>