<!DOCTYPE html><html data-color-mode="light" data-light-theme="light" data-dark-theme="dark" lang="en-US"><head><title>LLIKKE/Arxiv_GPT_Assistant</title><meta charset="utf-8"><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="description" content="Deepseek based personalized ArXiv paper assistant bot"><link rel="canonical" href="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta property="og:type" content="website"><meta property="og:url" content="https://llikke.github.io/Arxiv_GPT_Assistant/"><meta property="og:description" content="Deepseek based personalized ArXiv paper assistant bot"><meta property="og:locale" content="en_US"><meta property="og:site_name" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="LLIKKE/Arxiv_GPT_Assistant"><meta name="twitter:description" content="Deepseek based personalized ArXiv paper assistant bot"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon.png" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon.svg" media="(prefers-color-scheme: light)"><link class="js-site-favicon" rel="alternate icon" type="image/png" href="https://github.githubassets.com/favicons/favicon-dark.png" media="(prefers-color-scheme: dark)"><link class="js-site-favicon" rel="icon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon-dark.svg" media="(prefers-color-scheme: dark)"><link rel="mask-icon" href="https://github.githubassets.com/pinned-octocat.svg" color="#000000"><link href="index.css" rel="stylesheet"></head><body><div class="container-lg px-3 my-5 markdown-body"><div class="position-relative"><span class="profile-color-modes-toggle js-promo-color-modes-toggle" tabindex="0" aria-label="Toggle dark mode" aria-checked="true" role="checkbox"><div class="profile-color-modes-toggle-track" div></div><div class="profile-color-modes-toggle-thumb"><svg style="fill: var(--color-scale-yellow-0); margin: 7px 0 0 7px;" aria-hidden="true" width="14" height="13" viewBox="0 0 14 13" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.52208 7.71754C7.5782 7.71754 10.0557 5.24006 10.0557 2.18394C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961C9.95801 1.07727 10.3495 0.771159 10.6474 0.99992C12.1153 2.12716 13.0615 3.89999 13.0615 5.89383C13.0615 9.29958 10.3006 12.0605 6.89485 12.0605C3.95334 12.0605 1.49286 10.001 0.876728 7.24527C0.794841 6.87902 1.23668 6.65289 1.55321 6.85451C2.41106 7.40095 3.4296 7.71754 4.52208 7.71754Z"></path></svg></div></span></div><script type="text/javascript">(function() {
  var MODE_KEY = 'markdown_to_pages_dark_mode';
  function toggleMode() {
    var mode = document.documentElement.getAttribute('data-color-mode') === 'light' ? 'dark' : 'light';
    document.documentElement.setAttribute('data-color-mode', mode);
    localStorage.setItem(MODE_KEY, mode);
  }
  var mode = localStorage.getItem(MODE_KEY);
  if (mode == null) {
    var query = window.matchMedia('(prefers-color-scheme: dark)');
    mode = query.matches ? 'dark' : 'light';
  }
  document.documentElement.setAttribute('data-color-mode', mode);
  document.querySelector('.profile-color-modes-toggle').onclick = toggleMode;
})();</script><div><div class="markdown-heading"><h1 class="heading-element">Personalized Daily Arxiv Papers 08/26/2025</h1><a id="user-content-personalized-daily-arxiv-papers-08262025" class="anchor" aria-label="Permalink: Personalized Daily Arxiv Papers 08/26/2025" href="#personalized-daily-arxiv-papers-08262025"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p>Total relevant papers: 63</p>
<p>Paper selection prompt and criteria at the bottom</p>
<p>Table of contents with paper titles:</p>
<ol start="0">
<li>
<p><a href="#link0">Reconciling Communication Compression and Byzantine-Robustness in Distributed Learning</a>
<strong>Authors:</strong> Diksha Gupta, Nirupam Gupta, Chuan Xu, Giovanni Neglia</p>
</li>
<li>
<p><a href="#link1">A Human-In-The-Loop Approach for Improving Fairness in Predictive Business Process Monitoring</a>
<strong>Authors:</strong> Martin K"appel, Julian Neuberger, Felix M"ohrlein, Sven Weinzierl, Martin Matzner, Stefan Jablonski</p>
</li>
<li>
<p><a href="#link2">BudgetThinker: Empowering Budget-aware LLM Reasoning with Control Tokens</a>
<strong>Authors:</strong> Hao Wen, Xinrui Wu, Yi Sun, Feifei Zhang, Liye Chen, Jie Wang, Yunxin Liu, Ya-Qin Zhang, Yuanchun Li</p>
</li>
<li>
<p><a href="#link3">Limits of message passing for node classification: How class-bottlenecks restrict signal-to-noise ratio</a>
<strong>Authors:</strong> Jonathan Rubin, Sahil Loomba, Nick S. Jones</p>
</li>
<li>
<p><a href="#link4">Anchor-MoE: A Mean-Anchored Mixture of Experts For Probabilistic Regression</a>
<strong>Authors:</strong> Baozhuo Su, Zhengxian Qu</p>
</li>
<li>
<p><a href="#link5">Mimicking the Physicist's Eye:A VLM-centric Approach for Physics Formula Discovery</a>
<strong>Authors:</strong> Jiaqi Liu, Songning Lai, Pengze Li, Di Yu, Wenjie Zhou, Yiyang Zhou, Peng Xia, Zijun Wang, Xi Chen, Shixiang Tang, Lei Bai, Wanli Ouyang, Mingyu Ding, Huaxiu Yao, Aoran Wang</p>
</li>
<li>
<p><a href="#link6">FlowVLA: Thinking in Motion with a Visual Chain of Thought</a>
<strong>Authors:</strong> Zhide Zhong, Haodong Yan, Junfeng Li, Xiangchen Liu, Xin Gong, Wenxuan Song, Jiayi Chen, Haoang Li</p>
</li>
<li>
<p><a href="#link7">Module-Aware Parameter-Efficient Machine Unlearning on Transformers</a>
<strong>Authors:</strong> Wenjie Bao, Jian Lou, Yuke Hu, Xiaochen Li, Zhihao Liu, Jiaqi Liu, Zhan Qin, Kui Ren</p>
</li>
<li>
<p><a href="#link8">MoE-Inference-Bench: Performance Evaluation of Mixture of Expert Large Language and Vision Models</a>
<strong>Authors:</strong> Krishna Teja Chitty-Venkata, Sylvia Howland, Golara Azar, Daria Soboleva, Natalia Vassilieva, Siddhisanket Raskar, Murali Emani, Venkatram Vishwanath</p>
</li>
<li>
<p><a href="#link9">ShortListing Model: A Streamlined SimplexDiffusion for Discrete Variable Generation</a>
<strong>Authors:</strong> Yuxuan Song, Zhe Zhang, Yu Pei, Jingjing Gong, Qiying Yu, Zheng Zhang, Mingxuan Wang, Hao Zhou, Jingjing Liu, Wei-Ying Ma</p>
</li>
<li>
<p><a href="#link10">Neural Algorithmic Reasoners informed Large Language Model for Multi-Agent Path Finding</a>
<strong>Authors:</strong> Pu Feng, Size Wang, Yuhong Cao, Junkang Liang, Rongye Shi, Wenjun Wu</p>
</li>
<li>
<p><a href="#link11">Meta-R1: Empowering Large Reasoning Models with Metacognition</a>
<strong>Authors:</strong> Haonan Dong, Haoran Ye, Wenhao Zhu, Kehan Jiang, Guojie Song</p>
</li>
<li>
<p><a href="#link12">PowerChain: Automating Distribution Grid Analysis with Agentic AI Workflows</a>
<strong>Authors:</strong> Emmanuel O. Badmus, Peng Sang, Dimitrios Stamoulis, Amritanshu Pandey</p>
</li>
<li>
<p><a href="#link13">CALR: Corrective Adaptive Low-Rank Decomposition for Efficient Large Language Model Layer Compression</a>
<strong>Authors:</strong> Muchammad Daniyal Kautsar, Afra Majida Hariono, Widyawan, Syukron Abu Ishaq Alfarozi, Kuntpong Wararatpanya</p>
</li>
<li>
<p><a href="#link14">SuperGen: An Efficient Ultra-high-resolution Video Generation System with Sketching and Tiling</a>
<strong>Authors:</strong> Fanjiang Ye, Zepeng Zhao, Yi Mu, Jucheng Shen, Renjie Li, Kaijian Wang, Desen Sun, Saurabh Agarwal, Myungjin Lee, Triston Cao, Aditya Akella, Arvind Krishnamurthy, T. S. Eugene Ng, Zhengzhong Tu, Yuke Wang</p>
</li>
<li>
<p><a href="#link15">A Novel Framework for Uncertainty Quantification via Proper Scores for Classification and Beyond</a>
<strong>Authors:</strong> Sebastian G. Gruber</p>
</li>
<li>
<p><a href="#link16">Tri-Accel: Curvature-Aware Precision-Adaptive and Memory-Elastic Optimization for Efficient GPU Usage</a>
<strong>Authors:</strong> Mohsen Sheibanian, Pouya Shaeri, Alimohammad Beigi, Ryan T. Woo, Aryan Keluskar</p>
</li>
<li>
<p><a href="#link17">Learned Structure in CARTRIDGES: Keys as Shareable Routers in Self-Studied Representations</a>
<strong>Authors:</strong> Maurizio Diaz</p>
</li>
<li>
<p><a href="#link18">Speculative Safety-Aware Decoding</a>
<strong>Authors:</strong> Xuekang Wang, Shengyu Zhu, Xueqi Cheng</p>
</li>
<li>
<p><a href="#link19">Exploring Efficient Learning of Small BERT Networks with LoRA and DoRA</a>
<strong>Authors:</strong> Daniel Frees, Aditri Bhagirath, Moritz Bolling</p>
</li>
<li>
<p><a href="#link20">SafeBimanual: Diffusion-based Trajectory Optimization for Safe Bimanual Manipulation</a>
<strong>Authors:</strong> Haoyuan Deng, Wenkai Guo, Qianzhun Wang, Zhenyu Wu, Ziwei Wang</p>
</li>
<li>
<p><a href="#link21">DR-CircuitGNN: Training Acceleration of Heterogeneous Circuit Graph Neural Network on GPUs</a>
<strong>Authors:</strong> Yuebo Luo, Shiyang Li, Junran Tao, Kiran Thorat, Xi Xie, Hongwu Peng, Nuo Xu, Caiwen Ding, Shaoyi Huang</p>
</li>
<li>
<p><a href="#link22">UM3: Unsupervised Map to Map Matching</a>
<strong>Authors:</strong> Chaolong Ying, Yinan Zhang, Lei Zhang, Jiazhuang Wang, Shujun Jia, Tianshu Yu</p>
</li>
<li>
<p><a href="#link23">Generative Feature Imputing - A Technique for Error-resilient Semantic Communication</a>
<strong>Authors:</strong> Jianhao Huang, Qunsong Zeng, Hongyang Du, Kaibin Huang</p>
</li>
<li>
<p><a href="#link24">Effective Clustering for Large Multi-Relational Graphs</a>
<strong>Authors:</strong> Xiaoyang Lin, Runhao Jiang, Renchi Yang</p>
</li>
<li>
<p><a href="#link25">Frozen in Time: Parameter-Efficient Time Series Transformers via Reservoir-Induced Feature Expansion and Fixed Random Dynamics</a>
<strong>Authors:</strong> Pradeep Singh, Mehak Sharma, Anupriya Dey, Balasubramanian Raman</p>
</li>
<li>
<p><a href="#link26">Optimizing Grasping in Legged Robots: A Deep Learning Approach to Loco-Manipulation</a>
<strong>Authors:</strong> Dilermando Almeida, Guilherme Lazzarini, Juliano Negri, Thiago H. Segreto, Ricardo V. Godoy, Marcelo Becker</p>
</li>
<li>
<p><a href="#link27">Amortized Sampling with Transferable Normalizing Flows</a>
<strong>Authors:</strong> Charlie B. Tan, Majdi Hassan, Leon Klein, Saifuddin Syed, Dominique Beaini, Michael M. Bronstein, Alexander Tong, Kirill Neklyudov</p>
</li>
<li>
<p><a href="#link28">Quantum Graph Attention Network: A Novel Quantum Multi-Head Attention Mechanism for Graph Learning</a>
<strong>Authors:</strong> An Ning, Tai Yue Li, Nan Yow Chen</p>
</li>
<li>
<p><a href="#link29">FRAME : Comprehensive Risk Assessment Framework for Adversarial Machine Learning Threats</a>
<strong>Authors:</strong> Avishag Shapira, Simon Shigol, Asaf Shabtai</p>
</li>
<li>
<p><a href="#link30">GateTS: Versatile and Efficient Forecasting via Attention-Inspired routed Mixture-of-Experts</a>
<strong>Authors:</strong> Kyrylo Yemets, Mykola Lukashchuk, Ivan Izonin</p>
</li>
<li>
<p><a href="#link31">TradingGroup: A Multi-Agent Trading System with Self-Reflection and Data-Synthesis</a>
<strong>Authors:</strong> Feng Tian, Flora D. Salim, Hao Xue</p>
</li>
<li>
<p><a href="#link32">Enhancing Transformer-Based Foundation Models for Time Series Forecasting via Bagging, Boosting and Statistical Ensembles</a>
<strong>Authors:</strong> Dhruv D. Modi, Rong Pan</p>
</li>
<li>
<p><a href="#link33">A Dataset and Benchmark for Robotic Cloth Unfolding Grasp Selection: The ICRA 2024 Cloth Competition</a>
<strong>Authors:</strong> Victor-Louis De Gusseme, Thomas Lips, Remko Proesmans, Julius Hietala, Giwan Lee, Jiyoung Choi, Jeongil Choi, Geon Kim, Phayuth Yonrith, Domen Tabernik, Andrej Gams, Peter Nimac, Matej Urbas, Jon Muhovi\v{c}, Danijel Sko\v{c}aj, Matija Mavsar, Hyojeong Yu, Minseo Kwon, Young J. Kim, Yang Cong, Ronghan Chen, Yu Ren, Supeng Diao, Jiawei Weng, Jiayue Liu, Haoran Sun, Linhan Yang, Zeqing Zhang, Ning Guo, Lei Yang, Fang Wan, Chaoyang Song, Jia Pan, Yixiang Jin, Yong A, Jun Shi, Dingzhe Li, Yong Yang, Kakeru Yamasaki, Takumi Kajiwara, Yuki Nakadera, Krati Saxena, Tomohiro Shibata, Chongkun Xia, Kai Mo, Yanzhao Yu, Qihao Lin, Binqiang Ma, Uihun Sagong, JungHyun Choi, JeongHyun Park, Dongwoo Lee, Yeongmin Kim, Myun Joong Hwang, Yusuke Kuribayashi, Naoki Hiratsuka, Daisuke Tanaka, Solvi Arnold, Kimitoshi Yamazaki, Carlos Mateo-Agullo, Andreas Verleysen, Francis Wyffels</p>
</li>
<li>
<p><a href="#link34">AdapSNE: Adaptive Fireworks-Optimized and Entropy-Guided Dataset Sampling for Edge DNN Training</a>
<strong>Authors:</strong> Boran Zhao, Hetian Liu, Zihang Yuan, Li Zhu, Fan Yang, Lina Xie Tian Xia, Wenzhe Zhao, Pengju Ren</p>
</li>
<li>
<p><a href="#link35">TiKMiX: Take Data Influence into Dynamic Mixture for Language Model Pre-training</a>
<strong>Authors:</strong> Yifan Wang, Binbin Liu, Fengze Liu, Yuanfan Guo, Jiyao Deng, Xuecheng Wu, Weidong Zhou, Xiaohuan Zhou, Taifeng Wang</p>
</li>
<li>
<p><a href="#link36">Learning ON Large Datasets Using Bit-String Trees</a>
<strong>Authors:</strong> Prashant Gupta</p>
</li>
<li>
<p><a href="#link37">Drive As You Like: Strategy-Level Motion Planning Based on A Multi-Head Diffusion Model</a>
<strong>Authors:</strong> Fan Ding, Xuewen Luo, Hwa Hui Tew, Ruturaj Reddy, Xikun Wang, Junn Yong Loo</p>
</li>
<li>
<p><a href="#link38">OVITA: Open-Vocabulary Interpretable Trajectory Adaptations</a>
<strong>Authors:</strong> Anurag Maurya, Tashmoy Ghosh, Anh Nguyen, Ravi Prakash</p>
</li>
<li>
<p><a href="#link39">WISCA: A Lightweight Model Transition Method to Improve LLM Training via Weight Scaling</a>
<strong>Authors:</strong> Jiacheng Li, Jianchao Tan, Zhidong Yang, Pingwei Sun, Feiye Huo, Jiayu Qin, Yerui Sun, Yuchen Xie, Xunliang Cai, Xiangyu Zhang, Maoxin He, Guangming Tan, Weile Jia, Tong Zhao</p>
</li>
<li>
<p><a href="#link40">AdLoCo: adaptive batching significantly improves communications efficiency and convergence for Large Language Models</a>
<strong>Authors:</strong> Nikolay Kutuzov, Makar Baderko, Stepan Kulibaba, Artem Dzhalilov, Daniel Bobrov, Maxim Mashtaler, Alexander Gasnikov</p>
</li>
<li>
<p><a href="#link41">LLM-based Agentic Reasoning Frameworks: A Survey from Methods to Scenarios</a>
<strong>Authors:</strong> Bingxi Zhao, Lin Geng Foo, Ping Hu, Christian Theobalt, Hossein Rahmani, Jun Liu</p>
</li>
<li>
<p><a href="#link42">Riemannian Optimization for LoRA on the Stiefel Manifold</a>
<strong>Authors:</strong> Juneyoung Park, Minjae Kang, Seongbae Lee, Haegang Lee, Seongwan Kim, Jaeho Lee</p>
</li>
<li>
<p><a href="#link43">Modular MeanFlow: Towards Stable and Scalable One-Step Generative Modeling</a>
<strong>Authors:</strong> Haochen You, Baojing Liu, Hongyang He</p>
</li>
<li>
<p><a href="#link44">PerPilot: Personalizing VLM-based Mobile Agents via Memory and Exploration</a>
<strong>Authors:</strong> Xin Wang, Zhiyao Cui, Hao Li, Ya Zeng, Chenxu Wang, Ruiqi Song, Yihang Chen, Kun Shao, Qiaosheng Zhang, Jinzhuo Liu, Siyue Ren, Shuyue Hu, Zhen Wang</p>
</li>
<li>
<p><a href="#link45">Puzzle: Scheduling Multiple Deep Learning Models on Mobile Device with Heterogeneous Processors</a>
<strong>Authors:</strong> Duseok Kang, Yunseong Lee, Junghoon Kim</p>
</li>
<li>
<p><a href="#link46">HiCL: Hippocampal-Inspired Continual Learning</a>
<strong>Authors:</strong> Kushal Kapoor, Wyatt Mackey, Yiannis Aloimonos, Xiaomin Lin</p>
</li>
<li>
<p><a href="#link47">Sig-DEG for Distillation: Making Diffusion Models Faster and Lighter</a>
<strong>Authors:</strong> Lei Jiang, Wen Ge, Niels Cariou-Kotlarek, Mingxuan Yi, Po-Yu Chen, Lingyi Yang, Francois Buet-Golfouse, Gaurav Mittal, Hao Ni</p>
</li>
<li>
<p><a href="#link48">MoE-Beyond: Learning-Based Expert Activation Prediction on Edge Devices</a>
<strong>Authors:</strong> Nishant Gavhane, Arush Mehrotra, Rohit Chawla, Peter Proenca</p>
</li>
<li>
<p><a href="#link49">Reinforcement-Guided Hyper-Heuristic Hyperparameter Optimization for Fair and Explainable Spiking Neural Network-Based Financial Fraud Detection</a>
<strong>Authors:</strong> Sadman Mohammad Nasif, Md Abrar Jahin, M. F. Mridha</p>
</li>
<li>
<p><a href="#link50">Characterizing the Behavior of Training Mamba-based State Space Models on GPUs</a>
<strong>Authors:</strong> Trinayan Baruah, Kaustubh Shivdikar, Sara Prescott, David Kaeli</p>
</li>
<li>
<p><a href="#link51">Topology Aware Neural Interpolation of Scalar Fields</a>
<strong>Authors:</strong> Mohamed Kissi, Keanu Sisouk, Joshua A. Levine, Julien Tierny</p>
</li>
<li>
<p><a href="#link52">AdaptiveK Sparse Autoencoders: Dynamic Sparsity Allocation for Interpretable LLM Representations</a>
<strong>Authors:</strong> Yifei Yao, Mengnan Du</p>
</li>
<li>
<p><a href="#link53">In-Context Algorithm Emulation in Fixed-Weight Transformers</a>
<strong>Authors:</strong> Jerry Yao-Chieh Hu, Hude Liu, Jennifer Yuntong Zhang, Han Liu</p>
</li>
<li>
<p><a href="#link54">Multi-layer Abstraction for Nested Generation of Options (MANGO) in Hierarchical Reinforcement Learning</a>
<strong>Authors:</strong> Alessio Arcudi, Davide Sartor, Alberto Sinigaglia, Vincent Fran\c{c}ois-Lavet, Gian Antonio Susto</p>
</li>
<li>
<p><a href="#link55">Scene-Agnostic Traversability Labeling and Estimation via a Multimodal Self-supervised Framework</a>
<strong>Authors:</strong> Zipeng Fang, Yanbo Wang, Lei Zhao, Weidong Chen</p>
</li>
<li>
<p><a href="#link56">Attention Layers Add Into Low-Dimensional Residual Subspaces</a>
<strong>Authors:</strong> Junxuan Wang, Xuyang Ge, Wentao Shu, Zhengfu He, Xipeng Qiu</p>
</li>
<li>
<p><a href="#link57">A Retrieval Augmented Spatio-Temporal Framework for Traffic Prediction</a>
<strong>Authors:</strong> Weilin Ruan, Xilin Dang, Ziyu Zhou, Sisuo Lyu, Yuxuan Liang</p>
</li>
<li>
<p><a href="#link58">Few-shot Class-incremental Fault Diagnosis by Preserving Class-Agnostic Knowledge with Dual-Granularity Representations</a>
<strong>Authors:</strong> Zhendong Yang, Jie Wang, Liansong Zong, Xiaorong Liu, Quan Qian, Shiqian Chen</p>
</li>
<li>
<p><a href="#link59">AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration</a>
<strong>Authors:</strong> Aditri Paul, Archan Paul</p>
</li>
<li>
<p><a href="#link60">Aligning Distributionally Robust Optimization with Practical Deep Learning Needs</a>
<strong>Authors:</strong> Dmitrii Feoktistov, Igor Ignashin, Andrey Veprikov, Nikita Borovko, Alexander Bogdanov, Savelii Chezhegov, Aleksandr Beznosikov</p>
</li>
<li>
<p><a href="#link61">TreePO: Bridging the Gap of Policy Optimization and Efficacy and Inference Efficiency with Heuristic Tree-based Modeling</a>
<strong>Authors:</strong> Yizhi Li, Qingshui Gu, Zhoufutu Wen, Ziniu Li, Tianshun Xing, Shuyue Guo, Tianyu Zheng, Xin Zhou, Xingwei Qu, Wangchunshu Zhou, Zheng Zhang, Wei Shen, Qian Liu, Chenghua Lin, Jian Yang, Ge Zhang, Wenhao Huang</p>
</li>
<li>
<p><a href="#link62">Interpreting the Effects of Quantization on LLMs</a>
<strong>Authors:</strong> Manpreet Singh, Hassan Sajjad</p>
</li>
</ol>
<hr>
<div class="markdown-heading"><h2 class="heading-element">0. <a href="https://arxiv.org/abs/2508.17129" rel="nofollow">Reconciling Communication Compression and Byzantine-Robustness in Distributed Learning</a> <a id="user-content-link0"></a>
</h2><a id="user-content-0-reconciling-communication-compression-and-byzantine-robustness-in-distributed-learning-" class="anchor" aria-label="Permalink: 0. Reconciling Communication Compression and Byzantine-Robustness in Distributed Learning" href="#0-reconciling-communication-compression-and-byzantine-robustness-in-distributed-learning-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.17129
<strong>Authors:</strong> Diksha Gupta, Nirupam Gupta, Chuan Xu, Giovanni Neglia</p>
<p><strong>Abstract:</strong> arXiv:2508.17129v1 Announce Type: new  Abstract: Distributed learning (DL) enables scalable model training over decentralized data, but remains challenged by Byzantine faults and high communication costs. While both issues have been studied extensively in isolation, their interaction is less explored. Prior work shows that naively combining communication compression with Byzantine-robust aggregation degrades resilience to faulty nodes (or workers). The state-of-the-art algorithm, namely Byz-DASHA-PAGE [29], makes use of the momentum variance reduction scheme to mitigate the detrimental impact of compression noise on Byzantine-robustness. We propose a new algorithm, named RoSDHB, that integrates the classic Polyak's momentum with a new coordinated compression mechanism. We show that RoSDHB performs comparably to Byz-DASHA-PAGE under the standard (G, B)-gradient dissimilarity heterogeneity model, while it relies on fewer assumptions. In particular, we only assume Lipschitz smoothness of the average loss function of the honest workers, in contrast to [29]that additionally assumes a special smoothness of bounded global Hessian variance. Empirical results on benchmark image classification task show that RoSDHB achieves strong robustness with significant communication savings.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">1. <a href="https://arxiv.org/abs/2508.17477" rel="nofollow">A Human-In-The-Loop Approach for Improving Fairness in Predictive Business Process Monitoring</a> <a id="user-content-link1"></a>
</h2><a id="user-content-1-a-human-in-the-loop-approach-for-improving-fairness-in-predictive-business-process-monitoring-" class="anchor" aria-label="Permalink: 1. A Human-In-The-Loop Approach for Improving Fairness in Predictive Business Process Monitoring" href="#1-a-human-in-the-loop-approach-for-improving-fairness-in-predictive-business-process-monitoring-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.17477
<strong>Authors:</strong> Martin K"appel, Julian Neuberger, Felix M"ohrlein, Sven Weinzierl, Martin Matzner, Stefan Jablonski</p>
<p><strong>Abstract:</strong> arXiv:2508.17477v1 Announce Type: new  Abstract: Predictive process monitoring enables organizations to proactively react and intervene in running instances of a business process. Given an incomplete process instance, predictions about the outcome, next activity, or remaining time are created. This is done by powerful machine learning models, which have shown impressive predictive performance. However, the data-driven nature of these models makes them susceptible to finding unfair, biased, or unethical patterns in the data. Such patterns lead to biased predictions based on so-called sensitive attributes, such as the gender or age of process participants. Previous work has identified this problem and offered solutions that mitigate biases by removing sensitive attributes entirely from the process instance. However, sensitive attributes can be used both fairly and unfairly in the same process instance. For example, during a medical process, treatment decisions could be based on gender, while the decision to accept a patient should not be based on gender. This paper proposes a novel, model-agnostic approach for identifying and rectifying biased decisions in predictive business process monitoring models, even when the same sensitive attribute is used both fairly and unfairly. The proposed approach uses a human-in-the-loop approach to differentiate between fair and unfair decisions through simple alterations on a decision tree model distilled from the original prediction model. Our results show that the proposed approach achieves a promising tradeoff between fairness and accuracy in the presence of biased data. All source code and data are publicly available at <a href="https://doi.org/10.5281/zenodo.15387576" rel="nofollow">https://doi.org/10.5281/zenodo.15387576</a>.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">2. <a href="https://arxiv.org/abs/2508.17196" rel="nofollow">BudgetThinker: Empowering Budget-aware LLM Reasoning with Control Tokens</a> <a id="user-content-link2"></a>
</h2><a id="user-content-2-budgetthinker-empowering-budget-aware-llm-reasoning-with-control-tokens-" class="anchor" aria-label="Permalink: 2. BudgetThinker: Empowering Budget-aware LLM Reasoning with Control Tokens" href="#2-budgetthinker-empowering-budget-aware-llm-reasoning-with-control-tokens-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.17196
<strong>Authors:</strong> Hao Wen, Xinrui Wu, Yi Sun, Feifei Zhang, Liye Chen, Jie Wang, Yunxin Liu, Ya-Qin Zhang, Yuanchun Li</p>
<p><strong>Abstract:</strong> arXiv:2508.17196v1 Announce Type: new  Abstract: Recent advancements in Large Language Models (LLMs) have leveraged increased test-time computation to enhance reasoning capabilities, a strategy that, while effective, incurs significant latency and resource costs, limiting their applicability in real-world time-constrained or cost-sensitive scenarios. This paper introduces BudgetThinker, a novel framework designed to empower LLMs with budget-aware reasoning, enabling precise control over the length of their thought processes. We propose a methodology that periodically inserts special control tokens during inference to continuously inform the model of its remaining token budget. This approach is coupled with a comprehensive two-stage training pipeline, beginning with Supervised Fine-Tuning (SFT) to familiarize the model with budget constraints, followed by a curriculum-based Reinforcement Learning (RL) phase that utilizes a length-aware reward function to optimize for both accuracy and budget adherence. We demonstrate that BudgetThinker significantly surpasses strong baselines in maintaining performance across a variety of reasoning budgets on challenging mathematical benchmarks. Our method provides a scalable and effective solution for developing efficient and controllable LLM reasoning, making advanced models more practical for deployment in resource-constrained and real-time environments.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">3. <a href="https://arxiv.org/abs/2508.17822" rel="nofollow">Limits of message passing for node classification: How class-bottlenecks restrict signal-to-noise ratio</a> <a id="user-content-link3"></a>
</h2><a id="user-content-3-limits-of-message-passing-for-node-classification-how-class-bottlenecks-restrict-signal-to-noise-ratio-" class="anchor" aria-label="Permalink: 3. Limits of message passing for node classification: How class-bottlenecks restrict signal-to-noise ratio" href="#3-limits-of-message-passing-for-node-classification-how-class-bottlenecks-restrict-signal-to-noise-ratio-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.17822
<strong>Authors:</strong> Jonathan Rubin, Sahil Loomba, Nick S. Jones</p>
<p><strong>Abstract:</strong> arXiv:2508.17822v1 Announce Type: new  Abstract: Message passing neural networks (MPNNs) are powerful models for node classification but suffer from performance limitations under heterophily (low same-class connectivity) and structural bottlenecks in the graph. We provide a unifying statistical framework exposing the relationship between heterophily and bottlenecks through the signal-to-noise ratio (SNR) of MPNN representations. The SNR decomposes model performance into feature-dependent parameters and feature-independent sensitivities. We prove that the sensitivity to class-wise signals is bounded by higher-order homophily -- a generalisation of classical homophily to multi-hop neighbourhoods -- and show that low higher-order homophily manifests locally as the interaction between structural bottlenecks and class labels (class-bottlenecks). Through analysis of graph ensembles, we provide a further quantitative decomposition of bottlenecking into underreaching (lack of depth implying signals cannot arrive) and oversquashing (lack of breadth implying signals arriving on fewer paths) with closed-form expressions. We prove that optimal graph structures for maximising higher-order homophily are disjoint unions of single-class and two-class-bipartite clusters. This yields BRIDGE, a graph ensemble-based rewiring algorithm that achieves near-perfect classification accuracy across all homophily regimes on synthetic benchmarks and significant improvements on real-world benchmarks, by eliminating the ``mid-homophily pitfall'' where MPNNs typically struggle, surpassing current standard rewiring techniques from the literature. Our framework, whose code we make available for public use, provides both diagnostic tools for assessing MPNN performance, and simple yet effective methods for enhancing performance through principled graph modification.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">4. <a href="https://arxiv.org/abs/2508.16802" rel="nofollow">Anchor-MoE: A Mean-Anchored Mixture of Experts For Probabilistic Regression</a> <a id="user-content-link4"></a>
</h2><a id="user-content-4-anchor-moe-a-mean-anchored-mixture-of-experts-for-probabilistic-regression-" class="anchor" aria-label="Permalink: 4. Anchor-MoE: A Mean-Anchored Mixture of Experts For Probabilistic Regression" href="#4-anchor-moe-a-mean-anchored-mixture-of-experts-for-probabilistic-regression-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.16802
<strong>Authors:</strong> Baozhuo Su, Zhengxian Qu</p>
<p><strong>Abstract:</strong> arXiv:2508.16802v1 Announce Type: new  Abstract: Regression under uncertainty is fundamental across science and engineering. We present an Anchored Mixture of Experts (Anchor-MoE), a model that handles both probabilistic and point regression. For simplicity, we use a tuned gradient-boosting model to furnish the anchor mean; however, any off-the-shelf point regressor can serve as the anchor. The anchor prediction is projected into a latent space, where a learnable metric-window kernel scores locality and a soft router dispatches each sample to a small set of mixture-density-network experts; the experts produce a heteroscedastic correction and predictive variance. We train by minimizing negative log-likelihood, and on a disjoint calibration split fit a post-hoc linear map on predicted means to improve point accuracy. On the theory side, assuming a H"older smooth regression function of order~$\alpha$ and fixed Lipschitz partition-of-unity weights with bounded overlap, we show that Anchor-MoE attains the minimax-optimal $L^2$ risk rate $O!\big(N^{-2\alpha/(2\alpha+d)}\big)$. In addition, the CRPS test generalization gap scales as $\widetilde{O}!\Big(\sqrt{(\log(Mh)+P+K)/N}\Big)$; it is logarithmic in $Mh$ and scales as the square root in $P$ and $K$. Under bounded-overlap routing, $K$ can be replaced by $k$, and any dependence on a latent dimension is absorbed into $P$. Under uniformly bounded means and variances, an analogous $\widetilde{O}!\big(\sqrt{(\log(Mh)+P+K)/N}\big)$ scaling holds for the test NLL up to constants. Empirically, across standard UCI regressions, Anchor-MoE consistently matches or surpasses the strong NGBoost baseline in RMSE and NLL; on several datasets it achieves new state-of-the-art probabilistic regression results on our benchmark suite. Code is available at <a href="https://github.com/BaozhuoSU/Probabilistic_Regression">https://github.com/BaozhuoSU/Probabilistic_Regression</a>.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">5. <a href="https://arxiv.org/abs/2508.17380" rel="nofollow">Mimicking the Physicist's Eye:A VLM-centric Approach for Physics Formula Discovery</a> <a id="user-content-link5"></a>
</h2><a id="user-content-5-mimicking-the-physicists-eyea-vlm-centric-approach-for-physics-formula-discovery-" class="anchor" aria-label="Permalink: 5. Mimicking the Physicist's Eye:A VLM-centric Approach for Physics Formula Discovery" href="#5-mimicking-the-physicists-eyea-vlm-centric-approach-for-physics-formula-discovery-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.17380
<strong>Authors:</strong> Jiaqi Liu, Songning Lai, Pengze Li, Di Yu, Wenjie Zhou, Yiyang Zhou, Peng Xia, Zijun Wang, Xi Chen, Shixiang Tang, Lei Bai, Wanli Ouyang, Mingyu Ding, Huaxiu Yao, Aoran Wang</p>
<p><strong>Abstract:</strong> arXiv:2508.17380v1 Announce Type: new  Abstract: Automated discovery of physical laws from observational data in the real world is a grand challenge in AI. Current methods, relying on symbolic regression or LLMs, are limited to uni-modal data and overlook the rich, visual phenomenological representations of motion that are indispensable to physicists. This "sensory deprivation" severely weakens their ability to interpret the inherent spatio-temporal patterns within dynamic phenomena. To address this gap, we propose VIPER-R1, a multimodal model that performs Visual Induction for Physics-based Equation Reasoning to discover fundamental symbolic formulas. It integrates visual perception, trajectory data, and symbolic reasoning to emulate the scientific discovery process. The model is trained via a curriculum of Motion Structure Induction (MSI), using supervised fine-tuning to interpret kinematic phase portraits and to construct hypotheses guided by a Causal Chain of Thought (C-CoT), followed by Reward-Guided Symbolic Calibration (RGSC) to refine the formula structure with reinforcement learning. During inference, the trained VIPER-R1 acts as an agent: it first posits a high-confidence symbolic ansatz, then proactively invokes an external symbolic regression tool to perform Symbolic Residual Realignment (SR^2). This final step, analogous to a physicist's perturbation analysis, reconciles the theoretical model with empirical data. To support this research, we introduce PhysSymbol, a new 5,000-instance multimodal corpus. Experiments show that VIPER-R1 consistently outperforms state-of-the-art VLM baselines in accuracy and interpretability, enabling more precise discovery of physical laws. Project page: <a href="https://jiaaqiliu.github.io/VIPER-R1/" rel="nofollow">https://jiaaqiliu.github.io/VIPER-R1/</a></p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">6. <a href="https://arxiv.org/abs/2508.18269" rel="nofollow">FlowVLA: Thinking in Motion with a Visual Chain of Thought</a> <a id="user-content-link6"></a>
</h2><a id="user-content-6-flowvla-thinking-in-motion-with-a-visual-chain-of-thought-" class="anchor" aria-label="Permalink: 6. FlowVLA: Thinking in Motion with a Visual Chain of Thought" href="#6-flowvla-thinking-in-motion-with-a-visual-chain-of-thought-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.18269
<strong>Authors:</strong> Zhide Zhong, Haodong Yan, Junfeng Li, Xiangchen Liu, Xin Gong, Wenxuan Song, Jiayi Chen, Haoang Li</p>
<p><strong>Abstract:</strong> arXiv:2508.18269v1 Announce Type: new  Abstract: Many Vision-Language-Action (VLA) models rely on an internal world model trained via next-frame prediction. This approach, however, struggles with physical reasoning as it entangles static appearance with dynamic motion, often resulting in implausible visual forecasts and inefficient policy learning. To address these limitations, we introduce the Visual Chain of Thought (Visual CoT): a pre-training framework that encourages a model to reason about how a scene evolves before predicting what it will look like. We instantiate this principle in FlowVLA, which predicts a future frame ($v_{t+1}$) only after generating an intermediate optical flow representation ($f_t$) that encodes motion dynamics. This ``$v_t \rightarrow f_t \rightarrow v_{t+1}$'' reasoning process is implemented within a single autoregressive Transformer, guiding the model to learn disentangled dynamics. As a result, FlowVLA produces coherent visual predictions and facilitates more efficient policy learning. Experiments on challenging robotics manipulation benchmarks demonstrate state-of-the-art performance with substantially improved sample efficiency, pointing toward a more principled foundation for world modeling. Project page: <a href="https://irpn-lab.github.io/FlowVLA/" rel="nofollow">https://irpn-lab.github.io/FlowVLA/</a></p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">7. <a href="https://arxiv.org/abs/2508.17233" rel="nofollow">Module-Aware Parameter-Efficient Machine Unlearning on Transformers</a> <a id="user-content-link7"></a>
</h2><a id="user-content-7-module-aware-parameter-efficient-machine-unlearning-on-transformers-" class="anchor" aria-label="Permalink: 7. Module-Aware Parameter-Efficient Machine Unlearning on Transformers" href="#7-module-aware-parameter-efficient-machine-unlearning-on-transformers-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.17233
<strong>Authors:</strong> Wenjie Bao, Jian Lou, Yuke Hu, Xiaochen Li, Zhihao Liu, Jiaqi Liu, Zhan Qin, Kui Ren</p>
<p><strong>Abstract:</strong> arXiv:2508.17233v1 Announce Type: new  Abstract: Transformer has become fundamental to a vast series of pre-trained large models that have achieved remarkable success across diverse applications. Machine unlearning, which focuses on efficiently removing specific data influences to comply with privacy regulations, shows promise in restricting updates to influence-critical parameters. However, existing parameter-efficient unlearning methods are largely devised in a module-oblivious manner, which tends to inaccurately identify these parameters and leads to inferior unlearning performance for Transformers. In this paper, we propose {\tt MAPE-Unlearn}, a module-aware parameter-efficient machine unlearning approach that uses a learnable pair of masks to pinpoint influence-critical parameters in the heads and filters of Transformers. The learning objective of these masks is derived by desiderata of unlearning and optimized through an efficient algorithm featured by a greedy search with a warm start. Extensive experiments on various Transformer models and datasets demonstrate the effectiveness and robustness of {\tt MAPE-Unlearn} for unlearning.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">8. <a href="https://arxiv.org/abs/2508.17467" rel="nofollow">MoE-Inference-Bench: Performance Evaluation of Mixture of Expert Large Language and Vision Models</a> <a id="user-content-link8"></a>
</h2><a id="user-content-8-moe-inference-bench-performance-evaluation-of-mixture-of-expert-large-language-and-vision-models-" class="anchor" aria-label="Permalink: 8. MoE-Inference-Bench: Performance Evaluation of Mixture of Expert Large Language and Vision Models" href="#8-moe-inference-bench-performance-evaluation-of-mixture-of-expert-large-language-and-vision-models-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.17467
<strong>Authors:</strong> Krishna Teja Chitty-Venkata, Sylvia Howland, Golara Azar, Daria Soboleva, Natalia Vassilieva, Siddhisanket Raskar, Murali Emani, Venkatram Vishwanath</p>
<p><strong>Abstract:</strong> arXiv:2508.17467v1 Announce Type: new  Abstract: Mixture of Experts (MoE) models have enabled the scaling of Large Language Models (LLMs) and Vision Language Models (VLMs) by achieving massive parameter counts while maintaining computational efficiency. However, MoEs introduce several inference-time challenges, including load imbalance across experts and the additional routing computational overhead. To address these challenges and fully harness the benefits of MoE, a systematic evaluation of hardware acceleration techniques is essential. We present MoE-Inference-Bench, a comprehensive study to evaluate MoE performance across diverse scenarios. We analyze the impact of batch size, sequence length, and critical MoE hyperparameters such as FFN dimensions and number of experts on throughput. We evaluate several optimization techniques on Nvidia H100 GPUs, including pruning, Fused MoE operations, speculative decoding, quantization, and various parallelization strategies. Our evaluation includes MoEs from the Mixtral, DeepSeek, OLMoE and Qwen families. The results reveal performance differences across configurations and provide insights for the efficient deployment of MoEs.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">9. <a href="https://arxiv.org/abs/2508.17345" rel="nofollow">ShortListing Model: A Streamlined SimplexDiffusion for Discrete Variable Generation</a> <a id="user-content-link9"></a>
</h2><a id="user-content-9-shortlisting-model-a-streamlined-simplexdiffusion-for-discrete-variable-generation-" class="anchor" aria-label="Permalink: 9. ShortListing Model: A Streamlined SimplexDiffusion for Discrete Variable Generation" href="#9-shortlisting-model-a-streamlined-simplexdiffusion-for-discrete-variable-generation-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.17345
<strong>Authors:</strong> Yuxuan Song, Zhe Zhang, Yu Pei, Jingjing Gong, Qiying Yu, Zheng Zhang, Mingxuan Wang, Hao Zhou, Jingjing Liu, Wei-Ying Ma</p>
<p><strong>Abstract:</strong> arXiv:2508.17345v1 Announce Type: new  Abstract: Generative modeling of discrete variables is challenging yet crucial for applications in natural language processing and biological sequence design. We introduce the Shortlisting Model (SLM), a novel simplex-based diffusion model inspired by progressive candidate pruning. SLM operates on simplex centroids, reducing generation complexity and enhancing scalability. Additionally, SLM incorporates a flexible implementation of classifier-free guidance, enhancing unconditional generation performance. Extensive experiments on DNA promoter and enhancer design, protein design, character-level and large-vocabulary language modeling demonstrate the competitive performance and strong potential of SLM. Our code can be found at <a href="https://github.com/GenSI-THUAIR/SLM">https://github.com/GenSI-THUAIR/SLM</a></p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">10. <a href="https://arxiv.org/abs/2508.17971" rel="nofollow">Neural Algorithmic Reasoners informed Large Language Model for Multi-Agent Path Finding</a> <a id="user-content-link10"></a>
</h2><a id="user-content-10-neural-algorithmic-reasoners-informed-large-language-model-for-multi-agent-path-finding-" class="anchor" aria-label="Permalink: 10. Neural Algorithmic Reasoners informed Large Language Model for Multi-Agent Path Finding" href="#10-neural-algorithmic-reasoners-informed-large-language-model-for-multi-agent-path-finding-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.17971
<strong>Authors:</strong> Pu Feng, Size Wang, Yuhong Cao, Junkang Liang, Rongye Shi, Wenjun Wu</p>
<p><strong>Abstract:</strong> arXiv:2508.17971v1 Announce Type: new  Abstract: The development and application of large language models (LLM) have demonstrated that foundational models can be utilized to solve a wide array of tasks. However, their performance in multi-agent path finding (MAPF) tasks has been less than satisfactory, with only a few studies exploring this area. MAPF is a complex problem requiring both planning and multi-agent coordination. To improve the performance of LLM in MAPF tasks, we propose a novel framework, LLM-NAR, which leverages neural algorithmic reasoners (NAR) to inform LLM for MAPF. LLM-NAR consists of three key components: an LLM for MAPF, a pre-trained graph neural network-based NAR, and a cross-attention mechanism. This is the first work to propose using a neural algorithmic reasoner to integrate GNNs with the map information for MAPF, thereby guiding LLM to achieve superior performance. LLM-NAR can be easily adapted to various LLM models. Both simulation and real-world experiments demonstrate that our method significantly outperforms existing LLM-based approaches in solving MAPF problems.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">11. <a href="https://arxiv.org/abs/2508.17291" rel="nofollow">Meta-R1: Empowering Large Reasoning Models with Metacognition</a> <a id="user-content-link11"></a>
</h2><a id="user-content-11-meta-r1-empowering-large-reasoning-models-with-metacognition-" class="anchor" aria-label="Permalink: 11. Meta-R1: Empowering Large Reasoning Models with Metacognition" href="#11-meta-r1-empowering-large-reasoning-models-with-metacognition-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.17291
<strong>Authors:</strong> Haonan Dong, Haoran Ye, Wenhao Zhu, Kehan Jiang, Guojie Song</p>
<p><strong>Abstract:</strong> arXiv:2508.17291v1 Announce Type: new  Abstract: Large Reasoning Models (LRMs) demonstrate remarkable capabilities on complex tasks, exhibiting emergent, human-like thinking patterns. Despite their advances, we identify a fundamental limitation: current LRMs lack a dedicated meta-level cognitive system-an essential faculty in human cognition that enables "thinking about thinking". This absence leaves their emergent abilities uncontrollable (non-adaptive reasoning), unreliable (intermediate error), and inflexible (lack of a clear methodology). To address this gap, we introduce Meta-R1, a systematic and generic framework that endows LRMs with explicit metacognitive capabilities. Drawing on principles from cognitive science, Meta-R1 decomposes the reasoning process into distinct object-level and meta-level components, orchestrating proactive planning, online regulation, and adaptive early stopping within a cascaded framework. Experiments on three challenging benchmarks and against eight competitive baselines demonstrate that Meta-R1 is: (I) high-performing, surpassing state-of-the-art methods by up to 27.3%; (II) token-efficient, reducing token consumption to 15.7% ~ 32.7% and improving efficiency by up to 14.8% when compared to its vanilla counterparts; and (III) transferable, maintaining robust performance across datasets and model backbones.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">12. <a href="https://arxiv.org/abs/2508.17094" rel="nofollow">PowerChain: Automating Distribution Grid Analysis with Agentic AI Workflows</a> <a id="user-content-link12"></a>
</h2><a id="user-content-12-powerchain-automating-distribution-grid-analysis-with-agentic-ai-workflows-" class="anchor" aria-label="Permalink: 12. PowerChain: Automating Distribution Grid Analysis with Agentic AI Workflows" href="#12-powerchain-automating-distribution-grid-analysis-with-agentic-ai-workflows-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.17094
<strong>Authors:</strong> Emmanuel O. Badmus, Peng Sang, Dimitrios Stamoulis, Amritanshu Pandey</p>
<p><strong>Abstract:</strong> arXiv:2508.17094v1 Announce Type: new  Abstract: Due to the rapid pace of electrification and decarbonization, distribution grid (DG) operation and planning are becoming more complex, necessitating advanced computational analyses to ensure grid reliability and resilience. State-of-the-art DG analyses rely on disparate workflows of complex models, functions, and data pipelines, which require expert knowledge and are challenging to automate. Many small-scale utilities and cooperatives lack a large R&amp;D workforce and therefore cannot use advanced analysis at scale. To address this gap, we develop a novel agentic AI system, PowerChain, to solve unseen DG analysis tasks via automated agentic orchestration and large language models (LLMs) function-calling. Given a natural language query, PowerChain dynamically generates and executes an ordered sequence of domain-aware functions guided by the semantics of an expert-built power systems function pool and a select reference set of known, expert-generated workflow-query pairs. Our results show that PowerChain can produce expert-level workflows with both GPT-5 and open-source Qwen models on complex, unseen DG analysis tasks operating on real utility data.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">13. <a href="https://arxiv.org/abs/2508.16680" rel="nofollow">CALR: Corrective Adaptive Low-Rank Decomposition for Efficient Large Language Model Layer Compression</a> <a id="user-content-link13"></a>
</h2><a id="user-content-13-calr-corrective-adaptive-low-rank-decomposition-for-efficient-large-language-model-layer-compression-" class="anchor" aria-label="Permalink: 13. CALR: Corrective Adaptive Low-Rank Decomposition for Efficient Large Language Model Layer Compression" href="#13-calr-corrective-adaptive-low-rank-decomposition-for-efficient-large-language-model-layer-compression-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.16680
<strong>Authors:</strong> Muchammad Daniyal Kautsar, Afra Majida Hariono, Widyawan, Syukron Abu Ishaq Alfarozi, Kuntpong Wararatpanya</p>
<p><strong>Abstract:</strong> arXiv:2508.16680v1 Announce Type: new  Abstract: Large Language Models (LLMs) present significant deployment challenges due to their immense size and computational requirements. Model compression techniques are essential for making these models practical for resource-constrained environments. A prominent compression strategy is low-rank factorization via Singular Value Decomposition (SVD) to reduce model parameters by approximating weight matrices. However, standard SVD focuses on minimizing matrix reconstruction error, often leading to a substantial loss of the model's functional performance. This performance degradation occurs because existing methods do not adequately correct for the functional information lost during compression. To address this gap, we introduce Corrective Adaptive Low-Rank Decomposition (CALR), a two-component compression approach. CALR combines a primary path of SVD-compressed layers with a parallel, learnable, low-rank corrective module that is explicitly trained to recover the functional residual error. Our experimental evaluation on SmolLM2-135M, Qwen3-0.6B, and Llama-3.2-1B, demonstrates that CALR can reduce parameter counts by 26.93% to 51.77% while retaining 59.45% to 90.42% of the original model's performance, consistently outperforming LaCo, ShortGPT, and LoSparse. CALR's success shows that treating functional information loss as a learnable signal is a highly effective compression paradigm. This approach enables the creation of significantly smaller, more efficient LLMs, advancing their accessibility and practical deployment in real-world applications.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">14. <a href="https://arxiv.org/abs/2508.17756" rel="nofollow">SuperGen: An Efficient Ultra-high-resolution Video Generation System with Sketching and Tiling</a> <a id="user-content-link14"></a>
</h2><a id="user-content-14-supergen-an-efficient-ultra-high-resolution-video-generation-system-with-sketching-and-tiling-" class="anchor" aria-label="Permalink: 14. SuperGen: An Efficient Ultra-high-resolution Video Generation System with Sketching and Tiling" href="#14-supergen-an-efficient-ultra-high-resolution-video-generation-system-with-sketching-and-tiling-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.17756
<strong>Authors:</strong> Fanjiang Ye, Zepeng Zhao, Yi Mu, Jucheng Shen, Renjie Li, Kaijian Wang, Desen Sun, Saurabh Agarwal, Myungjin Lee, Triston Cao, Aditya Akella, Arvind Krishnamurthy, T. S. Eugene Ng, Zhengzhong Tu, Yuke Wang</p>
<p><strong>Abstract:</strong> arXiv:2508.17756v1 Announce Type: new  Abstract: Diffusion models have recently achieved remarkable success in generative tasks (e.g., image and video generation), and the demand for high-quality content (e.g., 2K/4K videos) is rapidly increasing across various domains. However, generating ultra-high-resolution videos on existing standard-resolution (e.g., 720p) platforms remains challenging due to the excessive re-training requirements and prohibitively high computational and memory costs. To this end, we introduce SuperGen, an efficient tile-based framework for ultra-high-resolution video generation. SuperGen features a novel training-free algorithmic innovation with tiling to successfully support a wide range of resolutions without additional training efforts while significantly reducing both memory footprint and computational complexity. Moreover, SuperGen incorporates a tile-tailored, adaptive, region-aware caching strategy that accelerates video generation by exploiting redundancy across denoising steps and spatial regions. SuperGen also integrates cache-guided, communication-minimized tile parallelism for enhanced throughput and minimized latency. Evaluations demonstrate that SuperGen harvests the maximum performance gains while achieving high output quality across various benchmarks.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">15. <a href="https://arxiv.org/abs/2508.18001" rel="nofollow">A Novel Framework for Uncertainty Quantification via Proper Scores for Classification and Beyond</a> <a id="user-content-link15"></a>
</h2><a id="user-content-15-a-novel-framework-for-uncertainty-quantification-via-proper-scores-for-classification-and-beyond-" class="anchor" aria-label="Permalink: 15. A Novel Framework for Uncertainty Quantification via Proper Scores for Classification and Beyond" href="#15-a-novel-framework-for-uncertainty-quantification-via-proper-scores-for-classification-and-beyond-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.18001
<strong>Authors:</strong> Sebastian G. Gruber</p>
<p><strong>Abstract:</strong> arXiv:2508.18001v1 Announce Type: new  Abstract: In this PhD thesis, we propose a novel framework for uncertainty quantification in machine learning, which is based on proper scores. Uncertainty quantification is an important cornerstone for trustworthy and reliable machine learning applications in practice. Usually, approaches to uncertainty quantification are problem-specific, and solutions and insights cannot be readily transferred from one task to another. Proper scores are loss functions minimized by predicting the target distribution. Due to their very general definition, proper scores apply to regression, classification, or even generative modeling tasks. We contribute several theoretical results, that connect epistemic uncertainty, aleatoric uncertainty, and model calibration with proper scores, resulting in a general and widely applicable framework. We achieve this by introducing a general bias-variance decomposition for strictly proper scores via functional Bregman divergences. Specifically, we use the kernel score, a kernel-based proper score, for evaluating sample-based generative models in various domains, like image, audio, and natural language generation. This includes a novel approach for uncertainty estimation of large language models, which outperforms state-of-the-art baselines. Further, we generalize the calibration-sharpness decomposition beyond classification, which motivates the definition of proper calibration errors. We then introduce a novel estimator for proper calibration errors in classification, and a novel risk-based approach to compare different estimators for squared calibration errors. Last, we offer a decomposition of the kernel spherical score, another kernel-based proper score, allowing a more fine-grained and interpretable evaluation of generative image models.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">16. <a href="https://arxiv.org/abs/2508.16905" rel="nofollow">Tri-Accel: Curvature-Aware Precision-Adaptive and Memory-Elastic Optimization for Efficient GPU Usage</a> <a id="user-content-link16"></a>
</h2><a id="user-content-16-tri-accel-curvature-aware-precision-adaptive-and-memory-elastic-optimization-for-efficient-gpu-usage-" class="anchor" aria-label="Permalink: 16. Tri-Accel: Curvature-Aware Precision-Adaptive and Memory-Elastic Optimization for Efficient GPU Usage" href="#16-tri-accel-curvature-aware-precision-adaptive-and-memory-elastic-optimization-for-efficient-gpu-usage-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.16905
<strong>Authors:</strong> Mohsen Sheibanian, Pouya Shaeri, Alimohammad Beigi, Ryan T. Woo, Aryan Keluskar</p>
<p><strong>Abstract:</strong> arXiv:2508.16905v1 Announce Type: new  Abstract: Deep neural networks are increasingly bottlenecked by the cost of optimization, both in terms of GPU memory and compute time. Existing acceleration techniques, such as mixed precision, second-order methods, and batch size scaling, are typically used in isolation. We present Tri-Accel, a unified optimization framework that co-adapts three acceleration strategies along with adaptive parameters during training: (1) Precision-Adaptive Updates that dynamically assign mixed-precision levels to layers based on curvature and gradient variance; (2) Sparse Second-Order Signals that exploit Hessian/Fisher sparsity patterns to guide precision and step size decisions; and (3) Memory-Elastic Batch Scaling that adjusts batch size in real time according to VRAM availability. On CIFAR-10 with ResNet-18 and EfficientNet-B0, Tri-Accel achieves up to 9.9% reduction in training time and 13.3% lower memory usage, while improving accuracy by +1.1 percentage points over FP32 baselines. Tested on CIFAR-10/100, our approach demonstrates adaptive learning behavior, with efficiency gradually improving over the course of training as the system learns to allocate resources more effectively. Compared to static mixed-precision training, Tri-Accel maintains 78.1% accuracy while reducing memory footprint from 0.35GB to 0.31GB on standard hardware. The framework is implemented with custom Triton kernels, whose hardware-aware adaptation enables automatic optimization without manual hyperparameter tuning, making it practical for deployment across diverse computational environments. This work demonstrates how algorithmic adaptivity and hardware awareness can be combined to improve scalability in resource-constrained settings, paving the way for more efficient neural network training on edge devices and cost-sensitive cloud deployments.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">17. <a href="https://arxiv.org/abs/2508.17032" rel="nofollow">Learned Structure in CARTRIDGES: Keys as Shareable Routers in Self-Studied Representations</a> <a id="user-content-link17"></a>
</h2><a id="user-content-17-learned-structure-in-cartridges-keys-as-shareable-routers-in-self-studied-representations-" class="anchor" aria-label="Permalink: 17. Learned Structure in CARTRIDGES: Keys as Shareable Routers in Self-Studied Representations" href="#17-learned-structure-in-cartridges-keys-as-shareable-routers-in-self-studied-representations-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.17032
<strong>Authors:</strong> Maurizio Diaz</p>
<p><strong>Abstract:</strong> arXiv:2508.17032v1 Announce Type: new  Abstract: A bottleneck for long-context LLM inference is the linearly growing KV cache. Recent work has proposed CARTRIDGES, an approach which leverages offline compute to train a much smaller KV cache than is typically required for a full document (up to 40x less memory usage at inference time). In this paper, we present the first mechanistic exploration of the learned CARTRIDGE key-value cache structure. In particular, we propose that (1) CARTRIDGE keys act as stable, shareable retrieval routers for the compressed corpora and (2) most of the learned compression occurs within the CARTRIDGE value vectors. We present empirical evidence of our routing theory across tasks, model families, and model sizes; for example, we can ablate the learned CARTRIDGE key vectors between tasks with little performance loss. Finally, we propose a slight improvement in initialization called Sampled Chunk Initialization (SCI). We suggest that SCI can lead to faster CARTRIDGE convergence than previously demonstrated in the literature. Our findings lay the groundwork for broader empirical study of CARTRIDGE training optimization which may be crucial for further scaling.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">18. <a href="https://arxiv.org/abs/2508.17739" rel="nofollow">Speculative Safety-Aware Decoding</a> <a id="user-content-link18"></a>
</h2><a id="user-content-18-speculative-safety-aware-decoding-" class="anchor" aria-label="Permalink: 18. Speculative Safety-Aware Decoding" href="#18-speculative-safety-aware-decoding-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.17739
<strong>Authors:</strong> Xuekang Wang, Shengyu Zhu, Xueqi Cheng</p>
<p><strong>Abstract:</strong> arXiv:2508.17739v1 Announce Type: new  Abstract: Despite extensive efforts to align Large Language Models (LLMs) with human values and safety rules, jailbreak attacks that exploit certain vulnerabilities continuously emerge, highlighting the need to strengthen existing LLMs with additional safety properties to defend against these attacks. However, tuning large models has become increasingly resource-intensive and may have difficulty ensuring consistent performance. We introduce Speculative Safety-Aware Decoding (SSD), a lightweight decoding-time approach that equips LLMs with the desired safety property while accelerating inference. We assume that there exists a small language model that possesses this desired property. SSD integrates speculative sampling during decoding and leverages the match ratio between the small and composite models to quantify jailbreak risks. This enables SSD to dynamically switch between decoding schemes to prioritize utility or safety, to handle the challenge of different model capacities. The output token is then sampled from a new distribution that combines the distributions of the original and the small models. Experimental results show that SSD successfully equips the large model with the desired safety property, and also allows the model to remain helpful to benign queries. Furthermore, SSD accelerates the inference time, thanks to the speculative sampling design.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">19. <a href="https://arxiv.org/abs/2508.17586" rel="nofollow">Exploring Efficient Learning of Small BERT Networks with LoRA and DoRA</a> <a id="user-content-link19"></a>
</h2><a id="user-content-19-exploring-efficient-learning-of-small-bert-networks-with-lora-and-dora-" class="anchor" aria-label="Permalink: 19. Exploring Efficient Learning of Small BERT Networks with LoRA and DoRA" href="#19-exploring-efficient-learning-of-small-bert-networks-with-lora-and-dora-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.17586
<strong>Authors:</strong> Daniel Frees, Aditri Bhagirath, Moritz Bolling</p>
<p><strong>Abstract:</strong> arXiv:2508.17586v1 Announce Type: new  Abstract: While Large Language Models (LLMs) have revolutionized artificial intelligence, fine-tuning LLMs is extraordinarily computationally expensive, preventing smaller businesses and research teams with limited GPU resources from engaging with new research. Hu et al and Liu et al introduce Low-Rank Adaptation (LoRA) and Weight-Decomposed Low-Rank Adaptation (DoRA) as highly efficient and performant solutions to the computational challenges of LLM fine-tuning, demonstrating huge speedups and memory usage savings for models such as GPT-3 and RoBERTa. We seek to expand upon the original LoRA and DoRA papers by benchmarking efficiency and performance of LoRA and DoRA when applied to a much smaller scale of language model: our case study here is the compact minBERT model. Our findings reveal that optimal custom configurations of LoRA and DoRA, coupled with Automatic Mixed Precision (AMP), significantly enhance training efficiency without compromising performance. Furthermore, while the parameterization of minBERT is significantly smaller than GPT-3, our results validate the observation that gradient updates to language models are inherently low-rank even in small model space, observing that rank 1 decompositions yield negligible performance deficits. Furthermore, aided by our highly efficient minBERT implementation, we investigate numerous architectures, custom loss functions, and hyperparameters to ultimately train an optimal ensembled multitask minBERT model to simultaneously perform sentiment analysis, paraphrase detection, and similarity scoring.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">20. <a href="https://arxiv.org/abs/2508.18268" rel="nofollow">SafeBimanual: Diffusion-based Trajectory Optimization for Safe Bimanual Manipulation</a> <a id="user-content-link20"></a>
</h2><a id="user-content-20-safebimanual-diffusion-based-trajectory-optimization-for-safe-bimanual-manipulation-" class="anchor" aria-label="Permalink: 20. SafeBimanual: Diffusion-based Trajectory Optimization for Safe Bimanual Manipulation" href="#20-safebimanual-diffusion-based-trajectory-optimization-for-safe-bimanual-manipulation-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.18268
<strong>Authors:</strong> Haoyuan Deng, Wenkai Guo, Qianzhun Wang, Zhenyu Wu, Ziwei Wang</p>
<p><strong>Abstract:</strong> arXiv:2508.18268v1 Announce Type: new  Abstract: Bimanual manipulation has been widely applied in household services and manufacturing, which enables the complex task completion with coordination requirements. Recent diffusion-based policy learning approaches have achieved promising performance in modeling action distributions for bimanual manipulation. However, they ignored the physical safety constraints of bimanual manipulation, which leads to the dangerous behaviors with damage to robots and objects. To this end, we propose a test-time trajectory optimization framework named SafeBimanual for any pre-trained diffusion-based bimanual manipulation policies, which imposes the safety constraints on bimanual actions to avoid dangerous robot behaviors with improved success rate. Specifically, we design diverse cost functions for safety constraints in different dual-arm cooperation patterns including avoidance of tearing objects and collision between arms and objects, which optimizes the manipulator trajectories with guided sampling of diffusion denoising process. Moreover, we employ a vision-language model (VLM) to schedule the cost functions by specifying keypoints and corresponding pairwise relationship, so that the optimal safety constraint is dynamically generated in the entire bimanual manipulation process. SafeBimanual demonstrates superiority on 8 simulated tasks in RoboTwin with a 13.7% increase in success rate and a 18.8% reduction in unsafe interactions over state-of-the-art diffusion-based methods. Extensive experiments on 4 real-world tasks further verify its practical value by improving the success rate by 32.5%.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">21. <a href="https://arxiv.org/abs/2508.16769" rel="nofollow">DR-CircuitGNN: Training Acceleration of Heterogeneous Circuit Graph Neural Network on GPUs</a> <a id="user-content-link21"></a>
</h2><a id="user-content-21-dr-circuitgnn-training-acceleration-of-heterogeneous-circuit-graph-neural-network-on-gpus-" class="anchor" aria-label="Permalink: 21. DR-CircuitGNN: Training Acceleration of Heterogeneous Circuit Graph Neural Network on GPUs" href="#21-dr-circuitgnn-training-acceleration-of-heterogeneous-circuit-graph-neural-network-on-gpus-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.16769
<strong>Authors:</strong> Yuebo Luo, Shiyang Li, Junran Tao, Kiran Thorat, Xi Xie, Hongwu Peng, Nuo Xu, Caiwen Ding, Shaoyi Huang</p>
<p><strong>Abstract:</strong> arXiv:2508.16769v1 Announce Type: new  Abstract: The increasing scale and complexity of integrated circuit design have led to increased challenges in Electronic Design Automation (EDA). Graph Neural Networks (GNNs) have emerged as a promising approach to assist EDA design as circuits can be naturally represented as graphs. While GNNs offer a foundation for circuit analysis, they often fail to capture the full complexity of EDA designs. Heterogeneous Graph Neural Networks (HGNNs) can better interpret EDA circuit graphs as they capture both topological relationships and geometric features. However, the improved representation capability comes at the cost of even higher computational complexity and processing cost due to their serial module-wise message-passing scheme, creating a significant performance bottleneck. In this paper, we propose DR-CircuitGNN, a fast GPU kernel design by leveraging row-wise sparsity-aware Dynamic-ReLU and optimizing SpMM kernels during heterogeneous message-passing to accelerate HGNNs training on EDA-related circuit graph datasets. To further enhance performance, we propose a parallel optimization strategy that maximizes CPU-GPU concurrency by concurrently processing independent subgraphs using multi-threaded CPU initialization and GPU kernel execution via multiple cudaStreams. Our experiments show that on three representative CircuitNet designs (small, medium, large), the proposed method can achieve up to 3.51x and 4.09x speedup compared to the SOTA for forward and backward propagation, respectively. On full-size CircuitNet and sampled Mini-CircuitNet, our parallel design enables up to 2.71x speed up over the official DGL implementation cuSPARSE with negligible impact on correlation scores and error rates.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">22. <a href="https://arxiv.org/abs/2508.16874" rel="nofollow">UM3: Unsupervised Map to Map Matching</a> <a id="user-content-link22"></a>
</h2><a id="user-content-22-um3-unsupervised-map-to-map-matching-" class="anchor" aria-label="Permalink: 22. UM3: Unsupervised Map to Map Matching" href="#22-um3-unsupervised-map-to-map-matching-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.16874
<strong>Authors:</strong> Chaolong Ying, Yinan Zhang, Lei Zhang, Jiazhuang Wang, Shujun Jia, Tianshu Yu</p>
<p><strong>Abstract:</strong> arXiv:2508.16874v1 Announce Type: new  Abstract: Map-to-map matching is a critical task for aligning spatial data across heterogeneous sources, yet it remains challenging due to the lack of ground truth correspondences, sparse node features, and scalability demands. In this paper, we propose an unsupervised graph-based framework that addresses these challenges through three key innovations. First, our method is an unsupervised learning approach that requires no training data, which is crucial for large-scale map data where obtaining labeled training samples is challenging. Second, we introduce pseudo coordinates that capture the relative spatial layout of nodes within each map, which enhances feature discriminability and enables scale-invariant learning. Third, we design an mechanism to adaptively balance feature and geometric similarity, as well as a geometric-consistent loss function, ensuring robustness to noisy or incomplete coordinate data. At the implementation level, to handle large-scale maps, we develop a tile-based post-processing pipeline with overlapping regions and majority voting, which enables parallel processing while preserving boundary coherence. Experiments on real-world datasets demonstrate that our method achieves state-of-the-art accuracy in matching tasks, surpassing existing methods by a large margin, particularly in high-noise and large-scale scenarios. Our framework provides a scalable and practical solution for map alignment, offering a robust and efficient alternative to traditional approaches.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">23. <a href="https://arxiv.org/abs/2508.17957" rel="nofollow">Generative Feature Imputing - A Technique for Error-resilient Semantic Communication</a> <a id="user-content-link23"></a>
</h2><a id="user-content-23-generative-feature-imputing---a-technique-for-error-resilient-semantic-communication-" class="anchor" aria-label="Permalink: 23. Generative Feature Imputing - A Technique for Error-resilient Semantic Communication" href="#23-generative-feature-imputing---a-technique-for-error-resilient-semantic-communication-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.17957
<strong>Authors:</strong> Jianhao Huang, Qunsong Zeng, Hongyang Du, Kaibin Huang</p>
<p><strong>Abstract:</strong> arXiv:2508.17957v1 Announce Type: new  Abstract: Semantic communication (SemCom) has emerged as a promising paradigm for achieving unprecedented communication efficiency in sixth-generation (6G) networks by leveraging artificial intelligence (AI) to extract and transmit the underlying meanings of source data. However, deploying SemCom over digital systems presents new challenges, particularly in ensuring robustness against transmission errors that may distort semantically critical content. To address this issue, this paper proposes a novel framework, termed generative feature imputing, which comprises three key techniques. First, we introduce a spatial error concentration packetization strategy that spatially concentrates feature distortions by encoding feature elements based on their channel mappings, a property crucial for both the effectiveness and reduced complexity of the subsequent techniques. Second, building on this strategy, we propose a generative feature imputing method that utilizes a diffusion model to efficiently reconstruct missing features caused by packet losses. Finally, we develop a semantic-aware power allocation scheme that enables unequal error protection by allocating transmission power according to the semantic importance of each packet. Experimental results demonstrate that the proposed framework outperforms conventional approaches, such as Deep Joint Source-Channel Coding (DJSCC) and JPEG2000, under block fading conditions, achieving higher semantic accuracy and lower Learned Perceptual Image Patch Similarity (LPIPS) scores.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">24. <a href="https://arxiv.org/abs/2508.17388" rel="nofollow">Effective Clustering for Large Multi-Relational Graphs</a> <a id="user-content-link24"></a>
</h2><a id="user-content-24-effective-clustering-for-large-multi-relational-graphs-" class="anchor" aria-label="Permalink: 24. Effective Clustering for Large Multi-Relational Graphs" href="#24-effective-clustering-for-large-multi-relational-graphs-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.17388
<strong>Authors:</strong> Xiaoyang Lin, Runhao Jiang, Renchi Yang</p>
<p><strong>Abstract:</strong> arXiv:2508.17388v1 Announce Type: new  Abstract: Multi-relational graphs (MRGs) are an expressive data structure for modeling diverse interactions/relations among real objects (i.e., nodes), which pervade extensive applications and scenarios. Given an MRG G with N nodes, partitioning the node set therein into K disjoint clusters (MRGC) is a fundamental task in analyzing MRGs, which has garnered considerable attention. However, the majority of existing solutions towards MRGC either yield severely compromised result quality by ineffective fusion of heterogeneous graph structures and attributes, or struggle to cope with sizable MRGs with millions of nodes and billions of edges due to the adoption of sophisticated and costly deep learning models.   In this paper, we present DEMM and DEMM+, two effective MRGC approaches to address the limitations above. Specifically, our algorithms are built on novel two-stage optimization objectives, where the former seeks to derive high-caliber node feature vectors by optimizing the multi-relational Dirichlet energy specialized for MRGs, while the latter minimizes the Dirichlet energy of clustering results over the node affinity graph. In particular, DEMM+ achieves significantly higher scalability and efficiency over our based method DEMM through a suite of well-thought-out optimizations. Key technical contributions include (i) a highly efficient approximation solver for constructing node feature vectors, and (ii) a theoretically-grounded problem transformation with carefully-crafted techniques that enable linear-time clustering without explicitly materializing the NxN dense affinity matrix. Further, we extend DEMM+ to handle attribute-less MRGs through non-trivial adaptations. Extensive experiments, comparing DEMM+ against 20 baselines over 11 real MRGs, exhibit that DEMM+ is consistently superior in terms of clustering quality measured against ground-truth labels, while often being remarkably faster.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">25. <a href="https://arxiv.org/abs/2508.18130" rel="nofollow">Frozen in Time: Parameter-Efficient Time Series Transformers via Reservoir-Induced Feature Expansion and Fixed Random Dynamics</a> <a id="user-content-link25"></a>
</h2><a id="user-content-25-frozen-in-time-parameter-efficient-time-series-transformers-via-reservoir-induced-feature-expansion-and-fixed-random-dynamics-" class="anchor" aria-label="Permalink: 25. Frozen in Time: Parameter-Efficient Time Series Transformers via Reservoir-Induced Feature Expansion and Fixed Random Dynamics" href="#25-frozen-in-time-parameter-efficient-time-series-transformers-via-reservoir-induced-feature-expansion-and-fixed-random-dynamics-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.18130
<strong>Authors:</strong> Pradeep Singh, Mehak Sharma, Anupriya Dey, Balasubramanian Raman</p>
<p><strong>Abstract:</strong> arXiv:2508.18130v1 Announce Type: new  Abstract: Transformers are the de-facto choice for sequence modelling, yet their quadratic self-attention and weak temporal bias can make long-range forecasting both expensive and brittle. We introduce FreezeTST, a lightweight hybrid that interleaves frozen random-feature (reservoir) blocks with standard trainable Transformer layers. The frozen blocks endow the network with rich nonlinear memory at no optimisation cost; the trainable layers learn to query this memory through self-attention. The design cuts trainable parameters and also lowers wall-clock training time, while leaving inference complexity unchanged. On seven standard long-term forecasting benchmarks, FreezeTST consistently matches or surpasses specialised variants such as Informer, Autoformer, and PatchTST; with substantially lower compute. Our results show that embedding reservoir principles within Transformers offers a simple, principled route to efficient long-term time-series prediction.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">26. <a href="https://arxiv.org/abs/2508.17466" rel="nofollow">Optimizing Grasping in Legged Robots: A Deep Learning Approach to Loco-Manipulation</a> <a id="user-content-link26"></a>
</h2><a id="user-content-26-optimizing-grasping-in-legged-robots-a-deep-learning-approach-to-loco-manipulation-" class="anchor" aria-label="Permalink: 26. Optimizing Grasping in Legged Robots: A Deep Learning Approach to Loco-Manipulation" href="#26-optimizing-grasping-in-legged-robots-a-deep-learning-approach-to-loco-manipulation-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.17466
<strong>Authors:</strong> Dilermando Almeida, Guilherme Lazzarini, Juliano Negri, Thiago H. Segreto, Ricardo V. Godoy, Marcelo Becker</p>
<p><strong>Abstract:</strong> arXiv:2508.17466v1 Announce Type: new  Abstract: Quadruped robots have emerged as highly efficient and versatile platforms, excelling in navigating complex and unstructured terrains where traditional wheeled robots might fail. Equipping these robots with manipulator arms unlocks the advanced capability of loco-manipulation to perform complex physical interaction tasks in areas ranging from industrial automation to search-and-rescue missions. However, achieving precise and adaptable grasping in such dynamic scenarios remains a significant challenge, often hindered by the need for extensive real-world calibration and pre-programmed grasp configurations. This paper introduces a deep learning framework designed to enhance the grasping capabilities of quadrupeds equipped with arms, focusing on improved precision and adaptability. Our approach centers on a sim-to-real methodology that minimizes reliance on physical data collection. We developed a pipeline within the Genesis simulation environment to generate a synthetic dataset of grasp attempts on common objects. By simulating thousands of interactions from various perspectives, we created pixel-wise annotated grasp-quality maps to serve as the ground truth for our model. This dataset was used to train a custom CNN with a U-Net-like architecture that processes multi-modal input from an onboard RGB and depth cameras, including RGB images, depth maps, segmentation masks, and surface normal maps. The trained model outputs a grasp-quality heatmap to identify the optimal grasp point. We validated the complete framework on a four-legged robot. The system successfully executed a full loco-manipulation task: autonomously navigating to a target object, perceiving it with its sensors, predicting the optimal grasp pose using our model, and performing a precise grasp. This work proves that leveraging simulated training with advanced sensing offers a scalable and effective solution for object handling.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">27. <a href="https://arxiv.org/abs/2508.18175" rel="nofollow">Amortized Sampling with Transferable Normalizing Flows</a> <a id="user-content-link27"></a>
</h2><a id="user-content-27-amortized-sampling-with-transferable-normalizing-flows-" class="anchor" aria-label="Permalink: 27. Amortized Sampling with Transferable Normalizing Flows" href="#27-amortized-sampling-with-transferable-normalizing-flows-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.18175
<strong>Authors:</strong> Charlie B. Tan, Majdi Hassan, Leon Klein, Saifuddin Syed, Dominique Beaini, Michael M. Bronstein, Alexander Tong, Kirill Neklyudov</p>
<p><strong>Abstract:</strong> arXiv:2508.18175v1 Announce Type: new  Abstract: Efficient equilibrium sampling of molecular conformations remains a core challenge in computational chemistry and statistical inference. Classical approaches such as molecular dynamics or Markov chain Monte Carlo inherently lack amortization; the computational cost of sampling must be paid in-full for each system of interest. The widespread success of generative models has inspired interest into overcoming this limitation through learning sampling algorithms. Despite performing on par with conventional methods when trained on a single system, learned samplers have so far demonstrated limited ability to transfer across systems. We prove that deep learning enables the design of scalable and transferable samplers by introducing Prose, a 280 million parameter all-atom transferable normalizing flow trained on a corpus of peptide molecular dynamics trajectories up to 8 residues in length. Prose draws zero-shot uncorrelated proposal samples for arbitrary peptide systems, achieving the previously intractable transferability across sequence length, whilst retaining the efficient likelihood evaluation of normalizing flows. Through extensive empirical evaluation we demonstrate the efficacy of Prose as a proposal for a variety of sampling algorithms, finding a simple importance sampling-based finetuning procedure to achieve superior performance to established methods such as sequential Monte Carlo on unseen tetrapeptides. We open-source the Prose codebase, model weights, and training dataset, to further stimulate research into amortized sampling methods and finetuning objectives.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">28. <a href="https://arxiv.org/abs/2508.17630" rel="nofollow">Quantum Graph Attention Network: A Novel Quantum Multi-Head Attention Mechanism for Graph Learning</a> <a id="user-content-link28"></a>
</h2><a id="user-content-28-quantum-graph-attention-network-a-novel-quantum-multi-head-attention-mechanism-for-graph-learning-" class="anchor" aria-label="Permalink: 28. Quantum Graph Attention Network: A Novel Quantum Multi-Head Attention Mechanism for Graph Learning" href="#28-quantum-graph-attention-network-a-novel-quantum-multi-head-attention-mechanism-for-graph-learning-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.17630
<strong>Authors:</strong> An Ning, Tai Yue Li, Nan Yow Chen</p>
<p><strong>Abstract:</strong> arXiv:2508.17630v1 Announce Type: new  Abstract: We propose the Quantum Graph Attention Network (QGAT), a hybrid graph neural network that integrates variational quantum circuits into the attention mechanism. At its core, QGAT employs strongly entangling quantum circuits with amplitude-encoded node features to enable expressive nonlinear interactions. Distinct from classical multi-head attention that separately computes each head, QGAT leverages a single quantum circuit to simultaneously generate multiple attention coefficients. This quantum parallelism facilitates parameter sharing across heads, substantially reducing computational overhead and model complexity. Classical projection weights and quantum circuit parameters are optimized jointly in an end-to-end manner, ensuring flexible adaptation to learning tasks. Empirical results demonstrate QGAT's effectiveness in capturing complex structural dependencies and improved generalization in inductive scenarios, highlighting its potential for scalable quantum-enhanced learning across domains such as chemistry, biology, and network analysis. Furthermore, experiments confirm that quantum embedding enhances robustness against feature and structural noise, suggesting advantages in handling real-world noisy data. The modularity of QGAT also ensures straightforward integration into existing architectures, allowing it to easily augment classical attention-based models.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">29. <a href="https://arxiv.org/abs/2508.17405" rel="nofollow">FRAME : Comprehensive Risk Assessment Framework for Adversarial Machine Learning Threats</a> <a id="user-content-link29"></a>
</h2><a id="user-content-29-frame--comprehensive-risk-assessment-framework-for-adversarial-machine-learning-threats-" class="anchor" aria-label="Permalink: 29. FRAME : Comprehensive Risk Assessment Framework for Adversarial Machine Learning Threats" href="#29-frame--comprehensive-risk-assessment-framework-for-adversarial-machine-learning-threats-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.17405
<strong>Authors:</strong> Avishag Shapira, Simon Shigol, Asaf Shabtai</p>
<p><strong>Abstract:</strong> arXiv:2508.17405v1 Announce Type: new  Abstract: The widespread adoption of machine learning (ML) systems increased attention to their security and emergence of adversarial machine learning (AML) techniques that exploit fundamental vulnerabilities in ML systems, creating an urgent need for comprehensive risk assessment for ML-based systems. While traditional risk assessment frameworks evaluate conventional cybersecurity risks, they lack ability to address unique challenges posed by AML threats. Existing AML threat evaluation approaches focus primarily on technical attack robustness, overlooking crucial real-world factors like deployment environments, system dependencies, and attack feasibility. Attempts at comprehensive AML risk assessment have been limited to domain-specific solutions, preventing application across diverse systems. Addressing these limitations, we present FRAME, the first comprehensive and automated framework for assessing AML risks across diverse ML-based systems. FRAME includes a novel risk assessment method that quantifies AML risks by systematically evaluating three key dimensions: target system's deployment environment, characteristics of diverse AML techniques, and empirical insights from prior research. FRAME incorporates a feasibility scoring mechanism and LLM-based customization for system-specific assessments. Additionally, we developed a comprehensive structured dataset of AML attacks enabling context-aware risk assessment. From an engineering application perspective, FRAME delivers actionable results designed for direct use by system owners with only technical knowledge of their systems, without expertise in AML. We validated it across six diverse real-world applications. Our evaluation demonstrated exceptional accuracy and strong alignment with analysis by AML experts. FRAME enables organizations to prioritize AML risks, supporting secure AI deployment in real-world environments.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">30. <a href="https://arxiv.org/abs/2508.17515" rel="nofollow">GateTS: Versatile and Efficient Forecasting via Attention-Inspired routed Mixture-of-Experts</a> <a id="user-content-link30"></a>
</h2><a id="user-content-30-gatets-versatile-and-efficient-forecasting-via-attention-inspired-routed-mixture-of-experts-" class="anchor" aria-label="Permalink: 30. GateTS: Versatile and Efficient Forecasting via Attention-Inspired routed Mixture-of-Experts" href="#30-gatets-versatile-and-efficient-forecasting-via-attention-inspired-routed-mixture-of-experts-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.17515
<strong>Authors:</strong> Kyrylo Yemets, Mykola Lukashchuk, Ivan Izonin</p>
<p><strong>Abstract:</strong> arXiv:2508.17515v1 Announce Type: new  Abstract: Accurate univariate forecasting remains a pressing need in real-world systems, such as energy markets, hydrology, retail demand, and IoT monitoring, where signals are often intermittent and horizons span both short- and long-term. While transformers and Mixture-of-Experts (MoE) architectures are increasingly favored for time-series forecasting, a key gap persists: MoE models typically require complicated training with both the main forecasting loss and auxiliary load-balancing losses, along with careful routing/temperature tuning, which hinders practical adoption. In this paper, we propose a model architecture that simplifies the training process for univariate time series forecasting and effectively addresses both long- and short-term horizons, including intermittent patterns. Our approach combines sparse MoE computation with a novel attention-inspired gating mechanism that replaces the traditional one-layer softmax router. Through extensive empirical evaluation, we demonstrate that our gating design naturally promotes balanced expert utilization and achieves superior predictive accuracy without requiring the auxiliary load-balancing losses typically used in classical MoE implementations. The model achieves better performance while utilizing only a fraction of the parameters required by state-of-the-art transformer models, such as PatchTST. Furthermore, experiments across diverse datasets confirm that our MoE architecture with the proposed gating mechanism is more computationally efficient than LSTM for both long- and short-term forecasting, enabling cost-effective inference. These results highlight the potential of our approach for practical time-series forecasting applications where both accuracy and computational efficiency are critical.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">31. <a href="https://arxiv.org/abs/2508.17565" rel="nofollow">TradingGroup: A Multi-Agent Trading System with Self-Reflection and Data-Synthesis</a> <a id="user-content-link31"></a>
</h2><a id="user-content-31-tradinggroup-a-multi-agent-trading-system-with-self-reflection-and-data-synthesis-" class="anchor" aria-label="Permalink: 31. TradingGroup: A Multi-Agent Trading System with Self-Reflection and Data-Synthesis" href="#31-tradinggroup-a-multi-agent-trading-system-with-self-reflection-and-data-synthesis-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.17565
<strong>Authors:</strong> Feng Tian, Flora D. Salim, Hao Xue</p>
<p><strong>Abstract:</strong> arXiv:2508.17565v1 Announce Type: new  Abstract: Recent advancements in large language models (LLMs) have enabled powerful agent-based applications in finance, particularly for sentiment analysis, financial report comprehension, and stock forecasting. However, existing systems often lack inter-agent coordination, structured self-reflection, and access to high-quality, domain-specific post-training data such as data from trading activities including both market conditions and agent decisions. These data are crucial for agents to understand the market dynamics, improve the quality of decision-making and promote effective coordination. We introduce TradingGroup, a multi-agent trading system designed to address these limitations through a self-reflective architecture and an end-to-end data-synthesis pipeline. TradingGroup consists of specialized agents for news sentiment analysis, financial report interpretation, stock trend forecasting, trading style adaptation, and a trading decision making agent that merges all signals and style preferences to produce buy, sell or hold decisions. Specifically, we design self-reflection mechanisms for the stock forecasting, style, and decision-making agents to distill past successes and failures for similar reasoning in analogous future scenarios and a dynamic risk-management model to offer configurable dynamic stop-loss and take-profit mechanisms. In addition, TradingGroup embeds an automated data-synthesis and annotation pipeline that generates high-quality post-training data for further improving the agent performance through post-training. Our backtesting experiments across five real-world stock datasets demonstrate TradingGroup's superior performance over rule-based, machine learning, reinforcement learning, and existing LLM-based trading strategies.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">32. <a href="https://arxiv.org/abs/2508.16641" rel="nofollow">Enhancing Transformer-Based Foundation Models for Time Series Forecasting via Bagging, Boosting and Statistical Ensembles</a> <a id="user-content-link32"></a>
</h2><a id="user-content-32-enhancing-transformer-based-foundation-models-for-time-series-forecasting-via-bagging-boosting-and-statistical-ensembles-" class="anchor" aria-label="Permalink: 32. Enhancing Transformer-Based Foundation Models for Time Series Forecasting via Bagging, Boosting and Statistical Ensembles" href="#32-enhancing-transformer-based-foundation-models-for-time-series-forecasting-via-bagging-boosting-and-statistical-ensembles-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.16641
<strong>Authors:</strong> Dhruv D. Modi, Rong Pan</p>
<p><strong>Abstract:</strong> arXiv:2508.16641v1 Announce Type: new  Abstract: Time series foundation models (TSFMs) such as Lag-Llama, TimeGPT, Chronos, MOMENT, UniTS, and TimesFM have shown strong generalization and zero-shot capabilities for time series forecasting, anomaly detection, classification, and imputation. Despite these advantages, their predictions still suffer from variance, domain-specific bias, and limited uncertainty quantification when deployed on real operational data. This paper investigates a suite of statistical and ensemble-based enhancement techniques, including bootstrap-based bagging, regression-based stacking, prediction interval construction, statistical residual modeling, and iterative error feedback, to improve robustness and accuracy. Using the Belgium Electricity Short-Term Load Forecasting dataset as a case study, we demonstrate that the proposed hybrids consistently outperform standalone foundation models across multiple horizons. Regression-based ensembles achieve the lowest mean squared error; bootstrap aggregation markedly reduces long-context errors; residual modeling corrects systematic bias; and the resulting prediction intervals achieve near nominal coverage with widths shrinking as context length increases. The results indicate that integrating statistical reasoning with modern foundation models yields measurable gains in accuracy, reliability, and interpretability for real-world time series applications.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">33. <a href="https://arxiv.org/abs/2508.16749" rel="nofollow">A Dataset and Benchmark for Robotic Cloth Unfolding Grasp Selection: The ICRA 2024 Cloth Competition</a> <a id="user-content-link33"></a>
</h2><a id="user-content-33-a-dataset-and-benchmark-for-robotic-cloth-unfolding-grasp-selection-the-icra-2024-cloth-competition-" class="anchor" aria-label="Permalink: 33. A Dataset and Benchmark for Robotic Cloth Unfolding Grasp Selection: The ICRA 2024 Cloth Competition" href="#33-a-dataset-and-benchmark-for-robotic-cloth-unfolding-grasp-selection-the-icra-2024-cloth-competition-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.16749
<strong>Authors:</strong> Victor-Louis De Gusseme, Thomas Lips, Remko Proesmans, Julius Hietala, Giwan Lee, Jiyoung Choi, Jeongil Choi, Geon Kim, Phayuth Yonrith, Domen Tabernik, Andrej Gams, Peter Nimac, Matej Urbas, Jon Muhovi\v{c}, Danijel Sko\v{c}aj, Matija Mavsar, Hyojeong Yu, Minseo Kwon, Young J. Kim, Yang Cong, Ronghan Chen, Yu Ren, Supeng Diao, Jiawei Weng, Jiayue Liu, Haoran Sun, Linhan Yang, Zeqing Zhang, Ning Guo, Lei Yang, Fang Wan, Chaoyang Song, Jia Pan, Yixiang Jin, Yong A, Jun Shi, Dingzhe Li, Yong Yang, Kakeru Yamasaki, Takumi Kajiwara, Yuki Nakadera, Krati Saxena, Tomohiro Shibata, Chongkun Xia, Kai Mo, Yanzhao Yu, Qihao Lin, Binqiang Ma, Uihun Sagong, JungHyun Choi, JeongHyun Park, Dongwoo Lee, Yeongmin Kim, Myun Joong Hwang, Yusuke Kuribayashi, Naoki Hiratsuka, Daisuke Tanaka, Solvi Arnold, Kimitoshi Yamazaki, Carlos Mateo-Agullo, Andreas Verleysen, Francis Wyffels</p>
<p><strong>Abstract:</strong> arXiv:2508.16749v1 Announce Type: new  Abstract: Robotic cloth manipulation suffers from a lack of standardized benchmarks and shared datasets for evaluating and comparing different approaches. To address this, we created a benchmark and organized the ICRA 2024 Cloth Competition, a unique head-to-head evaluation focused on grasp pose selection for in-air robotic cloth unfolding. Eleven diverse teams participated in the competition, utilizing our publicly released dataset of real-world robotic cloth unfolding attempts and a variety of methods to design their unfolding approaches. Afterwards, we also expanded our dataset with 176 competition evaluation trials, resulting in a dataset of 679 unfolding demonstrations across 34 garments. Analysis of the competition results revealed insights about the trade-off between grasp success and coverage, the surprisingly strong achievements of hand-engineered methods and a significant discrepancy between competition performance and prior work, underscoring the importance of independent, out-of-the-lab evaluation in robotic cloth manipulation. The associated dataset is a valuable resource for developing and evaluating grasp selection methods, particularly for learning-based approaches. We hope that our benchmark, dataset and competition results can serve as a foundation for future benchmarks and drive further progress in data-driven robotic cloth manipulation. The dataset and benchmarking code are available at <a href="https://airo.ugent.be/cloth_competition" rel="nofollow">https://airo.ugent.be/cloth_competition</a>.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">34. <a href="https://arxiv.org/abs/2508.16647" rel="nofollow">AdapSNE: Adaptive Fireworks-Optimized and Entropy-Guided Dataset Sampling for Edge DNN Training</a> <a id="user-content-link34"></a>
</h2><a id="user-content-34-adapsne-adaptive-fireworks-optimized-and-entropy-guided-dataset-sampling-for-edge-dnn-training-" class="anchor" aria-label="Permalink: 34. AdapSNE: Adaptive Fireworks-Optimized and Entropy-Guided Dataset Sampling for Edge DNN Training" href="#34-adapsne-adaptive-fireworks-optimized-and-entropy-guided-dataset-sampling-for-edge-dnn-training-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.16647
<strong>Authors:</strong> Boran Zhao, Hetian Liu, Zihang Yuan, Li Zhu, Fan Yang, Lina Xie Tian Xia, Wenzhe Zhao, Pengju Ren</p>
<p><strong>Abstract:</strong> arXiv:2508.16647v1 Announce Type: new  Abstract: Training deep neural networks (DNNs) directly on edge devices has attracted increasing attention, as it offers promising solutions to challenges such as domain adaptation and privacy preservation. However, conventional DNN training typically requires large-scale datasets, which imposes prohibitive overhead on edge devices-particularly for emerging large language model (LLM) tasks. To address this challenge, a DNN-free method (ie., dataset sampling without DNN), named NMS (Near-Memory Sampling), has been introduced. By first conducting dimensionality reduction of the dataset and then performing exemplar sampling in the reduced space, NMS avoids the architectural bias inherent in DNN-based methods and thus achieves better generalization. However, The state-of-the-art, NMS, suffers from two limitations: (1) The mismatch between the search method and the non-monotonic property of the perplexity error function leads to the emergence of outliers in the reduced representation; (2) Key parameter (ie., target perplexity) is selected empirically, introducing arbitrariness and leading to uneven sampling. These two issues lead to representative bias of examplars, resulting in degraded accuracy. To address these issues, we propose AdapSNE, which integrates an efficient non-monotonic search method-namely, the Fireworks Algorithm (FWA)-to suppress outliers, and employs entropy-guided optimization to enforce uniform sampling, thereby ensuring representative training samples and consequently boosting training accuracy. To cut the edge-side cost arising from the iterative computations of FWA search and entropy-guided optimization, we design an accelerator with custom dataflow and time-multiplexing markedly reducing on-device training energy and area.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">35. <a href="https://arxiv.org/abs/2508.17677" rel="nofollow">TiKMiX: Take Data Influence into Dynamic Mixture for Language Model Pre-training</a> <a id="user-content-link35"></a>
</h2><a id="user-content-35-tikmix-take-data-influence-into-dynamic-mixture-for-language-model-pre-training-" class="anchor" aria-label="Permalink: 35. TiKMiX: Take Data Influence into Dynamic Mixture for Language Model Pre-training" href="#35-tikmix-take-data-influence-into-dynamic-mixture-for-language-model-pre-training-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.17677
<strong>Authors:</strong> Yifan Wang, Binbin Liu, Fengze Liu, Yuanfan Guo, Jiyao Deng, Xuecheng Wu, Weidong Zhou, Xiaohuan Zhou, Taifeng Wang</p>
<p><strong>Abstract:</strong> arXiv:2508.17677v1 Announce Type: new  Abstract: The data mixture used in the pre-training of a language model is a cornerstone of its final performance. However, a static mixing strategy is suboptimal, as the model's learning preferences for various data domains shift dynamically throughout training. Crucially, observing these evolving preferences in a computationally efficient manner remains a significant challenge. To address this, we propose TiKMiX, a method that dynamically adjusts the data mixture according to the model's evolving preferences. TiKMiX introduces Group Influence, an efficient metric for evaluating the impact of data domains on the model. This metric enables the formulation of the data mixing problem as a search for an optimal, influence-maximizing distribution. We solve this via two approaches: TiKMiX-D for direct optimization, and TiKMiX-M, which uses a regression model to predict a superior mixture. We trained models with different numbers of parameters, on up to 1 trillion tokens. TiKMiX-D exceeds the performance of state-of-the-art methods like REGMIX while using just 20% of the computational resources. TiKMiX-M leads to an average performance gain of 2% across 9 downstream benchmarks. Our experiments reveal that a model's data preferences evolve with training progress and scale, and we demonstrate that dynamically adjusting the data mixture based on Group Influence, a direct measure of these preferences, significantly improves performance by mitigating the underdigestion of data seen with static ratios.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">36. <a href="https://arxiv.org/abs/2508.17083" rel="nofollow">Learning ON Large Datasets Using Bit-String Trees</a> <a id="user-content-link36"></a>
</h2><a id="user-content-36-learning-on-large-datasets-using-bit-string-trees-" class="anchor" aria-label="Permalink: 36. Learning ON Large Datasets Using Bit-String Trees" href="#36-learning-on-large-datasets-using-bit-string-trees-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.17083
<strong>Authors:</strong> Prashant Gupta</p>
<p><strong>Abstract:</strong> arXiv:2508.17083v1 Announce Type: new  Abstract: This thesis develops computational methods in similarity-preserving hashing, classification, and cancer genomics. Standard space partitioning-based hashing relies on Binary Search Trees (BSTs), but their exponential growth and sparsity hinder efficiency. To overcome this, we introduce Compressed BST of Inverted hash tables (ComBI), which enables fast approximate nearest-neighbor search with reduced memory. On datasets of up to one billion samples, ComBI achieves 0.90 precision with 4X-296X speed-ups over Multi-Index Hashing, and also outperforms Cellfishing.jl on single-cell RNA-seq searches with 2X-13X gains. Building on hashing structures, we propose Guided Random Forest (GRAF), a tree-based ensemble classifier that integrates global and local partitioning, bridging decision trees and boosting while reducing generalization error. Across 115 datasets, GRAF delivers competitive or superior accuracy, and its unsupervised variant (uGRAF) supports guided hashing and importance sampling. We show that GRAF and ComBI can be used to estimate per-sample classifiability, which enables scalable prediction of cancer patient survival. To address challenges in interpreting mutations, we introduce Continuous Representation of Codon Switches (CRCS), a deep learning framework that embeds genetic changes into numerical vectors. CRCS allows identification of somatic mutations without matched normals, discovery of driver genes, and scoring of tumor mutations, with survival prediction validated in bladder, liver, and brain cancers. Together, these methods provide efficient, scalable, and interpretable tools for large-scale data analysis and biomedical applications.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">37. <a href="https://arxiv.org/abs/2508.16947" rel="nofollow">Drive As You Like: Strategy-Level Motion Planning Based on A Multi-Head Diffusion Model</a> <a id="user-content-link37"></a>
</h2><a id="user-content-37-drive-as-you-like-strategy-level-motion-planning-based-on-a-multi-head-diffusion-model-" class="anchor" aria-label="Permalink: 37. Drive As You Like: Strategy-Level Motion Planning Based on A Multi-Head Diffusion Model" href="#37-drive-as-you-like-strategy-level-motion-planning-based-on-a-multi-head-diffusion-model-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.16947
<strong>Authors:</strong> Fan Ding, Xuewen Luo, Hwa Hui Tew, Ruturaj Reddy, Xikun Wang, Junn Yong Loo</p>
<p><strong>Abstract:</strong> arXiv:2508.16947v1 Announce Type: new  Abstract: Recent advances in motion planning for autonomous driving have led to models capable of generating high-quality trajectories. However, most existing planners tend to fix their policy after supervised training, leading to consistent but rigid driving behaviors. This limits their ability to reflect human preferences or adapt to dynamic, instruction-driven demands. In this work, we propose a diffusion-based multi-head trajectory planner(M-diffusion planner). During the early training stage, all output heads share weights to learn to generate high-quality trajectories. Leveraging the probabilistic nature of diffusion models, we then apply Group Relative Policy Optimization (GRPO) to fine-tune the pre-trained model for diverse policy-specific behaviors. At inference time, we incorporate a large language model (LLM) to guide strategy selection, enabling dynamic, instruction-aware planning without switching models. Closed-loop simulation demonstrates that our post-trained planner retains strong planning capability while achieving state-of-the-art (SOTA) performance on the nuPlan val14 benchmark. Open-loop results further show that the generated trajectories exhibit clear diversity, effectively satisfying multi-modal driving behavior requirements. The code and related experiments will be released upon acceptance of the paper.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">38. <a href="https://arxiv.org/abs/2508.17260" rel="nofollow">OVITA: Open-Vocabulary Interpretable Trajectory Adaptations</a> <a id="user-content-link38"></a>
</h2><a id="user-content-38-ovita-open-vocabulary-interpretable-trajectory-adaptations-" class="anchor" aria-label="Permalink: 38. OVITA: Open-Vocabulary Interpretable Trajectory Adaptations" href="#38-ovita-open-vocabulary-interpretable-trajectory-adaptations-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.17260
<strong>Authors:</strong> Anurag Maurya, Tashmoy Ghosh, Anh Nguyen, Ravi Prakash</p>
<p><strong>Abstract:</strong> arXiv:2508.17260v1 Announce Type: new  Abstract: Adapting trajectories to dynamic situations and user preferences is crucial for robot operation in unstructured environments with non-expert users. Natural language enables users to express these adjustments in an interactive manner. We introduce OVITA, an interpretable, open-vocabulary, language-driven framework designed for adapting robot trajectories in dynamic and novel situations based on human instructions. OVITA leverages multiple pre-trained Large Language Models (LLMs) to integrate user commands into trajectories generated by motion planners or those learned through demonstrations. OVITA employs code as an adaptation policy generated by an LLM, enabling users to adjust individual waypoints, thus providing flexible control. Another LLM, which acts as a code explainer, removes the need for expert users, enabling intuitive interactions. The efficacy and significance of the proposed OVITA framework is demonstrated through extensive simulations and real-world environments with diverse tasks involving spatiotemporal variations on heterogeneous robotic platforms such as a KUKA IIWA robot manipulator, Clearpath Jackal ground robot, and CrazyFlie drone.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">39. <a href="https://arxiv.org/abs/2508.16676" rel="nofollow">WISCA: A Lightweight Model Transition Method to Improve LLM Training via Weight Scaling</a> <a id="user-content-link39"></a>
</h2><a id="user-content-39-wisca-a-lightweight-model-transition-method-to-improve-llm-training-via-weight-scaling-" class="anchor" aria-label="Permalink: 39. WISCA: A Lightweight Model Transition Method to Improve LLM Training via Weight Scaling" href="#39-wisca-a-lightweight-model-transition-method-to-improve-llm-training-via-weight-scaling-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.16676
<strong>Authors:</strong> Jiacheng Li, Jianchao Tan, Zhidong Yang, Pingwei Sun, Feiye Huo, Jiayu Qin, Yerui Sun, Yuchen Xie, Xunliang Cai, Xiangyu Zhang, Maoxin He, Guangming Tan, Weile Jia, Tong Zhao</p>
<p><strong>Abstract:</strong> arXiv:2508.16676v1 Announce Type: new  Abstract: Transformer architecture gradually dominates the LLM field. Recent advances in training optimization for Transformer-based large language models (LLMs) primarily focus on architectural modifications or optimizer adjustments. However, these approaches lack systematic optimization of weight patterns during training. Weight pattern refers to the distribution and relative magnitudes of weight parameters in a neural network. To address this issue, we propose a Weight Scaling method called WISCA to enhance training efficiency and model quality by strategically improving neural network weight patterns without changing network structures. By rescaling weights while preserving model outputs, WISCA indirectly optimizes the model's training trajectory. Experiments demonstrate that WISCA significantly improves convergence quality (measured by generalization capability and loss reduction), particularly in LLMs with Grouped Query Attention (GQA) architectures and LoRA fine-tuning tasks. Empirical results show 5.6% average improvement on zero-shot validation tasks and 2.12% average reduction in training perplexity across multiple architectures.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">40. <a href="https://arxiv.org/abs/2508.18182" rel="nofollow">AdLoCo: adaptive batching significantly improves communications efficiency and convergence for Large Language Models</a> <a id="user-content-link40"></a>
</h2><a id="user-content-40-adloco-adaptive-batching-significantly-improves-communications-efficiency-and-convergence-for-large-language-models-" class="anchor" aria-label="Permalink: 40. AdLoCo: adaptive batching significantly improves communications efficiency and convergence for Large Language Models" href="#40-adloco-adaptive-batching-significantly-improves-communications-efficiency-and-convergence-for-large-language-models-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.18182
<strong>Authors:</strong> Nikolay Kutuzov, Makar Baderko, Stepan Kulibaba, Artem Dzhalilov, Daniel Bobrov, Maxim Mashtaler, Alexander Gasnikov</p>
<p><strong>Abstract:</strong> arXiv:2508.18182v1 Announce Type: new  Abstract: Scaling distributed training of Large Language Models (LLMs) requires not only algorithmic advances but also efficient utilization of heterogeneous hardware resources. While existing methods such as DiLoCo have demonstrated promising results, they often fail to fully exploit computational clusters under dynamic workloads. To address this limitation, we propose a three-stage method that combines Multi-Instance Training (MIT), Adaptive Batched DiLoCo, and switch mode mechanism. MIT allows individual nodes to run multiple lightweight training streams with different model instances in parallel and merge them to combine knowledge, increasing throughput and reducing idle time. Adaptive Batched DiLoCo dynamically adjusts local batch sizes to balance computation and communication, substantially lowering synchronization delays. Switch mode further stabilizes training by seamlessly introducing gradient accumulation once adaptive batch sizes grow beyond hardware-friendly limits. Together, these innovations improve both convergence speed and system efficiency. We also provide a theoretical estimate of the number of communications required for the full convergence of a model trained using our method.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">41. <a href="https://arxiv.org/abs/2508.17692" rel="nofollow">LLM-based Agentic Reasoning Frameworks: A Survey from Methods to Scenarios</a> <a id="user-content-link41"></a>
</h2><a id="user-content-41-llm-based-agentic-reasoning-frameworks-a-survey-from-methods-to-scenarios-" class="anchor" aria-label="Permalink: 41. LLM-based Agentic Reasoning Frameworks: A Survey from Methods to Scenarios" href="#41-llm-based-agentic-reasoning-frameworks-a-survey-from-methods-to-scenarios-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.17692
<strong>Authors:</strong> Bingxi Zhao, Lin Geng Foo, Ping Hu, Christian Theobalt, Hossein Rahmani, Jun Liu</p>
<p><strong>Abstract:</strong> arXiv:2508.17692v1 Announce Type: new  Abstract: Recent advances in the intrinsic reasoning capabilities of large language models (LLMs) have given rise to LLM-based agent systems that exhibit near-human performance on a variety of automated tasks. However, although these systems share similarities in terms of their use of LLMs, different reasoning frameworks of the agent system steer and organize the reasoning process in different ways. In this survey, we propose a systematic taxonomy that decomposes agentic reasoning frameworks and analyze how these frameworks dominate framework-level reasoning by comparing their applications across different scenarios. Specifically, we propose an unified formal language to further classify agentic reasoning systems into single-agent methods, tool-based methods, and multi-agent methods. After that, we provide a comprehensive review of their key application scenarios in scientific discovery, healthcare, software engineering, social simulation, and economics. We also analyze the characteristic features of each framework and summarize different evaluation strategies. Our survey aims to provide the research community with a panoramic view to facilitate understanding of the strengths, suitable scenarios, and evaluation practices of different agentic reasoning frameworks.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">42. <a href="https://arxiv.org/abs/2508.17901" rel="nofollow">Riemannian Optimization for LoRA on the Stiefel Manifold</a> <a id="user-content-link42"></a>
</h2><a id="user-content-42-riemannian-optimization-for-lora-on-the-stiefel-manifold-" class="anchor" aria-label="Permalink: 42. Riemannian Optimization for LoRA on the Stiefel Manifold" href="#42-riemannian-optimization-for-lora-on-the-stiefel-manifold-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.17901
<strong>Authors:</strong> Juneyoung Park, Minjae Kang, Seongbae Lee, Haegang Lee, Seongwan Kim, Jaeho Lee</p>
<p><strong>Abstract:</strong> arXiv:2508.17901v1 Announce Type: new  Abstract: While powerful, large language models (LLMs) present significant fine-tuning challenges due to their size. Parameter-efficient fine-tuning (PEFT) methods like LoRA provide solutions, yet suffer from critical optimizer inefficiencies; notably basis redundancy in LoRA's $B$ matrix when using AdamW, which fundamentally limits performance. We address this by optimizing the $B$ matrix on the Stiefel manifold, imposing explicit orthogonality constraints that achieve near-perfect orthogonality and full effective rank. This geometric approach dramatically enhances parameter efficiency and representational capacity. Our Stiefel optimizer consistently outperforms AdamW across benchmarks with both LoRA and DoRA, demonstrating that geometric constraints are the key to unlocking LoRA's full potential for effective LLM fine-tuning.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">43. <a href="https://arxiv.org/abs/2508.17426" rel="nofollow">Modular MeanFlow: Towards Stable and Scalable One-Step Generative Modeling</a> <a id="user-content-link43"></a>
</h2><a id="user-content-43-modular-meanflow-towards-stable-and-scalable-one-step-generative-modeling-" class="anchor" aria-label="Permalink: 43. Modular MeanFlow: Towards Stable and Scalable One-Step Generative Modeling" href="#43-modular-meanflow-towards-stable-and-scalable-one-step-generative-modeling-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.17426
<strong>Authors:</strong> Haochen You, Baojing Liu, Hongyang He</p>
<p><strong>Abstract:</strong> arXiv:2508.17426v1 Announce Type: new  Abstract: One-step generative modeling seeks to generate high-quality data samples in a single function evaluation, significantly improving efficiency over traditional diffusion or flow-based models. In this work, we introduce Modular MeanFlow (MMF), a flexible and theoretically grounded approach for learning time-averaged velocity fields. Our method derives a family of loss functions based on a differential identity linking instantaneous and average velocities, and incorporates a gradient modulation mechanism that enables stable training without sacrificing expressiveness. We further propose a curriculum-style warmup schedule to smoothly transition from coarse supervision to fully differentiable training. The MMF formulation unifies and generalizes existing consistency-based and flow-matching methods, while avoiding expensive higher-order derivatives. Empirical results across image synthesis and trajectory modeling tasks demonstrate that MMF achieves competitive sample quality, robust convergence, and strong generalization, particularly under low-data or out-of-distribution settings.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">44. <a href="https://arxiv.org/abs/2508.18040" rel="nofollow">PerPilot: Personalizing VLM-based Mobile Agents via Memory and Exploration</a> <a id="user-content-link44"></a>
</h2><a id="user-content-44-perpilot-personalizing-vlm-based-mobile-agents-via-memory-and-exploration-" class="anchor" aria-label="Permalink: 44. PerPilot: Personalizing VLM-based Mobile Agents via Memory and Exploration" href="#44-perpilot-personalizing-vlm-based-mobile-agents-via-memory-and-exploration-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.18040
<strong>Authors:</strong> Xin Wang, Zhiyao Cui, Hao Li, Ya Zeng, Chenxu Wang, Ruiqi Song, Yihang Chen, Kun Shao, Qiaosheng Zhang, Jinzhuo Liu, Siyue Ren, Shuyue Hu, Zhen Wang</p>
<p><strong>Abstract:</strong> arXiv:2508.18040v1 Announce Type: new  Abstract: Vision language model (VLM)-based mobile agents show great potential for assisting users in performing instruction-driven tasks. However, these agents typically struggle with personalized instructions -- those containing ambiguous, user-specific context -- a challenge that has been largely overlooked in previous research. In this paper, we define personalized instructions and introduce PerInstruct, a novel human-annotated dataset covering diverse personalized instructions across various mobile scenarios. Furthermore, given the limited personalization capabilities of existing mobile agents, we propose PerPilot, a plug-and-play framework powered by large language models (LLMs) that enables mobile agents to autonomously perceive, understand, and execute personalized user instructions. PerPilot identifies personalized elements and autonomously completes instructions via two complementary approaches: memory-based retrieval and reasoning-based exploration. Experimental results demonstrate that PerPilot effectively handles personalized tasks with minimal user intervention and progressively improves its performance with continued use, underscoring the importance of personalization-aware reasoning for next-generation mobile agents. The dataset and code are available at: <a href="https://github.com/xinwang-nwpu/PerPilot">https://github.com/xinwang-nwpu/PerPilot</a></p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">45. <a href="https://arxiv.org/abs/2508.17764" rel="nofollow">Puzzle: Scheduling Multiple Deep Learning Models on Mobile Device with Heterogeneous Processors</a> <a id="user-content-link45"></a>
</h2><a id="user-content-45-puzzle-scheduling-multiple-deep-learning-models-on-mobile-device-with-heterogeneous-processors-" class="anchor" aria-label="Permalink: 45. Puzzle: Scheduling Multiple Deep Learning Models on Mobile Device with Heterogeneous Processors" href="#45-puzzle-scheduling-multiple-deep-learning-models-on-mobile-device-with-heterogeneous-processors-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.17764
<strong>Authors:</strong> Duseok Kang, Yunseong Lee, Junghoon Kim</p>
<p><strong>Abstract:</strong> arXiv:2508.17764v1 Announce Type: new  Abstract: As deep learning models are increasingly deployed on mobile devices, modern mobile devices incorporate deep learning-specific accelerators to handle the growing computational demands, thus increasing their hardware heterogeneity. However, existing works on scheduling deep learning workloads across these processors have significant limitations: most studies focus on single-model scenarios rather than realistic multi-model scenarios, overlook performance variations from different hardware/software configurations, and struggle with accurate execution time estimation. To address these challenges, we propose a novel genetic algorithm-based methodology for scheduling multiple deep learning networks on heterogeneous processors by partitioning the networks into multiple subgraphs. Our approach incorporates three different types of chromosomes for partition/mapping/priority exploration, and leverages device-in-the-loop profiling and evaluation for accurate execution time estimation. Based on this methodology, our system, Puzzle, demonstrates superior performance in extensive evaluations with randomly generated scenarios involving nine state-of-the-art networks. The results demonstrate Puzzle can support 3.7 and 2.2 times higher request frequency on average compared to the two heuristic baselines, NPU Only and Best Mapping, respectively, while satisfying the equivalent level of real-time requirements.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">46. <a href="https://arxiv.org/abs/2508.16651" rel="nofollow">HiCL: Hippocampal-Inspired Continual Learning</a> <a id="user-content-link46"></a>
</h2><a id="user-content-46-hicl-hippocampal-inspired-continual-learning-" class="anchor" aria-label="Permalink: 46. HiCL: Hippocampal-Inspired Continual Learning" href="#46-hicl-hippocampal-inspired-continual-learning-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.16651
<strong>Authors:</strong> Kushal Kapoor, Wyatt Mackey, Yiannis Aloimonos, Xiaomin Lin</p>
<p><strong>Abstract:</strong> arXiv:2508.16651v1 Announce Type: new  Abstract: We propose HiCL, a novel hippocampal-inspired dual-memory continual learning architecture designed to mitigate catastrophic forgetting by using elements inspired by the hippocampal circuitry. Our system encodes inputs through a grid-cell-like layer, followed by sparse pattern separation using a dentate gyrus-inspired module with top-k sparsity. Episodic memory traces are maintained in a CA3-like autoassociative memory. Task-specific processing is dynamically managed via a DG-gated mixture-of-experts mechanism, wherein inputs are routed to experts based on cosine similarity between their normalized sparse DG representations and learned task-specific DG prototypes computed through online exponential moving averages. This biologically grounded yet mathematically principled gating strategy enables differentiable, scalable task-routing without relying on a separate gating network, and enhances the model's adaptability and efficiency in learning multiple sequential tasks. Cortical outputs are consolidated using Elastic Weight Consolidation weighted by inter-task similarity. Crucially, we incorporate prioritized replay of stored patterns to reinforce essential past experiences. Evaluations on standard continual learning benchmarks demonstrate the effectiveness of our architecture in reducing task interference, achieving near state-of-the-art results in continual learning tasks at lower computational costs.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">47. <a href="https://arxiv.org/abs/2508.16939" rel="nofollow">Sig-DEG for Distillation: Making Diffusion Models Faster and Lighter</a> <a id="user-content-link47"></a>
</h2><a id="user-content-47-sig-deg-for-distillation-making-diffusion-models-faster-and-lighter-" class="anchor" aria-label="Permalink: 47. Sig-DEG for Distillation: Making Diffusion Models Faster and Lighter" href="#47-sig-deg-for-distillation-making-diffusion-models-faster-and-lighter-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.16939
<strong>Authors:</strong> Lei Jiang, Wen Ge, Niels Cariou-Kotlarek, Mingxuan Yi, Po-Yu Chen, Lingyi Yang, Francois Buet-Golfouse, Gaurav Mittal, Hao Ni</p>
<p><strong>Abstract:</strong> arXiv:2508.16939v1 Announce Type: new  Abstract: Diffusion models have achieved state-of-the-art results in generative modelling but remain computationally intensive at inference time, often requiring thousands of discretization steps. To this end, we propose Sig-DEG (Signature-based Differential Equation Generator), a novel generator for distilling pre-trained diffusion models, which can universally approximate the backward diffusion process at a coarse temporal resolution. Inspired by high-order approximations of stochastic differential equations (SDEs), Sig-DEG leverages partial signatures to efficiently summarize Brownian motion over sub-intervals and adopts a recurrent structure to enable accurate global approximation of the SDE solution. Distillation is formulated as a supervised learning task, where Sig-DEG is trained to match the outputs of a fine-resolution diffusion model on a coarse time grid. During inference, Sig-DEG enables fast generation, as the partial signature terms can be simulated exactly without requiring fine-grained Brownian paths. Experiments demonstrate that Sig-DEG achieves competitive generation quality while reducing the number of inference steps by an order of magnitude. Our results highlight the effectiveness of signature-based approximations for efficient generative modeling.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">48. <a href="https://arxiv.org/abs/2508.17137" rel="nofollow">MoE-Beyond: Learning-Based Expert Activation Prediction on Edge Devices</a> <a id="user-content-link48"></a>
</h2><a id="user-content-48-moe-beyond-learning-based-expert-activation-prediction-on-edge-devices-" class="anchor" aria-label="Permalink: 48. MoE-Beyond: Learning-Based Expert Activation Prediction on Edge Devices" href="#48-moe-beyond-learning-based-expert-activation-prediction-on-edge-devices-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.17137
<strong>Authors:</strong> Nishant Gavhane, Arush Mehrotra, Rohit Chawla, Peter Proenca</p>
<p><strong>Abstract:</strong> arXiv:2508.17137v1 Announce Type: new  Abstract: The deployment of large-scale Mixture-of-Experts (MoE) models on edge devices presents significant challenges due to memory constraints. While MoE architectures enable efficient utilization of computational resources by activating only a subset of experts per inference, they require careful memory management to operate efficiently in resource-constrained environments. Traditional heuristic-based expert caching strategies such as MoE-Infinity struggle to maintain high cache hit rates as models parameters scale. In this work, we introduce MoE-Beyond, a learning-based expert activation predictor trained to predict expert activations during autoregressive decoding. By framing the task as a multi-label sequence prediction problem, we train a lightweight transformer model on 66 million expert activation traces extracted from LDJnr-Puffin dataset [5] using DeepSeek-V2-Chat-Lite MoE. Our predictor generalizes effectively across unseen prompts from WebGLM-QA dataset [6], achieving 97.5% accuracy and an 86.6% F1-score. Simulation results show that MoE-Beyond improves GPU cache hit rate from 17% to 72% when only 10% of experts fit in GPU cache, outperforming heuristic baselines.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">49. <a href="https://arxiv.org/abs/2508.16915" rel="nofollow">Reinforcement-Guided Hyper-Heuristic Hyperparameter Optimization for Fair and Explainable Spiking Neural Network-Based Financial Fraud Detection</a> <a id="user-content-link49"></a>
</h2><a id="user-content-49-reinforcement-guided-hyper-heuristic-hyperparameter-optimization-for-fair-and-explainable-spiking-neural-network-based-financial-fraud-detection-" class="anchor" aria-label="Permalink: 49. Reinforcement-Guided Hyper-Heuristic Hyperparameter Optimization for Fair and Explainable Spiking Neural Network-Based Financial Fraud Detection" href="#49-reinforcement-guided-hyper-heuristic-hyperparameter-optimization-for-fair-and-explainable-spiking-neural-network-based-financial-fraud-detection-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.16915
<strong>Authors:</strong> Sadman Mohammad Nasif, Md Abrar Jahin, M. F. Mridha</p>
<p><strong>Abstract:</strong> arXiv:2508.16915v1 Announce Type: new  Abstract: The growing adoption of home banking systems has heightened the risk of cyberfraud, necessitating fraud detection mechanisms that are not only accurate but also fair and explainable. While AI models have shown promise in this domain, they face key limitations, including computational inefficiency, the interpretability challenges of spiking neural networks (SNNs), and the complexity and convergence instability of hyper-heuristic reinforcement learning (RL)-based hyperparameter optimization. To address these issues, we propose a novel framework that integrates a Cortical Spiking Network with Population Coding (CSNPC) and a Reinforcement-Guided Hyper-Heuristic Optimizer for Spiking Systems (RHOSS). The CSNPC, a biologically inspired SNN, employs population coding for robust classification, while RHOSS uses Q-learning to dynamically select low-level heuristics for hyperparameter optimization under fairness and recall constraints. Embedded within the Modular Supervisory Framework for Spiking Network Training and Interpretation (MoSSTI), the system incorporates explainable AI (XAI) techniques, specifically, saliency-based attribution and spike activity profiling, to increase transparency. Evaluated on the Bank Account Fraud (BAF) dataset suite, our model achieves a $90.8%$ recall at a strict $5%$ false positive rate (FPR), outperforming state-of-the-art spiking and non-spiking models while maintaining over $98%$ predictive equality across key demographic attributes. The explainability module further confirms that saliency attributions align with spiking dynamics, validating interpretability. These results demonstrate the potential of combining population-coded SNNs with reinforcement-guided hyper-heuristics for fair, transparent, and high-performance fraud detection in real-world financial applications.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">50. <a href="https://arxiv.org/abs/2508.17679" rel="nofollow">Characterizing the Behavior of Training Mamba-based State Space Models on GPUs</a> <a id="user-content-link50"></a>
</h2><a id="user-content-50-characterizing-the-behavior-of-training-mamba-based-state-space-models-on-gpus-" class="anchor" aria-label="Permalink: 50. Characterizing the Behavior of Training Mamba-based State Space Models on GPUs" href="#50-characterizing-the-behavior-of-training-mamba-based-state-space-models-on-gpus-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.17679
<strong>Authors:</strong> Trinayan Baruah, Kaustubh Shivdikar, Sara Prescott, David Kaeli</p>
<p><strong>Abstract:</strong> arXiv:2508.17679v1 Announce Type: new  Abstract: Mamba-based State Space Models (SSM) have emerged as a promising alternative to the ubiquitous transformers. Despite the expressive power of transformers, the quadratic complexity of computing attention is a major impediment to scaling performance as we increase the sequence length. SSMs provide an alternative path that addresses this problem, reducing the computational complexity requirements of self-attention with novel model architectures for different domains and fields such as video, text generation and graphs. Thus, it is important to characterize the behavior of these emerging workloads on GPUs and understand their requirements during GPU microarchitectural design. In this work we evaluate Mamba-based SSMs and characterize their behavior during training on GPUs. We construct a workload suite that offers representative models that span different model architectures. We then use this suite to analyze the architectural implications of running Mamba-based SSMs on GPUs. Our work sheds new light on potential optimizations to continue scaling the performance for such models.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">51. <a href="https://arxiv.org/abs/2508.17995" rel="nofollow">Topology Aware Neural Interpolation of Scalar Fields</a> <a id="user-content-link51"></a>
</h2><a id="user-content-51-topology-aware-neural-interpolation-of-scalar-fields-" class="anchor" aria-label="Permalink: 51. Topology Aware Neural Interpolation of Scalar Fields" href="#51-topology-aware-neural-interpolation-of-scalar-fields-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.17995
<strong>Authors:</strong> Mohamed Kissi, Keanu Sisouk, Joshua A. Levine, Julien Tierny</p>
<p><strong>Abstract:</strong> arXiv:2508.17995v1 Announce Type: new  Abstract: This paper presents a neural scheme for the topology-aware interpolation of time-varying scalar fields. Given a time-varying sequence of persistence diagrams, along with a sparse temporal sampling of the corresponding scalar fields, denoted as keyframes, our interpolation approach aims at "inverting" the non-keyframe diagrams to produce plausible estimations of the corresponding, missing data. For this, we rely on a neural architecture which learns the relation from a time value to the corresponding scalar field, based on the keyframe examples, and reliably extends this relation to the non-keyframe time steps. We show how augmenting this architecture with specific topological losses exploiting the input diagrams both improves the geometrical and topological reconstruction of the non-keyframe time steps. At query time, given an input time value for which an interpolation is desired, our approach instantaneously produces an output, via a single propagation of the time input through the network. Experiments interpolating 2D and 3D time-varying datasets show our approach superiority, both in terms of data and topological fitting, with regard to reference interpolation schemes.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">52. <a href="https://arxiv.org/abs/2508.17320" rel="nofollow">AdaptiveK Sparse Autoencoders: Dynamic Sparsity Allocation for Interpretable LLM Representations</a> <a id="user-content-link52"></a>
</h2><a id="user-content-52-adaptivek-sparse-autoencoders-dynamic-sparsity-allocation-for-interpretable-llm-representations-" class="anchor" aria-label="Permalink: 52. AdaptiveK Sparse Autoencoders: Dynamic Sparsity Allocation for Interpretable LLM Representations" href="#52-adaptivek-sparse-autoencoders-dynamic-sparsity-allocation-for-interpretable-llm-representations-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.17320
<strong>Authors:</strong> Yifei Yao, Mengnan Du</p>
<p><strong>Abstract:</strong> arXiv:2508.17320v1 Announce Type: new  Abstract: Understanding the internal representations of large language models (LLMs) remains a central challenge for interpretability research. Sparse autoencoders (SAEs) offer a promising solution by decomposing activations into interpretable features, but existing approaches rely on fixed sparsity constraints that fail to account for input complexity. We propose Adaptive Top K Sparse Autoencoders (AdaptiveK), a novel framework that dynamically adjusts sparsity levels based on the semantic complexity of each input. Leveraging linear probes, we demonstrate that context complexity is linearly encoded in LLM representations, and we use this signal to guide feature allocation during training. Experiments across three language models (Pythia-70M, Pythia-160M, and Gemma-2-2B) demonstrate that this complexity-driven adaptation significantly outperforms fixed-sparsity approaches on reconstruction fidelity, explained variance, and cosine similarity metrics while eliminating the computational burden of extensive hyperparameter tuning.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">53. <a href="https://arxiv.org/abs/2508.17550" rel="nofollow">In-Context Algorithm Emulation in Fixed-Weight Transformers</a> <a id="user-content-link53"></a>
</h2><a id="user-content-53-in-context-algorithm-emulation-in-fixed-weight-transformers-" class="anchor" aria-label="Permalink: 53. In-Context Algorithm Emulation in Fixed-Weight Transformers" href="#53-in-context-algorithm-emulation-in-fixed-weight-transformers-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.17550
<strong>Authors:</strong> Jerry Yao-Chieh Hu, Hude Liu, Jennifer Yuntong Zhang, Han Liu</p>
<p><strong>Abstract:</strong> arXiv:2508.17550v1 Announce Type: new  Abstract: We prove that a minimal Transformer architecture with frozen weights is capable of emulating a broad class of algorithms by in-context prompting. In particular, for any algorithm implementable by a fixed-weight attention head (e.g. one-step gradient descent or linear/ridge regression), there exists a prompt that drives a two-layer softmax attention module to reproduce the algorithm's output with arbitrary precision. This guarantee extends even to a single-head attention layer (using longer prompts if necessary), achieving architectural minimality. Our key idea is to construct prompts that encode an algorithm's parameters into token representations, creating sharp dot-product gaps that force the softmax attention to follow the intended computation. This construction requires no feed-forward layers and no parameter updates. All adaptation happens through the prompt alone. These findings forge a direct link between in-context learning and algorithmic emulation, and offer a simple mechanism for large Transformers to serve as prompt-programmable libraries of algorithms. They illuminate how GPT-style foundation models may swap algorithms via prompts alone, establishing a form of algorithmic universality in modern Transformer models.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">54. <a href="https://arxiv.org/abs/2508.17751" rel="nofollow">Multi-layer Abstraction for Nested Generation of Options (MANGO) in Hierarchical Reinforcement Learning</a> <a id="user-content-link54"></a>
</h2><a id="user-content-54-multi-layer-abstraction-for-nested-generation-of-options-mango-in-hierarchical-reinforcement-learning-" class="anchor" aria-label="Permalink: 54. Multi-layer Abstraction for Nested Generation of Options (MANGO) in Hierarchical Reinforcement Learning" href="#54-multi-layer-abstraction-for-nested-generation-of-options-mango-in-hierarchical-reinforcement-learning-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.17751
<strong>Authors:</strong> Alessio Arcudi, Davide Sartor, Alberto Sinigaglia, Vincent Fran\c{c}ois-Lavet, Gian Antonio Susto</p>
<p><strong>Abstract:</strong> arXiv:2508.17751v1 Announce Type: new  Abstract: This paper introduces MANGO (Multilayer Abstraction for Nested Generation of Options), a novel hierarchical reinforcement learning framework designed to address the challenges of long-term sparse reward environments. MANGO decomposes complex tasks into multiple layers of abstraction, where each layer defines an abstract state space and employs options to modularize trajectories into macro-actions. These options are nested across layers, allowing for efficient reuse of learned movements and improved sample efficiency. The framework introduces intra-layer policies that guide the agent's transitions within the abstract state space, and task actions that integrate task-specific components such as reward functions. Experiments conducted in procedurally-generated grid environments demonstrate substantial improvements in both sample efficiency and generalization capabilities compared to standard RL methods. MANGO also enhances interpretability by making the agent's decision-making process transparent across layers, which is particularly valuable in safety-critical and industrial applications. Future work will explore automated discovery of abstractions and abstract actions, adaptation to continuous or fuzzy environments, and more robust multi-layer training strategies.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">55. <a href="https://arxiv.org/abs/2508.18249" rel="nofollow">Scene-Agnostic Traversability Labeling and Estimation via a Multimodal Self-supervised Framework</a> <a id="user-content-link55"></a>
</h2><a id="user-content-55-scene-agnostic-traversability-labeling-and-estimation-via-a-multimodal-self-supervised-framework-" class="anchor" aria-label="Permalink: 55. Scene-Agnostic Traversability Labeling and Estimation via a Multimodal Self-supervised Framework" href="#55-scene-agnostic-traversability-labeling-and-estimation-via-a-multimodal-self-supervised-framework-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.18249
<strong>Authors:</strong> Zipeng Fang, Yanbo Wang, Lei Zhao, Weidong Chen</p>
<p><strong>Abstract:</strong> arXiv:2508.18249v1 Announce Type: new  Abstract: Traversability estimation is critical for enabling robots to navigate across diverse terrains and environments. While recent self-supervised learning methods achieve promising results, they often fail to capture the characteristics of non-traversable regions. Moreover, most prior works concentrate on a single modality, overlooking the complementary strengths offered by integrating heterogeneous sensory modalities for more robust traversability estimation. To address these limitations, we propose a multimodal self-supervised framework for traversability labeling and estimation. First, our annotation pipeline integrates footprint, LiDAR, and camera data as prompts for a vision foundation model, generating traversability labels that account for both semantic and geometric cues. Then, leveraging these labels, we train a dual-stream network that jointly learns from different modalities in a decoupled manner, enhancing its capacity to recognize diverse traversability patterns. In addition, we incorporate sparse LiDAR-based supervision to mitigate the noise introduced by pseudo labels. Finally, extensive experiments conducted across urban, off-road, and campus environments demonstrate the effectiveness of our approach. The proposed automatic labeling method consistently achieves around 88% IoU across diverse datasets. Compared to existing self-supervised state-of-the-art methods, our multimodal traversability estimation network yields consistently higher IoU, improving by 1.6-3.5% on all evaluated datasets.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">56. <a href="https://arxiv.org/abs/2508.16929" rel="nofollow">Attention Layers Add Into Low-Dimensional Residual Subspaces</a> <a id="user-content-link56"></a>
</h2><a id="user-content-56-attention-layers-add-into-low-dimensional-residual-subspaces-" class="anchor" aria-label="Permalink: 56. Attention Layers Add Into Low-Dimensional Residual Subspaces" href="#56-attention-layers-add-into-low-dimensional-residual-subspaces-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.16929
<strong>Authors:</strong> Junxuan Wang, Xuyang Ge, Wentao Shu, Zhengfu He, Xipeng Qiu</p>
<p><strong>Abstract:</strong> arXiv:2508.16929v1 Announce Type: new  Abstract: While transformer models are widely believed to operate in high-dimensional hidden spaces, we show that attention outputs are confined to a surprisingly low-dimensional subspace, where about 60% of the directions account for 99% of the variance--a phenomenon that is induced by the attention output projection matrix and consistently observed across diverse model families and datasets. Critically, we find this low-rank structure as a fundamental cause of the prevalent dead feature problem in sparse dictionary learning, where it creates a mismatch between randomly initialized features and the intrinsic geometry of the activation space. Building on this insight, we propose a subspace-constrained training method for sparse autoencoders (SAEs), initializing feature directions into the active subspace of activations. Our approach reduces dead features from 87% to below 1% in Attention Output SAEs with 1M features, and can further extend to other sparse dictionary learning methods. Our findings provide both new insights into the geometry of attention and practical tools for improving sparse dictionary learning in large language models.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">57. <a href="https://arxiv.org/abs/2508.16623" rel="nofollow">A Retrieval Augmented Spatio-Temporal Framework for Traffic Prediction</a> <a id="user-content-link57"></a>
</h2><a id="user-content-57-a-retrieval-augmented-spatio-temporal-framework-for-traffic-prediction-" class="anchor" aria-label="Permalink: 57. A Retrieval Augmented Spatio-Temporal Framework for Traffic Prediction" href="#57-a-retrieval-augmented-spatio-temporal-framework-for-traffic-prediction-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.16623
<strong>Authors:</strong> Weilin Ruan, Xilin Dang, Ziyu Zhou, Sisuo Lyu, Yuxuan Liang</p>
<p><strong>Abstract:</strong> arXiv:2508.16623v1 Announce Type: new  Abstract: Traffic prediction is a cornerstone of modern intelligent transportation systems and a critical task in spatio-temporal forecasting. Although advanced Spatio-temporal Graph Neural Networks (STGNNs) and pre-trained models have achieved significant progress in traffic prediction, two key challenges remain: (i) limited contextual capacity when modeling complex spatio-temporal dependencies, and (ii) low predictability at fine-grained spatio-temporal points due to heterogeneous patterns. Inspired by Retrieval-Augmented Generation (RAG), we propose RAST, a universal framework that integrates retrieval-augmented mechanisms with spatio-temporal modeling to address these challenges. Our framework consists of three key designs: 1) Decoupled Encoder and Query Generator to capture decoupled spatial and temporal features and construct a fusion query via residual fusion; 2) Spatio-temporal Retrieval Store and Retrievers to maintain and retrieve vectorized fine-grained patterns; and 3) Universal Backbone Predictor that flexibly accommodates pre-trained STGNNs or simple MLP predictors. Extensive experiments on six real-world traffic networks, including large-scale datasets, demonstrate that RAST achieves superior performance while maintaining computational efficiency.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">58. <a href="https://arxiv.org/abs/2508.16634" rel="nofollow">Few-shot Class-incremental Fault Diagnosis by Preserving Class-Agnostic Knowledge with Dual-Granularity Representations</a> <a id="user-content-link58"></a>
</h2><a id="user-content-58-few-shot-class-incremental-fault-diagnosis-by-preserving-class-agnostic-knowledge-with-dual-granularity-representations-" class="anchor" aria-label="Permalink: 58. Few-shot Class-incremental Fault Diagnosis by Preserving Class-Agnostic Knowledge with Dual-Granularity Representations" href="#58-few-shot-class-incremental-fault-diagnosis-by-preserving-class-agnostic-knowledge-with-dual-granularity-representations-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.16634
<strong>Authors:</strong> Zhendong Yang, Jie Wang, Liansong Zong, Xiaorong Liu, Quan Qian, Shiqian Chen</p>
<p><strong>Abstract:</strong> arXiv:2508.16634v1 Announce Type: new  Abstract: Few-Shot Class-Incremental Fault Diagnosis (FSC-FD), which aims to continuously learn from new fault classes with only a few samples without forgetting old ones, is critical for real-world industrial systems. However, this challenging task severely amplifies the issues of catastrophic forgetting of old knowledge and overfitting on scarce new data. To address these challenges, this paper proposes a novel framework built upon Dual-Granularity Representations, termed the Dual-Granularity Guidance Network (DGGN). Our DGGN explicitly decouples feature learning into two parallel streams: 1) a fine-grained representation stream, which utilizes a novel Multi-Order Interaction Aggregation module to capture discriminative, class-specific features from the limited new samples. 2) a coarse-grained representation stream, designed to model and preserve general, class-agnostic knowledge shared across all fault types. These two representations are dynamically fused by a multi-semantic cross-attention mechanism, where the stable coarse-grained knowledge guides the learning of fine-grained features, preventing overfitting and alleviating feature conflicts. To further mitigate catastrophic forgetting, we design a Boundary-Aware Exemplar Prioritization strategy. Moreover, a decoupled Balanced Random Forest classifier is employed to counter the decision boundary bias caused by data imbalance. Extensive experiments on the TEP benchmark and a real-world MFF dataset demonstrate that our proposed DGGN achieves superior diagnostic performance and stability compared to state-of-the-art FSC-FD approaches. Our code is publicly available at <a href="https://github.com/MentaY/DGGN">https://github.com/MentaY/DGGN</a></p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">59. <a href="https://arxiv.org/abs/2508.18025" rel="nofollow">AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration</a> <a id="user-content-link59"></a>
</h2><a id="user-content-59-aq-pcdsys-an-adaptive-quantized-planetary-crater-detection-system-for-autonomous-space-exploration-" class="anchor" aria-label="Permalink: 59. AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration" href="#59-aq-pcdsys-an-adaptive-quantized-planetary-crater-detection-system-for-autonomous-space-exploration-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.18025
<strong>Authors:</strong> Aditri Paul, Archan Paul</p>
<p><strong>Abstract:</strong> arXiv:2508.18025v1 Announce Type: new  Abstract: Autonomous planetary exploration missions are critically dependent on real-time, accurate environmental perception for navigation and hazard avoidance. However, deploying deep learning models on the resource-constrained computational hardware of planetary exploration platforms remains a significant challenge. This paper introduces the Adaptive Quantized Planetary Crater Detection System (AQ-PCDSys), a novel framework specifically engineered for real-time, onboard deployment in the computationally constrained environments of space exploration missions. AQ-PCDSys synergistically integrates a Quantized Neural Network (QNN) architecture, trained using Quantization-Aware Training (QAT), with an Adaptive Multi-Sensor Fusion (AMF) module. The QNN architecture significantly optimizes model size and inference latency suitable for real-time onboard deployment in space exploration missions, while preserving high accuracy. The AMF module intelligently fuses data from Optical Imagery (OI) and Digital Elevation Models (DEMs) at the feature level, utilizing an Adaptive Weighting Mechanism (AWM) to dynamically prioritize the most relevant and reliable sensor modality based on planetary ambient conditions. This approach enhances detection robustness across diverse planetary landscapes. Paired with Multi-Scale Detection Heads specifically designed for robust and efficient detection of craters across a wide range of sizes, AQ-PCDSys provides a computationally efficient, reliable and accurate solution for planetary crater detection, a critical capability for enabling the next generation of autonomous planetary landing, navigation, and scientific exploration.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">60. <a href="https://arxiv.org/abs/2508.16734" rel="nofollow">Aligning Distributionally Robust Optimization with Practical Deep Learning Needs</a> <a id="user-content-link60"></a>
</h2><a id="user-content-60-aligning-distributionally-robust-optimization-with-practical-deep-learning-needs-" class="anchor" aria-label="Permalink: 60. Aligning Distributionally Robust Optimization with Practical Deep Learning Needs" href="#60-aligning-distributionally-robust-optimization-with-practical-deep-learning-needs-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.16734
<strong>Authors:</strong> Dmitrii Feoktistov, Igor Ignashin, Andrey Veprikov, Nikita Borovko, Alexander Bogdanov, Savelii Chezhegov, Aleksandr Beznosikov</p>
<p><strong>Abstract:</strong> arXiv:2508.16734v1 Announce Type: new  Abstract: While traditional Deep Learning (DL) optimization methods treat all training samples equally, Distributionally Robust Optimization (DRO) adaptively assigns importance weights to different samples. However, a significant gap exists between DRO and current DL practices. Modern DL optimizers require adaptivity and the ability to handle stochastic gradients, as these methods demonstrate superior performance. Additionally, for practical applications, a method should allow weight assignment not only to individual samples, but also to groups of objects (for example, all samples of the same class). This paper aims to bridge this gap by introducing ALSO $\unicode{x2013}$ Adaptive Loss Scaling Optimizer $\unicode{x2013}$ an adaptive algorithm for a modified DRO objective that can handle weight assignment to sample groups. We prove the convergence of our proposed algorithm for non-convex objectives, which is the typical case for DL models. Empirical evaluation across diverse Deep Learning tasks, from Tabular DL to Split Learning tasks, demonstrates that ALSO outperforms both traditional optimizers and existing DRO methods.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">61. <a href="https://arxiv.org/abs/2508.17445" rel="nofollow">TreePO: Bridging the Gap of Policy Optimization and Efficacy and Inference Efficiency with Heuristic Tree-based Modeling</a> <a id="user-content-link61"></a>
</h2><a id="user-content-61-treepo-bridging-the-gap-of-policy-optimization-and-efficacy-and-inference-efficiency-with-heuristic-tree-based-modeling-" class="anchor" aria-label="Permalink: 61. TreePO: Bridging the Gap of Policy Optimization and Efficacy and Inference Efficiency with Heuristic Tree-based Modeling" href="#61-treepo-bridging-the-gap-of-policy-optimization-and-efficacy-and-inference-efficiency-with-heuristic-tree-based-modeling-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.17445
<strong>Authors:</strong> Yizhi Li, Qingshui Gu, Zhoufutu Wen, Ziniu Li, Tianshun Xing, Shuyue Guo, Tianyu Zheng, Xin Zhou, Xingwei Qu, Wangchunshu Zhou, Zheng Zhang, Wei Shen, Qian Liu, Chenghua Lin, Jian Yang, Ge Zhang, Wenhao Huang</p>
<p><strong>Abstract:</strong> arXiv:2508.17445v1 Announce Type: new  Abstract: Recent advancements in aligning large language models via reinforcement learning have achieved remarkable gains in solving complex reasoning problems, but at the cost of expensive on-policy rollouts and limited exploration of diverse reasoning paths. In this work, we introduce TreePO, involving a self-guided rollout algorithm that views sequence generation as a tree-structured searching process. Composed of dynamic tree sampling policy and fixed-length segment decoding, TreePO leverages local uncertainty to warrant additional branches. By amortizing computation across common prefixes and pruning low-value paths early, TreePO essentially reduces the per-update compute burden while preserving or enhancing exploration diversity. Key contributions include: (1) a segment-wise sampling algorithm that alleviates the KV cache burden through contiguous segments and spawns new branches along with an early-stop mechanism; (2) a tree-based segment-level advantage estimation that considers both global and local proximal policy optimization. and (3) analysis on the effectiveness of probability and quality-driven dynamic divergence and fallback strategy. We empirically validate the performance gain of TreePO on a set reasoning benchmarks and the efficiency saving of GPU hours from 22% up to 43% of the sampling design for the trained models, meanwhile showing up to 40% reduction at trajectory-level and 35% at token-level sampling compute for the existing models. While offering a free lunch of inference efficiency, TreePO reveals a practical path toward scaling RL-based post-training with fewer samples and less compute. Home page locates at <a href="https://m-a-p.ai/TreePO" rel="nofollow">https://m-a-p.ai/TreePO</a>.</p>
<hr>
<div class="markdown-heading"><h2 class="heading-element">62. <a href="https://arxiv.org/abs/2508.16785" rel="nofollow">Interpreting the Effects of Quantization on LLMs</a> <a id="user-content-link62"></a>
</h2><a id="user-content-62-interpreting-the-effects-of-quantization-on-llms-" class="anchor" aria-label="Permalink: 62. Interpreting the Effects of Quantization on LLMs" href="#62-interpreting-the-effects-of-quantization-on-llms-"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<p><strong>ArXiv ID:</strong> 2508.16785
<strong>Authors:</strong> Manpreet Singh, Hassan Sajjad</p>
<p><strong>Abstract:</strong> arXiv:2508.16785v1 Announce Type: new  Abstract: Quantization offers a practical solution to deploy LLMs in resource-constraint environments. However, its impact on internal representations remains understudied, raising questions about the reliability of quantized models. In this study, we employ a range of interpretability techniques to investigate how quantization affects model and neuron behavior. We analyze multiple LLMs under 4-bit and 8-bit quantization. Our findings reveal that the impact of quantization on model calibration is generally minor. Analysis of neuron activations indicates that the number of dead neurons, i.e., those with activation values close to 0 across the dataset, remains consistent regardless of quantization. In terms of neuron contribution to predictions, we observe that smaller full precision models exhibit fewer salient neurons, whereas larger models tend to have more, with the exception of Llama-2-7B. The effect of quantization on neuron redundancy varies across models. Overall, our findings suggest that effect of quantization may vary by model and tasks, however, we did not observe any drastic change which may discourage the use of quantization as a reliable model compression technique.</p>
<hr>
<hr>
<div class="markdown-heading"><h2 class="heading-element">Paper selection prompt</h2><a id="user-content-paper-selection-prompt" class="anchor" aria-label="Permalink: Paper selection prompt" href="#paper-selection-prompt"><span aria-hidden="true" class="octicon octicon-link"></span></a></div>
<ol>
<li>Quantization, Pruning, and KVCache Compression for Efficient Large Language Models
<ul>
<li>Relevant: To optimize large language models (LLMs) for reduced memory and computational costs while maintaining performance, this research direction integrates quantization, pruning, and KVCache compression into a unified framework.
In suggesting papers to your friend, remember that he enjoys papers on large language model (llm) compression, inference acceleration techniques, and related algorithms such as quantization and pruning. He is particularly interested in research that explores new methods for reducing large language model size and improving inference speed, as well as innovative approaches to optimizing large language model. Furthermore, it incorporates Mixture-of-Experts (MoE) architectures to significantly decrease deployment overhead and accelerate inference speed, enabling more efficient and scalable model serving in resource-constrained environments.</li>
</ul>
</li>
</ol>
</div></div><div class="footer container-xl width-full p-responsive"><div class="position-relative flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between pt-4 pb-4 mt-6 f6 color-text-secondary border-top color-border-secondary text-center"><div class="footer-octicon d-lg-block mx-lg-4"><a title="LLIKKE/Arxiv_GPT_Assistant" href="https://github.com/LLIKKE/Arxiv_GPT_Assistant" target="_blank" rel="noreferrer noopener"><svg class="octicon octicon-mark-github gh-logo" width="36" height="36" viewBox="0 0 98 98" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"></path></svg></a></div><span class="mt-2 d-block footprint"><span>powered by </span><a href="https://github.com/wranders/markdown-to-pages-action" target="_blank" rel="noreferrer noopener">markdown-to-pages-action</a></span></div></div></body></html>